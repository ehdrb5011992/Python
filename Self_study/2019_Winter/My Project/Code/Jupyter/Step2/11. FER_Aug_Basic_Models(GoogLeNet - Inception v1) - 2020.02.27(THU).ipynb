{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwVmRuFcUBkT"
   },
   "source": [
    "# [GoogLeNet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0MMz6DhUBkW"
   },
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ywk25Fr79dWe"
   },
   "source": [
    "## Contents\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8ffQ4gg5ODH"
   },
   "source": [
    "1. Almost Original GoogLeNet & Data Import\n",
    "```\n",
    "1) Data Import\n",
    "2) Data Augmentation (Multiple Input & Output)\n",
    "3) Almost Original GoogLeNet\n",
    "```\n",
    "2. My GoogLeNet\n",
    "```\n",
    "1) Size = 64\n",
    "2) Size = 48.\n",
    "```\n",
    "3. For Size = 48, No Early Stopping\n",
    "```\n",
    "1) Epoch = 50\n",
    "2) Epoch = 100\n",
    "3) Epoch = 300 (Exception)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U01q4o40UBkY"
   },
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 95973,
     "status": "ok",
     "timestamp": 1583384668086,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "q6UFtp5VEZsr",
    "outputId": "ef5c5c6c-46cd-4654-c884-5d3ec1112371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 38kB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 29.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 50.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (45.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Found existing installation: tensorflow 1.15.0\n",
      "    Uninstalling tensorflow-1.15.0:\n",
      "      Successfully uninstalled tensorflow-1.15.0\n",
      "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjdygsS_UBke"
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114449,
     "status": "ok",
     "timestamp": 1583384686597,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "o1tpIlBhXG2i",
    "outputId": "aa8aead3-d4e0-46a4-bf92-4d0c860e672d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114439,
     "status": "ok",
     "timestamp": 1583384686599,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "IJdbC2nRXR6h",
    "outputId": "76692ba0-bcf6-426a-969d-213271d5a0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/project\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Colab Notebooks/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCx2JDrkW6sn"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114424,
     "status": "ok",
     "timestamp": 1583384686600,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "qQKQi4SjY3Ug",
    "outputId": "ce07eb51-6f54-44b4-ceaf-c4925421e919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/env/python',\n",
       " '/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/root/.ipython']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모듈로 받을 경로 확인\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9dGjq6aY3cN"
   },
   "outputs": [],
   "source": [
    "# 내 노트북이 아닌, 전산실 컴퓨터의 colab에서 돌렸으므로, 다시돌리려면 경로 수정할것!\n",
    "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HxNdfTtNwd9J"
   },
   "outputs": [],
   "source": [
    "from lrn import LRN # 만든 모듈, class\n",
    "from f1score import macro_f1score,weighted_f1score\n",
    "from pool_helper import PoolHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLMWqbuUBkf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential , Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D,GlobalMaxPooling2D,ZeroPadding2D\n",
    "from tensorflow.keras.layers import Concatenate, Reshape , AveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping , LearningRateScheduler\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_file, to_categorical\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120420,
     "status": "ok",
     "timestamp": 1583384692622,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "cbiFovMgXTax",
    "outputId": "1fc31a42-73f9-4eb6-c094-b4ddc7df0947"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/project'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEDKbmg5EYHq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120415,
     "status": "ok",
     "timestamp": 1583384692623,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "aeqQ6tagEcQi",
    "outputId": "add34cdc-12eb-46ab-89c6-7ab5bf9ef9c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120796,
     "status": "ok",
     "timestamp": 1583384693007,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "dskXxmkc_-fK",
    "outputId": "cfd686b3-609a-414c-d7eb-872200a413df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gpYuNpeSUBlY"
   },
   "source": [
    "## 1. Almost Original GoogLeNet (Inception v1) & Data Import\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEBqSUZYEPRq"
   },
   "source": [
    "### 1) Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FU8MecfwUBkt"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "x_train = pd.read_csv(\"mydata/X_train.csv\",header=0,index_col=0)\n",
    "x_valid = pd.read_csv(\"mydata/X_private_test.csv\",header=0,index_col=0)\n",
    "x_test = pd.read_csv(\"mydata/X_public_test.csv\",header=0,index_col=0)\n",
    "y_train = pd.read_csv(\"mydata/y_train.csv\",header=0,index_col=0)\n",
    "y_valid = pd.read_csv(\"mydata/y_private_test.csv\",header=0,index_col=0)\n",
    "y_test = pd.read_csv(\"mydata/y_public_test.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6WA42tMvBn7"
   },
   "outputs": [],
   "source": [
    "# data handling\n",
    "x_train = np.array(x_train).reshape([-1,48,48,3]) \n",
    "x_valid = np.array(x_valid).reshape([-1,48,48,3]) \n",
    "x_test = np.array(x_test).reshape([-1,48,48,3]) \n",
    "\n",
    "y_train=to_categorical(y_train) # one hot encoding\n",
    "y_valid=to_categorical(y_valid)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wuAEBQRtUBk3"
   },
   "outputs": [],
   "source": [
    "# data handling\n",
    "# uint는 부호없는 정수로, 타입을 바꿔줘야함!\n",
    "size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUh5IzGYUBk-"
   },
   "outputs": [],
   "source": [
    "x_train_zoom = np.zeros([x_train.shape[0],size,size,3],dtype=\"float32\")\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train_zoom[i,:] = cv2.resize(x_train[i,:].astype('uint8'), (size, size),\n",
    "                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPHUMDkCUBlB"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3qmmnzNUBlE"
   },
   "outputs": [],
   "source": [
    "x_valid = np.array(x_valid).reshape([-1,48,48,3])\n",
    "x_valid_zoom = np.zeros([x_valid.shape[0],size,size,3],dtype=\"float32\")\n",
    "for i in range(x_valid.shape[0]):\n",
    "    x_valid_zoom[i,:] = cv2.resize(x_valid[i,:].astype('uint8'), (size, size),\n",
    "                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3V15xJuUBlH"
   },
   "outputs": [],
   "source": [
    " x_valid = x_valid / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFInNp5RUBlK"
   },
   "outputs": [],
   "source": [
    "x_test = np.array(x_test).reshape([-1,48,48,3])\n",
    "x_test_zoom = np.zeros([x_test.shape[0],size,size,3],dtype=\"float32\")\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_test_zoom[i,:] = cv2.resize(x_test[i,:].astype('uint8'), (size, size),\n",
    "                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZHAXg5nUBlV"
   },
   "outputs": [],
   "source": [
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "De4AjiHJEPSH"
   },
   "source": [
    "### 2) Data Augmentation (Multiple Input & Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RldjwO4M8_o"
   },
   "outputs": [],
   "source": [
    "# GoogLeNet은 input이 3개, output이 3개이므로 imagedatagenerator 사용방법이 다소 다르다.\n",
    "# model.fit에 다중 input으로 들어갈 함수를 개인이 만들어서 사용해야 하며, 그 함수는 아래와 같다. \n",
    "# 매우 간단하다.\n",
    "\n",
    "#1. train data\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                              featurewise_std_normalization=False,\n",
    "                              rotation_range=10,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              horizontal_flip=True,\n",
    "                              zoom_range=[0.9,1.0])\n",
    "\n",
    "\n",
    "def generate_train_for_three(X , Y):\n",
    "\n",
    "      batches_xy = datagen.flow(X , Y, batch_size=128)\n",
    "\n",
    "      while True:\n",
    "\n",
    "            batch_xy = batches_xy.next()\n",
    "            yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOMw3HckS2s7"
   },
   "outputs": [],
   "source": [
    "# 2. valid data\n",
    "\n",
    "datagen_val = ImageDataGenerator()\n",
    "\n",
    "def generate_valid_for_three(X , Y):\n",
    "\n",
    "      batches_xy = datagen_val.flow(X , Y, batch_size=128)\n",
    "\n",
    "      while True:\n",
    "\n",
    "            batch_xy = batches_xy.next()\n",
    "            yield  batch_xy[0], [ batch_xy[1],batch_xy[1],batch_xy[1] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JcsJNpFIEPSR"
   },
   "source": [
    "### 3) Almost Original GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQQSvuzfUBlZ"
   },
   "outputs": [],
   "source": [
    "# GoogLeNet를 최대한 논문에 가깝게 맞춰 모형작성.\n",
    "# 또한, Data Augmentation은 컴퓨터 성능의 한계로 하지 않음.\n",
    "\n",
    "def googlenet(input_shape=(224,224,3), classes=7 , weights_path = None):\n",
    "    # shape, classes 수정\n",
    "\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    input_pad = ZeroPadding2D(padding=(3, 3))(input)\n",
    "    conv1_7x7_s2 = Conv2D(64, (7,7), strides=(2,2), padding='valid', activation='relu', name='conv1/7x7_s2', kernel_regularizer=l2(0.0002))(input_pad)\n",
    "    conv1_zero_pad = ZeroPadding2D(padding=(1, 1))(conv1_7x7_s2)\n",
    "    pool1_helper = PoolHelper()(conv1_zero_pad) # 짝수를 하나씩 지움으로써 홀수차원으로 만든다. 직접 만든함수.\n",
    "    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool1/3x3_s2')(pool1_helper)\n",
    "    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n",
    "\n",
    "    conv2_3x3_reduce = Conv2D(64, (1,1), padding='same', activation='relu', name='conv2/3x3_reduce', kernel_regularizer=l2(0.0002))(pool1_norm1)\n",
    "    conv2_3x3 = Conv2D(192, (3,3), padding='same', activation='relu', name='conv2/3x3', kernel_regularizer=l2(0.0002))(conv2_3x3_reduce)\n",
    "    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n",
    "    conv2_zero_pad = ZeroPadding2D(padding=(1, 1))(conv2_norm2)\n",
    "    pool2_helper = PoolHelper()(conv2_zero_pad)\n",
    "    pool2_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool2/3x3_s2')(pool2_helper)\n",
    "\n",
    "    inception_3a_1x1 = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_3a/1x1', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_3a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3_reduce)\n",
    "    inception_3a_3x3 = Conv2D(128, (3,3), padding='valid', activation='relu', name='inception_3a/3x3', kernel_regularizer=l2(0.0002))(inception_3a_3x3_pad)\n",
    "    inception_3a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5_reduce)\n",
    "    inception_3a_5x5 = Conv2D(32, (5,5), padding='valid', activation='relu', name='inception_3a/5x5', kernel_regularizer=l2(0.0002))(inception_3a_5x5_pad)\n",
    "    inception_3a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3a/pool')(pool2_3x3_s2)\n",
    "    inception_3a_pool_proj = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_3a/pool_proj', kernel_regularizer=l2(0.0002))(inception_3a_pool)\n",
    "    inception_3a_output = Concatenate(axis=-1, name='inception_3a/output')([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj])\n",
    "    # Concatenate axis 수정.\n",
    "\n",
    "    inception_3b_1x1 = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_3b/1x1', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_reduce = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_3b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3_reduce)\n",
    "    inception_3b_3x3 = Conv2D(192, (3,3), padding='valid', activation='relu', name='inception_3b/3x3', kernel_regularizer=l2(0.0002))(inception_3b_3x3_pad)\n",
    "    inception_3b_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_3b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5_reduce)\n",
    "    inception_3b_5x5 = Conv2D(96, (5,5), padding='valid', activation='relu', name='inception_3b/5x5', kernel_regularizer=l2(0.0002))(inception_3b_5x5_pad)\n",
    "    inception_3b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3b/pool')(inception_3a_output)\n",
    "    inception_3b_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_3b/pool_proj', kernel_regularizer=l2(0.0002))(inception_3b_pool)\n",
    "    inception_3b_output = Concatenate(axis=-1, name='inception_3b/output')([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj])\n",
    "\n",
    "    inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_output)\n",
    "    pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n",
    "    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool3/3x3_s2')(pool3_helper)\n",
    "\n",
    "    inception_4a_1x1 = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_4a/1x1', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_4a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3_reduce)\n",
    "    inception_4a_3x3 = Conv2D(208, (3,3), padding='valid', activation='relu', name='inception_4a/3x3' ,kernel_regularizer=l2(0.0002))(inception_4a_3x3_pad)\n",
    "    inception_4a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4a_5x5_reduce)\n",
    "    inception_4a_5x5 = Conv2D(48, (5,5), padding='valid', activation='relu', name='inception_4a/5x5', kernel_regularizer=l2(0.0002))(inception_4a_5x5_pad)\n",
    "    inception_4a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4a/pool')(pool3_3x3_s2)\n",
    "    inception_4a_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4a/pool_proj', kernel_regularizer=l2(0.0002))(inception_4a_pool)\n",
    "    inception_4a_output = Concatenate(axis=-1, name='inception_4a/output')([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj])\n",
    "\n",
    "    loss1_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss1/ave_pool')(inception_4a_output)\n",
    "    loss1_conv = Conv2D(128, (1,1), padding='same', activation='relu', name='loss1/conv', kernel_regularizer=l2(0.0002))(loss1_ave_pool)\n",
    "    loss1_flat = Flatten()(loss1_conv)\n",
    "    loss1_fc = Dense(1024, activation='relu', name='loss1/fc', kernel_regularizer=l2(0.0002))(loss1_flat)\n",
    "    loss1_drop_fc = Dropout(rate=0.7)(loss1_fc)\n",
    "    loss1_classifier = Dense(classes, name='loss1/classifier', kernel_regularizer=l2(0.0002))(loss1_drop_fc)\n",
    "    loss1_classifier_act = Activation('softmax')(loss1_classifier)\n",
    "\n",
    "    inception_4b_1x1 = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_4b/1x1', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_reduce = Conv2D(112, (1,1), padding='same', activation='relu', name='inception_4b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4b_3x3_reduce)\n",
    "    inception_4b_3x3 = Conv2D(224, (3,3), padding='valid', activation='relu', name='inception_4b/3x3', kernel_regularizer=l2(0.0002))(inception_4b_3x3_pad)\n",
    "    inception_4b_5x5_reduce = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4b_5x5_reduce)\n",
    "    inception_4b_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4b/5x5', kernel_regularizer=l2(0.0002))(inception_4b_5x5_pad)\n",
    "    inception_4b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4b/pool')(inception_4a_output)\n",
    "    inception_4b_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4b/pool_proj', kernel_regularizer=l2(0.0002))(inception_4b_pool)\n",
    "    inception_4b_output = Concatenate(axis=-1, name='inception_4b/output')([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj])\n",
    "\n",
    "    inception_4c_1x1 = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4c/1x1', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_reduce = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4c/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4c_3x3_reduce)\n",
    "    inception_4c_3x3 = Conv2D(256, (3,3), padding='valid', activation='relu', name='inception_4c/3x3', kernel_regularizer=l2(0.0002))(inception_4c_3x3_pad)\n",
    "    inception_4c_5x5_reduce = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4c/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4c_5x5_reduce)\n",
    "    inception_4c_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4c/5x5', kernel_regularizer=l2(0.0002))(inception_4c_5x5_pad)\n",
    "    inception_4c_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4c/pool')(inception_4b_output)\n",
    "    inception_4c_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4c/pool_proj', kernel_regularizer=l2(0.0002))(inception_4c_pool)\n",
    "    inception_4c_output = Concatenate(axis=-1, name='inception_4c/output')([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj])\n",
    "\n",
    "    inception_4d_1x1 = Conv2D(112, (1,1), padding='same', activation='relu', name='inception_4d/1x1', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_reduce = Conv2D(144, (1,1), padding='same', activation='relu', name='inception_4d/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4d_3x3_reduce)\n",
    "    inception_4d_3x3 = Conv2D(288, (3,3), padding='valid', activation='relu', name='inception_4d/3x3', kernel_regularizer=l2(0.0002))(inception_4d_3x3_pad)\n",
    "    inception_4d_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4d/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4d_5x5_reduce)\n",
    "    inception_4d_5x5 = Conv2D(64, (5,5), padding='valid', activation='relu', name='inception_4d/5x5', kernel_regularizer=l2(0.0002))(inception_4d_5x5_pad)\n",
    "    inception_4d_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4d/pool')(inception_4c_output)\n",
    "    inception_4d_pool_proj = Conv2D(64, (1,1), padding='same', activation='relu', name='inception_4d/pool_proj', kernel_regularizer=l2(0.0002))(inception_4d_pool)\n",
    "    inception_4d_output = Concatenate(axis=-1, name='inception_4d/output')([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj])\n",
    "\n",
    "    loss2_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss2/ave_pool')(inception_4d_output)\n",
    "    loss2_conv = Conv2D(128, (1,1), padding='same', activation='relu', name='loss2/conv', kernel_regularizer=l2(0.0002))(loss2_ave_pool)\n",
    "    loss2_flat = Flatten()(loss2_conv)\n",
    "    loss2_fc = Dense(1024, activation='relu', name='loss2/fc', kernel_regularizer=l2(0.0002))(loss2_flat)\n",
    "    loss2_drop_fc = Dropout(rate=0.7)(loss2_fc)\n",
    "    loss2_classifier = Dense(classes, name='loss2/classifier', kernel_regularizer=l2(0.0002))(loss2_drop_fc)\n",
    "    loss2_classifier_act = Activation('softmax')(loss2_classifier)\n",
    "\n",
    "    inception_4e_1x1 = Conv2D(256, (1,1), padding='same', activation='relu', name='inception_4e/1x1', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_reduce = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_4e/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3_reduce)\n",
    "    inception_4e_3x3 = Conv2D(320, (3,3), padding='valid', activation='relu', name='inception_4e/3x3', kernel_regularizer=l2(0.0002))(inception_4e_3x3_pad)\n",
    "    inception_4e_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4e/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5_reduce)\n",
    "    inception_4e_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_4e/5x5', kernel_regularizer=l2(0.0002))(inception_4e_5x5_pad)\n",
    "    inception_4e_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4e/pool')(inception_4d_output)\n",
    "    inception_4e_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_4e/pool_proj', kernel_regularizer=l2(0.0002))(inception_4e_pool)\n",
    "    inception_4e_output = Concatenate(axis=-1, name='inception_4e/output')([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj])\n",
    "\n",
    "    inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_output)\n",
    "    pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n",
    "    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool4/3x3_s2')(pool4_helper)\n",
    "\n",
    "    inception_5a_1x1 = Conv2D(256, (1,1), padding='same', activation='relu', name='inception_5a/1x1', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_reduce = Conv2D(160, (1,1), padding='same', activation='relu', name='inception_5a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3_reduce)\n",
    "    inception_5a_3x3 = Conv2D(320, (3,3), padding='valid', activation='relu', name='inception_5a/3x3', kernel_regularizer=l2(0.0002))(inception_5a_3x3_pad)\n",
    "    inception_5a_5x5_reduce = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_5a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5a_5x5_reduce)\n",
    "    inception_5a_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_5a/5x5', kernel_regularizer=l2(0.0002))(inception_5a_5x5_pad)\n",
    "    inception_5a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5a/pool')(pool4_3x3_s2)\n",
    "    inception_5a_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_5a/pool_proj', kernel_regularizer=l2(0.0002))(inception_5a_pool)\n",
    "    inception_5a_output = Concatenate(axis=-1, name='inception_5a/output')([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj])\n",
    "\n",
    "    inception_5b_1x1 = Conv2D(384, (1,1), padding='same', activation='relu', name='inception_5b/1x1', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_reduce = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_5b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5b_3x3_reduce)\n",
    "    inception_5b_3x3 = Conv2D(384, (3,3), padding='valid', activation='relu', name='inception_5b/3x3', kernel_regularizer=l2(0.0002))(inception_5b_3x3_pad)\n",
    "    inception_5b_5x5_reduce = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5b_5x5_reduce)\n",
    "    inception_5b_5x5 = Conv2D(128, (5,5), padding='valid', activation='relu', name='inception_5b/5x5', kernel_regularizer=l2(0.0002))(inception_5b_5x5_pad)\n",
    "    inception_5b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5b/pool')(inception_5a_output)\n",
    "    inception_5b_pool_proj = Conv2D(128, (1,1), padding='same', activation='relu', name='inception_5b/pool_proj', kernel_regularizer=l2(0.0002))(inception_5b_pool)\n",
    "    inception_5b_output = Concatenate(axis=-1, name='inception_5b/output')([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj])\n",
    "\n",
    "    pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7), strides=(1,1), name='pool5/7x7_s2')(inception_5b_output)\n",
    "    loss3_flat = Flatten()(pool5_7x7_s1)\n",
    "    pool5_drop_7x7_s1 = Dropout(rate=0.4)(loss3_flat)\n",
    "    loss3_classifier = Dense(classes, name='loss3/classifier', kernel_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n",
    "    loss3_classifier_act = Activation('softmax', name='prob')(loss3_classifier)\n",
    "\n",
    "    googlenet = Model(inputs=input, outputs=[loss1_classifier_act,loss2_classifier_act,loss3_classifier_act])\n",
    "\n",
    "    if weights_path:\n",
    "        googlenet.load_weights(weights_path)\n",
    "\n",
    "    # if tf.keras.backend.backend() == 'tensorflow':\n",
    "    #     # 우리는 tf.keras를 쓰므로, 이상황은 늘 True.\n",
    "    #     # 또한, 아래의 코드도 시행할 필요가 없다.\n",
    "    #     # 혹시모를 , 나중의 상황에 대비해 코드만 남겨놓는다.\n",
    "    #\n",
    "    #     ops = []\n",
    "    #     for layer in googlenet.layers:\n",
    "    #         if layer.__class__.__name__ == 'Conv2D': # layer의 class의 이름이 'conv2d'이면 ~\n",
    "    #             original_w = K.get_value(layer.kernel)\n",
    "    #             converted_w = convert_kernel(original_w)\n",
    "    #             ops.append(tf.assign(layer.kernel, converted_w).op)\n",
    "    #     K.get_session().run(ops)\n",
    "\n",
    "    return googlenet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185253,
     "status": "ok",
     "timestamp": 1583384757507,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "te4pinumUBle",
    "outputId": "98d47c51-30a5-4f18-a8ba-47ecb40e8218",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "model = googlenet(input_shape=(224, 224, 3), classes=1000, weights_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 185597,
     "status": "ok",
     "timestamp": 1583384757860,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "vmeG8i1uwd-I",
    "outputId": "89100b26-d634-49e7-c97c-d840f401d056"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper (PoolHelper)        (None, 113, 113, 64) 0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool1/3x3_s2 (MaxPooling2D)     (None, 56, 56, 64)   0           pool_helper[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool1/norm1 (LRN)               (None, 56, 56, 64)   0           pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3_reduce (Conv2D)       (None, 56, 56, 64)   4160        pool1/norm1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3 (Conv2D)              (None, 56, 56, 192)  110784      conv2/3x3_reduce[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2/norm2 (LRN)               (None, 56, 56, 192)  0           conv2/3x3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 58, 58, 192)  0           conv2/norm2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_1 (PoolHelper)      (None, 57, 57, 192)  0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool2/3x3_s2 (MaxPooling2D)     (None, 28, 28, 192)  0           pool_helper_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3_reduce (Conv2D (None, 28, 28, 96)   18528       pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5_reduce (Conv2D (None, 28, 28, 16)   3088        pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 30, 30, 96)   0           inception_3a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 32, 32, 16)   0           inception_3a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool (MaxPooling2D (None, 28, 28, 192)  0           pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/1x1 (Conv2D)       (None, 28, 28, 64)   12352       pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3 (Conv2D)       (None, 28, 28, 128)  110720      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5 (Conv2D)       (None, 28, 28, 32)   12832       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool_proj (Conv2D) (None, 28, 28, 32)   6176        inception_3a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/output (Concatenat (None, 28, 28, 256)  0           inception_3a/1x1[0][0]           \n",
      "                                                                 inception_3a/3x3[0][0]           \n",
      "                                                                 inception_3a/5x5[0][0]           \n",
      "                                                                 inception_3a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3_reduce (Conv2D (None, 28, 28, 128)  32896       inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5_reduce (Conv2D (None, 28, 28, 32)   8224        inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 30, 30, 128)  0           inception_3b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 32, 32, 32)   0           inception_3b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool (MaxPooling2D (None, 28, 28, 256)  0           inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/1x1 (Conv2D)       (None, 28, 28, 128)  32896       inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3 (Conv2D)       (None, 28, 28, 192)  221376      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5 (Conv2D)       (None, 28, 28, 96)   76896       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool_proj (Conv2D) (None, 28, 28, 64)   16448       inception_3b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/output (Concatenat (None, 28, 28, 480)  0           inception_3b/1x1[0][0]           \n",
      "                                                                 inception_3b/3x3[0][0]           \n",
      "                                                                 inception_3b/5x5[0][0]           \n",
      "                                                                 inception_3b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 30, 30, 480)  0           inception_3b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_2 (PoolHelper)      (None, 29, 29, 480)  0           zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "pool3/3x3_s2 (MaxPooling2D)     (None, 14, 14, 480)  0           pool_helper_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3_reduce (Conv2D (None, 14, 14, 96)   46176       pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5_reduce (Conv2D (None, 14, 14, 16)   7696        pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 16, 16, 96)   0           inception_4a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 18, 18, 16)   0           inception_4a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool (MaxPooling2D (None, 14, 14, 480)  0           pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/1x1 (Conv2D)       (None, 14, 14, 192)  92352       pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3 (Conv2D)       (None, 14, 14, 208)  179920      zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5 (Conv2D)       (None, 14, 14, 48)   19248       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool_proj (Conv2D) (None, 14, 14, 64)   30784       inception_4a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/output (Concatenat (None, 14, 14, 512)  0           inception_4a/1x1[0][0]           \n",
      "                                                                 inception_4a/3x3[0][0]           \n",
      "                                                                 inception_4a/5x5[0][0]           \n",
      "                                                                 inception_4a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3_reduce (Conv2D (None, 14, 14, 112)  57456       inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5_reduce (Conv2D (None, 14, 14, 24)   12312       inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 16, 16, 112)  0           inception_4b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 18, 18, 24)   0           inception_4b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/1x1 (Conv2D)       (None, 14, 14, 160)  82080       inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3 (Conv2D)       (None, 14, 14, 224)  226016      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5 (Conv2D)       (None, 14, 14, 64)   38464       zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/output (Concatenat (None, 14, 14, 512)  0           inception_4b/1x1[0][0]           \n",
      "                                                                 inception_4b/3x3[0][0]           \n",
      "                                                                 inception_4b/5x5[0][0]           \n",
      "                                                                 inception_4b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3_reduce (Conv2D (None, 14, 14, 128)  65664       inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5_reduce (Conv2D (None, 14, 14, 24)   12312       inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 16, 16, 128)  0           inception_4c/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 18, 18, 24)   0           inception_4c/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/1x1 (Conv2D)       (None, 14, 14, 128)  65664       inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3 (Conv2D)       (None, 14, 14, 256)  295168      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5 (Conv2D)       (None, 14, 14, 64)   38464       zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4c/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/output (Concatenat (None, 14, 14, 512)  0           inception_4c/1x1[0][0]           \n",
      "                                                                 inception_4c/3x3[0][0]           \n",
      "                                                                 inception_4c/5x5[0][0]           \n",
      "                                                                 inception_4c/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3_reduce (Conv2D (None, 14, 14, 144)  73872       inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5_reduce (Conv2D (None, 14, 14, 32)   16416       inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 16, 16, 144)  0           inception_4d/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 18, 18, 32)   0           inception_4d/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool (MaxPooling2D (None, 14, 14, 512)  0           inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/1x1 (Conv2D)       (None, 14, 14, 112)  57456       inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3 (Conv2D)       (None, 14, 14, 288)  373536      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5 (Conv2D)       (None, 14, 14, 64)   51264       zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool_proj (Conv2D) (None, 14, 14, 64)   32832       inception_4d/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/output (Concatenat (None, 14, 14, 528)  0           inception_4d/1x1[0][0]           \n",
      "                                                                 inception_4d/3x3[0][0]           \n",
      "                                                                 inception_4d/5x5[0][0]           \n",
      "                                                                 inception_4d/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3_reduce (Conv2D (None, 14, 14, 160)  84640       inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5_reduce (Conv2D (None, 14, 14, 32)   16928       inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 16, 16, 160)  0           inception_4e/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 18, 18, 32)   0           inception_4e/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool (MaxPooling2D (None, 14, 14, 528)  0           inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/1x1 (Conv2D)       (None, 14, 14, 256)  135424      inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3 (Conv2D)       (None, 14, 14, 320)  461120      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5 (Conv2D)       (None, 14, 14, 128)  102528      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool_proj (Conv2D) (None, 14, 14, 128)  67712       inception_4e/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/output (Concatenat (None, 14, 14, 832)  0           inception_4e/1x1[0][0]           \n",
      "                                                                 inception_4e/3x3[0][0]           \n",
      "                                                                 inception_4e/5x5[0][0]           \n",
      "                                                                 inception_4e/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 16, 16, 832)  0           inception_4e/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_3 (PoolHelper)      (None, 15, 15, 832)  0           zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool4/3x3_s2 (MaxPooling2D)     (None, 7, 7, 832)    0           pool_helper_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3_reduce (Conv2D (None, 7, 7, 160)    133280      pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5_reduce (Conv2D (None, 7, 7, 32)     26656       pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 9, 9, 160)    0           inception_5a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 11, 11, 32)   0           inception_5a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool (MaxPooling2D (None, 7, 7, 832)    0           pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/1x1 (Conv2D)       (None, 7, 7, 256)    213248      pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3 (Conv2D)       (None, 7, 7, 320)    461120      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5 (Conv2D)       (None, 7, 7, 128)    102528      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool_proj (Conv2D) (None, 7, 7, 128)    106624      inception_5a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/output (Concatenat (None, 7, 7, 832)    0           inception_5a/1x1[0][0]           \n",
      "                                                                 inception_5a/3x3[0][0]           \n",
      "                                                                 inception_5a/5x5[0][0]           \n",
      "                                                                 inception_5a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3_reduce (Conv2D (None, 7, 7, 192)    159936      inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5_reduce (Conv2D (None, 7, 7, 48)     39984       inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 9, 9, 192)    0           inception_5b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 11, 11, 48)   0           inception_5b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool (MaxPooling2D (None, 7, 7, 832)    0           inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss1/ave_pool (AveragePooling2 (None, 4, 4, 512)    0           inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss2/ave_pool (AveragePooling2 (None, 4, 4, 528)    0           inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/1x1 (Conv2D)       (None, 7, 7, 384)    319872      inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3 (Conv2D)       (None, 7, 7, 384)    663936      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5 (Conv2D)       (None, 7, 7, 128)    153728      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool_proj (Conv2D) (None, 7, 7, 128)    106624      inception_5b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "loss1/conv (Conv2D)             (None, 4, 4, 128)    65664       loss1/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "loss2/conv (Conv2D)             (None, 4, 4, 128)    67712       loss2/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/output (Concatenat (None, 7, 7, 1024)   0           inception_5b/1x1[0][0]           \n",
      "                                                                 inception_5b/3x3[0][0]           \n",
      "                                                                 inception_5b/5x5[0][0]           \n",
      "                                                                 inception_5b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           loss1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           loss2/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool5/7x7_s2 (AveragePooling2D) (None, 1, 1, 1024)   0           inception_5b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss1/fc (Dense)                (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "loss2/fc (Dense)                (None, 1024)         2098176     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 1024)         0           pool5/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           loss1/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           loss2/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss1/classifier (Dense)        (None, 1000)         1025000     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "loss2/classifier (Dense)        (None, 1000)         1025000     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss3/classifier (Dense)        (None, 1000)         1025000     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1000)         0           loss1/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1000)         0           loss2/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prob (Activation)               (None, 1000)         0           loss3/classifier[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 13,378,280\n",
      "Trainable params: 13,378,280\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# auxiliary classifier 2개를 포함하기 때문에, 모수의 개수는 1300만개쯤 된다.\n",
    "# 메인은 670만개 가량의 모수.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kiu3oJRIagkw"
   },
   "source": [
    "## 2. My GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJwwvvImGO2X"
   },
   "source": [
    "### 1) Size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSApK_jeb_Lo"
   },
   "outputs": [],
   "source": [
    "# 기존의 GoogLeNet 개조\n",
    "\n",
    "# Data Augmentation은 컴퓨터 성능의 한계로 못하기 때문에 변형함.\n",
    "\n",
    "# 주의 !!!!기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!!!\n",
    "\n",
    "# 다음의 절차로 모형을 개조한다.\n",
    "\n",
    "# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n",
    "# 2. stride 2개, pool_size 1개를 변형해서, 최대한 전체적인 모형의 변화를 줄였다.\n",
    "# 3. 다음과 같이 모형을 재구성한다.\n",
    "\n",
    "\n",
    "def my_googlenet(input_shape=(64,64,3), classes=7 , weights_path = None ):\n",
    "\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    input_pad = ZeroPadding2D(padding=(3, 3))(input)\n",
    "    conv1_7x7_s2 = Conv2D(8, (7,7), strides=(1,1), padding='valid', activation='relu', name='conv1/7x7_s2', kernel_regularizer=l2(0.0002))(input_pad)\n",
    "    # 위에서 stride 2 -> 1로 바꿈.\n",
    "    conv1_zero_pad = ZeroPadding2D(padding=(1, 1))(conv1_7x7_s2)\n",
    "    pool1_helper = PoolHelper()(conv1_zero_pad)\n",
    "    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool1/3x3_s2')(pool1_helper)\n",
    "    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n",
    "\n",
    "    conv2_3x3_reduce = Conv2D(8, (1,1), padding='same', activation='relu', name='conv2/3x3_reduce', kernel_regularizer=l2(0.0002))(pool1_norm1)\n",
    "    conv2_3x3 = Conv2D(24, (3,3), padding='same', activation='relu', name='conv2/3x3', kernel_regularizer=l2(0.0002))(conv2_3x3_reduce)\n",
    "    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n",
    "    conv2_zero_pad = ZeroPadding2D(padding=(1, 1))(conv2_norm2)\n",
    "    pool2_helper = PoolHelper()(conv2_zero_pad)\n",
    "    pool2_3x3_s2 = MaxPooling2D(pool_size=(6,6), strides=(1,1), padding='valid', name='pool2/3x3_s2')(pool2_helper)\n",
    "    # 위에서 strdie 2 -> 1로 바꿈. , pool_size 3 -> 6 으로 바꿈.  /// 여기까지 완료하면 r x c = 28 x 28 이 됨.\n",
    "\n",
    "    inception_3a_1x1 = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3a/1x1', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_reduce = Conv2D(12, (1,1), padding='same', activation='relu', name='inception_3a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3_reduce)\n",
    "    inception_3a_3x3 = Conv2D(16, (3,3), padding='valid', activation='relu', name='inception_3a/3x3', kernel_regularizer=l2(0.0002))(inception_3a_3x3_pad)\n",
    "    inception_3a_5x5_reduce = Conv2D(2, (1,1), padding='same', activation='relu', name='inception_3a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5_reduce)\n",
    "    inception_3a_5x5 = Conv2D(4, (5,5), padding='valid', activation='relu', name='inception_3a/5x5', kernel_regularizer=l2(0.0002))(inception_3a_5x5_pad)\n",
    "    inception_3a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3a/pool')(pool2_3x3_s2)\n",
    "    inception_3a_pool_proj = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3a/pool_proj', kernel_regularizer=l2(0.0002))(inception_3a_pool)\n",
    "    inception_3a_output = Concatenate(axis=-1, name='inception_3a/output')([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj])\n",
    "\n",
    "    inception_3b_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/1x1', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3_reduce)\n",
    "    inception_3b_3x3 = Conv2D(24, (3,3), padding='valid', activation='relu', name='inception_3b/3x3', kernel_regularizer=l2(0.0002))(inception_3b_3x3_pad)\n",
    "    inception_3b_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5_reduce)\n",
    "    inception_3b_5x5 = Conv2D(12, (5,5), padding='valid', activation='relu', name='inception_3b/5x5', kernel_regularizer=l2(0.0002))(inception_3b_5x5_pad)\n",
    "    inception_3b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3b/pool')(inception_3a_output)\n",
    "    inception_3b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3b/pool_proj', kernel_regularizer=l2(0.0002))(inception_3b_pool)\n",
    "    inception_3b_output = Concatenate(axis=-1, name='inception_3b/output')([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj])\n",
    "\n",
    "    inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_output)\n",
    "    pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n",
    "    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool3/3x3_s2')(pool3_helper)\n",
    "\n",
    "    inception_4a_1x1 = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4a/1x1', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_4a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3_reduce)\n",
    "    inception_4a_3x3 = Conv2D(26, (3,3), padding='valid', activation='relu', name='inception_4a/3x3' ,kernel_regularizer=l2(0.0002))(inception_4a_3x3_pad)\n",
    "    inception_4a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4a_5x5_reduce)\n",
    "    inception_4a_5x5 = Conv2D(6, (5,5), padding='valid', activation='relu', name='inception_4a/5x5', kernel_regularizer=l2(0.0002))(inception_4a_5x5_pad)\n",
    "    inception_4a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4a/pool')(pool3_3x3_s2)\n",
    "    inception_4a_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4a/pool_proj', kernel_regularizer=l2(0.0002))(inception_4a_pool)\n",
    "    inception_4a_output = Concatenate(axis=-1, name='inception_4a/output')([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj])\n",
    "\n",
    "    loss1_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss1/ave_pool')(inception_4a_output)\n",
    "    loss1_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss1/conv', kernel_regularizer=l2(0.0002))(loss1_ave_pool)\n",
    "    loss1_flat = Flatten()(loss1_conv)\n",
    "    loss1_fc = Dense(64, activation='relu', name='loss1/fc', kernel_regularizer=l2(0.0002))(loss1_flat)\n",
    "    loss1_drop_fc = Dropout(rate=0.7)(loss1_fc)\n",
    "    loss1_classifier = Dense(classes, name='loss1/classifier', kernel_regularizer=l2(0.0002))(loss1_drop_fc)\n",
    "    loss1_classifier_act = Activation('softmax')(loss1_classifier)\n",
    "\n",
    "    inception_4b_1x1 = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4b/1x1', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_reduce = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4b_3x3_reduce)\n",
    "    inception_4b_3x3 = Conv2D(28, (3,3), padding='valid', activation='relu', name='inception_4b/3x3', kernel_regularizer=l2(0.0002))(inception_4b_3x3_pad)\n",
    "    inception_4b_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4b_5x5_reduce)\n",
    "    inception_4b_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4b/5x5', kernel_regularizer=l2(0.0002))(inception_4b_5x5_pad)\n",
    "    inception_4b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4b/pool')(inception_4a_output)\n",
    "    inception_4b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4b/pool_proj', kernel_regularizer=l2(0.0002))(inception_4b_pool)\n",
    "    inception_4b_output = Concatenate(axis=-1, name='inception_4b/output')([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj])\n",
    "\n",
    "    inception_4c_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/1x1', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4c_3x3_reduce)\n",
    "    inception_4c_3x3 = Conv2D(32, (3,3), padding='valid', activation='relu', name='inception_4c/3x3', kernel_regularizer=l2(0.0002))(inception_4c_3x3_pad)\n",
    "    inception_4c_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4c/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4c_5x5_reduce)\n",
    "    inception_4c_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4c/5x5', kernel_regularizer=l2(0.0002))(inception_4c_5x5_pad)\n",
    "    inception_4c_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4c/pool')(inception_4b_output)\n",
    "    inception_4c_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4c/pool_proj', kernel_regularizer=l2(0.0002))(inception_4c_pool)\n",
    "    inception_4c_output = Concatenate(axis=-1, name='inception_4c/output')([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj])\n",
    "\n",
    "    inception_4d_1x1 = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4d/1x1', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_reduce = Conv2D(18, (1,1), padding='same', activation='relu', name='inception_4d/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4d_3x3_reduce)\n",
    "    inception_4d_3x3 = Conv2D(36, (3,3), padding='valid', activation='relu', name='inception_4d/3x3', kernel_regularizer=l2(0.0002))(inception_4d_3x3_pad)\n",
    "    inception_4d_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4d/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4d_5x5_reduce)\n",
    "    inception_4d_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4d/5x5', kernel_regularizer=l2(0.0002))(inception_4d_5x5_pad)\n",
    "    inception_4d_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4d/pool')(inception_4c_output)\n",
    "    inception_4d_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4d/pool_proj', kernel_regularizer=l2(0.0002))(inception_4d_pool)\n",
    "    inception_4d_output = Concatenate(axis=-1, name='inception_4d/output')([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj])\n",
    "\n",
    "    loss2_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss2/ave_pool')(inception_4d_output)\n",
    "    loss2_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss2/conv', kernel_regularizer=l2(0.0002))(loss2_ave_pool)\n",
    "    loss2_flat = Flatten()(loss2_conv)\n",
    "    loss2_fc = Dense(8, activation='relu', name='loss2/fc', kernel_regularizer=l2(0.0002))(loss2_flat)\n",
    "    loss2_drop_fc = Dropout(rate=0.7)(loss2_fc)\n",
    "    loss2_classifier = Dense(classes, name='loss2/classifier', kernel_regularizer=l2(0.0002))(loss2_drop_fc)\n",
    "    loss2_classifier_act = Activation('softmax')(loss2_classifier)\n",
    "\n",
    "    inception_4e_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4e/1x1', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4e/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3_reduce)\n",
    "    inception_4e_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_4e/3x3', kernel_regularizer=l2(0.0002))(inception_4e_3x3_pad)\n",
    "    inception_4e_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4e/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5_reduce)\n",
    "    inception_4e_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_4e/5x5', kernel_regularizer=l2(0.0002))(inception_4e_5x5_pad)\n",
    "    inception_4e_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4e/pool')(inception_4d_output)\n",
    "    inception_4e_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4e/pool_proj', kernel_regularizer=l2(0.0002))(inception_4e_pool)\n",
    "    inception_4e_output = Concatenate(axis=-1, name='inception_4e/output')([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj])\n",
    "\n",
    "    inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_output)\n",
    "    pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n",
    "    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool4/3x3_s2')(pool4_helper)\n",
    "\n",
    "    inception_5a_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_5a/1x1', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_5a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3_reduce)\n",
    "    inception_5a_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_5a/3x3', kernel_regularizer=l2(0.0002))(inception_5a_3x3_pad)\n",
    "    inception_5a_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_5a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5a_5x5_reduce)\n",
    "    inception_5a_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5a/5x5', kernel_regularizer=l2(0.0002))(inception_5a_5x5_pad)\n",
    "    inception_5a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5a/pool')(pool4_3x3_s2)\n",
    "    inception_5a_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5a/pool_proj', kernel_regularizer=l2(0.0002))(inception_5a_pool)\n",
    "    inception_5a_output = Concatenate(axis=-1, name='inception_5a/output')([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj])\n",
    "\n",
    "    inception_5b_1x1 = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/1x1', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_reduce = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_5b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5b_3x3_reduce)\n",
    "    inception_5b_3x3 = Conv2D(48, (3,3), padding='valid', activation='relu', name='inception_5b/3x3', kernel_regularizer=l2(0.0002))(inception_5b_3x3_pad)\n",
    "    inception_5b_5x5_reduce = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5b_5x5_reduce)\n",
    "    inception_5b_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5b/5x5', kernel_regularizer=l2(0.0002))(inception_5b_5x5_pad)\n",
    "    inception_5b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5b/pool')(inception_5a_output)\n",
    "    inception_5b_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5b/pool_proj', kernel_regularizer=l2(0.0002))(inception_5b_pool)\n",
    "    inception_5b_output = Concatenate(axis=-1, name='inception_5b/output')([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj])\n",
    "\n",
    "    pool5_7x7_s1 = AveragePooling2D(pool_size=(7,7), strides=(1,1), name='pool5/7x7_s2')(inception_5b_output)\n",
    "    loss3_flat = Flatten()(pool5_7x7_s1)\n",
    "    pool5_drop_7x7_s1 = Dropout(rate=0.4)(loss3_flat)\n",
    "    loss3_classifier = Dense(classes, name='loss3/classifier', kernel_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n",
    "    loss3_classifier_act = Activation('softmax', name='prob')(loss3_classifier)\n",
    "\n",
    "    googlenet = Model(inputs=input, outputs=[loss1_classifier_act,loss2_classifier_act,loss3_classifier_act])\n",
    "\n",
    "\n",
    "    if weights_path:\n",
    "        googlenet.load_weights(weights_path)\n",
    "\n",
    "    # if tf.keras.backend.backend() == 'tensorflow':\n",
    "    #     # 우리는 tf.keras를 쓰므로, 이상황은 늘 True.\n",
    "    #     # 또한, 아래의 코드도 시행할 필요가 없다.\n",
    "    #     # 혹시모를 , 나중의 상황에 대비해 코드만 남겨놓는다.\n",
    "    #\n",
    "    #     ops = []\n",
    "    #     for layer in googlenet.layers:\n",
    "    #         if layer.__class__.__name__ == 'Conv2D': # layer의 class의 이름이 'conv2d'이면 ~\n",
    "    #             original_w = K.get_value(layer.kernel)\n",
    "    #             converted_w = convert_kernel(original_w)\n",
    "    #             ops.append(tf.assign(layer.kernel, converted_w).op)\n",
    "    #     K.get_session().run(ops)\n",
    "\n",
    "    return googlenet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186991,
     "status": "ok",
     "timestamp": 1583384759266,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "6BGhZH2FcL4S",
    "outputId": "04b4a3bb-b39d-4a78-8723-5ace96874978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "#내 데이터 맞춤형 모형\n",
    "\n",
    "model = my_googlenet(input_shape=(64, 64, 3), classes=7, weights_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186984,
     "status": "ok",
     "timestamp": 1583384759268,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "TKsFtx5-b_PS",
    "outputId": "8eb39532-21c3-4529-a84d-cb876f70f718",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 70, 70, 3)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 64, 64, 8)    1184        zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 66, 66, 8)    0           conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_4 (PoolHelper)      (None, 65, 65, 8)    0           zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool1/3x3_s2 (MaxPooling2D)     (None, 32, 32, 8)    0           pool_helper_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool1/norm1 (LRN)               (None, 32, 32, 8)    0           pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3_reduce (Conv2D)       (None, 32, 32, 8)    72          pool1/norm1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3 (Conv2D)              (None, 32, 32, 24)   1752        conv2/3x3_reduce[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2/norm2 (LRN)               (None, 32, 32, 24)   0           conv2/3x3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 34, 34, 24)   0           conv2/norm2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_5 (PoolHelper)      (None, 33, 33, 24)   0           zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool2/3x3_s2 (MaxPooling2D)     (None, 28, 28, 24)   0           pool_helper_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3_reduce (Conv2D (None, 28, 28, 12)   300         pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5_reduce (Conv2D (None, 28, 28, 2)    50          pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 30, 30, 12)   0           inception_3a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 32, 32, 2)    0           inception_3a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool (MaxPooling2D (None, 28, 28, 24)   0           pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/1x1 (Conv2D)       (None, 28, 28, 8)    200         pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3 (Conv2D)       (None, 28, 28, 16)   1744        zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5 (Conv2D)       (None, 28, 28, 4)    204         zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool_proj (Conv2D) (None, 28, 28, 4)    100         inception_3a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/output (Concatenat (None, 28, 28, 32)   0           inception_3a/1x1[0][0]           \n",
      "                                                                 inception_3a/3x3[0][0]           \n",
      "                                                                 inception_3a/5x5[0][0]           \n",
      "                                                                 inception_3a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3_reduce (Conv2D (None, 28, 28, 16)   528         inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5_reduce (Conv2D (None, 28, 28, 4)    132         inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 30, 30, 16)   0           inception_3b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 32, 32, 4)    0           inception_3b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool (MaxPooling2D (None, 28, 28, 32)   0           inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/1x1 (Conv2D)       (None, 28, 28, 16)   528         inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3 (Conv2D)       (None, 28, 28, 24)   3480        zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5 (Conv2D)       (None, 28, 28, 12)   1212        zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool_proj (Conv2D) (None, 28, 28, 8)    264         inception_3b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/output (Concatenat (None, 28, 28, 60)   0           inception_3b/1x1[0][0]           \n",
      "                                                                 inception_3b/3x3[0][0]           \n",
      "                                                                 inception_3b/5x5[0][0]           \n",
      "                                                                 inception_3b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 30, 30, 60)   0           inception_3b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_6 (PoolHelper)      (None, 29, 29, 60)   0           zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool3/3x3_s2 (MaxPooling2D)     (None, 14, 14, 60)   0           pool_helper_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3_reduce (Conv2D (None, 14, 14, 96)   5856        pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5_reduce (Conv2D (None, 14, 14, 16)   976         pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 16, 16, 96)   0           inception_4a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 18, 18, 16)   0           inception_4a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool (MaxPooling2D (None, 14, 14, 60)   0           pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/1x1 (Conv2D)       (None, 14, 14, 24)   1464        pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3 (Conv2D)       (None, 14, 14, 26)   22490       zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5 (Conv2D)       (None, 14, 14, 6)    2406        zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool_proj (Conv2D) (None, 14, 14, 8)    488         inception_4a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/output (Concatenat (None, 14, 14, 64)   0           inception_4a/1x1[0][0]           \n",
      "                                                                 inception_4a/3x3[0][0]           \n",
      "                                                                 inception_4a/5x5[0][0]           \n",
      "                                                                 inception_4a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3_reduce (Conv2D (None, 14, 14, 14)   910         inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5_reduce (Conv2D (None, 14, 14, 3)    195         inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 16, 16, 14)   0           inception_4b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, 18, 18, 3)    0           inception_4b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool (MaxPooling2D (None, 14, 14, 64)   0           inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/1x1 (Conv2D)       (None, 14, 14, 20)   1300        inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3 (Conv2D)       (None, 14, 14, 28)   3556        zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5 (Conv2D)       (None, 14, 14, 8)    608         zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool_proj (Conv2D) (None, 14, 14, 8)    520         inception_4b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/output (Concatenat (None, 14, 14, 64)   0           inception_4b/1x1[0][0]           \n",
      "                                                                 inception_4b/3x3[0][0]           \n",
      "                                                                 inception_4b/5x5[0][0]           \n",
      "                                                                 inception_4b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3_reduce (Conv2D (None, 14, 14, 16)   1040        inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5_reduce (Conv2D (None, 14, 14, 3)    195         inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPadding2 (None, 16, 16, 16)   0           inception_4c/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPadding2 (None, 18, 18, 3)    0           inception_4c/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool (MaxPooling2D (None, 14, 14, 64)   0           inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/1x1 (Conv2D)       (None, 14, 14, 16)   1040        inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3 (Conv2D)       (None, 14, 14, 32)   4640        zero_padding2d_35[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5 (Conv2D)       (None, 14, 14, 8)    608         zero_padding2d_36[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool_proj (Conv2D) (None, 14, 14, 8)    520         inception_4c/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/output (Concatenat (None, 14, 14, 64)   0           inception_4c/1x1[0][0]           \n",
      "                                                                 inception_4c/3x3[0][0]           \n",
      "                                                                 inception_4c/5x5[0][0]           \n",
      "                                                                 inception_4c/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3_reduce (Conv2D (None, 14, 14, 18)   1170        inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5_reduce (Conv2D (None, 14, 14, 4)    260         inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_37 (ZeroPadding2 (None, 16, 16, 18)   0           inception_4d/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_38 (ZeroPadding2 (None, 18, 18, 4)    0           inception_4d/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool (MaxPooling2D (None, 14, 14, 64)   0           inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/1x1 (Conv2D)       (None, 14, 14, 14)   910         inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3 (Conv2D)       (None, 14, 14, 36)   5868        zero_padding2d_37[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5 (Conv2D)       (None, 14, 14, 8)    808         zero_padding2d_38[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool_proj (Conv2D) (None, 14, 14, 8)    520         inception_4d/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/output (Concatenat (None, 14, 14, 66)   0           inception_4d/1x1[0][0]           \n",
      "                                                                 inception_4d/3x3[0][0]           \n",
      "                                                                 inception_4d/5x5[0][0]           \n",
      "                                                                 inception_4d/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3_reduce (Conv2D (None, 14, 14, 20)   1340        inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5_reduce (Conv2D (None, 14, 14, 4)    268         inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_39 (ZeroPadding2 (None, 16, 16, 20)   0           inception_4e/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_40 (ZeroPadding2 (None, 18, 18, 4)    0           inception_4e/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool (MaxPooling2D (None, 14, 14, 66)   0           inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/1x1 (Conv2D)       (None, 14, 14, 32)   2144        inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3 (Conv2D)       (None, 14, 14, 40)   7240        zero_padding2d_39[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5 (Conv2D)       (None, 14, 14, 16)   1616        zero_padding2d_40[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool_proj (Conv2D) (None, 14, 14, 16)   1072        inception_4e/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/output (Concatenat (None, 14, 14, 104)  0           inception_4e/1x1[0][0]           \n",
      "                                                                 inception_4e/3x3[0][0]           \n",
      "                                                                 inception_4e/5x5[0][0]           \n",
      "                                                                 inception_4e/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_41 (ZeroPadding2 (None, 16, 16, 104)  0           inception_4e/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_7 (PoolHelper)      (None, 15, 15, 104)  0           zero_padding2d_41[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool4/3x3_s2 (MaxPooling2D)     (None, 7, 7, 104)    0           pool_helper_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3_reduce (Conv2D (None, 7, 7, 20)     2100        pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5_reduce (Conv2D (None, 7, 7, 4)      420         pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_42 (ZeroPadding2 (None, 9, 9, 20)     0           inception_5a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_43 (ZeroPadding2 (None, 11, 11, 4)    0           inception_5a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool (MaxPooling2D (None, 7, 7, 104)    0           pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/1x1 (Conv2D)       (None, 7, 7, 32)     3360        pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3 (Conv2D)       (None, 7, 7, 40)     7240        zero_padding2d_42[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5 (Conv2D)       (None, 7, 7, 16)     1616        zero_padding2d_43[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool_proj (Conv2D) (None, 7, 7, 16)     1680        inception_5a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/output (Concatenat (None, 7, 7, 104)    0           inception_5a/1x1[0][0]           \n",
      "                                                                 inception_5a/3x3[0][0]           \n",
      "                                                                 inception_5a/5x5[0][0]           \n",
      "                                                                 inception_5a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3_reduce (Conv2D (None, 7, 7, 192)    20160       inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5_reduce (Conv2D (None, 7, 7, 48)     5040        inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_44 (ZeroPadding2 (None, 9, 9, 192)    0           inception_5b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_45 (ZeroPadding2 (None, 11, 11, 48)   0           inception_5b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool (MaxPooling2D (None, 7, 7, 104)    0           inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss1/ave_pool (AveragePooling2 (None, 4, 4, 64)     0           inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss2/ave_pool (AveragePooling2 (None, 4, 4, 66)     0           inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/1x1 (Conv2D)       (None, 7, 7, 48)     5040        inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3 (Conv2D)       (None, 7, 7, 48)     82992       zero_padding2d_44[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5 (Conv2D)       (None, 7, 7, 16)     19216       zero_padding2d_45[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool_proj (Conv2D) (None, 7, 7, 16)     1680        inception_5b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "loss1/conv (Conv2D)             (None, 4, 4, 16)     1040        loss1/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "loss2/conv (Conv2D)             (None, 4, 4, 16)     1072        loss2/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/output (Concatenat (None, 7, 7, 128)    0           inception_5b/1x1[0][0]           \n",
      "                                                                 inception_5b/3x3[0][0]           \n",
      "                                                                 inception_5b/5x5[0][0]           \n",
      "                                                                 inception_5b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 256)          0           loss1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 256)          0           loss2/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool5/7x7_s2 (AveragePooling2D) (None, 1, 1, 128)    0           inception_5b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss1/fc (Dense)                (None, 64)           16448       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss2/fc (Dense)                (None, 8)            2056        flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 128)          0           pool5/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           loss1/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8)            0           loss2/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss1/classifier (Dense)        (None, 7)            455         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss2/classifier (Dense)        (None, 7)            63          dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss3/classifier (Dense)        (None, 7)            903         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 7)            0           loss1/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 7)            0           loss2/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prob (Activation)               (None, 7)            0           loss3/classifier[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 256,359\n",
      "Trainable params: 256,359\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGFPbxTX9Qei"
   },
   "outputs": [],
   "source": [
    "initial_lrate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr9vu6qP3jdW"
   },
   "outputs": [],
   "source": [
    "def decay(epoch, steps=100) : # learning rate decay를 하기 위해 정의한 함수. // step은 왜 100으로 정의하는지 자세히는 모르겠다... LearningRateScheduler에서 필요할지도 모름\n",
    "  initial_lrate=0.01\n",
    "  drop = 0.96\n",
    "  epochs_drop = 8\n",
    "  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop)) # math.pow 는 거듭제곱 계산으로, 여기서 drop^(math.floor~) 의 형태이다. 입출력이 모두 실수형(double)이다.\n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKdF0ohN9XSq"
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=initial_lrate , momentum=0.9 , nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFKcnlQ43jmM"
   },
   "outputs": [],
   "source": [
    "# auxiliary classifier는 regularization의 일종이다. (loss에서 가중치를 주어 계산하는 셈이기 때문.)\n",
    "model.compile(optimizer=sgd, loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], loss_weights=[0.3,0.3,1],\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipySpUqSb_TI"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_prob_macro_f1score',patience = 3 , verbose=1,mode='max')\n",
    "lr_sc = LearningRateScheduler(decay,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 167335,
     "status": "ok",
     "timestamp": 1583390141924,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "kDIuXikrb_R2",
    "outputId": "f2c29fa3-d596-4617-92af-045710f45bdc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 49s 219ms/step - loss: 3.2671 - activation_2_loss: 1.8679 - activation_3_loss: 1.8877 - prob_loss: 1.8320 - activation_2_accuracy: 0.2329 - activation_2_macro_f1score: 0.0000e+00 - activation_2_weighted_f1score: 0.0000e+00 - activation_3_accuracy: 0.2494 - activation_3_macro_f1score: 0.0000e+00 - activation_3_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2502 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3273 - val_activation_2_loss: 1.8226 - val_activation_3_loss: 1.8501 - val_prob_loss: 1.8096 - val_activation_2_accuracy: 0.2449 - val_activation_2_macro_f1score: 0.0000e+00 - val_activation_2_weighted_f1score: 0.0000e+00 - val_activation_3_accuracy: 0.2449 - val_activation_3_macro_f1score: 0.0000e+00 - val_activation_3_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2449 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 39s 172ms/step - loss: 3.2191 - activation_2_loss: 1.8330 - activation_3_loss: 1.8379 - prob_loss: 1.8149 - activation_2_accuracy: 0.2479 - activation_2_macro_f1score: 0.0000e+00 - activation_2_weighted_f1score: 0.0000e+00 - activation_3_accuracy: 0.2514 - activation_3_macro_f1score: 0.0000e+00 - activation_3_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2510 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3135 - val_activation_2_loss: 1.8151 - val_activation_3_loss: 1.8287 - val_prob_loss: 1.8103 - val_activation_2_accuracy: 0.2452 - val_activation_2_macro_f1score: 0.0000e+00 - val_activation_2_weighted_f1score: 0.0000e+00 - val_activation_3_accuracy: 0.2452 - val_activation_3_macro_f1score: 0.0000e+00 - val_activation_3_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2452 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 40s 176ms/step - loss: 3.2042 - activation_2_loss: 1.8228 - activation_3_loss: 1.8246 - prob_loss: 1.8124 - activation_2_accuracy: 0.2514 - activation_2_macro_f1score: 0.0000e+00 - activation_2_weighted_f1score: 0.0000e+00 - activation_3_accuracy: 0.2514 - activation_3_macro_f1score: 0.0000e+00 - activation_3_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2513 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2933 - val_activation_2_loss: 1.8046 - val_activation_3_loss: 1.8192 - val_prob_loss: 1.8021 - val_activation_2_accuracy: 0.2466 - val_activation_2_macro_f1score: 0.0000e+00 - val_activation_2_weighted_f1score: 0.0000e+00 - val_activation_3_accuracy: 0.2466 - val_activation_3_macro_f1score: 0.0000e+00 - val_activation_3_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2466 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 39s 172ms/step - loss: 3.1930 - activation_2_loss: 1.8170 - activation_3_loss: 1.8189 - prob_loss: 1.8098 - activation_2_accuracy: 0.2514 - activation_2_macro_f1score: 0.0000e+00 - activation_2_weighted_f1score: 0.0000e+00 - activation_3_accuracy: 0.2514 - activation_3_macro_f1score: 0.0000e+00 - activation_3_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2514 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3088 - val_activation_2_loss: 1.8176 - val_activation_3_loss: 1.8286 - val_prob_loss: 1.8154 - val_activation_2_accuracy: 0.2419 - val_activation_2_macro_f1score: 0.0000e+00 - val_activation_2_weighted_f1score: 0.0000e+00 - val_activation_3_accuracy: 0.2419 - val_activation_3_macro_f1score: 0.0000e+00 - val_activation_3_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2419 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9aacab07b8>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_train_for_three(x_train_zoom,y_train), steps_per_epoch=len(x_train)/128, validation_data= generate_valid_for_three(x_valid_zoom,y_valid), validation_steps=len(x_valid_zoom)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 91081,
     "status": "ok",
     "timestamp": 1583390145637,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "Zn21Eq3PxULW",
    "outputId": "5d64c267-6c23-4f48-ced5-0c54652eb5ed",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 4s 1ms/sample - loss: 3.1799 - activation_2_loss: 1.8031 - activation_3_loss: 1.8138 - prob_loss: 1.7990 - activation_2_accuracy: 0.2494 - activation_2_macro_f1score: 0.0000e+00 - activation_2_weighted_f1score: 0.0000e+00 - activation_3_accuracy: 0.2494 - activation_3_macro_f1score: 0.0000e+00 - activation_3_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2494 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00\n",
      "\n",
      "Final Accuracy: 0.2494, Final Macro F1 Score: 0.0000, Final Weighted F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "*_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,[y_test,y_test,y_test],batch_size=128)\n",
    "print(\"\\nFinal Accuracy: {:.4f}, Final Macro F1 Score: {:.4f}, Final Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ndm2YY1cGO23"
   },
   "source": [
    "### 2) Size = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d1VYw0zTGO23"
   },
   "outputs": [],
   "source": [
    "# size=64의 googlenet과의 차이점은, AveragePooling2D size가 7에서 5로 바뀌었다는점이다.\n",
    "\n",
    "def my_googlenet(input_shape=(48,48,3), classes=7 , weights_path = None ):\n",
    "\n",
    "    input = Input(input_shape)\n",
    "\n",
    "    input_pad = ZeroPadding2D(padding=(3, 3))(input)\n",
    "    conv1_7x7_s2 = Conv2D(8, (7,7), strides=(1,1), padding='valid', activation='relu', name='conv1/7x7_s2', kernel_regularizer=l2(0.0002))(input_pad)\n",
    "    # 위에서 stride 2 -> 1로 바꿈.\n",
    "    conv1_zero_pad = ZeroPadding2D(padding=(1, 1))(conv1_7x7_s2)\n",
    "    pool1_helper = PoolHelper()(conv1_zero_pad)\n",
    "    pool1_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool1/3x3_s2')(pool1_helper)\n",
    "    pool1_norm1 = LRN(name='pool1/norm1')(pool1_3x3_s2)\n",
    "\n",
    "    conv2_3x3_reduce = Conv2D(8, (1,1), padding='same', activation='relu', name='conv2/3x3_reduce', kernel_regularizer=l2(0.0002))(pool1_norm1)\n",
    "    conv2_3x3 = Conv2D(24, (3,3), padding='same', activation='relu', name='conv2/3x3', kernel_regularizer=l2(0.0002))(conv2_3x3_reduce)\n",
    "    conv2_norm2 = LRN(name='conv2/norm2')(conv2_3x3)\n",
    "    conv2_zero_pad = ZeroPadding2D(padding=(1, 1))(conv2_norm2)\n",
    "    pool2_helper = PoolHelper()(conv2_zero_pad)\n",
    "    pool2_3x3_s2 = MaxPooling2D(pool_size=(6,6), strides=(1,1), padding='valid', name='pool2/3x3_s2')(pool2_helper)\n",
    "    # 위에서 strdie 2 -> 1로 바꿈. , pool_size 3 -> 6 으로 바꿈.  /// 여기까지 완료하면 r x c = 28 x 28 이 됨.\n",
    "\n",
    "    inception_3a_1x1 = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3a/1x1', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_reduce = Conv2D(12, (1,1), padding='same', activation='relu', name='inception_3a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3_reduce)\n",
    "    inception_3a_3x3 = Conv2D(16, (3,3), padding='valid', activation='relu', name='inception_3a/3x3', kernel_regularizer=l2(0.0002))(inception_3a_3x3_pad)\n",
    "    inception_3a_5x5_reduce = Conv2D(2, (1,1), padding='same', activation='relu', name='inception_3a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool2_3x3_s2)\n",
    "    inception_3a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5_reduce)\n",
    "    inception_3a_5x5 = Conv2D(4, (5,5), padding='valid', activation='relu', name='inception_3a/5x5', kernel_regularizer=l2(0.0002))(inception_3a_5x5_pad)\n",
    "    inception_3a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3a/pool')(pool2_3x3_s2)\n",
    "    inception_3a_pool_proj = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3a/pool_proj', kernel_regularizer=l2(0.0002))(inception_3a_pool)\n",
    "    inception_3a_output = Concatenate(axis=-1, name='inception_3a/output')([inception_3a_1x1,inception_3a_3x3,inception_3a_5x5,inception_3a_pool_proj])\n",
    "\n",
    "    inception_3b_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/1x1', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_3b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3_reduce)\n",
    "    inception_3b_3x3 = Conv2D(24, (3,3), padding='valid', activation='relu', name='inception_3b/3x3', kernel_regularizer=l2(0.0002))(inception_3b_3x3_pad)\n",
    "    inception_3b_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_3b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_3a_output)\n",
    "    inception_3b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5_reduce)\n",
    "    inception_3b_5x5 = Conv2D(12, (5,5), padding='valid', activation='relu', name='inception_3b/5x5', kernel_regularizer=l2(0.0002))(inception_3b_5x5_pad)\n",
    "    inception_3b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_3b/pool')(inception_3a_output)\n",
    "    inception_3b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_3b/pool_proj', kernel_regularizer=l2(0.0002))(inception_3b_pool)\n",
    "    inception_3b_output = Concatenate(axis=-1, name='inception_3b/output')([inception_3b_1x1,inception_3b_3x3,inception_3b_5x5,inception_3b_pool_proj])\n",
    "\n",
    "    inception_3b_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_3b_output)\n",
    "    pool3_helper = PoolHelper()(inception_3b_output_zero_pad)\n",
    "    pool3_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool3/3x3_s2')(pool3_helper)\n",
    "\n",
    "    inception_4a_1x1 = Conv2D(24, (1,1), padding='same', activation='relu', name='inception_4a/1x1', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_reduce = Conv2D(96, (1,1), padding='same', activation='relu', name='inception_4a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4a_3x3_reduce)\n",
    "    inception_4a_3x3 = Conv2D(26, (3,3), padding='valid', activation='relu', name='inception_4a/3x3' ,kernel_regularizer=l2(0.0002))(inception_4a_3x3_pad)\n",
    "    inception_4a_5x5_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool3_3x3_s2)\n",
    "    inception_4a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4a_5x5_reduce)\n",
    "    inception_4a_5x5 = Conv2D(6, (5,5), padding='valid', activation='relu', name='inception_4a/5x5', kernel_regularizer=l2(0.0002))(inception_4a_5x5_pad)\n",
    "    inception_4a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4a/pool')(pool3_3x3_s2)\n",
    "    inception_4a_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4a/pool_proj', kernel_regularizer=l2(0.0002))(inception_4a_pool)\n",
    "    inception_4a_output = Concatenate(axis=-1, name='inception_4a/output')([inception_4a_1x1,inception_4a_3x3,inception_4a_5x5,inception_4a_pool_proj])\n",
    "\n",
    "    loss1_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss1/ave_pool')(inception_4a_output)\n",
    "    loss1_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss1/conv', kernel_regularizer=l2(0.0002))(loss1_ave_pool)\n",
    "    loss1_flat = Flatten()(loss1_conv)\n",
    "    loss1_fc = Dense(64, activation='relu', name='loss1/fc', kernel_regularizer=l2(0.0002))(loss1_flat)\n",
    "    loss1_drop_fc = Dropout(rate=0.7)(loss1_fc)\n",
    "    loss1_classifier = Dense(classes, name='loss1/classifier', kernel_regularizer=l2(0.0002))(loss1_drop_fc)\n",
    "    loss1_classifier_act = Activation('softmax')(loss1_classifier)\n",
    "\n",
    "    inception_4b_1x1 = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4b/1x1', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_reduce = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4b_3x3_reduce)\n",
    "    inception_4b_3x3 = Conv2D(28, (3,3), padding='valid', activation='relu', name='inception_4b/3x3', kernel_regularizer=l2(0.0002))(inception_4b_3x3_pad)\n",
    "    inception_4b_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4a_output)\n",
    "    inception_4b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4b_5x5_reduce)\n",
    "    inception_4b_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4b/5x5', kernel_regularizer=l2(0.0002))(inception_4b_5x5_pad)\n",
    "    inception_4b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4b/pool')(inception_4a_output)\n",
    "    inception_4b_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4b/pool_proj', kernel_regularizer=l2(0.0002))(inception_4b_pool)\n",
    "    inception_4b_output = Concatenate(axis=-1, name='inception_4b/output')([inception_4b_1x1,inception_4b_3x3,inception_4b_5x5,inception_4b_pool_proj])\n",
    "\n",
    "    inception_4c_1x1 = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/1x1', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_reduce = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4c/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4c_3x3_reduce)\n",
    "    inception_4c_3x3 = Conv2D(32, (3,3), padding='valid', activation='relu', name='inception_4c/3x3', kernel_regularizer=l2(0.0002))(inception_4c_3x3_pad)\n",
    "    inception_4c_5x5_reduce = Conv2D(3, (1,1), padding='same', activation='relu', name='inception_4c/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4b_output)\n",
    "    inception_4c_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4c_5x5_reduce)\n",
    "    inception_4c_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4c/5x5', kernel_regularizer=l2(0.0002))(inception_4c_5x5_pad)\n",
    "    inception_4c_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4c/pool')(inception_4b_output)\n",
    "    inception_4c_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4c/pool_proj', kernel_regularizer=l2(0.0002))(inception_4c_pool)\n",
    "    inception_4c_output = Concatenate(axis=-1, name='inception_4c/output')([inception_4c_1x1,inception_4c_3x3,inception_4c_5x5,inception_4c_pool_proj])\n",
    "\n",
    "    inception_4d_1x1 = Conv2D(14, (1,1), padding='same', activation='relu', name='inception_4d/1x1', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_reduce = Conv2D(18, (1,1), padding='same', activation='relu', name='inception_4d/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4d_3x3_reduce)\n",
    "    inception_4d_3x3 = Conv2D(36, (3,3), padding='valid', activation='relu', name='inception_4d/3x3', kernel_regularizer=l2(0.0002))(inception_4d_3x3_pad)\n",
    "    inception_4d_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4d/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4c_output)\n",
    "    inception_4d_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4d_5x5_reduce)\n",
    "    inception_4d_5x5 = Conv2D(8, (5,5), padding='valid', activation='relu', name='inception_4d/5x5', kernel_regularizer=l2(0.0002))(inception_4d_5x5_pad)\n",
    "    inception_4d_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4d/pool')(inception_4c_output)\n",
    "    inception_4d_pool_proj = Conv2D(8, (1,1), padding='same', activation='relu', name='inception_4d/pool_proj', kernel_regularizer=l2(0.0002))(inception_4d_pool)\n",
    "    inception_4d_output = Concatenate(axis=-1, name='inception_4d/output')([inception_4d_1x1,inception_4d_3x3,inception_4d_5x5,inception_4d_pool_proj])\n",
    "\n",
    "    loss2_ave_pool = AveragePooling2D(pool_size=(5,5), strides=(3,3), name='loss2/ave_pool')(inception_4d_output)\n",
    "    loss2_conv = Conv2D(16, (1,1), padding='same', activation='relu', name='loss2/conv', kernel_regularizer=l2(0.0002))(loss2_ave_pool)\n",
    "    loss2_flat = Flatten()(loss2_conv)\n",
    "    loss2_fc = Dense(8, activation='relu', name='loss2/fc', kernel_regularizer=l2(0.0002))(loss2_flat)\n",
    "    loss2_drop_fc = Dropout(rate=0.7)(loss2_fc)\n",
    "    loss2_classifier = Dense(classes, name='loss2/classifier', kernel_regularizer=l2(0.0002))(loss2_drop_fc)\n",
    "    loss2_classifier_act = Activation('softmax')(loss2_classifier)\n",
    "\n",
    "    inception_4e_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_4e/1x1', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_4e/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_3x3_reduce)\n",
    "    inception_4e_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_4e/3x3', kernel_regularizer=l2(0.0002))(inception_4e_3x3_pad)\n",
    "    inception_4e_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_4e/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_4d_output)\n",
    "    inception_4e_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_4e_5x5_reduce)\n",
    "    inception_4e_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_4e/5x5', kernel_regularizer=l2(0.0002))(inception_4e_5x5_pad)\n",
    "    inception_4e_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_4e/pool')(inception_4d_output)\n",
    "    inception_4e_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_4e/pool_proj', kernel_regularizer=l2(0.0002))(inception_4e_pool)\n",
    "    inception_4e_output = Concatenate(axis=-1, name='inception_4e/output')([inception_4e_1x1,inception_4e_3x3,inception_4e_5x5,inception_4e_pool_proj])\n",
    "\n",
    "    inception_4e_output_zero_pad = ZeroPadding2D(padding=(1, 1))(inception_4e_output)\n",
    "    pool4_helper = PoolHelper()(inception_4e_output_zero_pad)\n",
    "    pool4_3x3_s2 = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid', name='pool4/3x3_s2')(pool4_helper)\n",
    "\n",
    "    inception_5a_1x1 = Conv2D(32, (1,1), padding='same', activation='relu', name='inception_5a/1x1', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_reduce = Conv2D(20, (1,1), padding='same', activation='relu', name='inception_5a/3x3_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5a_3x3_reduce)\n",
    "    inception_5a_3x3 = Conv2D(40, (3,3), padding='valid', activation='relu', name='inception_5a/3x3', kernel_regularizer=l2(0.0002))(inception_5a_3x3_pad)\n",
    "    inception_5a_5x5_reduce = Conv2D(4, (1,1), padding='same', activation='relu', name='inception_5a/5x5_reduce', kernel_regularizer=l2(0.0002))(pool4_3x3_s2)\n",
    "    inception_5a_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5a_5x5_reduce)\n",
    "    inception_5a_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5a/5x5', kernel_regularizer=l2(0.0002))(inception_5a_5x5_pad)\n",
    "    inception_5a_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5a/pool')(pool4_3x3_s2)\n",
    "    inception_5a_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5a/pool_proj', kernel_regularizer=l2(0.0002))(inception_5a_pool)\n",
    "    inception_5a_output = Concatenate(axis=-1, name='inception_5a/output')([inception_5a_1x1,inception_5a_3x3,inception_5a_5x5,inception_5a_pool_proj])\n",
    "\n",
    "    inception_5b_1x1 = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/1x1', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_reduce = Conv2D(192, (1,1), padding='same', activation='relu', name='inception_5b/3x3_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_3x3_pad = ZeroPadding2D(padding=(1, 1))(inception_5b_3x3_reduce)\n",
    "    inception_5b_3x3 = Conv2D(48, (3,3), padding='valid', activation='relu', name='inception_5b/3x3', kernel_regularizer=l2(0.0002))(inception_5b_3x3_pad)\n",
    "    inception_5b_5x5_reduce = Conv2D(48, (1,1), padding='same', activation='relu', name='inception_5b/5x5_reduce', kernel_regularizer=l2(0.0002))(inception_5a_output)\n",
    "    inception_5b_5x5_pad = ZeroPadding2D(padding=(2, 2))(inception_5b_5x5_reduce)\n",
    "    inception_5b_5x5 = Conv2D(16, (5,5), padding='valid', activation='relu', name='inception_5b/5x5', kernel_regularizer=l2(0.0002))(inception_5b_5x5_pad)\n",
    "    inception_5b_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1), padding='same', name='inception_5b/pool')(inception_5a_output)\n",
    "    inception_5b_pool_proj = Conv2D(16, (1,1), padding='same', activation='relu', name='inception_5b/pool_proj', kernel_regularizer=l2(0.0002))(inception_5b_pool)\n",
    "    inception_5b_output = Concatenate(axis=-1, name='inception_5b/output')([inception_5b_1x1,inception_5b_3x3,inception_5b_5x5,inception_5b_pool_proj])\n",
    "\n",
    "    pool5_7x7_s1 = AveragePooling2D(pool_size=(5,5), strides=(1,1), name='pool5/7x7_s2')(inception_5b_output) # 여기가 기존 7에서 5로 바뀐다.\n",
    "    loss3_flat = Flatten()(pool5_7x7_s1)\n",
    "    pool5_drop_7x7_s1 = Dropout(rate=0.4)(loss3_flat)\n",
    "    loss3_classifier = Dense(classes, name='loss3/classifier', kernel_regularizer=l2(0.0002))(pool5_drop_7x7_s1)\n",
    "    loss3_classifier_act = Activation('softmax', name='prob')(loss3_classifier)\n",
    "\n",
    "    googlenet = Model(inputs=input, outputs=[loss1_classifier_act,loss2_classifier_act,loss3_classifier_act])\n",
    "\n",
    "\n",
    "    if weights_path:\n",
    "        googlenet.load_weights(weights_path)\n",
    "\n",
    "    # if tf.keras.backend.backend() == 'tensorflow':\n",
    "    #     # 우리는 tf.keras를 쓰므로, 이상황은 늘 True.\n",
    "    #     # 또한, 아래의 코드도 시행할 필요가 없다.\n",
    "    #     # 혹시모를 , 나중의 상황에 대비해 코드만 남겨놓는다.\n",
    "    #\n",
    "    #     ops = []\n",
    "    #     for layer in googlenet.layers:\n",
    "    #         if layer.__class__.__name__ == 'Conv2D': # layer의 class의 이름이 'conv2d'이면 ~\n",
    "    #             original_w = K.get_value(layer.kernel)\n",
    "    #             converted_w = convert_kernel(original_w)\n",
    "    #             ops.append(tf.assign(layer.kernel, converted_w).op)\n",
    "    #     K.get_session().run(ops)\n",
    "\n",
    "    return googlenet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlX8DtKOHxEw"
   },
   "outputs": [],
   "source": [
    "model = my_googlenet(input_shape=(48, 48, 3), classes=7, weights_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1243,
     "status": "ok",
     "timestamp": 1583390206308,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "Fw2ZqjAOHxBp",
    "outputId": "c861dd3f-6ad6-4c94-966e-a3ddd8afdf3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 48, 48, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_46 (ZeroPadding2 (None, 54, 54, 3)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/7x7_s2 (Conv2D)           (None, 48, 48, 8)    1184        zero_padding2d_46[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_47 (ZeroPadding2 (None, 50, 50, 8)    0           conv1/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_8 (PoolHelper)      (None, 49, 49, 8)    0           zero_padding2d_47[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool1/3x3_s2 (MaxPooling2D)     (None, 24, 24, 8)    0           pool_helper_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "pool1/norm1 (LRN)               (None, 24, 24, 8)    0           pool1/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3_reduce (Conv2D)       (None, 24, 24, 8)    72          pool1/norm1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2/3x3 (Conv2D)              (None, 24, 24, 24)   1752        conv2/3x3_reduce[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2/norm2 (LRN)               (None, 24, 24, 24)   0           conv2/3x3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_48 (ZeroPadding2 (None, 26, 26, 24)   0           conv2/norm2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_9 (PoolHelper)      (None, 25, 25, 24)   0           zero_padding2d_48[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool2/3x3_s2 (MaxPooling2D)     (None, 20, 20, 24)   0           pool_helper_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3_reduce (Conv2D (None, 20, 20, 12)   300         pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5_reduce (Conv2D (None, 20, 20, 2)    50          pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_49 (ZeroPadding2 (None, 22, 22, 12)   0           inception_3a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_50 (ZeroPadding2 (None, 24, 24, 2)    0           inception_3a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool (MaxPooling2D (None, 20, 20, 24)   0           pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/1x1 (Conv2D)       (None, 20, 20, 8)    200         pool2/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/3x3 (Conv2D)       (None, 20, 20, 16)   1744        zero_padding2d_49[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/5x5 (Conv2D)       (None, 20, 20, 4)    204         zero_padding2d_50[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/pool_proj (Conv2D) (None, 20, 20, 4)    100         inception_3a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3a/output (Concatenat (None, 20, 20, 32)   0           inception_3a/1x1[0][0]           \n",
      "                                                                 inception_3a/3x3[0][0]           \n",
      "                                                                 inception_3a/5x5[0][0]           \n",
      "                                                                 inception_3a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3_reduce (Conv2D (None, 20, 20, 16)   528         inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5_reduce (Conv2D (None, 20, 20, 4)    132         inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_51 (ZeroPadding2 (None, 22, 22, 16)   0           inception_3b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_52 (ZeroPadding2 (None, 24, 24, 4)    0           inception_3b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool (MaxPooling2D (None, 20, 20, 32)   0           inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/1x1 (Conv2D)       (None, 20, 20, 16)   528         inception_3a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/3x3 (Conv2D)       (None, 20, 20, 24)   3480        zero_padding2d_51[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/5x5 (Conv2D)       (None, 20, 20, 12)   1212        zero_padding2d_52[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/pool_proj (Conv2D) (None, 20, 20, 8)    264         inception_3b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_3b/output (Concatenat (None, 20, 20, 60)   0           inception_3b/1x1[0][0]           \n",
      "                                                                 inception_3b/3x3[0][0]           \n",
      "                                                                 inception_3b/5x5[0][0]           \n",
      "                                                                 inception_3b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_53 (ZeroPadding2 (None, 22, 22, 60)   0           inception_3b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_10 (PoolHelper)     (None, 21, 21, 60)   0           zero_padding2d_53[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool3/3x3_s2 (MaxPooling2D)     (None, 10, 10, 60)   0           pool_helper_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3_reduce (Conv2D (None, 10, 10, 96)   5856        pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5_reduce (Conv2D (None, 10, 10, 16)   976         pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_54 (ZeroPadding2 (None, 12, 12, 96)   0           inception_4a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_55 (ZeroPadding2 (None, 14, 14, 16)   0           inception_4a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool (MaxPooling2D (None, 10, 10, 60)   0           pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/1x1 (Conv2D)       (None, 10, 10, 24)   1464        pool3/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/3x3 (Conv2D)       (None, 10, 10, 26)   22490       zero_padding2d_54[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/5x5 (Conv2D)       (None, 10, 10, 6)    2406        zero_padding2d_55[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/pool_proj (Conv2D) (None, 10, 10, 8)    488         inception_4a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4a/output (Concatenat (None, 10, 10, 64)   0           inception_4a/1x1[0][0]           \n",
      "                                                                 inception_4a/3x3[0][0]           \n",
      "                                                                 inception_4a/5x5[0][0]           \n",
      "                                                                 inception_4a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3_reduce (Conv2D (None, 10, 10, 14)   910         inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5_reduce (Conv2D (None, 10, 10, 3)    195         inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_56 (ZeroPadding2 (None, 12, 12, 14)   0           inception_4b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_57 (ZeroPadding2 (None, 14, 14, 3)    0           inception_4b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool (MaxPooling2D (None, 10, 10, 64)   0           inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/1x1 (Conv2D)       (None, 10, 10, 20)   1300        inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/3x3 (Conv2D)       (None, 10, 10, 28)   3556        zero_padding2d_56[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/5x5 (Conv2D)       (None, 10, 10, 8)    608         zero_padding2d_57[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/pool_proj (Conv2D) (None, 10, 10, 8)    520         inception_4b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4b/output (Concatenat (None, 10, 10, 64)   0           inception_4b/1x1[0][0]           \n",
      "                                                                 inception_4b/3x3[0][0]           \n",
      "                                                                 inception_4b/5x5[0][0]           \n",
      "                                                                 inception_4b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3_reduce (Conv2D (None, 10, 10, 16)   1040        inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5_reduce (Conv2D (None, 10, 10, 3)    195         inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_58 (ZeroPadding2 (None, 12, 12, 16)   0           inception_4c/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_59 (ZeroPadding2 (None, 14, 14, 3)    0           inception_4c/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool (MaxPooling2D (None, 10, 10, 64)   0           inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/1x1 (Conv2D)       (None, 10, 10, 16)   1040        inception_4b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/3x3 (Conv2D)       (None, 10, 10, 32)   4640        zero_padding2d_58[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/5x5 (Conv2D)       (None, 10, 10, 8)    608         zero_padding2d_59[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/pool_proj (Conv2D) (None, 10, 10, 8)    520         inception_4c/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4c/output (Concatenat (None, 10, 10, 64)   0           inception_4c/1x1[0][0]           \n",
      "                                                                 inception_4c/3x3[0][0]           \n",
      "                                                                 inception_4c/5x5[0][0]           \n",
      "                                                                 inception_4c/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3_reduce (Conv2D (None, 10, 10, 18)   1170        inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5_reduce (Conv2D (None, 10, 10, 4)    260         inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_60 (ZeroPadding2 (None, 12, 12, 18)   0           inception_4d/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61 (ZeroPadding2 (None, 14, 14, 4)    0           inception_4d/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool (MaxPooling2D (None, 10, 10, 64)   0           inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/1x1 (Conv2D)       (None, 10, 10, 14)   910         inception_4c/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/3x3 (Conv2D)       (None, 10, 10, 36)   5868        zero_padding2d_60[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/5x5 (Conv2D)       (None, 10, 10, 8)    808         zero_padding2d_61[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/pool_proj (Conv2D) (None, 10, 10, 8)    520         inception_4d/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4d/output (Concatenat (None, 10, 10, 66)   0           inception_4d/1x1[0][0]           \n",
      "                                                                 inception_4d/3x3[0][0]           \n",
      "                                                                 inception_4d/5x5[0][0]           \n",
      "                                                                 inception_4d/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3_reduce (Conv2D (None, 10, 10, 20)   1340        inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5_reduce (Conv2D (None, 10, 10, 4)    268         inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_62 (ZeroPadding2 (None, 12, 12, 20)   0           inception_4e/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_63 (ZeroPadding2 (None, 14, 14, 4)    0           inception_4e/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool (MaxPooling2D (None, 10, 10, 66)   0           inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/1x1 (Conv2D)       (None, 10, 10, 32)   2144        inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/3x3 (Conv2D)       (None, 10, 10, 40)   7240        zero_padding2d_62[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/5x5 (Conv2D)       (None, 10, 10, 16)   1616        zero_padding2d_63[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/pool_proj (Conv2D) (None, 10, 10, 16)   1072        inception_4e/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_4e/output (Concatenat (None, 10, 10, 104)  0           inception_4e/1x1[0][0]           \n",
      "                                                                 inception_4e/3x3[0][0]           \n",
      "                                                                 inception_4e/5x5[0][0]           \n",
      "                                                                 inception_4e/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_64 (ZeroPadding2 (None, 12, 12, 104)  0           inception_4e/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool_helper_11 (PoolHelper)     (None, 11, 11, 104)  0           zero_padding2d_64[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "pool4/3x3_s2 (MaxPooling2D)     (None, 5, 5, 104)    0           pool_helper_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3_reduce (Conv2D (None, 5, 5, 20)     2100        pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5_reduce (Conv2D (None, 5, 5, 4)      420         pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65 (ZeroPadding2 (None, 7, 7, 20)     0           inception_5a/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66 (ZeroPadding2 (None, 9, 9, 4)      0           inception_5a/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool (MaxPooling2D (None, 5, 5, 104)    0           pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/1x1 (Conv2D)       (None, 5, 5, 32)     3360        pool4/3x3_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/3x3 (Conv2D)       (None, 5, 5, 40)     7240        zero_padding2d_65[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/5x5 (Conv2D)       (None, 5, 5, 16)     1616        zero_padding2d_66[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/pool_proj (Conv2D) (None, 5, 5, 16)     1680        inception_5a/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5a/output (Concatenat (None, 5, 5, 104)    0           inception_5a/1x1[0][0]           \n",
      "                                                                 inception_5a/3x3[0][0]           \n",
      "                                                                 inception_5a/5x5[0][0]           \n",
      "                                                                 inception_5a/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3_reduce (Conv2D (None, 5, 5, 192)    20160       inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5_reduce (Conv2D (None, 5, 5, 48)     5040        inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_67 (ZeroPadding2 (None, 7, 7, 192)    0           inception_5b/3x3_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_68 (ZeroPadding2 (None, 9, 9, 48)     0           inception_5b/5x5_reduce[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool (MaxPooling2D (None, 5, 5, 104)    0           inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss1/ave_pool (AveragePooling2 (None, 2, 2, 64)     0           inception_4a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss2/ave_pool (AveragePooling2 (None, 2, 2, 66)     0           inception_4d/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/1x1 (Conv2D)       (None, 5, 5, 48)     5040        inception_5a/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/3x3 (Conv2D)       (None, 5, 5, 48)     82992       zero_padding2d_67[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/5x5 (Conv2D)       (None, 5, 5, 16)     19216       zero_padding2d_68[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/pool_proj (Conv2D) (None, 5, 5, 16)     1680        inception_5b/pool[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "loss1/conv (Conv2D)             (None, 2, 2, 16)     1040        loss1/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "loss2/conv (Conv2D)             (None, 2, 2, 16)     1072        loss2/ave_pool[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "inception_5b/output (Concatenat (None, 5, 5, 128)    0           inception_5b/1x1[0][0]           \n",
      "                                                                 inception_5b/3x3[0][0]           \n",
      "                                                                 inception_5b/5x5[0][0]           \n",
      "                                                                 inception_5b/pool_proj[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 64)           0           loss1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 64)           0           loss2/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool5/7x7_s2 (AveragePooling2D) (None, 1, 1, 128)    0           inception_5b/output[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "loss1/fc (Dense)                (None, 64)           4160        flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss2/fc (Dense)                (None, 8)            520         flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 128)          0           pool5/7x7_s2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           loss1/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 8)            0           loss2/fc[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss1/classifier (Dense)        (None, 7)            455         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss2/classifier (Dense)        (None, 7)            63          dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "loss3/classifier (Dense)        (None, 7)            903         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 7)            0           loss1/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 7)            0           loss2/classifier[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "prob (Activation)               (None, 7)            0           loss3/classifier[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 242,535\n",
      "Trainable params: 242,535\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjqg9ry7GO2-"
   },
   "outputs": [],
   "source": [
    "initial_lrate = 0.01\n",
    "def decay(epoch, steps=100) : # learning rate decay를 하기 위해 정의한 함수. // step은 왜 100으로 정의하는지 자세히는 모르겠다... LearningRateScheduler에서 필요할지도 모름\n",
    "  initial_lrate=0.01\n",
    "  drop = 0.96\n",
    "  epochs_drop = 8\n",
    "  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop)) # math.pow 는 거듭제곱 계산으로, 여기서 drop^(math.floor~) 의 형태이다. 입출력이 모두 실수형(double)이다.\n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "viLZ8e9QPxp-"
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=initial_lrate , momentum=0.9 , nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOawzgeZGO3C"
   },
   "outputs": [],
   "source": [
    "# auxiliary classifier는 regularization의 일종이다. (loss에서 가중치를 주어 계산하는 셈이기 때문.)\n",
    "model.compile(optimizer=sgd, loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], loss_weights=[0.3,0.3,1],\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZC2AO6uGO3F"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor = 'val_prob_macro_f1score',patience = 3 , verbose=1,mode='max')\n",
    "lr_sc = LearningRateScheduler(decay,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 133481,
     "status": "ok",
     "timestamp": 1583390347025,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "bpk9nH4JGO3I",
    "outputId": "82c3d263-5692-4b6e-acb0-c256743372ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 41s 181ms/step - loss: 3.2548 - activation_4_loss: 1.8663 - activation_5_loss: 1.8846 - prob_loss: 1.8297 - activation_4_accuracy: 0.2308 - activation_4_macro_f1score: 0.0000e+00 - activation_4_weighted_f1score: 0.0000e+00 - activation_5_accuracy: 0.2384 - activation_5_macro_f1score: 0.0000e+00 - activation_5_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2436 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3301 - val_activation_4_loss: 1.8295 - val_activation_5_loss: 1.8513 - val_prob_loss: 1.8184 - val_activation_4_accuracy: 0.2449 - val_activation_4_macro_f1score: 0.0000e+00 - val_activation_4_weighted_f1score: 0.0000e+00 - val_activation_5_accuracy: 0.2449 - val_activation_5_macro_f1score: 0.0000e+00 - val_activation_5_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2449 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 30s 136ms/step - loss: 3.2107 - activation_4_loss: 1.8321 - activation_5_loss: 1.8393 - prob_loss: 1.8147 - activation_4_accuracy: 0.2495 - activation_4_macro_f1score: 0.0000e+00 - activation_4_weighted_f1score: 0.0000e+00 - activation_5_accuracy: 0.2514 - activation_5_macro_f1score: 0.0000e+00 - activation_5_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2510 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3023 - val_activation_4_loss: 1.8160 - val_activation_5_loss: 1.8278 - val_prob_loss: 1.8079 - val_activation_4_accuracy: 0.2460 - val_activation_4_macro_f1score: 0.0000e+00 - val_activation_4_weighted_f1score: 0.0000e+00 - val_activation_5_accuracy: 0.2460 - val_activation_5_macro_f1score: 0.0000e+00 - val_activation_5_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2460 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 30s 136ms/step - loss: 3.1952 - activation_4_loss: 1.8226 - activation_5_loss: 1.8264 - prob_loss: 1.8112 - activation_4_accuracy: 0.2501 - activation_4_macro_f1score: 0.0000e+00 - activation_4_weighted_f1score: 0.0000e+00 - activation_5_accuracy: 0.2514 - activation_5_macro_f1score: 0.0000e+00 - activation_5_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2514 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2853 - val_activation_4_loss: 1.8107 - val_activation_5_loss: 1.8181 - val_prob_loss: 1.8010 - val_activation_4_accuracy: 0.2385 - val_activation_4_macro_f1score: 0.0000e+00 - val_activation_4_weighted_f1score: 0.0000e+00 - val_activation_5_accuracy: 0.2385 - val_activation_5_macro_f1score: 0.0000e+00 - val_activation_5_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2385 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 3.1813 - activation_4_loss: 1.8191 - activation_5_loss: 1.8185 - prob_loss: 1.8056 - activation_4_accuracy: 0.2512 - activation_4_macro_f1score: 0.0000e+00 - activation_4_weighted_f1score: 0.0000e+00 - activation_5_accuracy: 0.2514 - activation_5_macro_f1score: 0.0000e+00 - activation_5_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2524 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3216 - val_activation_4_loss: 1.8312 - val_activation_5_loss: 1.8354 - val_prob_loss: 1.8296 - val_activation_4_accuracy: 0.2446 - val_activation_4_macro_f1score: 0.0000e+00 - val_activation_4_weighted_f1score: 0.0000e+00 - val_activation_5_accuracy: 0.2446 - val_activation_5_macro_f1score: 0.0000e+00 - val_activation_5_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2446 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9aac5d3748>"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_train_for_three(x_train,y_train), steps_per_epoch=len(x_train)/128, validation_data= generate_valid_for_three(x_valid,y_valid), validation_steps=len(x_valid)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 136221,
     "status": "ok",
     "timestamp": 1583390350284,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "wukS_TUWGO3L",
    "outputId": "fe87cde8-7ccc-4fc7-a04d-5dea3212a1af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 3s 876us/sample - loss: 3.1833 - activation_4_loss: 1.8117 - activation_5_loss: 1.8152 - prob_loss: 1.8063 - activation_4_accuracy: 0.2494 - activation_4_macro_f1score: 0.0000e+00 - activation_4_weighted_f1score: 0.0000e+00 - activation_5_accuracy: 0.2494 - activation_5_macro_f1score: 0.0000e+00 - activation_5_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2494 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00\n",
      "\n",
      "Final Accuracy: 0.2494, Final Macro F1 Score: 0.0000, Final Weighted F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "*_, acc, mac_f1, wei_f1 = model.evaluate(x_test,[y_test,y_test,y_test],batch_size=128)\n",
    "print(\"\\nFinal Accuracy: {:.4f}, Final Macro F1 Score: {:.4f}, Final Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcsxqBKKDQBU"
   },
   "source": [
    "## 3. For Size = 48 , No Early Stoppping\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVhEyqYaDQJc"
   },
   "source": [
    "### 1) Epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcVpL1buCgY0"
   },
   "outputs": [],
   "source": [
    "model = my_googlenet(input_shape=(48, 48, 3), classes=7, weights_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ple6UhxbCgU3"
   },
   "outputs": [],
   "source": [
    "def decay(epoch, steps=100) : # learning rate decay를 하기 위해 정의한 함수. // step은 왜 100으로 정의하는지 자세히는 모르겠다... LearningRateScheduler에서 필요할지도 모름\n",
    "  initial_lrate=0.01\n",
    "  drop = 0.96\n",
    "  epochs_drop = 8\n",
    "  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop)) # math.pow 는 거듭제곱 계산으로, 여기서 drop^(math.floor~) 의 형태이다. 입출력이 모두 실수형(double)이다.\n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDMH5hL-PerC"
   },
   "outputs": [],
   "source": [
    "initial_lrate = 0.01\n",
    "lr_sc = LearningRateScheduler(decay,verbose=1)\n",
    "sgd = SGD(lr=initial_lrate , momentum=0.9 , nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hLlBRBDkrEm6"
   },
   "outputs": [],
   "source": [
    "# 편의를 위해 Adam으로 해보자.\n",
    "# auxiliary classifier는 regularization의 일종이다. (loss에서 가중치를 주어 계산하는 셈이기 때문.)\n",
    "model.compile(optimizer=sgd, loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], loss_weights=[0.3,0.3,1],\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1502766,
     "status": "ok",
     "timestamp": 1583391853997,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "8NZVub0HrEr5",
    "outputId": "c56e80ef-2ef9-4459-e68a-4c8906eae57c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/50\n",
      "225/224 [==============================] - 39s 174ms/step - loss: 3.2576 - activation_6_loss: 1.8678 - activation_7_loss: 1.8853 - prob_loss: 1.8333 - activation_6_accuracy: 0.2433 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2389 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2499 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3326 - val_activation_6_loss: 1.8356 - val_activation_7_loss: 1.8551 - val_prob_loss: 1.8192 - val_activation_6_accuracy: 0.2449 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2449 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2449 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/50\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 3.2079 - activation_6_loss: 1.8343 - activation_7_loss: 1.8384 - prob_loss: 1.8129 - activation_6_accuracy: 0.2451 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2514 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2513 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3094 - val_activation_6_loss: 1.8235 - val_activation_7_loss: 1.8329 - val_prob_loss: 1.8123 - val_activation_6_accuracy: 0.2466 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2466 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2466 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 3/50\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 3.1887 - activation_6_loss: 1.8238 - activation_7_loss: 1.8255 - prob_loss: 1.8058 - activation_6_accuracy: 0.2493 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2514 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2512 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2727 - val_activation_6_loss: 1.8137 - val_activation_7_loss: 1.8214 - val_prob_loss: 1.7881 - val_activation_6_accuracy: 0.2463 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2463 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2463 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 4/50\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 3.1723 - activation_6_loss: 1.8180 - activation_7_loss: 1.8181 - prob_loss: 1.7983 - activation_6_accuracy: 0.2509 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2514 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2518 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2882 - val_activation_6_loss: 1.8214 - val_activation_7_loss: 1.8236 - val_prob_loss: 1.8050 - val_activation_6_accuracy: 0.2435 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2435 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2497 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 5/50\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 3.1639 - activation_6_loss: 1.8147 - activation_7_loss: 1.8135 - prob_loss: 1.7972 - activation_6_accuracy: 0.2509 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2511 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2498 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2793 - val_activation_6_loss: 1.8194 - val_activation_7_loss: 1.8241 - val_prob_loss: 1.8018 - val_activation_6_accuracy: 0.2452 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2452 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2591 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 6/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 3.1528 - activation_6_loss: 1.8115 - activation_7_loss: 1.8109 - prob_loss: 1.7926 - activation_6_accuracy: 0.2509 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2509 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2527 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2547 - val_activation_6_loss: 1.8133 - val_activation_7_loss: 1.8160 - val_prob_loss: 1.7869 - val_activation_6_accuracy: 0.2421 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2421 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2633 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 7/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.1398 - activation_6_loss: 1.8074 - activation_7_loss: 1.8084 - prob_loss: 1.7861 - activation_6_accuracy: 0.2510 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2504 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2573 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2236 - val_activation_6_loss: 1.8020 - val_activation_7_loss: 1.8077 - val_prob_loss: 1.7672 - val_activation_6_accuracy: 0.2446 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2446 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2611 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 8/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 3.1186 - activation_6_loss: 1.8000 - activation_7_loss: 1.8047 - prob_loss: 1.7726 - activation_6_accuracy: 0.2515 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2509 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2668 - prob_macro_f1score: 5.1980e-04 - prob_weighted_f1score: 5.2432e-05 - val_loss: 3.1918 - val_activation_6_loss: 1.7928 - val_activation_7_loss: 1.8024 - val_prob_loss: 1.7450 - val_activation_6_accuracy: 0.2463 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2463 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2792 - val_prob_macro_f1score: 5.1854e-04 - val_prob_weighted_f1score: 7.2919e-05\n",
      "Epoch 9/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.0928 - activation_6_loss: 1.7919 - activation_7_loss: 1.7984 - prob_loss: 1.7551 - activation_6_accuracy: 0.2551 - activation_6_macro_f1score: 0.0000e+00 - activation_6_weighted_f1score: 0.0000e+00 - activation_7_accuracy: 0.2529 - activation_7_macro_f1score: 0.0000e+00 - activation_7_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2778 - prob_macro_f1score: 0.0100 - prob_weighted_f1score: 0.0011 - val_loss: 3.3078 - val_activation_6_loss: 1.8026 - val_activation_7_loss: 1.7933 - val_prob_loss: 1.8607 - val_activation_6_accuracy: 0.2627 - val_activation_6_macro_f1score: 0.0000e+00 - val_activation_6_weighted_f1score: 0.0000e+00 - val_activation_7_accuracy: 0.2561 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2118 - val_prob_macro_f1score: 0.0634 - val_prob_weighted_f1score: 0.0073\n",
      "Epoch 10/50\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 3.0685 - activation_6_loss: 1.7757 - activation_7_loss: 1.7913 - prob_loss: 1.7416 - activation_6_accuracy: 0.2645 - activation_6_macro_f1score: 0.0018 - activation_6_weighted_f1score: 2.0402e-04 - activation_7_accuracy: 0.2590 - activation_7_macro_f1score: 0.0028 - activation_7_weighted_f1score: 2.8126e-04 - prob_accuracy: 0.2844 - prob_macro_f1score: 0.0202 - prob_weighted_f1score: 0.0022 - val_loss: 3.1134 - val_activation_6_loss: 1.7324 - val_activation_7_loss: 1.7625 - val_prob_loss: 1.7068 - val_activation_6_accuracy: 0.2981 - val_activation_6_macro_f1score: 0.0010 - val_activation_6_weighted_f1score: 1.4600e-04 - val_activation_7_accuracy: 0.2775 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.3048 - val_prob_macro_f1score: 0.0314 - val_prob_weighted_f1score: 0.0039\n",
      "Epoch 11/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.0380 - activation_6_loss: 1.7560 - activation_7_loss: 1.7806 - prob_loss: 1.7240 - activation_6_accuracy: 0.2797 - activation_6_macro_f1score: 0.0130 - activation_6_weighted_f1score: 0.0015 - activation_7_accuracy: 0.2651 - activation_7_macro_f1score: 0.0107 - activation_7_weighted_f1score: 0.0012 - prob_accuracy: 0.2944 - prob_macro_f1score: 0.0353 - prob_weighted_f1score: 0.0040 - val_loss: 3.0741 - val_activation_6_loss: 1.7099 - val_activation_7_loss: 1.7511 - val_prob_loss: 1.6828 - val_activation_6_accuracy: 0.2953 - val_activation_6_macro_f1score: 0.0264 - val_activation_6_weighted_f1score: 0.0031 - val_activation_7_accuracy: 0.2786 - val_activation_7_macro_f1score: 0.0000e+00 - val_activation_7_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2998 - val_prob_macro_f1score: 0.0478 - val_prob_weighted_f1score: 0.0056\n",
      "Epoch 12/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 3.0205 - activation_6_loss: 1.7414 - activation_7_loss: 1.7767 - prob_loss: 1.7158 - activation_6_accuracy: 0.2874 - activation_6_macro_f1score: 0.0233 - activation_6_weighted_f1score: 0.0027 - activation_7_accuracy: 0.2723 - activation_7_macro_f1score: 0.0140 - activation_7_weighted_f1score: 0.0015 - prob_accuracy: 0.2968 - prob_macro_f1score: 0.0379 - prob_weighted_f1score: 0.0043 - val_loss: 3.0462 - val_activation_6_loss: 1.6783 - val_activation_7_loss: 1.7305 - val_prob_loss: 1.6752 - val_activation_6_accuracy: 0.3096 - val_activation_6_macro_f1score: 0.0465 - val_activation_6_weighted_f1score: 0.0055 - val_activation_7_accuracy: 0.3001 - val_activation_7_macro_f1score: 0.0026 - val_activation_7_weighted_f1score: 3.5514e-04 - val_prob_accuracy: 0.3073 - val_prob_macro_f1score: 0.0469 - val_prob_weighted_f1score: 0.0057\n",
      "Epoch 13/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.9855 - activation_6_loss: 1.7213 - activation_7_loss: 1.7668 - prob_loss: 1.6934 - activation_6_accuracy: 0.2973 - activation_6_macro_f1score: 0.0363 - activation_6_weighted_f1score: 0.0041 - activation_7_accuracy: 0.2765 - activation_7_macro_f1score: 0.0224 - activation_7_weighted_f1score: 0.0025 - prob_accuracy: 0.3056 - prob_macro_f1score: 0.0504 - prob_weighted_f1score: 0.0056 - val_loss: 3.1005 - val_activation_6_loss: 1.7033 - val_activation_7_loss: 1.7295 - val_prob_loss: 1.7240 - val_activation_6_accuracy: 0.3018 - val_activation_6_macro_f1score: 0.0688 - val_activation_6_weighted_f1score: 0.0080 - val_activation_7_accuracy: 0.3082 - val_activation_7_macro_f1score: 0.0335 - val_activation_7_weighted_f1score: 0.0039 - val_prob_accuracy: 0.3043 - val_prob_macro_f1score: 0.0758 - val_prob_weighted_f1score: 0.0090\n",
      "Epoch 14/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.9680 - activation_6_loss: 1.7147 - activation_7_loss: 1.7630 - prob_loss: 1.6825 - activation_6_accuracy: 0.3023 - activation_6_macro_f1score: 0.0398 - activation_6_weighted_f1score: 0.0046 - activation_7_accuracy: 0.2780 - activation_7_macro_f1score: 0.0266 - activation_7_weighted_f1score: 0.0029 - prob_accuracy: 0.3105 - prob_macro_f1score: 0.0641 - prob_weighted_f1score: 0.0087 - val_loss: 3.0792 - val_activation_6_loss: 1.6715 - val_activation_7_loss: 1.7005 - val_prob_loss: 1.7251 - val_activation_6_accuracy: 0.3129 - val_activation_6_macro_f1score: 0.0747 - val_activation_6_weighted_f1score: 0.0090 - val_activation_7_accuracy: 0.3210 - val_activation_7_macro_f1score: 0.0538 - val_activation_7_weighted_f1score: 0.0064 - val_prob_accuracy: 0.3076 - val_prob_macro_f1score: 0.0805 - val_prob_weighted_f1score: 0.0102\n",
      "Epoch 15/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.9593 - activation_6_loss: 1.7095 - activation_7_loss: 1.7600 - prob_loss: 1.6796 - activation_6_accuracy: 0.3051 - activation_6_macro_f1score: 0.0502 - activation_6_weighted_f1score: 0.0068 - activation_7_accuracy: 0.2786 - activation_7_macro_f1score: 0.0275 - activation_7_weighted_f1score: 0.0030 - prob_accuracy: 0.3155 - prob_macro_f1score: 0.0789 - prob_weighted_f1score: 0.0128 - val_loss: 3.0057 - val_activation_6_loss: 1.6683 - val_activation_7_loss: 1.7288 - val_prob_loss: 1.6498 - val_activation_6_accuracy: 0.3031 - val_activation_6_macro_f1score: 0.0347 - val_activation_6_weighted_f1score: 0.0043 - val_activation_7_accuracy: 0.2887 - val_activation_7_macro_f1score: 0.0039 - val_activation_7_weighted_f1score: 5.0851e-04 - val_prob_accuracy: 0.3182 - val_prob_macro_f1score: 0.1140 - val_prob_weighted_f1score: 0.0229\n",
      "Epoch 16/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.9208 - activation_6_loss: 1.6911 - activation_7_loss: 1.7549 - prob_loss: 1.6512 - activation_6_accuracy: 0.3109 - activation_6_macro_f1score: 0.0671 - activation_6_weighted_f1score: 0.0107 - activation_7_accuracy: 0.2802 - activation_7_macro_f1score: 0.0279 - activation_7_weighted_f1score: 0.0031 - prob_accuracy: 0.3381 - prob_macro_f1score: 0.0997 - prob_weighted_f1score: 0.0176 - val_loss: 2.9310 - val_activation_6_loss: 1.6322 - val_activation_7_loss: 1.6930 - val_prob_loss: 1.6020 - val_activation_6_accuracy: 0.3477 - val_activation_6_macro_f1score: 0.0688 - val_activation_6_weighted_f1score: 0.0096 - val_activation_7_accuracy: 0.3121 - val_activation_7_macro_f1score: 0.0201 - val_activation_7_weighted_f1score: 0.0023 - val_prob_accuracy: 0.3639 - val_prob_macro_f1score: 0.1027 - val_prob_weighted_f1score: 0.0157\n",
      "Epoch 17/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.8865 - activation_6_loss: 1.6767 - activation_7_loss: 1.7476 - prob_loss: 1.6262 - activation_6_accuracy: 0.3247 - activation_6_macro_f1score: 0.0801 - activation_6_weighted_f1score: 0.0136 - activation_7_accuracy: 0.2806 - activation_7_macro_f1score: 0.0342 - activation_7_weighted_f1score: 0.0046 - prob_accuracy: 0.3503 - prob_macro_f1score: 0.1158 - prob_weighted_f1score: 0.0207 - val_loss: 2.9555 - val_activation_6_loss: 1.6420 - val_activation_7_loss: 1.6823 - val_prob_loss: 1.6286 - val_activation_6_accuracy: 0.3508 - val_activation_6_macro_f1score: 0.0885 - val_activation_6_weighted_f1score: 0.0124 - val_activation_7_accuracy: 0.3218 - val_activation_7_macro_f1score: 0.0380 - val_activation_7_weighted_f1score: 0.0046 - val_prob_accuracy: 0.3553 - val_prob_macro_f1score: 0.1100 - val_prob_weighted_f1score: 0.0173\n",
      "Epoch 18/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.8549 - activation_6_loss: 1.6626 - activation_7_loss: 1.7395 - prob_loss: 1.6039 - activation_6_accuracy: 0.3341 - activation_6_macro_f1score: 0.0907 - activation_6_weighted_f1score: 0.0164 - activation_7_accuracy: 0.2851 - activation_7_macro_f1score: 0.0435 - activation_7_weighted_f1score: 0.0067 - prob_accuracy: 0.3672 - prob_macro_f1score: 0.1240 - prob_weighted_f1score: 0.0228 - val_loss: 2.8372 - val_activation_6_loss: 1.5992 - val_activation_7_loss: 1.6673 - val_prob_loss: 1.5341 - val_activation_6_accuracy: 0.3683 - val_activation_6_macro_f1score: 0.1118 - val_activation_6_weighted_f1score: 0.0183 - val_activation_7_accuracy: 0.3213 - val_activation_7_macro_f1score: 0.0206 - val_activation_7_weighted_f1score: 0.0025 - val_prob_accuracy: 0.4115 - val_prob_macro_f1score: 0.1163 - val_prob_weighted_f1score: 0.0219\n",
      "Epoch 19/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.8447 - activation_6_loss: 1.6652 - activation_7_loss: 1.7341 - prob_loss: 1.5970 - activation_6_accuracy: 0.3368 - activation_6_macro_f1score: 0.0909 - activation_6_weighted_f1score: 0.0166 - activation_7_accuracy: 0.2848 - activation_7_macro_f1score: 0.0530 - activation_7_weighted_f1score: 0.0094 - prob_accuracy: 0.3718 - prob_macro_f1score: 0.1233 - prob_weighted_f1score: 0.0229 - val_loss: 2.8062 - val_activation_6_loss: 1.5770 - val_activation_7_loss: 1.6463 - val_prob_loss: 1.5195 - val_activation_6_accuracy: 0.3853 - val_activation_6_macro_f1score: 0.1235 - val_activation_6_weighted_f1score: 0.0223 - val_activation_7_accuracy: 0.3324 - val_activation_7_macro_f1score: 0.0161 - val_activation_7_weighted_f1score: 0.0020 - val_prob_accuracy: 0.3979 - val_prob_macro_f1score: 0.1442 - val_prob_weighted_f1score: 0.0268\n",
      "Epoch 20/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.7994 - activation_6_loss: 1.6399 - activation_7_loss: 1.7236 - prob_loss: 1.5650 - activation_6_accuracy: 0.3507 - activation_6_macro_f1score: 0.1034 - activation_6_weighted_f1score: 0.0195 - activation_7_accuracy: 0.2890 - activation_7_macro_f1score: 0.0671 - activation_7_weighted_f1score: 0.0125 - prob_accuracy: 0.3884 - prob_macro_f1score: 0.1377 - prob_weighted_f1score: 0.0257 - val_loss: 2.7943 - val_activation_6_loss: 1.5718 - val_activation_7_loss: 1.6477 - val_prob_loss: 1.5116 - val_activation_6_accuracy: 0.3904 - val_activation_6_macro_f1score: 0.1384 - val_activation_6_weighted_f1score: 0.0245 - val_activation_7_accuracy: 0.3332 - val_activation_7_macro_f1score: 0.0498 - val_activation_7_weighted_f1score: 0.0086 - val_prob_accuracy: 0.4160 - val_prob_macro_f1score: 0.1567 - val_prob_weighted_f1score: 0.0283\n",
      "Epoch 21/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.7766 - activation_6_loss: 1.6298 - activation_7_loss: 1.7154 - prob_loss: 1.5500 - activation_6_accuracy: 0.3526 - activation_6_macro_f1score: 0.1083 - activation_6_weighted_f1score: 0.0207 - activation_7_accuracy: 0.2898 - activation_7_macro_f1score: 0.0741 - activation_7_weighted_f1score: 0.0140 - prob_accuracy: 0.3918 - prob_macro_f1score: 0.1422 - prob_weighted_f1score: 0.0267 - val_loss: 2.7554 - val_activation_6_loss: 1.5492 - val_activation_7_loss: 1.6256 - val_prob_loss: 1.4898 - val_activation_6_accuracy: 0.4154 - val_activation_6_macro_f1score: 0.1338 - val_activation_6_weighted_f1score: 0.0250 - val_activation_7_accuracy: 0.3444 - val_activation_7_macro_f1score: 0.0788 - val_activation_7_weighted_f1score: 0.0156 - val_prob_accuracy: 0.4177 - val_prob_macro_f1score: 0.1524 - val_prob_weighted_f1score: 0.0286\n",
      "Epoch 22/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.7494 - activation_6_loss: 1.6133 - activation_7_loss: 1.7072 - prob_loss: 1.5326 - activation_6_accuracy: 0.3619 - activation_6_macro_f1score: 0.1149 - activation_6_weighted_f1score: 0.0221 - activation_7_accuracy: 0.2926 - activation_7_macro_f1score: 0.0766 - activation_7_weighted_f1score: 0.0149 - prob_accuracy: 0.3991 - prob_macro_f1score: 0.1473 - prob_weighted_f1score: 0.0277 - val_loss: 2.7395 - val_activation_6_loss: 1.5381 - val_activation_7_loss: 1.6170 - val_prob_loss: 1.4827 - val_activation_6_accuracy: 0.4029 - val_activation_6_macro_f1score: 0.1464 - val_activation_6_weighted_f1score: 0.0262 - val_activation_7_accuracy: 0.3477 - val_activation_7_macro_f1score: 0.0894 - val_activation_7_weighted_f1score: 0.0170 - val_prob_accuracy: 0.4232 - val_prob_macro_f1score: 0.1613 - val_prob_weighted_f1score: 0.0289\n",
      "Epoch 23/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.7261 - activation_6_loss: 1.6016 - activation_7_loss: 1.6985 - prob_loss: 1.5177 - activation_6_accuracy: 0.3681 - activation_6_macro_f1score: 0.1198 - activation_6_weighted_f1score: 0.0229 - activation_7_accuracy: 0.2935 - activation_7_macro_f1score: 0.0873 - activation_7_weighted_f1score: 0.0168 - prob_accuracy: 0.4045 - prob_macro_f1score: 0.1518 - prob_weighted_f1score: 0.0285 - val_loss: 2.7039 - val_activation_6_loss: 1.5364 - val_activation_7_loss: 1.6009 - val_prob_loss: 1.4559 - val_activation_6_accuracy: 0.3957 - val_activation_6_macro_f1score: 0.1437 - val_activation_6_weighted_f1score: 0.0249 - val_activation_7_accuracy: 0.3706 - val_activation_7_macro_f1score: 0.1021 - val_activation_7_weighted_f1score: 0.0181 - val_prob_accuracy: 0.4280 - val_prob_macro_f1score: 0.1664 - val_prob_weighted_f1score: 0.0297\n",
      "Epoch 24/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.7058 - activation_6_loss: 1.5902 - activation_7_loss: 1.6933 - prob_loss: 1.5047 - activation_6_accuracy: 0.3725 - activation_6_macro_f1score: 0.1226 - activation_6_weighted_f1score: 0.0236 - activation_7_accuracy: 0.2952 - activation_7_macro_f1score: 0.0910 - activation_7_weighted_f1score: 0.0181 - prob_accuracy: 0.4130 - prob_macro_f1score: 0.1544 - prob_weighted_f1score: 0.0290 - val_loss: 2.6868 - val_activation_6_loss: 1.4940 - val_activation_7_loss: 1.5957 - val_prob_loss: 1.4559 - val_activation_6_accuracy: 0.4135 - val_activation_6_macro_f1score: 0.1489 - val_activation_6_weighted_f1score: 0.0299 - val_activation_7_accuracy: 0.3235 - val_activation_7_macro_f1score: 0.1047 - val_activation_7_weighted_f1score: 0.0248 - val_prob_accuracy: 0.4238 - val_prob_macro_f1score: 0.1555 - val_prob_weighted_f1score: 0.0316\n",
      "Epoch 25/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.6893 - activation_6_loss: 1.5778 - activation_7_loss: 1.6919 - prob_loss: 1.4946 - activation_6_accuracy: 0.3810 - activation_6_macro_f1score: 0.1291 - activation_6_weighted_f1score: 0.0247 - activation_7_accuracy: 0.2972 - activation_7_macro_f1score: 0.0908 - activation_7_weighted_f1score: 0.0182 - prob_accuracy: 0.4171 - prob_macro_f1score: 0.1574 - prob_weighted_f1score: 0.0299 - val_loss: 2.6971 - val_activation_6_loss: 1.5139 - val_activation_7_loss: 1.5880 - val_prob_loss: 1.4646 - val_activation_6_accuracy: 0.3968 - val_activation_6_macro_f1score: 0.1535 - val_activation_6_weighted_f1score: 0.0300 - val_activation_7_accuracy: 0.3650 - val_activation_7_macro_f1score: 0.1006 - val_activation_7_weighted_f1score: 0.0229 - val_prob_accuracy: 0.4338 - val_prob_macro_f1score: 0.1628 - val_prob_weighted_f1score: 0.0316\n",
      "Epoch 26/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.6778 - activation_6_loss: 1.5744 - activation_7_loss: 1.6930 - prob_loss: 1.4859 - activation_6_accuracy: 0.3819 - activation_6_macro_f1score: 0.1276 - activation_6_weighted_f1score: 0.0244 - activation_7_accuracy: 0.2980 - activation_7_macro_f1score: 0.0913 - activation_7_weighted_f1score: 0.0182 - prob_accuracy: 0.4180 - prob_macro_f1score: 0.1609 - prob_weighted_f1score: 0.0302 - val_loss: 2.8254 - val_activation_6_loss: 1.5888 - val_activation_7_loss: 1.6326 - val_prob_loss: 1.5548 - val_activation_6_accuracy: 0.3711 - val_activation_6_macro_f1score: 0.1267 - val_activation_6_weighted_f1score: 0.0274 - val_activation_7_accuracy: 0.3210 - val_activation_7_macro_f1score: 0.0919 - val_activation_7_weighted_f1score: 0.0220 - val_prob_accuracy: 0.4096 - val_prob_macro_f1score: 0.1383 - val_prob_weighted_f1score: 0.0291\n",
      "Epoch 27/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.6500 - activation_6_loss: 1.5558 - activation_7_loss: 1.6836 - prob_loss: 1.4686 - activation_6_accuracy: 0.3923 - activation_6_macro_f1score: 0.1371 - activation_6_weighted_f1score: 0.0262 - activation_7_accuracy: 0.2986 - activation_7_macro_f1score: 0.0964 - activation_7_weighted_f1score: 0.0195 - prob_accuracy: 0.4277 - prob_macro_f1score: 0.1638 - prob_weighted_f1score: 0.0310 - val_loss: 2.6813 - val_activation_6_loss: 1.5080 - val_activation_7_loss: 1.5979 - val_prob_loss: 1.4522 - val_activation_6_accuracy: 0.4210 - val_activation_6_macro_f1score: 0.1597 - val_activation_6_weighted_f1score: 0.0288 - val_activation_7_accuracy: 0.3912 - val_activation_7_macro_f1score: 0.1129 - val_activation_7_weighted_f1score: 0.0214 - val_prob_accuracy: 0.4497 - val_prob_macro_f1score: 0.1832 - val_prob_weighted_f1score: 0.0333\n",
      "Epoch 28/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.6350 - activation_6_loss: 1.5527 - activation_7_loss: 1.6767 - prob_loss: 1.4587 - activation_6_accuracy: 0.3938 - activation_6_macro_f1score: 0.1355 - activation_6_weighted_f1score: 0.0260 - activation_7_accuracy: 0.3035 - activation_7_macro_f1score: 0.1005 - activation_7_weighted_f1score: 0.0200 - prob_accuracy: 0.4307 - prob_macro_f1score: 0.1665 - prob_weighted_f1score: 0.0316 - val_loss: 2.5939 - val_activation_6_loss: 1.4612 - val_activation_7_loss: 1.5435 - val_prob_loss: 1.4001 - val_activation_6_accuracy: 0.4257 - val_activation_6_macro_f1score: 0.1701 - val_activation_6_weighted_f1score: 0.0317 - val_activation_7_accuracy: 0.3931 - val_activation_7_macro_f1score: 0.1365 - val_activation_7_weighted_f1score: 0.0270 - val_prob_accuracy: 0.4578 - val_prob_macro_f1score: 0.1870 - val_prob_weighted_f1score: 0.0356\n",
      "Epoch 29/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.6237 - activation_6_loss: 1.5462 - activation_7_loss: 1.6715 - prob_loss: 1.4528 - activation_6_accuracy: 0.3916 - activation_6_macro_f1score: 0.1382 - activation_6_weighted_f1score: 0.0264 - activation_7_accuracy: 0.3059 - activation_7_macro_f1score: 0.1043 - activation_7_weighted_f1score: 0.0204 - prob_accuracy: 0.4314 - prob_macro_f1score: 0.1704 - prob_weighted_f1score: 0.0320 - val_loss: 2.5655 - val_activation_6_loss: 1.4495 - val_activation_7_loss: 1.5334 - val_prob_loss: 1.3808 - val_activation_6_accuracy: 0.4425 - val_activation_6_macro_f1score: 0.1784 - val_activation_6_weighted_f1score: 0.0339 - val_activation_7_accuracy: 0.4277 - val_activation_7_macro_f1score: 0.1316 - val_activation_7_weighted_f1score: 0.0272 - val_prob_accuracy: 0.4728 - val_prob_macro_f1score: 0.2085 - val_prob_weighted_f1score: 0.0389\n",
      "Epoch 30/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.6138 - activation_6_loss: 1.5403 - activation_7_loss: 1.6724 - prob_loss: 1.4463 - activation_6_accuracy: 0.3950 - activation_6_macro_f1score: 0.1420 - activation_6_weighted_f1score: 0.0272 - activation_7_accuracy: 0.3073 - activation_7_macro_f1score: 0.1039 - activation_7_weighted_f1score: 0.0206 - prob_accuracy: 0.4378 - prob_macro_f1score: 0.1755 - prob_weighted_f1score: 0.0331 - val_loss: 2.6269 - val_activation_6_loss: 1.4712 - val_activation_7_loss: 1.5806 - val_prob_loss: 1.4216 - val_activation_6_accuracy: 0.4252 - val_activation_6_macro_f1score: 0.1518 - val_activation_6_weighted_f1score: 0.0281 - val_activation_7_accuracy: 0.4071 - val_activation_7_macro_f1score: 0.0909 - val_activation_7_weighted_f1score: 0.0187 - val_prob_accuracy: 0.4664 - val_prob_macro_f1score: 0.1651 - val_prob_weighted_f1score: 0.0297\n",
      "Epoch 31/50\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.5917 - activation_6_loss: 1.5246 - activation_7_loss: 1.6615 - prob_loss: 1.4340 - activation_6_accuracy: 0.3963 - activation_6_macro_f1score: 0.1449 - activation_6_weighted_f1score: 0.0281 - activation_7_accuracy: 0.3143 - activation_7_macro_f1score: 0.1059 - activation_7_weighted_f1score: 0.0212 - prob_accuracy: 0.4423 - prob_macro_f1score: 0.1772 - prob_weighted_f1score: 0.0335 - val_loss: 2.6171 - val_activation_6_loss: 1.4701 - val_activation_7_loss: 1.5394 - val_prob_loss: 1.4265 - val_activation_6_accuracy: 0.4216 - val_activation_6_macro_f1score: 0.1594 - val_activation_6_weighted_f1score: 0.0332 - val_activation_7_accuracy: 0.3862 - val_activation_7_macro_f1score: 0.1148 - val_activation_7_weighted_f1score: 0.0280 - val_prob_accuracy: 0.4483 - val_prob_macro_f1score: 0.1777 - val_prob_weighted_f1score: 0.0356\n",
      "Epoch 32/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.5746 - activation_6_loss: 1.5172 - activation_7_loss: 1.6622 - prob_loss: 1.4208 - activation_6_accuracy: 0.4030 - activation_6_macro_f1score: 0.1460 - activation_6_weighted_f1score: 0.0282 - activation_7_accuracy: 0.3150 - activation_7_macro_f1score: 0.1061 - activation_7_weighted_f1score: 0.0213 - prob_accuracy: 0.4472 - prob_macro_f1score: 0.1825 - prob_weighted_f1score: 0.0343 - val_loss: 2.5427 - val_activation_6_loss: 1.4107 - val_activation_7_loss: 1.5319 - val_prob_loss: 1.3766 - val_activation_6_accuracy: 0.4505 - val_activation_6_macro_f1score: 0.1707 - val_activation_6_weighted_f1score: 0.0326 - val_activation_7_accuracy: 0.4260 - val_activation_7_macro_f1score: 0.1269 - val_activation_7_weighted_f1score: 0.0254 - val_prob_accuracy: 0.4427 - val_prob_macro_f1score: 0.2055 - val_prob_weighted_f1score: 0.0374\n",
      "Epoch 33/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.5517 - activation_6_loss: 1.5035 - activation_7_loss: 1.6492 - prob_loss: 1.4077 - activation_6_accuracy: 0.4098 - activation_6_macro_f1score: 0.1523 - activation_6_weighted_f1score: 0.0292 - activation_7_accuracy: 0.3189 - activation_7_macro_f1score: 0.1113 - activation_7_weighted_f1score: 0.0221 - prob_accuracy: 0.4544 - prob_macro_f1score: 0.1886 - prob_weighted_f1score: 0.0352 - val_loss: 2.5495 - val_activation_6_loss: 1.4457 - val_activation_7_loss: 1.5560 - val_prob_loss: 1.3671 - val_activation_6_accuracy: 0.4492 - val_activation_6_macro_f1score: 0.1782 - val_activation_6_weighted_f1score: 0.0329 - val_activation_7_accuracy: 0.4140 - val_activation_7_macro_f1score: 0.1175 - val_activation_7_weighted_f1score: 0.0239 - val_prob_accuracy: 0.4734 - val_prob_macro_f1score: 0.2126 - val_prob_weighted_f1score: 0.0388\n",
      "Epoch 34/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.5436 - activation_6_loss: 1.5025 - activation_7_loss: 1.6476 - prob_loss: 1.4021 - activation_6_accuracy: 0.4177 - activation_6_macro_f1score: 0.1505 - activation_6_weighted_f1score: 0.0291 - activation_7_accuracy: 0.3233 - activation_7_macro_f1score: 0.1097 - activation_7_weighted_f1score: 0.0219 - prob_accuracy: 0.4596 - prob_macro_f1score: 0.1943 - prob_weighted_f1score: 0.0364 - val_loss: 2.7589 - val_activation_6_loss: 1.5266 - val_activation_7_loss: 1.5900 - val_prob_loss: 1.5369 - val_activation_6_accuracy: 0.4274 - val_activation_6_macro_f1score: 0.1731 - val_activation_6_weighted_f1score: 0.0319 - val_activation_7_accuracy: 0.3619 - val_activation_7_macro_f1score: 0.1357 - val_activation_7_weighted_f1score: 0.0275 - val_prob_accuracy: 0.4338 - val_prob_macro_f1score: 0.2190 - val_prob_weighted_f1score: 0.0400\n",
      "Epoch 35/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.5305 - activation_6_loss: 1.4951 - activation_7_loss: 1.6359 - prob_loss: 1.3964 - activation_6_accuracy: 0.4154 - activation_6_macro_f1score: 0.1532 - activation_6_weighted_f1score: 0.0296 - activation_7_accuracy: 0.3251 - activation_7_macro_f1score: 0.1162 - activation_7_weighted_f1score: 0.0230 - prob_accuracy: 0.4596 - prob_macro_f1score: 0.1964 - prob_weighted_f1score: 0.0366 - val_loss: 2.6562 - val_activation_6_loss: 1.4644 - val_activation_7_loss: 1.5744 - val_prob_loss: 1.4626 - val_activation_6_accuracy: 0.4455 - val_activation_6_macro_f1score: 0.1595 - val_activation_6_weighted_f1score: 0.0316 - val_activation_7_accuracy: 0.4062 - val_activation_7_macro_f1score: 0.1112 - val_activation_7_weighted_f1score: 0.0252 - val_prob_accuracy: 0.4531 - val_prob_macro_f1score: 0.1774 - val_prob_weighted_f1score: 0.0349\n",
      "Epoch 36/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.5117 - activation_6_loss: 1.4864 - activation_7_loss: 1.6351 - prob_loss: 1.3821 - activation_6_accuracy: 0.4201 - activation_6_macro_f1score: 0.1562 - activation_6_weighted_f1score: 0.0300 - activation_7_accuracy: 0.3280 - activation_7_macro_f1score: 0.1168 - activation_7_weighted_f1score: 0.0232 - prob_accuracy: 0.4664 - prob_macro_f1score: 0.2033 - prob_weighted_f1score: 0.0379 - val_loss: 2.4630 - val_activation_6_loss: 1.3834 - val_activation_7_loss: 1.4953 - val_prob_loss: 1.3255 - val_activation_6_accuracy: 0.4597 - val_activation_6_macro_f1score: 0.1837 - val_activation_6_weighted_f1score: 0.0347 - val_activation_7_accuracy: 0.4216 - val_activation_7_macro_f1score: 0.1572 - val_activation_7_weighted_f1score: 0.0315 - val_prob_accuracy: 0.4879 - val_prob_macro_f1score: 0.2296 - val_prob_weighted_f1score: 0.0431\n",
      "Epoch 37/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.5010 - activation_6_loss: 1.4794 - activation_7_loss: 1.6361 - prob_loss: 1.3748 - activation_6_accuracy: 0.4219 - activation_6_macro_f1score: 0.1592 - activation_6_weighted_f1score: 0.0306 - activation_7_accuracy: 0.3278 - activation_7_macro_f1score: 0.1185 - activation_7_weighted_f1score: 0.0232 - prob_accuracy: 0.4669 - prob_macro_f1score: 0.2088 - prob_weighted_f1score: 0.0386 - val_loss: 2.4931 - val_activation_6_loss: 1.3975 - val_activation_7_loss: 1.4842 - val_prob_loss: 1.3551 - val_activation_6_accuracy: 0.4670 - val_activation_6_macro_f1score: 0.1748 - val_activation_6_weighted_f1score: 0.0327 - val_activation_7_accuracy: 0.4316 - val_activation_7_macro_f1score: 0.1552 - val_activation_7_weighted_f1score: 0.0299 - val_prob_accuracy: 0.4634 - val_prob_macro_f1score: 0.2559 - val_prob_weighted_f1score: 0.0458\n",
      "Epoch 38/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.4954 - activation_6_loss: 1.4763 - activation_7_loss: 1.6309 - prob_loss: 1.3731 - activation_6_accuracy: 0.4236 - activation_6_macro_f1score: 0.1586 - activation_6_weighted_f1score: 0.0304 - activation_7_accuracy: 0.3285 - activation_7_macro_f1score: 0.1210 - activation_7_weighted_f1score: 0.0234 - prob_accuracy: 0.4698 - prob_macro_f1score: 0.2121 - prob_weighted_f1score: 0.0391 - val_loss: 2.5387 - val_activation_6_loss: 1.4393 - val_activation_7_loss: 1.5280 - val_prob_loss: 1.3751 - val_activation_6_accuracy: 0.4636 - val_activation_6_macro_f1score: 0.1692 - val_activation_6_weighted_f1score: 0.0312 - val_activation_7_accuracy: 0.4205 - val_activation_7_macro_f1score: 0.1439 - val_activation_7_weighted_f1score: 0.0273 - val_prob_accuracy: 0.4815 - val_prob_macro_f1score: 0.1995 - val_prob_weighted_f1score: 0.0364\n",
      "Epoch 39/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.4802 - activation_6_loss: 1.4697 - activation_7_loss: 1.6307 - prob_loss: 1.3615 - activation_6_accuracy: 0.4276 - activation_6_macro_f1score: 0.1640 - activation_6_weighted_f1score: 0.0314 - activation_7_accuracy: 0.3291 - activation_7_macro_f1score: 0.1187 - activation_7_weighted_f1score: 0.0232 - prob_accuracy: 0.4723 - prob_macro_f1score: 0.2152 - prob_weighted_f1score: 0.0397 - val_loss: 2.5637 - val_activation_6_loss: 1.4375 - val_activation_7_loss: 1.5593 - val_prob_loss: 1.3920 - val_activation_6_accuracy: 0.4636 - val_activation_6_macro_f1score: 0.1464 - val_activation_6_weighted_f1score: 0.0287 - val_activation_7_accuracy: 0.4093 - val_activation_7_macro_f1score: 0.1027 - val_activation_7_weighted_f1score: 0.0214 - val_prob_accuracy: 0.4394 - val_prob_macro_f1score: 0.1991 - val_prob_weighted_f1score: 0.0364\n",
      "Epoch 40/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.4667 - activation_6_loss: 1.4618 - activation_7_loss: 1.6264 - prob_loss: 1.3533 - activation_6_accuracy: 0.4330 - activation_6_macro_f1score: 0.1647 - activation_6_weighted_f1score: 0.0317 - activation_7_accuracy: 0.3312 - activation_7_macro_f1score: 0.1223 - activation_7_weighted_f1score: 0.0239 - prob_accuracy: 0.4803 - prob_macro_f1score: 0.2190 - prob_weighted_f1score: 0.0402 - val_loss: 2.4854 - val_activation_6_loss: 1.4156 - val_activation_7_loss: 1.4962 - val_prob_loss: 1.3433 - val_activation_6_accuracy: 0.4639 - val_activation_6_macro_f1score: 0.1878 - val_activation_6_weighted_f1score: 0.0347 - val_activation_7_accuracy: 0.4369 - val_activation_7_macro_f1score: 0.1717 - val_activation_7_weighted_f1score: 0.0319 - val_prob_accuracy: 0.4976 - val_prob_macro_f1score: 0.2557 - val_prob_weighted_f1score: 0.0458\n",
      "Epoch 41/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.4481 - activation_6_loss: 1.4487 - activation_7_loss: 1.6179 - prob_loss: 1.3427 - activation_6_accuracy: 0.4399 - activation_6_macro_f1score: 0.1666 - activation_6_weighted_f1score: 0.0320 - activation_7_accuracy: 0.3397 - activation_7_macro_f1score: 0.1244 - activation_7_weighted_f1score: 0.0243 - prob_accuracy: 0.4846 - prob_macro_f1score: 0.2229 - prob_weighted_f1score: 0.0411 - val_loss: 2.3984 - val_activation_6_loss: 1.3505 - val_activation_7_loss: 1.4891 - val_prob_loss: 1.2824 - val_activation_6_accuracy: 0.4706 - val_activation_6_macro_f1score: 0.1810 - val_activation_6_weighted_f1score: 0.0346 - val_activation_7_accuracy: 0.4288 - val_activation_7_macro_f1score: 0.1433 - val_activation_7_weighted_f1score: 0.0292 - val_prob_accuracy: 0.4968 - val_prob_macro_f1score: 0.2469 - val_prob_weighted_f1score: 0.0457\n",
      "Epoch 42/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.4459 - activation_6_loss: 1.4463 - activation_7_loss: 1.6234 - prob_loss: 1.3411 - activation_6_accuracy: 0.4385 - activation_6_macro_f1score: 0.1690 - activation_6_weighted_f1score: 0.0324 - activation_7_accuracy: 0.3348 - activation_7_macro_f1score: 0.1238 - activation_7_weighted_f1score: 0.0242 - prob_accuracy: 0.4840 - prob_macro_f1score: 0.2267 - prob_weighted_f1score: 0.0418 - val_loss: 2.3853 - val_activation_6_loss: 1.3360 - val_activation_7_loss: 1.4573 - val_prob_loss: 1.2849 - val_activation_6_accuracy: 0.4765 - val_activation_6_macro_f1score: 0.1927 - val_activation_6_weighted_f1score: 0.0356 - val_activation_7_accuracy: 0.4344 - val_activation_7_macro_f1score: 0.1742 - val_activation_7_weighted_f1score: 0.0331 - val_prob_accuracy: 0.5046 - val_prob_macro_f1score: 0.2497 - val_prob_weighted_f1score: 0.0451\n",
      "Epoch 43/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.4236 - activation_6_loss: 1.4414 - activation_7_loss: 1.6115 - prob_loss: 1.3251 - activation_6_accuracy: 0.4470 - activation_6_macro_f1score: 0.1721 - activation_6_weighted_f1score: 0.0327 - activation_7_accuracy: 0.3404 - activation_7_macro_f1score: 0.1285 - activation_7_weighted_f1score: 0.0250 - prob_accuracy: 0.4927 - prob_macro_f1score: 0.2350 - prob_weighted_f1score: 0.0432 - val_loss: 2.3829 - val_activation_6_loss: 1.3436 - val_activation_7_loss: 1.4592 - val_prob_loss: 1.2812 - val_activation_6_accuracy: 0.4673 - val_activation_6_macro_f1score: 0.1877 - val_activation_6_weighted_f1score: 0.0360 - val_activation_7_accuracy: 0.4391 - val_activation_7_macro_f1score: 0.1696 - val_activation_7_weighted_f1score: 0.0321 - val_prob_accuracy: 0.4971 - val_prob_macro_f1score: 0.2484 - val_prob_weighted_f1score: 0.0464\n",
      "Epoch 44/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 2.4256 - activation_6_loss: 1.4408 - activation_7_loss: 1.6162 - prob_loss: 1.3273 - activation_6_accuracy: 0.4426 - activation_6_macro_f1score: 0.1732 - activation_6_weighted_f1score: 0.0332 - activation_7_accuracy: 0.3366 - activation_7_macro_f1score: 0.1247 - activation_7_weighted_f1score: 0.0245 - prob_accuracy: 0.4902 - prob_macro_f1score: 0.2344 - prob_weighted_f1score: 0.0431 - val_loss: 2.4110 - val_activation_6_loss: 1.3875 - val_activation_7_loss: 1.4735 - val_prob_loss: 1.2922 - val_activation_6_accuracy: 0.4675 - val_activation_6_macro_f1score: 0.1875 - val_activation_6_weighted_f1score: 0.0351 - val_activation_7_accuracy: 0.4394 - val_activation_7_macro_f1score: 0.1628 - val_activation_7_weighted_f1score: 0.0306 - val_prob_accuracy: 0.5032 - val_prob_macro_f1score: 0.2668 - val_prob_weighted_f1score: 0.0483\n",
      "Epoch 45/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.4120 - activation_6_loss: 1.4343 - activation_7_loss: 1.6156 - prob_loss: 1.3172 - activation_6_accuracy: 0.4476 - activation_6_macro_f1score: 0.1774 - activation_6_weighted_f1score: 0.0336 - activation_7_accuracy: 0.3380 - activation_7_macro_f1score: 0.1281 - activation_7_weighted_f1score: 0.0248 - prob_accuracy: 0.4966 - prob_macro_f1score: 0.2426 - prob_weighted_f1score: 0.0444 - val_loss: 2.4294 - val_activation_6_loss: 1.3518 - val_activation_7_loss: 1.4488 - val_prob_loss: 1.3293 - val_activation_6_accuracy: 0.4723 - val_activation_6_macro_f1score: 0.1949 - val_activation_6_weighted_f1score: 0.0374 - val_activation_7_accuracy: 0.4455 - val_activation_7_macro_f1score: 0.1828 - val_activation_7_weighted_f1score: 0.0351 - val_prob_accuracy: 0.4915 - val_prob_macro_f1score: 0.2501 - val_prob_weighted_f1score: 0.0468\n",
      "Epoch 46/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.4116 - activation_6_loss: 1.4319 - activation_7_loss: 1.6151 - prob_loss: 1.3187 - activation_6_accuracy: 0.4500 - activation_6_macro_f1score: 0.1774 - activation_6_weighted_f1score: 0.0338 - activation_7_accuracy: 0.3426 - activation_7_macro_f1score: 0.1262 - activation_7_weighted_f1score: 0.0247 - prob_accuracy: 0.4931 - prob_macro_f1score: 0.2408 - prob_weighted_f1score: 0.0442 - val_loss: 2.3970 - val_activation_6_loss: 1.3604 - val_activation_7_loss: 1.4538 - val_prob_loss: 1.2952 - val_activation_6_accuracy: 0.4642 - val_activation_6_macro_f1score: 0.1789 - val_activation_6_weighted_f1score: 0.0337 - val_activation_7_accuracy: 0.4369 - val_activation_7_macro_f1score: 0.1682 - val_activation_7_weighted_f1score: 0.0321 - val_prob_accuracy: 0.4968 - val_prob_macro_f1score: 0.2516 - val_prob_weighted_f1score: 0.0455\n",
      "Epoch 47/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.3989 - activation_6_loss: 1.4300 - activation_7_loss: 1.6034 - prob_loss: 1.3116 - activation_6_accuracy: 0.4483 - activation_6_macro_f1score: 0.1791 - activation_6_weighted_f1score: 0.0341 - activation_7_accuracy: 0.3435 - activation_7_macro_f1score: 0.1308 - activation_7_weighted_f1score: 0.0254 - prob_accuracy: 0.4996 - prob_macro_f1score: 0.2449 - prob_weighted_f1score: 0.0449 - val_loss: 2.3361 - val_activation_6_loss: 1.3144 - val_activation_7_loss: 1.4425 - val_prob_loss: 1.2548 - val_activation_6_accuracy: 0.4868 - val_activation_6_macro_f1score: 0.1939 - val_activation_6_weighted_f1score: 0.0368 - val_activation_7_accuracy: 0.4441 - val_activation_7_macro_f1score: 0.1625 - val_activation_7_weighted_f1score: 0.0327 - val_prob_accuracy: 0.5013 - val_prob_macro_f1score: 0.2774 - val_prob_weighted_f1score: 0.0507\n",
      "Epoch 48/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 2.3960 - activation_6_loss: 1.4247 - activation_7_loss: 1.6059 - prob_loss: 1.3106 - activation_6_accuracy: 0.4526 - activation_6_macro_f1score: 0.1810 - activation_6_weighted_f1score: 0.0346 - activation_7_accuracy: 0.3428 - activation_7_macro_f1score: 0.1292 - activation_7_weighted_f1score: 0.0252 - prob_accuracy: 0.4977 - prob_macro_f1score: 0.2458 - prob_weighted_f1score: 0.0452 - val_loss: 2.3896 - val_activation_6_loss: 1.3417 - val_activation_7_loss: 1.4569 - val_prob_loss: 1.2951 - val_activation_6_accuracy: 0.4876 - val_activation_6_macro_f1score: 0.1776 - val_activation_6_weighted_f1score: 0.0337 - val_activation_7_accuracy: 0.4550 - val_activation_7_macro_f1score: 0.1617 - val_activation_7_weighted_f1score: 0.0319 - val_prob_accuracy: 0.5052 - val_prob_macro_f1score: 0.2684 - val_prob_weighted_f1score: 0.0490\n",
      "Epoch 49/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.3843 - activation_6_loss: 1.4236 - activation_7_loss: 1.6098 - prob_loss: 1.2993 - activation_6_accuracy: 0.4549 - activation_6_macro_f1score: 0.1834 - activation_6_weighted_f1score: 0.0347 - activation_7_accuracy: 0.3372 - activation_7_macro_f1score: 0.1282 - activation_7_weighted_f1score: 0.0249 - prob_accuracy: 0.5039 - prob_macro_f1score: 0.2545 - prob_weighted_f1score: 0.0463 - val_loss: 2.3740 - val_activation_6_loss: 1.3405 - val_activation_7_loss: 1.4706 - val_prob_loss: 1.2776 - val_activation_6_accuracy: 0.4865 - val_activation_6_macro_f1score: 0.1925 - val_activation_6_weighted_f1score: 0.0364 - val_activation_7_accuracy: 0.4636 - val_activation_7_macro_f1score: 0.1538 - val_activation_7_weighted_f1score: 0.0301 - val_prob_accuracy: 0.5065 - val_prob_macro_f1score: 0.2426 - val_prob_weighted_f1score: 0.0448\n",
      "Epoch 50/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 2.3758 - activation_6_loss: 1.4169 - activation_7_loss: 1.6034 - prob_loss: 1.2959 - activation_6_accuracy: 0.4574 - activation_6_macro_f1score: 0.1853 - activation_6_weighted_f1score: 0.0352 - activation_7_accuracy: 0.3440 - activation_7_macro_f1score: 0.1283 - activation_7_weighted_f1score: 0.0253 - prob_accuracy: 0.5037 - prob_macro_f1score: 0.2594 - prob_weighted_f1score: 0.0475 - val_loss: 2.3754 - val_activation_6_loss: 1.3348 - val_activation_7_loss: 1.4698 - val_prob_loss: 1.2822 - val_activation_6_accuracy: 0.4815 - val_activation_6_macro_f1score: 0.1910 - val_activation_6_weighted_f1score: 0.0358 - val_activation_7_accuracy: 0.4408 - val_activation_7_macro_f1score: 0.1571 - val_activation_7_weighted_f1score: 0.0316 - val_prob_accuracy: 0.5032 - val_prob_macro_f1score: 0.2622 - val_prob_weighted_f1score: 0.0474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9aa9d3ccc0>"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_train_for_three(x_train,y_train), steps_per_epoch=len(x_train)/128, validation_data= generate_valid_for_three(x_valid,y_valid), validation_steps=len(x_valid)/128, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1505372,
     "status": "ok",
     "timestamp": 1583391856612,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "wGPJHnc-rFDS",
    "outputId": "32e705d7-2086-40b0-d32c-d74558814036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 3s 731us/sample - loss: 2.2604 - activation_6_loss: 1.3097 - activation_7_loss: 1.4406 - prob_loss: 1.2491 - activation_6_accuracy: 0.4922 - activation_6_macro_f1score: 0.2026 - activation_6_weighted_f1score: 0.0377 - activation_7_accuracy: 0.4504 - activation_7_macro_f1score: 0.1713 - activation_7_weighted_f1score: 0.0339 - prob_accuracy: 0.5117 - prob_macro_f1score: 0.2710 - prob_weighted_f1score: 0.0490\n",
      "\n",
      "Final Accuracy: 0.5117, Final Macro F1 Score: 0.2710, Final Weighted F1 Score: 0.0490\n"
     ]
    }
   ],
   "source": [
    "*_, acc, mac_f1, wei_f1 = model.evaluate(x_test,[y_test,y_test,y_test],batch_size=128)\n",
    "print(\"\\nFinal Accuracy: {:.4f}, Final Macro F1 Score: {:.4f}, Final Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "te4zwA0uDa23"
   },
   "source": [
    "### 2) Epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TJfn0lHxCfWz"
   },
   "outputs": [],
   "source": [
    "model = my_googlenet(input_shape=(48, 48, 3), classes=7, weights_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMw5bpxICfUh"
   },
   "outputs": [],
   "source": [
    "def decay(epoch, steps=100) : # learning rate decay를 하기 위해 정의한 함수. // step은 왜 100으로 정의하는지 자세히는 모르겠다... LearningRateScheduler에서 필요할지도 모름\n",
    "  initial_lrate=0.01\n",
    "  drop = 0.96\n",
    "  epochs_drop = 8\n",
    "  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop)) # math.pow 는 거듭제곱 계산으로, 여기서 drop^(math.floor~) 의 형태이다. 입출력이 모두 실수형(double)이다.\n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlJdKqS0Pf8m"
   },
   "outputs": [],
   "source": [
    "initial_lrate = 0.01\n",
    "lr_sc = LearningRateScheduler(decay,verbose=1)\n",
    "sgd = SGD(lr=initial_lrate , momentum=0.9 , nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LM3SIWcGrEp5"
   },
   "outputs": [],
   "source": [
    "# 편의를 위해 Adam으로 해보자.\n",
    "# auxiliary classifier는 regularization의 일종이다. (loss에서 가중치를 주어 계산하는 셈이기 때문.)\n",
    "model.compile(optimizer=sgd, loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], loss_weights=[0.3,0.3,1],\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1192325,
     "status": "ok",
     "timestamp": 1583394860488,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "_VAbHui3rEkm",
    "outputId": "d2842449-3ce2-4faa-a280-8f39f82a0bec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 39s 171ms/step - loss: 3.2558 - activation_8_loss: 1.8671 - activation_9_loss: 1.8849 - prob_loss: 1.8311 - activation_8_accuracy: 0.2383 - activation_8_macro_f1score: 0.0000e+00 - activation_8_weighted_f1score: 0.0000e+00 - activation_9_accuracy: 0.2484 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2475 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3350 - val_activation_8_loss: 1.8372 - val_activation_9_loss: 1.8564 - val_prob_loss: 1.8199 - val_activation_8_accuracy: 0.2449 - val_activation_8_macro_f1score: 0.0000e+00 - val_activation_8_weighted_f1score: 0.0000e+00 - val_activation_9_accuracy: 0.2449 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2449 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.2094 - activation_8_loss: 1.8346 - activation_9_loss: 1.8393 - prob_loss: 1.8135 - activation_8_accuracy: 0.2513 - activation_8_macro_f1score: 0.0000e+00 - activation_8_weighted_f1score: 0.0000e+00 - activation_9_accuracy: 0.2514 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2512 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2986 - val_activation_8_loss: 1.8154 - val_activation_9_loss: 1.8279 - val_prob_loss: 1.8051 - val_activation_8_accuracy: 0.2527 - val_activation_8_macro_f1score: 0.0000e+00 - val_activation_8_weighted_f1score: 0.0000e+00 - val_activation_9_accuracy: 0.2527 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2527 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 3.1904 - activation_8_loss: 1.8231 - activation_9_loss: 1.8252 - prob_loss: 1.8072 - activation_8_accuracy: 0.2511 - activation_8_macro_f1score: 0.0000e+00 - activation_8_weighted_f1score: 0.0000e+00 - activation_9_accuracy: 0.2514 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2514 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2932 - val_activation_8_loss: 1.8191 - val_activation_9_loss: 1.8288 - val_prob_loss: 1.8035 - val_activation_8_accuracy: 0.2474 - val_activation_8_macro_f1score: 0.0000e+00 - val_activation_8_weighted_f1score: 0.0000e+00 - val_activation_9_accuracy: 0.2474 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2474 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.1775 - activation_8_loss: 1.8188 - activation_9_loss: 1.8195 - prob_loss: 1.8022 - activation_8_accuracy: 0.2515 - activation_8_macro_f1score: 0.0000e+00 - activation_8_weighted_f1score: 0.0000e+00 - activation_9_accuracy: 0.2514 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2525 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3034 - val_activation_8_loss: 1.8137 - val_activation_9_loss: 1.8238 - val_prob_loss: 1.8212 - val_activation_8_accuracy: 0.2393 - val_activation_8_macro_f1score: 0.0000e+00 - val_activation_8_weighted_f1score: 0.0000e+00 - val_activation_9_accuracy: 0.2393 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2120 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.1597 - activation_8_loss: 1.8119 - activation_9_loss: 1.8154 - prob_loss: 1.7925 - activation_8_accuracy: 0.2507 - activation_8_macro_f1score: 0.0000e+00 - activation_8_weighted_f1score: 0.0000e+00 - activation_9_accuracy: 0.2514 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2533 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2721 - val_activation_8_loss: 1.8038 - val_activation_9_loss: 1.8136 - val_prob_loss: 1.8019 - val_activation_8_accuracy: 0.2499 - val_activation_8_macro_f1score: 0.0000e+00 - val_activation_8_weighted_f1score: 0.0000e+00 - val_activation_9_accuracy: 0.2499 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2510 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.1492 - activation_8_loss: 1.8067 - activation_9_loss: 1.8137 - prob_loss: 1.7888 - activation_8_accuracy: 0.2527 - activation_8_macro_f1score: 0.0000e+00 - activation_8_weighted_f1score: 0.0000e+00 - activation_9_accuracy: 0.2514 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2559 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2377 - val_activation_8_loss: 1.7954 - val_activation_9_loss: 1.8169 - val_prob_loss: 1.7747 - val_activation_8_accuracy: 0.2416 - val_activation_8_macro_f1score: 0.0000e+00 - val_activation_8_weighted_f1score: 0.0000e+00 - val_activation_9_accuracy: 0.2388 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2508 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.1229 - activation_8_loss: 1.7952 - activation_9_loss: 1.8106 - prob_loss: 1.7713 - activation_8_accuracy: 0.2547 - activation_8_macro_f1score: 7.9365e-05 - activation_8_weighted_f1score: 9.3006e-06 - activation_9_accuracy: 0.2514 - activation_9_macro_f1score: 0.0000e+00 - activation_9_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2636 - prob_macro_f1score: 0.0011 - prob_weighted_f1score: 1.0353e-04 - val_loss: 3.1964 - val_activation_8_loss: 1.7692 - val_activation_9_loss: 1.8019 - val_prob_loss: 1.7515 - val_activation_8_accuracy: 0.2600 - val_activation_8_macro_f1score: 0.0000e+00 - val_activation_8_weighted_f1score: 0.0000e+00 - val_activation_9_accuracy: 0.2430 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2714 - val_prob_macro_f1score: 0.0042 - val_prob_weighted_f1score: 4.4542e-04\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 3.0901 - activation_8_loss: 1.7750 - activation_9_loss: 1.8039 - prob_loss: 1.7507 - activation_8_accuracy: 0.2680 - activation_8_macro_f1score: 0.0061 - activation_8_weighted_f1score: 6.9829e-04 - activation_9_accuracy: 0.2526 - activation_9_macro_f1score: 7.0547e-05 - activation_9_weighted_f1score: 9.3695e-06 - prob_accuracy: 0.2810 - prob_macro_f1score: 0.0142 - prob_weighted_f1score: 0.0016 - val_loss: 3.1756 - val_activation_8_loss: 1.7591 - val_activation_9_loss: 1.7989 - val_prob_loss: 1.7394 - val_activation_8_accuracy: 0.2862 - val_activation_8_macro_f1score: 0.0243 - val_activation_8_weighted_f1score: 0.0030 - val_activation_9_accuracy: 0.2497 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2873 - val_prob_macro_f1score: 0.0542 - val_prob_weighted_f1score: 0.0065\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 3.0570 - activation_8_loss: 1.7563 - activation_9_loss: 1.7863 - prob_loss: 1.7326 - activation_8_accuracy: 0.2782 - activation_8_macro_f1score: 0.0227 - activation_8_weighted_f1score: 0.0025 - activation_9_accuracy: 0.2637 - activation_9_macro_f1score: 0.0087 - activation_9_weighted_f1score: 9.6934e-04 - prob_accuracy: 0.2875 - prob_macro_f1score: 0.0339 - prob_weighted_f1score: 0.0037 - val_loss: 3.1452 - val_activation_8_loss: 1.7329 - val_activation_9_loss: 1.7694 - val_prob_loss: 1.7306 - val_activation_8_accuracy: 0.2814 - val_activation_8_macro_f1score: 0.0201 - val_activation_8_weighted_f1score: 0.0023 - val_activation_9_accuracy: 0.2513 - val_activation_9_macro_f1score: 0.0000e+00 - val_activation_9_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2820 - val_prob_macro_f1score: 0.0395 - val_prob_weighted_f1score: 0.0043\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 3.0405 - activation_8_loss: 1.7481 - activation_9_loss: 1.7751 - prob_loss: 1.7259 - activation_8_accuracy: 0.2814 - activation_8_macro_f1score: 0.0310 - activation_8_weighted_f1score: 0.0035 - activation_9_accuracy: 0.2682 - activation_9_macro_f1score: 0.0158 - activation_9_weighted_f1score: 0.0018 - prob_accuracy: 0.2902 - prob_macro_f1score: 0.0389 - prob_weighted_f1score: 0.0043 - val_loss: 3.0725 - val_activation_8_loss: 1.6910 - val_activation_9_loss: 1.7153 - val_prob_loss: 1.6932 - val_activation_8_accuracy: 0.3093 - val_activation_8_macro_f1score: 0.0630 - val_activation_8_weighted_f1score: 0.0085 - val_activation_9_accuracy: 0.3045 - val_activation_9_macro_f1score: 0.0213 - val_activation_9_weighted_f1score: 0.0025 - val_prob_accuracy: 0.3001 - val_prob_macro_f1score: 0.0655 - val_prob_weighted_f1score: 0.0088\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 3.0177 - activation_8_loss: 1.7367 - activation_9_loss: 1.7652 - prob_loss: 1.7135 - activation_8_accuracy: 0.2856 - activation_8_macro_f1score: 0.0321 - activation_8_weighted_f1score: 0.0036 - activation_9_accuracy: 0.2743 - activation_9_macro_f1score: 0.0241 - activation_9_weighted_f1score: 0.0027 - prob_accuracy: 0.2949 - prob_macro_f1score: 0.0427 - prob_weighted_f1score: 0.0048 - val_loss: 3.1642 - val_activation_8_loss: 1.7324 - val_activation_9_loss: 1.7146 - val_prob_loss: 1.7735 - val_activation_8_accuracy: 0.2772 - val_activation_8_macro_f1score: 0.0700 - val_activation_8_weighted_f1score: 0.0092 - val_activation_9_accuracy: 0.2945 - val_activation_9_macro_f1score: 0.0594 - val_activation_9_weighted_f1score: 0.0078 - val_prob_accuracy: 0.2672 - val_prob_macro_f1score: 0.0732 - val_prob_weighted_f1score: 0.0096\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.9934 - activation_8_loss: 1.7271 - activation_9_loss: 1.7560 - prob_loss: 1.6986 - activation_8_accuracy: 0.2877 - activation_8_macro_f1score: 0.0347 - activation_8_weighted_f1score: 0.0039 - activation_9_accuracy: 0.2820 - activation_9_macro_f1score: 0.0294 - activation_9_weighted_f1score: 0.0033 - prob_accuracy: 0.3002 - prob_macro_f1score: 0.0502 - prob_weighted_f1score: 0.0057 - val_loss: 3.0674 - val_activation_8_loss: 1.7079 - val_activation_9_loss: 1.6989 - val_prob_loss: 1.6957 - val_activation_8_accuracy: 0.2931 - val_activation_8_macro_f1score: 0.0701 - val_activation_8_weighted_f1score: 0.0081 - val_activation_9_accuracy: 0.3059 - val_activation_9_macro_f1score: 0.0535 - val_activation_9_weighted_f1score: 0.0063 - val_prob_accuracy: 0.3043 - val_prob_macro_f1score: 0.0752 - val_prob_weighted_f1score: 0.0086\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.9655 - activation_8_loss: 1.7123 - activation_9_loss: 1.7465 - prob_loss: 1.6817 - activation_8_accuracy: 0.2932 - activation_8_macro_f1score: 0.0433 - activation_8_weighted_f1score: 0.0049 - activation_9_accuracy: 0.2848 - activation_9_macro_f1score: 0.0370 - activation_9_weighted_f1score: 0.0042 - prob_accuracy: 0.3061 - prob_macro_f1score: 0.0615 - prob_weighted_f1score: 0.0069 - val_loss: 3.0401 - val_activation_8_loss: 1.6858 - val_activation_9_loss: 1.7200 - val_prob_loss: 1.6732 - val_activation_8_accuracy: 0.3029 - val_activation_8_macro_f1score: 0.0489 - val_activation_8_weighted_f1score: 0.0057 - val_activation_9_accuracy: 0.2903 - val_activation_9_macro_f1score: 0.0196 - val_activation_9_weighted_f1score: 0.0022 - val_prob_accuracy: 0.3079 - val_prob_macro_f1score: 0.0589 - val_prob_weighted_f1score: 0.0069\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.9457 - activation_8_loss: 1.6980 - activation_9_loss: 1.7430 - prob_loss: 1.6708 - activation_8_accuracy: 0.3017 - activation_8_macro_f1score: 0.0494 - activation_8_weighted_f1score: 0.0056 - activation_9_accuracy: 0.2866 - activation_9_macro_f1score: 0.0417 - activation_9_weighted_f1score: 0.0046 - prob_accuracy: 0.3110 - prob_macro_f1score: 0.0652 - prob_weighted_f1score: 0.0073 - val_loss: 2.9962 - val_activation_8_loss: 1.6588 - val_activation_9_loss: 1.6746 - val_prob_loss: 1.6561 - val_activation_8_accuracy: 0.3129 - val_activation_8_macro_f1score: 0.0715 - val_activation_8_weighted_f1score: 0.0087 - val_activation_9_accuracy: 0.3140 - val_activation_9_macro_f1score: 0.0550 - val_activation_9_weighted_f1score: 0.0066 - val_prob_accuracy: 0.3168 - val_prob_macro_f1score: 0.0784 - val_prob_weighted_f1score: 0.0095\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.9347 - activation_8_loss: 1.6890 - activation_9_loss: 1.7468 - prob_loss: 1.6650 - activation_8_accuracy: 0.3043 - activation_8_macro_f1score: 0.0544 - activation_8_weighted_f1score: 0.0061 - activation_9_accuracy: 0.2850 - activation_9_macro_f1score: 0.0376 - activation_9_weighted_f1score: 0.0042 - prob_accuracy: 0.3129 - prob_macro_f1score: 0.0687 - prob_weighted_f1score: 0.0076 - val_loss: 3.0172 - val_activation_8_loss: 1.6917 - val_activation_9_loss: 1.6751 - val_prob_loss: 1.6700 - val_activation_8_accuracy: 0.2998 - val_activation_8_macro_f1score: 0.0843 - val_activation_8_weighted_f1score: 0.0101 - val_activation_9_accuracy: 0.3126 - val_activation_9_macro_f1score: 0.0666 - val_activation_9_weighted_f1score: 0.0078 - val_prob_accuracy: 0.3057 - val_prob_macro_f1score: 0.0879 - val_prob_weighted_f1score: 0.0104\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.9200 - activation_8_loss: 1.6872 - activation_9_loss: 1.7338 - prob_loss: 1.6582 - activation_8_accuracy: 0.3046 - activation_8_macro_f1score: 0.0559 - activation_8_weighted_f1score: 0.0062 - activation_9_accuracy: 0.2902 - activation_9_macro_f1score: 0.0431 - activation_9_weighted_f1score: 0.0048 - prob_accuracy: 0.3147 - prob_macro_f1score: 0.0680 - prob_weighted_f1score: 0.0076 - val_loss: 2.9692 - val_activation_8_loss: 1.6497 - val_activation_9_loss: 1.6751 - val_prob_loss: 1.6396 - val_activation_8_accuracy: 0.3193 - val_activation_8_macro_f1score: 0.0740 - val_activation_8_weighted_f1score: 0.0085 - val_activation_9_accuracy: 0.3188 - val_activation_9_macro_f1score: 0.0583 - val_activation_9_weighted_f1score: 0.0067 - val_prob_accuracy: 0.3179 - val_prob_macro_f1score: 0.0801 - val_prob_weighted_f1score: 0.0092\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.8969 - activation_8_loss: 1.6723 - activation_9_loss: 1.7295 - prob_loss: 1.6444 - activation_8_accuracy: 0.3082 - activation_8_macro_f1score: 0.0605 - activation_8_weighted_f1score: 0.0067 - activation_9_accuracy: 0.2908 - activation_9_macro_f1score: 0.0454 - activation_9_weighted_f1score: 0.0050 - prob_accuracy: 0.3203 - prob_macro_f1score: 0.0722 - prob_weighted_f1score: 0.0081 - val_loss: 3.0031 - val_activation_8_loss: 1.6604 - val_activation_9_loss: 1.6965 - val_prob_loss: 1.6662 - val_activation_8_accuracy: 0.3082 - val_activation_8_macro_f1score: 0.0680 - val_activation_8_weighted_f1score: 0.0079 - val_activation_9_accuracy: 0.3015 - val_activation_9_macro_f1score: 0.0457 - val_activation_9_weighted_f1score: 0.0052 - val_prob_accuracy: 0.3154 - val_prob_macro_f1score: 0.0737 - val_prob_weighted_f1score: 0.0086\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.8866 - activation_8_loss: 1.6714 - activation_9_loss: 1.7294 - prob_loss: 1.6377 - activation_8_accuracy: 0.3116 - activation_8_macro_f1score: 0.0607 - activation_8_weighted_f1score: 0.0068 - activation_9_accuracy: 0.2919 - activation_9_macro_f1score: 0.0439 - activation_9_weighted_f1score: 0.0050 - prob_accuracy: 0.3227 - prob_macro_f1score: 0.0733 - prob_weighted_f1score: 0.0082 - val_loss: 2.9818 - val_activation_8_loss: 1.6594 - val_activation_9_loss: 1.6715 - val_prob_loss: 1.6568 - val_activation_8_accuracy: 0.3238 - val_activation_8_macro_f1score: 0.0813 - val_activation_8_weighted_f1score: 0.0096 - val_activation_9_accuracy: 0.3227 - val_activation_9_macro_f1score: 0.0730 - val_activation_9_weighted_f1score: 0.0087 - val_prob_accuracy: 0.3318 - val_prob_macro_f1score: 0.0851 - val_prob_weighted_f1score: 0.0100\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.8723 - activation_8_loss: 1.6657 - activation_9_loss: 1.7246 - prob_loss: 1.6299 - activation_8_accuracy: 0.3144 - activation_8_macro_f1score: 0.0599 - activation_8_weighted_f1score: 0.0067 - activation_9_accuracy: 0.2961 - activation_9_macro_f1score: 0.0472 - activation_9_weighted_f1score: 0.0053 - prob_accuracy: 0.3342 - prob_macro_f1score: 0.0744 - prob_weighted_f1score: 0.0085 - val_loss: 2.9136 - val_activation_8_loss: 1.6301 - val_activation_9_loss: 1.6749 - val_prob_loss: 1.6018 - val_activation_8_accuracy: 0.3229 - val_activation_8_macro_f1score: 0.0767 - val_activation_8_weighted_f1score: 0.0089 - val_activation_9_accuracy: 0.3123 - val_activation_9_macro_f1score: 0.0445 - val_activation_9_weighted_f1score: 0.0050 - val_prob_accuracy: 0.3449 - val_prob_macro_f1score: 0.0830 - val_prob_weighted_f1score: 0.0109\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.8648 - activation_8_loss: 1.6594 - activation_9_loss: 1.7248 - prob_loss: 1.6273 - activation_8_accuracy: 0.3196 - activation_8_macro_f1score: 0.0649 - activation_8_weighted_f1score: 0.0074 - activation_9_accuracy: 0.2943 - activation_9_macro_f1score: 0.0446 - activation_9_weighted_f1score: 0.0049 - prob_accuracy: 0.3385 - prob_macro_f1score: 0.0801 - prob_weighted_f1score: 0.0103 - val_loss: 2.9862 - val_activation_8_loss: 1.6936 - val_activation_9_loss: 1.6613 - val_prob_loss: 1.6598 - val_activation_8_accuracy: 0.3151 - val_activation_8_macro_f1score: 0.0827 - val_activation_8_weighted_f1score: 0.0092 - val_activation_9_accuracy: 0.3201 - val_activation_9_macro_f1score: 0.0780 - val_activation_9_weighted_f1score: 0.0086 - val_prob_accuracy: 0.3318 - val_prob_macro_f1score: 0.0891 - val_prob_weighted_f1score: 0.0106\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.8261 - activation_8_loss: 1.6511 - activation_9_loss: 1.7109 - prob_loss: 1.5980 - activation_8_accuracy: 0.3234 - activation_8_macro_f1score: 0.0737 - activation_8_weighted_f1score: 0.0098 - activation_9_accuracy: 0.2985 - activation_9_macro_f1score: 0.0542 - activation_9_weighted_f1score: 0.0069 - prob_accuracy: 0.3568 - prob_macro_f1score: 0.1172 - prob_weighted_f1score: 0.0192 - val_loss: 2.8292 - val_activation_8_loss: 1.5834 - val_activation_9_loss: 1.6270 - val_prob_loss: 1.5541 - val_activation_8_accuracy: 0.3427 - val_activation_8_macro_f1score: 0.0851 - val_activation_8_weighted_f1score: 0.0115 - val_activation_9_accuracy: 0.3282 - val_activation_9_macro_f1score: 0.0660 - val_activation_9_weighted_f1score: 0.0073 - val_prob_accuracy: 0.3795 - val_prob_macro_f1score: 0.1499 - val_prob_weighted_f1score: 0.0279\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.8041 - activation_8_loss: 1.6373 - activation_9_loss: 1.7117 - prob_loss: 1.5824 - activation_8_accuracy: 0.3365 - activation_8_macro_f1score: 0.0915 - activation_8_weighted_f1score: 0.0142 - activation_9_accuracy: 0.2970 - activation_9_macro_f1score: 0.0617 - activation_9_weighted_f1score: 0.0094 - prob_accuracy: 0.3699 - prob_macro_f1score: 0.1333 - prob_weighted_f1score: 0.0233 - val_loss: 2.9239 - val_activation_8_loss: 1.5922 - val_activation_9_loss: 1.6241 - val_prob_loss: 1.6463 - val_activation_8_accuracy: 0.3728 - val_activation_8_macro_f1score: 0.1370 - val_activation_8_weighted_f1score: 0.0236 - val_activation_9_accuracy: 0.3330 - val_activation_9_macro_f1score: 0.0691 - val_activation_9_weighted_f1score: 0.0085 - val_prob_accuracy: 0.3541 - val_prob_macro_f1score: 0.1451 - val_prob_weighted_f1score: 0.0255\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.7634 - activation_8_loss: 1.6169 - activation_9_loss: 1.7000 - prob_loss: 1.5535 - activation_8_accuracy: 0.3481 - activation_8_macro_f1score: 0.1079 - activation_8_weighted_f1score: 0.0182 - activation_9_accuracy: 0.2981 - activation_9_macro_f1score: 0.0806 - activation_9_weighted_f1score: 0.0139 - prob_accuracy: 0.3815 - prob_macro_f1score: 0.1411 - prob_weighted_f1score: 0.0254 - val_loss: 2.7885 - val_activation_8_loss: 1.5463 - val_activation_9_loss: 1.6053 - val_prob_loss: 1.5369 - val_activation_8_accuracy: 0.3631 - val_activation_8_macro_f1score: 0.1576 - val_activation_8_weighted_f1score: 0.0295 - val_activation_9_accuracy: 0.3107 - val_activation_9_macro_f1score: 0.0997 - val_activation_9_weighted_f1score: 0.0182 - val_prob_accuracy: 0.3867 - val_prob_macro_f1score: 0.1604 - val_prob_weighted_f1score: 0.0308\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.7258 - activation_8_loss: 1.5928 - activation_9_loss: 1.6878 - prob_loss: 1.5289 - activation_8_accuracy: 0.3677 - activation_8_macro_f1score: 0.1244 - activation_8_weighted_f1score: 0.0225 - activation_9_accuracy: 0.2985 - activation_9_macro_f1score: 0.0948 - activation_9_weighted_f1score: 0.0174 - prob_accuracy: 0.3938 - prob_macro_f1score: 0.1519 - prob_weighted_f1score: 0.0279 - val_loss: 2.7969 - val_activation_8_loss: 1.5731 - val_activation_9_loss: 1.6032 - val_prob_loss: 1.5398 - val_activation_8_accuracy: 0.4004 - val_activation_8_macro_f1score: 0.1478 - val_activation_8_weighted_f1score: 0.0257 - val_activation_9_accuracy: 0.3483 - val_activation_9_macro_f1score: 0.1286 - val_activation_9_weighted_f1score: 0.0221 - val_prob_accuracy: 0.4004 - val_prob_macro_f1score: 0.1713 - val_prob_weighted_f1score: 0.0311\n",
      "Epoch 25/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.7125 - activation_8_loss: 1.5874 - activation_9_loss: 1.6863 - prob_loss: 1.5199 - activation_8_accuracy: 0.3710 - activation_8_macro_f1score: 0.1255 - activation_8_weighted_f1score: 0.0230 - activation_9_accuracy: 0.2985 - activation_9_macro_f1score: 0.0938 - activation_9_weighted_f1score: 0.0172 - prob_accuracy: 0.3974 - prob_macro_f1score: 0.1523 - prob_weighted_f1score: 0.0282 - val_loss: 2.6729 - val_activation_8_loss: 1.4997 - val_activation_9_loss: 1.5796 - val_prob_loss: 1.4511 - val_activation_8_accuracy: 0.4218 - val_activation_8_macro_f1score: 0.1570 - val_activation_8_weighted_f1score: 0.0282 - val_activation_9_accuracy: 0.3360 - val_activation_9_macro_f1score: 0.1086 - val_activation_9_weighted_f1score: 0.0187 - val_prob_accuracy: 0.4358 - val_prob_macro_f1score: 0.1654 - val_prob_weighted_f1score: 0.0302\n",
      "Epoch 26/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.6806 - activation_8_loss: 1.5695 - activation_9_loss: 1.6772 - prob_loss: 1.4981 - activation_8_accuracy: 0.3782 - activation_8_macro_f1score: 0.1311 - activation_8_weighted_f1score: 0.0243 - activation_9_accuracy: 0.3041 - activation_9_macro_f1score: 0.0998 - activation_9_weighted_f1score: 0.0183 - prob_accuracy: 0.4081 - prob_macro_f1score: 0.1569 - prob_weighted_f1score: 0.0294 - val_loss: 2.7101 - val_activation_8_loss: 1.5227 - val_activation_9_loss: 1.5573 - val_prob_loss: 1.4888 - val_activation_8_accuracy: 0.4260 - val_activation_8_macro_f1score: 0.1824 - val_activation_8_weighted_f1score: 0.0342 - val_activation_9_accuracy: 0.3558 - val_activation_9_macro_f1score: 0.1599 - val_activation_9_weighted_f1score: 0.0299 - val_prob_accuracy: 0.4363 - val_prob_macro_f1score: 0.1850 - val_prob_weighted_f1score: 0.0349\n",
      "Epoch 27/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.6482 - activation_8_loss: 1.5576 - activation_9_loss: 1.6727 - prob_loss: 1.4727 - activation_8_accuracy: 0.3897 - activation_8_macro_f1score: 0.1353 - activation_8_weighted_f1score: 0.0255 - activation_9_accuracy: 0.3044 - activation_9_macro_f1score: 0.0984 - activation_9_weighted_f1score: 0.0185 - prob_accuracy: 0.4231 - prob_macro_f1score: 0.1653 - prob_weighted_f1score: 0.0311 - val_loss: 2.6313 - val_activation_8_loss: 1.4604 - val_activation_9_loss: 1.5635 - val_prob_loss: 1.4317 - val_activation_8_accuracy: 0.4369 - val_activation_8_macro_f1score: 0.1784 - val_activation_8_weighted_f1score: 0.0336 - val_activation_9_accuracy: 0.3422 - val_activation_9_macro_f1score: 0.1076 - val_activation_9_weighted_f1score: 0.0201 - val_prob_accuracy: 0.4405 - val_prob_macro_f1score: 0.1690 - val_prob_weighted_f1score: 0.0318\n",
      "Epoch 28/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.6269 - activation_8_loss: 1.5426 - activation_9_loss: 1.6693 - prob_loss: 1.4589 - activation_8_accuracy: 0.3922 - activation_8_macro_f1score: 0.1381 - activation_8_weighted_f1score: 0.0264 - activation_9_accuracy: 0.3067 - activation_9_macro_f1score: 0.1007 - activation_9_weighted_f1score: 0.0191 - prob_accuracy: 0.4277 - prob_macro_f1score: 0.1692 - prob_weighted_f1score: 0.0319 - val_loss: 2.7626 - val_activation_8_loss: 1.5417 - val_activation_9_loss: 1.5199 - val_prob_loss: 1.5489 - val_activation_8_accuracy: 0.4143 - val_activation_8_macro_f1score: 0.1854 - val_activation_8_weighted_f1score: 0.0348 - val_activation_9_accuracy: 0.3678 - val_activation_9_macro_f1score: 0.1755 - val_activation_9_weighted_f1score: 0.0334 - val_prob_accuracy: 0.4296 - val_prob_macro_f1score: 0.2099 - val_prob_weighted_f1score: 0.0393\n",
      "Epoch 29/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.6152 - activation_8_loss: 1.5378 - activation_9_loss: 1.6695 - prob_loss: 1.4505 - activation_8_accuracy: 0.3983 - activation_8_macro_f1score: 0.1415 - activation_8_weighted_f1score: 0.0268 - activation_9_accuracy: 0.3074 - activation_9_macro_f1score: 0.0981 - activation_9_weighted_f1score: 0.0188 - prob_accuracy: 0.4357 - prob_macro_f1score: 0.1749 - prob_weighted_f1score: 0.0329 - val_loss: 2.6464 - val_activation_8_loss: 1.4657 - val_activation_9_loss: 1.5330 - val_prob_loss: 1.4577 - val_activation_8_accuracy: 0.4352 - val_activation_8_macro_f1score: 0.1786 - val_activation_8_weighted_f1score: 0.0330 - val_activation_9_accuracy: 0.3458 - val_activation_9_macro_f1score: 0.1443 - val_activation_9_weighted_f1score: 0.0267 - val_prob_accuracy: 0.4352 - val_prob_macro_f1score: 0.1840 - val_prob_weighted_f1score: 0.0341\n",
      "Epoch 30/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.5929 - activation_8_loss: 1.5278 - activation_9_loss: 1.6656 - prob_loss: 1.4344 - activation_8_accuracy: 0.3974 - activation_8_macro_f1score: 0.1442 - activation_8_weighted_f1score: 0.0275 - activation_9_accuracy: 0.3089 - activation_9_macro_f1score: 0.1022 - activation_9_weighted_f1score: 0.0193 - prob_accuracy: 0.4449 - prob_macro_f1score: 0.1823 - prob_weighted_f1score: 0.0341 - val_loss: 2.7107 - val_activation_8_loss: 1.5184 - val_activation_9_loss: 1.6158 - val_prob_loss: 1.4813 - val_activation_8_accuracy: 0.4271 - val_activation_8_macro_f1score: 0.1456 - val_activation_8_weighted_f1score: 0.0266 - val_activation_9_accuracy: 0.3252 - val_activation_9_macro_f1score: 0.0782 - val_activation_9_weighted_f1score: 0.0140 - val_prob_accuracy: 0.4380 - val_prob_macro_f1score: 0.1499 - val_prob_weighted_f1score: 0.0276\n",
      "Epoch 31/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.5703 - activation_8_loss: 1.5129 - activation_9_loss: 1.6575 - prob_loss: 1.4206 - activation_8_accuracy: 0.4032 - activation_8_macro_f1score: 0.1464 - activation_8_weighted_f1score: 0.0280 - activation_9_accuracy: 0.3096 - activation_9_macro_f1score: 0.1057 - activation_9_weighted_f1score: 0.0201 - prob_accuracy: 0.4500 - prob_macro_f1score: 0.1858 - prob_weighted_f1score: 0.0350 - val_loss: 2.6486 - val_activation_8_loss: 1.4757 - val_activation_9_loss: 1.5437 - val_prob_loss: 1.4574 - val_activation_8_accuracy: 0.4374 - val_activation_8_macro_f1score: 0.1878 - val_activation_8_weighted_f1score: 0.0360 - val_activation_9_accuracy: 0.3792 - val_activation_9_macro_f1score: 0.1567 - val_activation_9_weighted_f1score: 0.0288 - val_prob_accuracy: 0.4341 - val_prob_macro_f1score: 0.2013 - val_prob_weighted_f1score: 0.0387\n",
      "Epoch 32/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.5438 - activation_8_loss: 1.4999 - activation_9_loss: 1.6547 - prob_loss: 1.4007 - activation_8_accuracy: 0.4169 - activation_8_macro_f1score: 0.1501 - activation_8_weighted_f1score: 0.0286 - activation_9_accuracy: 0.3186 - activation_9_macro_f1score: 0.1068 - activation_9_weighted_f1score: 0.0201 - prob_accuracy: 0.4546 - prob_macro_f1score: 0.1955 - prob_weighted_f1score: 0.0367 - val_loss: 2.6592 - val_activation_8_loss: 1.5109 - val_activation_9_loss: 1.5454 - val_prob_loss: 1.4584 - val_activation_8_accuracy: 0.4199 - val_activation_8_macro_f1score: 0.1763 - val_activation_8_weighted_f1score: 0.0320 - val_activation_9_accuracy: 0.3670 - val_activation_9_macro_f1score: 0.1442 - val_activation_9_weighted_f1score: 0.0257 - val_prob_accuracy: 0.4308 - val_prob_macro_f1score: 0.2012 - val_prob_weighted_f1score: 0.0368\n",
      "Epoch 33/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 2.5558 - activation_8_loss: 1.5054 - activation_9_loss: 1.6555 - prob_loss: 1.4126 - activation_8_accuracy: 0.4132 - activation_8_macro_f1score: 0.1491 - activation_8_weighted_f1score: 0.0284 - activation_9_accuracy: 0.3157 - activation_9_macro_f1score: 0.1078 - activation_9_weighted_f1score: 0.0204 - prob_accuracy: 0.4519 - prob_macro_f1score: 0.1904 - prob_weighted_f1score: 0.0357 - val_loss: 2.5688 - val_activation_8_loss: 1.4254 - val_activation_9_loss: 1.4781 - val_prob_loss: 1.4186 - val_activation_8_accuracy: 0.4544 - val_activation_8_macro_f1score: 0.1887 - val_activation_8_weighted_f1score: 0.0359 - val_activation_9_accuracy: 0.3959 - val_activation_9_macro_f1score: 0.1769 - val_activation_9_weighted_f1score: 0.0346 - val_prob_accuracy: 0.4745 - val_prob_macro_f1score: 0.2363 - val_prob_weighted_f1score: 0.0439\n",
      "Epoch 34/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.5242 - activation_8_loss: 1.4934 - activation_9_loss: 1.6448 - prob_loss: 1.3897 - activation_8_accuracy: 0.4147 - activation_8_macro_f1score: 0.1530 - activation_8_weighted_f1score: 0.0294 - activation_9_accuracy: 0.3209 - activation_9_macro_f1score: 0.1094 - activation_9_weighted_f1score: 0.0211 - prob_accuracy: 0.4591 - prob_macro_f1score: 0.2029 - prob_weighted_f1score: 0.0381 - val_loss: 2.5503 - val_activation_8_loss: 1.4147 - val_activation_9_loss: 1.4941 - val_prob_loss: 1.4010 - val_activation_8_accuracy: 0.4570 - val_activation_8_macro_f1score: 0.1879 - val_activation_8_weighted_f1score: 0.0358 - val_activation_9_accuracy: 0.3954 - val_activation_9_macro_f1score: 0.1615 - val_activation_9_weighted_f1score: 0.0308 - val_prob_accuracy: 0.4578 - val_prob_macro_f1score: 0.2084 - val_prob_weighted_f1score: 0.0389\n",
      "Epoch 35/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.5102 - activation_8_loss: 1.4797 - activation_9_loss: 1.6458 - prob_loss: 1.3813 - activation_8_accuracy: 0.4225 - activation_8_macro_f1score: 0.1562 - activation_8_weighted_f1score: 0.0299 - activation_9_accuracy: 0.3225 - activation_9_macro_f1score: 0.1106 - activation_9_weighted_f1score: 0.0209 - prob_accuracy: 0.4657 - prob_macro_f1score: 0.2047 - prob_weighted_f1score: 0.0382 - val_loss: 2.4874 - val_activation_8_loss: 1.3984 - val_activation_9_loss: 1.5353 - val_prob_loss: 1.3346 - val_activation_8_accuracy: 0.4611 - val_activation_8_macro_f1score: 0.1768 - val_activation_8_weighted_f1score: 0.0330 - val_activation_9_accuracy: 0.3859 - val_activation_9_macro_f1score: 0.1304 - val_activation_9_weighted_f1score: 0.0248 - val_prob_accuracy: 0.4751 - val_prob_macro_f1score: 0.2478 - val_prob_weighted_f1score: 0.0452\n",
      "Epoch 36/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.4914 - activation_8_loss: 1.4738 - activation_9_loss: 1.6469 - prob_loss: 1.3658 - activation_8_accuracy: 0.4267 - activation_8_macro_f1score: 0.1554 - activation_8_weighted_f1score: 0.0299 - activation_9_accuracy: 0.3224 - activation_9_macro_f1score: 0.1072 - activation_9_weighted_f1score: 0.0210 - prob_accuracy: 0.4712 - prob_macro_f1score: 0.2107 - prob_weighted_f1score: 0.0396 - val_loss: 2.4730 - val_activation_8_loss: 1.4048 - val_activation_9_loss: 1.5271 - val_prob_loss: 1.3230 - val_activation_8_accuracy: 0.4695 - val_activation_8_macro_f1score: 0.1714 - val_activation_8_weighted_f1score: 0.0319 - val_activation_9_accuracy: 0.4207 - val_activation_9_macro_f1score: 0.1305 - val_activation_9_weighted_f1score: 0.0249 - val_prob_accuracy: 0.4882 - val_prob_macro_f1score: 0.2388 - val_prob_weighted_f1score: 0.0435\n",
      "Epoch 37/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.4874 - activation_8_loss: 1.4706 - activation_9_loss: 1.6409 - prob_loss: 1.3662 - activation_8_accuracy: 0.4243 - activation_8_macro_f1score: 0.1585 - activation_8_weighted_f1score: 0.0304 - activation_9_accuracy: 0.3245 - activation_9_macro_f1score: 0.1094 - activation_9_weighted_f1score: 0.0210 - prob_accuracy: 0.4680 - prob_macro_f1score: 0.2150 - prob_weighted_f1score: 0.0399 - val_loss: 2.4909 - val_activation_8_loss: 1.3882 - val_activation_9_loss: 1.4817 - val_prob_loss: 1.3605 - val_activation_8_accuracy: 0.4581 - val_activation_8_macro_f1score: 0.1787 - val_activation_8_weighted_f1score: 0.0358 - val_activation_9_accuracy: 0.3990 - val_activation_9_macro_f1score: 0.1553 - val_activation_9_weighted_f1score: 0.0321 - val_prob_accuracy: 0.4712 - val_prob_macro_f1score: 0.2195 - val_prob_weighted_f1score: 0.0422\n",
      "Epoch 38/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.4786 - activation_8_loss: 1.4611 - activation_9_loss: 1.6387 - prob_loss: 1.3626 - activation_8_accuracy: 0.4298 - activation_8_macro_f1score: 0.1613 - activation_8_weighted_f1score: 0.0309 - activation_9_accuracy: 0.3243 - activation_9_macro_f1score: 0.1121 - activation_9_weighted_f1score: 0.0215 - prob_accuracy: 0.4724 - prob_macro_f1score: 0.2128 - prob_weighted_f1score: 0.0399 - val_loss: 2.4404 - val_activation_8_loss: 1.3820 - val_activation_9_loss: 1.4872 - val_prob_loss: 1.3134 - val_activation_8_accuracy: 0.4792 - val_activation_8_macro_f1score: 0.1903 - val_activation_8_weighted_f1score: 0.0347 - val_activation_9_accuracy: 0.4113 - val_activation_9_macro_f1score: 0.1661 - val_activation_9_weighted_f1score: 0.0313 - val_prob_accuracy: 0.5001 - val_prob_macro_f1score: 0.2663 - val_prob_weighted_f1score: 0.0479\n",
      "Epoch 39/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.4465 - activation_8_loss: 1.4471 - activation_9_loss: 1.6201 - prob_loss: 1.3419 - activation_8_accuracy: 0.4406 - activation_8_macro_f1score: 0.1665 - activation_8_weighted_f1score: 0.0319 - activation_9_accuracy: 0.3272 - activation_9_macro_f1score: 0.1181 - activation_9_weighted_f1score: 0.0228 - prob_accuracy: 0.4847 - prob_macro_f1score: 0.2248 - prob_weighted_f1score: 0.0417 - val_loss: 2.4709 - val_activation_8_loss: 1.3909 - val_activation_9_loss: 1.4918 - val_prob_loss: 1.3406 - val_activation_8_accuracy: 0.4578 - val_activation_8_macro_f1score: 0.1819 - val_activation_8_weighted_f1score: 0.0352 - val_activation_9_accuracy: 0.3918 - val_activation_9_macro_f1score: 0.1569 - val_activation_9_weighted_f1score: 0.0323 - val_prob_accuracy: 0.4809 - val_prob_macro_f1score: 0.2472 - val_prob_weighted_f1score: 0.0461\n",
      "Epoch 40/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.4518 - activation_8_loss: 1.4486 - activation_9_loss: 1.6019 - prob_loss: 1.3536 - activation_8_accuracy: 0.4386 - activation_8_macro_f1score: 0.1658 - activation_8_weighted_f1score: 0.0317 - activation_9_accuracy: 0.3373 - activation_9_macro_f1score: 0.1236 - activation_9_weighted_f1score: 0.0243 - prob_accuracy: 0.4768 - prob_macro_f1score: 0.2212 - prob_weighted_f1score: 0.0408 - val_loss: 2.4627 - val_activation_8_loss: 1.3985 - val_activation_9_loss: 1.4663 - val_prob_loss: 1.3394 - val_activation_8_accuracy: 0.4661 - val_activation_8_macro_f1score: 0.1858 - val_activation_8_weighted_f1score: 0.0351 - val_activation_9_accuracy: 0.4296 - val_activation_9_macro_f1score: 0.1590 - val_activation_9_weighted_f1score: 0.0307 - val_prob_accuracy: 0.4857 - val_prob_macro_f1score: 0.2409 - val_prob_weighted_f1score: 0.0435\n",
      "Epoch 41/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.4395 - activation_8_loss: 1.4470 - activation_9_loss: 1.5909 - prob_loss: 1.3466 - activation_8_accuracy: 0.4380 - activation_8_macro_f1score: 0.1670 - activation_8_weighted_f1score: 0.0318 - activation_9_accuracy: 0.3491 - activation_9_macro_f1score: 0.1327 - activation_9_weighted_f1score: 0.0259 - prob_accuracy: 0.4802 - prob_macro_f1score: 0.2250 - prob_weighted_f1score: 0.0414 - val_loss: 2.4143 - val_activation_8_loss: 1.3607 - val_activation_9_loss: 1.4430 - val_prob_loss: 1.3124 - val_activation_8_accuracy: 0.4795 - val_activation_8_macro_f1score: 0.1802 - val_activation_8_weighted_f1score: 0.0343 - val_activation_9_accuracy: 0.4455 - val_activation_9_macro_f1score: 0.1658 - val_activation_9_weighted_f1score: 0.0319 - val_prob_accuracy: 0.4843 - val_prob_macro_f1score: 0.2374 - val_prob_weighted_f1score: 0.0430\n",
      "Epoch 42/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 2.4228 - activation_8_loss: 1.4433 - activation_9_loss: 1.5778 - prob_loss: 1.3362 - activation_8_accuracy: 0.4401 - activation_8_macro_f1score: 0.1666 - activation_8_weighted_f1score: 0.0321 - activation_9_accuracy: 0.3474 - activation_9_macro_f1score: 0.1316 - activation_9_weighted_f1score: 0.0261 - prob_accuracy: 0.4847 - prob_macro_f1score: 0.2289 - prob_weighted_f1score: 0.0424 - val_loss: 2.3761 - val_activation_8_loss: 1.3497 - val_activation_9_loss: 1.4325 - val_prob_loss: 1.2832 - val_activation_8_accuracy: 0.4787 - val_activation_8_macro_f1score: 0.1889 - val_activation_8_weighted_f1score: 0.0363 - val_activation_9_accuracy: 0.4492 - val_activation_9_macro_f1score: 0.1670 - val_activation_9_weighted_f1score: 0.0329 - val_prob_accuracy: 0.4985 - val_prob_macro_f1score: 0.2537 - val_prob_weighted_f1score: 0.0479\n",
      "Epoch 43/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.4129 - activation_8_loss: 1.4398 - activation_9_loss: 1.5812 - prob_loss: 1.3278 - activation_8_accuracy: 0.4399 - activation_8_macro_f1score: 0.1683 - activation_8_weighted_f1score: 0.0322 - activation_9_accuracy: 0.3488 - activation_9_macro_f1score: 0.1299 - activation_9_weighted_f1score: 0.0260 - prob_accuracy: 0.4892 - prob_macro_f1score: 0.2349 - prob_weighted_f1score: 0.0433 - val_loss: 2.3907 - val_activation_8_loss: 1.3575 - val_activation_9_loss: 1.4265 - val_prob_loss: 1.2982 - val_activation_8_accuracy: 0.4770 - val_activation_8_macro_f1score: 0.1842 - val_activation_8_weighted_f1score: 0.0353 - val_activation_9_accuracy: 0.4461 - val_activation_9_macro_f1score: 0.1675 - val_activation_9_weighted_f1score: 0.0329 - val_prob_accuracy: 0.5060 - val_prob_macro_f1score: 0.2660 - val_prob_weighted_f1score: 0.0492\n",
      "Epoch 44/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.3945 - activation_8_loss: 1.4263 - activation_9_loss: 1.5729 - prob_loss: 1.3173 - activation_8_accuracy: 0.4481 - activation_8_macro_f1score: 0.1735 - activation_8_weighted_f1score: 0.0331 - activation_9_accuracy: 0.3523 - activation_9_macro_f1score: 0.1343 - activation_9_weighted_f1score: 0.0266 - prob_accuracy: 0.4917 - prob_macro_f1score: 0.2390 - prob_weighted_f1score: 0.0438 - val_loss: 2.4054 - val_activation_8_loss: 1.3453 - val_activation_9_loss: 1.4373 - val_prob_loss: 1.3143 - val_activation_8_accuracy: 0.4854 - val_activation_8_macro_f1score: 0.1834 - val_activation_8_weighted_f1score: 0.0360 - val_activation_9_accuracy: 0.4464 - val_activation_9_macro_f1score: 0.1694 - val_activation_9_weighted_f1score: 0.0349 - val_prob_accuracy: 0.4806 - val_prob_macro_f1score: 0.2441 - val_prob_weighted_f1score: 0.0459\n",
      "Epoch 45/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.3970 - activation_8_loss: 1.4268 - activation_9_loss: 1.5711 - prob_loss: 1.3217 - activation_8_accuracy: 0.4470 - activation_8_macro_f1score: 0.1734 - activation_8_weighted_f1score: 0.0333 - activation_9_accuracy: 0.3532 - activation_9_macro_f1score: 0.1358 - activation_9_weighted_f1score: 0.0269 - prob_accuracy: 0.4925 - prob_macro_f1score: 0.2342 - prob_weighted_f1score: 0.0431 - val_loss: 2.4475 - val_activation_8_loss: 1.3584 - val_activation_9_loss: 1.4818 - val_prob_loss: 1.3390 - val_activation_8_accuracy: 0.4817 - val_activation_8_macro_f1score: 0.1781 - val_activation_8_weighted_f1score: 0.0334 - val_activation_9_accuracy: 0.4335 - val_activation_9_macro_f1score: 0.1541 - val_activation_9_weighted_f1score: 0.0308 - val_prob_accuracy: 0.4951 - val_prob_macro_f1score: 0.2357 - val_prob_weighted_f1score: 0.0425\n",
      "Epoch 46/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.3810 - activation_8_loss: 1.4173 - activation_9_loss: 1.5728 - prob_loss: 1.3093 - activation_8_accuracy: 0.4522 - activation_8_macro_f1score: 0.1761 - activation_8_weighted_f1score: 0.0337 - activation_9_accuracy: 0.3546 - activation_9_macro_f1score: 0.1359 - activation_9_weighted_f1score: 0.0266 - prob_accuracy: 0.4949 - prob_macro_f1score: 0.2408 - prob_weighted_f1score: 0.0443 - val_loss: 2.3709 - val_activation_8_loss: 1.3467 - val_activation_9_loss: 1.4148 - val_prob_loss: 1.2900 - val_activation_8_accuracy: 0.4901 - val_activation_8_macro_f1score: 0.1989 - val_activation_8_weighted_f1score: 0.0364 - val_activation_9_accuracy: 0.4544 - val_activation_9_macro_f1score: 0.1825 - val_activation_9_weighted_f1score: 0.0340 - val_prob_accuracy: 0.5079 - val_prob_macro_f1score: 0.2847 - val_prob_weighted_f1score: 0.0500\n",
      "Epoch 47/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.3807 - activation_8_loss: 1.4231 - activation_9_loss: 1.5701 - prob_loss: 1.3095 - activation_8_accuracy: 0.4493 - activation_8_macro_f1score: 0.1786 - activation_8_weighted_f1score: 0.0341 - activation_9_accuracy: 0.3570 - activation_9_macro_f1score: 0.1350 - activation_9_weighted_f1score: 0.0268 - prob_accuracy: 0.4941 - prob_macro_f1score: 0.2425 - prob_weighted_f1score: 0.0445 - val_loss: 2.4442 - val_activation_8_loss: 1.4012 - val_activation_9_loss: 1.4301 - val_prob_loss: 1.3410 - val_activation_8_accuracy: 0.4695 - val_activation_8_macro_f1score: 0.1947 - val_activation_8_weighted_f1score: 0.0361 - val_activation_9_accuracy: 0.4505 - val_activation_9_macro_f1score: 0.1810 - val_activation_9_weighted_f1score: 0.0340 - val_prob_accuracy: 0.4974 - val_prob_macro_f1score: 0.2812 - val_prob_weighted_f1score: 0.0512\n",
      "Epoch 48/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.3685 - activation_8_loss: 1.4157 - activation_9_loss: 1.5647 - prob_loss: 1.3024 - activation_8_accuracy: 0.4500 - activation_8_macro_f1score: 0.1785 - activation_8_weighted_f1score: 0.0341 - activation_9_accuracy: 0.3579 - activation_9_macro_f1score: 0.1377 - activation_9_weighted_f1score: 0.0270 - prob_accuracy: 0.4982 - prob_macro_f1score: 0.2470 - prob_weighted_f1score: 0.0451 - val_loss: 2.4320 - val_activation_8_loss: 1.3975 - val_activation_9_loss: 1.4185 - val_prob_loss: 1.3353 - val_activation_8_accuracy: 0.4614 - val_activation_8_macro_f1score: 0.1987 - val_activation_8_weighted_f1score: 0.0373 - val_activation_9_accuracy: 0.4634 - val_activation_9_macro_f1score: 0.1860 - val_activation_9_weighted_f1score: 0.0356 - val_prob_accuracy: 0.4918 - val_prob_macro_f1score: 0.2607 - val_prob_weighted_f1score: 0.0484\n",
      "Epoch 49/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.3608 - activation_8_loss: 1.4058 - activation_9_loss: 1.5669 - prob_loss: 1.2983 - activation_8_accuracy: 0.4538 - activation_8_macro_f1score: 0.1817 - activation_8_weighted_f1score: 0.0346 - activation_9_accuracy: 0.3602 - activation_9_macro_f1score: 0.1355 - activation_9_weighted_f1score: 0.0270 - prob_accuracy: 0.4983 - prob_macro_f1score: 0.2474 - prob_weighted_f1score: 0.0454 - val_loss: 2.3555 - val_activation_8_loss: 1.3237 - val_activation_9_loss: 1.4125 - val_prob_loss: 1.2865 - val_activation_8_accuracy: 0.4845 - val_activation_8_macro_f1score: 0.2016 - val_activation_8_weighted_f1score: 0.0375 - val_activation_9_accuracy: 0.4606 - val_activation_9_macro_f1score: 0.1810 - val_activation_9_weighted_f1score: 0.0346 - val_prob_accuracy: 0.5099 - val_prob_macro_f1score: 0.2797 - val_prob_weighted_f1score: 0.0510\n",
      "Epoch 50/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.3620 - activation_8_loss: 1.4094 - activation_9_loss: 1.5629 - prob_loss: 1.3008 - activation_8_accuracy: 0.4525 - activation_8_macro_f1score: 0.1796 - activation_8_weighted_f1score: 0.0342 - activation_9_accuracy: 0.3544 - activation_9_macro_f1score: 0.1389 - activation_9_weighted_f1score: 0.0272 - prob_accuracy: 0.5002 - prob_macro_f1score: 0.2457 - prob_weighted_f1score: 0.0450 - val_loss: 2.3542 - val_activation_8_loss: 1.3548 - val_activation_9_loss: 1.4131 - val_prob_loss: 1.2769 - val_activation_8_accuracy: 0.4879 - val_activation_8_macro_f1score: 0.1989 - val_activation_8_weighted_f1score: 0.0374 - val_activation_9_accuracy: 0.4505 - val_activation_9_macro_f1score: 0.1817 - val_activation_9_weighted_f1score: 0.0352 - val_prob_accuracy: 0.5194 - val_prob_macro_f1score: 0.2813 - val_prob_weighted_f1score: 0.0513\n",
      "Epoch 51/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.3403 - activation_8_loss: 1.3954 - activation_9_loss: 1.5572 - prob_loss: 1.2862 - activation_8_accuracy: 0.4634 - activation_8_macro_f1score: 0.1874 - activation_8_weighted_f1score: 0.0358 - activation_9_accuracy: 0.3614 - activation_9_macro_f1score: 0.1384 - activation_9_weighted_f1score: 0.0277 - prob_accuracy: 0.5061 - prob_macro_f1score: 0.2542 - prob_weighted_f1score: 0.0466 - val_loss: 2.5058 - val_activation_8_loss: 1.4310 - val_activation_9_loss: 1.4174 - val_prob_loss: 1.4005 - val_activation_8_accuracy: 0.4388 - val_activation_8_macro_f1score: 0.1970 - val_activation_8_weighted_f1score: 0.0364 - val_activation_9_accuracy: 0.4452 - val_activation_9_macro_f1score: 0.1968 - val_activation_9_weighted_f1score: 0.0364 - val_prob_accuracy: 0.4784 - val_prob_macro_f1score: 0.2649 - val_prob_weighted_f1score: 0.0477\n",
      "Epoch 52/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.3335 - activation_8_loss: 1.3921 - activation_9_loss: 1.5527 - prob_loss: 1.2830 - activation_8_accuracy: 0.4623 - activation_8_macro_f1score: 0.1887 - activation_8_weighted_f1score: 0.0360 - activation_9_accuracy: 0.3662 - activation_9_macro_f1score: 0.1416 - activation_9_weighted_f1score: 0.0279 - prob_accuracy: 0.5086 - prob_macro_f1score: 0.2548 - prob_weighted_f1score: 0.0466 - val_loss: 2.4259 - val_activation_8_loss: 1.3408 - val_activation_9_loss: 1.4386 - val_prob_loss: 1.3453 - val_activation_8_accuracy: 0.4737 - val_activation_8_macro_f1score: 0.1901 - val_activation_8_weighted_f1score: 0.0363 - val_activation_9_accuracy: 0.4511 - val_activation_9_macro_f1score: 0.1490 - val_activation_9_weighted_f1score: 0.0311 - val_prob_accuracy: 0.4940 - val_prob_macro_f1score: 0.2725 - val_prob_weighted_f1score: 0.0495\n",
      "Epoch 53/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.3224 - activation_8_loss: 1.3878 - activation_9_loss: 1.5570 - prob_loss: 1.2731 - activation_8_accuracy: 0.4646 - activation_8_macro_f1score: 0.1902 - activation_8_weighted_f1score: 0.0362 - activation_9_accuracy: 0.3612 - activation_9_macro_f1score: 0.1374 - activation_9_weighted_f1score: 0.0275 - prob_accuracy: 0.5103 - prob_macro_f1score: 0.2619 - prob_weighted_f1score: 0.0478 - val_loss: 2.3204 - val_activation_8_loss: 1.3131 - val_activation_9_loss: 1.3734 - val_prob_loss: 1.2723 - val_activation_8_accuracy: 0.4840 - val_activation_8_macro_f1score: 0.2275 - val_activation_8_weighted_f1score: 0.0430 - val_activation_9_accuracy: 0.4684 - val_activation_9_macro_f1score: 0.1918 - val_activation_9_weighted_f1score: 0.0375 - val_prob_accuracy: 0.5074 - val_prob_macro_f1score: 0.2967 - val_prob_weighted_f1score: 0.0539\n",
      "Epoch 54/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.3257 - activation_8_loss: 1.3914 - activation_9_loss: 1.5509 - prob_loss: 1.2783 - activation_8_accuracy: 0.4599 - activation_8_macro_f1score: 0.1891 - activation_8_weighted_f1score: 0.0359 - activation_9_accuracy: 0.3623 - activation_9_macro_f1score: 0.1395 - activation_9_weighted_f1score: 0.0277 - prob_accuracy: 0.5094 - prob_macro_f1score: 0.2597 - prob_weighted_f1score: 0.0474 - val_loss: 2.3538 - val_activation_8_loss: 1.3432 - val_activation_9_loss: 1.4144 - val_prob_loss: 1.2844 - val_activation_8_accuracy: 0.4993 - val_activation_8_macro_f1score: 0.1943 - val_activation_8_weighted_f1score: 0.0363 - val_activation_9_accuracy: 0.4533 - val_activation_9_macro_f1score: 0.1674 - val_activation_9_weighted_f1score: 0.0325 - val_prob_accuracy: 0.5247 - val_prob_macro_f1score: 0.2790 - val_prob_weighted_f1score: 0.0493\n",
      "Epoch 55/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.3165 - activation_8_loss: 1.3818 - activation_9_loss: 1.5534 - prob_loss: 1.2723 - activation_8_accuracy: 0.4675 - activation_8_macro_f1score: 0.1936 - activation_8_weighted_f1score: 0.0366 - activation_9_accuracy: 0.3597 - activation_9_macro_f1score: 0.1411 - activation_9_weighted_f1score: 0.0278 - prob_accuracy: 0.5145 - prob_macro_f1score: 0.2649 - prob_weighted_f1score: 0.0483 - val_loss: 2.3277 - val_activation_8_loss: 1.2994 - val_activation_9_loss: 1.3838 - val_prob_loss: 1.2825 - val_activation_8_accuracy: 0.4909 - val_activation_8_macro_f1score: 0.2192 - val_activation_8_weighted_f1score: 0.0423 - val_activation_9_accuracy: 0.4628 - val_activation_9_macro_f1score: 0.1766 - val_activation_9_weighted_f1score: 0.0356 - val_prob_accuracy: 0.5135 - val_prob_macro_f1score: 0.2878 - val_prob_weighted_f1score: 0.0535\n",
      "Epoch 56/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2966 - activation_8_loss: 1.3765 - activation_9_loss: 1.5387 - prob_loss: 1.2595 - activation_8_accuracy: 0.4721 - activation_8_macro_f1score: 0.2005 - activation_8_weighted_f1score: 0.0376 - activation_9_accuracy: 0.3684 - activation_9_macro_f1score: 0.1442 - activation_9_weighted_f1score: 0.0285 - prob_accuracy: 0.5145 - prob_macro_f1score: 0.2698 - prob_weighted_f1score: 0.0490 - val_loss: 2.3359 - val_activation_8_loss: 1.3085 - val_activation_9_loss: 1.4160 - val_prob_loss: 1.2790 - val_activation_8_accuracy: 0.5210 - val_activation_8_macro_f1score: 0.2137 - val_activation_8_weighted_f1score: 0.0392 - val_activation_9_accuracy: 0.4898 - val_activation_9_macro_f1score: 0.1751 - val_activation_9_weighted_f1score: 0.0333 - val_prob_accuracy: 0.5196 - val_prob_macro_f1score: 0.2984 - val_prob_weighted_f1score: 0.0524\n",
      "Epoch 57/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.2979 - activation_8_loss: 1.3752 - activation_9_loss: 1.5477 - prob_loss: 1.2596 - activation_8_accuracy: 0.4720 - activation_8_macro_f1score: 0.1963 - activation_8_weighted_f1score: 0.0372 - activation_9_accuracy: 0.3618 - activation_9_macro_f1score: 0.1396 - activation_9_weighted_f1score: 0.0278 - prob_accuracy: 0.5195 - prob_macro_f1score: 0.2735 - prob_weighted_f1score: 0.0497 - val_loss: 2.2846 - val_activation_8_loss: 1.3029 - val_activation_9_loss: 1.3806 - val_prob_loss: 1.2430 - val_activation_8_accuracy: 0.5038 - val_activation_8_macro_f1score: 0.2217 - val_activation_8_weighted_f1score: 0.0405 - val_activation_9_accuracy: 0.4575 - val_activation_9_macro_f1score: 0.1850 - val_activation_9_weighted_f1score: 0.0352 - val_prob_accuracy: 0.5316 - val_prob_macro_f1score: 0.3005 - val_prob_weighted_f1score: 0.0533\n",
      "Epoch 58/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.2901 - activation_8_loss: 1.3677 - activation_9_loss: 1.5414 - prob_loss: 1.2570 - activation_8_accuracy: 0.4780 - activation_8_macro_f1score: 0.2061 - activation_8_weighted_f1score: 0.0384 - activation_9_accuracy: 0.3649 - activation_9_macro_f1score: 0.1429 - activation_9_weighted_f1score: 0.0282 - prob_accuracy: 0.5176 - prob_macro_f1score: 0.2749 - prob_weighted_f1score: 0.0498 - val_loss: 2.2660 - val_activation_8_loss: 1.2760 - val_activation_9_loss: 1.3765 - val_prob_loss: 1.2352 - val_activation_8_accuracy: 0.5021 - val_activation_8_macro_f1score: 0.2401 - val_activation_8_weighted_f1score: 0.0448 - val_activation_9_accuracy: 0.4539 - val_activation_9_macro_f1score: 0.1820 - val_activation_9_weighted_f1score: 0.0356 - val_prob_accuracy: 0.5255 - val_prob_macro_f1score: 0.2905 - val_prob_weighted_f1score: 0.0525\n",
      "Epoch 59/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2862 - activation_8_loss: 1.3668 - activation_9_loss: 1.5451 - prob_loss: 1.2532 - activation_8_accuracy: 0.4746 - activation_8_macro_f1score: 0.2037 - activation_8_weighted_f1score: 0.0384 - activation_9_accuracy: 0.3705 - activation_9_macro_f1score: 0.1413 - activation_9_weighted_f1score: 0.0280 - prob_accuracy: 0.5199 - prob_macro_f1score: 0.2779 - prob_weighted_f1score: 0.0503 - val_loss: 2.3133 - val_activation_8_loss: 1.2814 - val_activation_9_loss: 1.3763 - val_prob_loss: 1.2804 - val_activation_8_accuracy: 0.5054 - val_activation_8_macro_f1score: 0.2285 - val_activation_8_weighted_f1score: 0.0437 - val_activation_9_accuracy: 0.4717 - val_activation_9_macro_f1score: 0.1789 - val_activation_9_weighted_f1score: 0.0347 - val_prob_accuracy: 0.4965 - val_prob_macro_f1score: 0.2904 - val_prob_weighted_f1score: 0.0526\n",
      "Epoch 60/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.2805 - activation_8_loss: 1.3682 - activation_9_loss: 1.5427 - prob_loss: 1.2487 - activation_8_accuracy: 0.4735 - activation_8_macro_f1score: 0.1984 - activation_8_weighted_f1score: 0.0376 - activation_9_accuracy: 0.3766 - activation_9_macro_f1score: 0.1429 - activation_9_weighted_f1score: 0.0281 - prob_accuracy: 0.5216 - prob_macro_f1score: 0.2812 - prob_weighted_f1score: 0.0509 - val_loss: 2.3684 - val_activation_8_loss: 1.3361 - val_activation_9_loss: 1.4210 - val_prob_loss: 1.3046 - val_activation_8_accuracy: 0.4974 - val_activation_8_macro_f1score: 0.2189 - val_activation_8_weighted_f1score: 0.0418 - val_activation_9_accuracy: 0.4416 - val_activation_9_macro_f1score: 0.1546 - val_activation_9_weighted_f1score: 0.0315 - val_prob_accuracy: 0.5185 - val_prob_macro_f1score: 0.3003 - val_prob_weighted_f1score: 0.0548\n",
      "Epoch 61/100\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.2838 - activation_8_loss: 1.3667 - activation_9_loss: 1.5451 - prob_loss: 1.2524 - activation_8_accuracy: 0.4723 - activation_8_macro_f1score: 0.2036 - activation_8_weighted_f1score: 0.0383 - activation_9_accuracy: 0.3730 - activation_9_macro_f1score: 0.1406 - activation_9_weighted_f1score: 0.0279 - prob_accuracy: 0.5201 - prob_macro_f1score: 0.2805 - prob_weighted_f1score: 0.0508 - val_loss: 2.2534 - val_activation_8_loss: 1.2860 - val_activation_9_loss: 1.3829 - val_prob_loss: 1.2206 - val_activation_8_accuracy: 0.5077 - val_activation_8_macro_f1score: 0.2296 - val_activation_8_weighted_f1score: 0.0413 - val_activation_9_accuracy: 0.4597 - val_activation_9_macro_f1score: 0.1799 - val_activation_9_weighted_f1score: 0.0334 - val_prob_accuracy: 0.5300 - val_prob_macro_f1score: 0.3133 - val_prob_weighted_f1score: 0.0553\n",
      "Epoch 62/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.2765 - activation_8_loss: 1.3612 - activation_9_loss: 1.5414 - prob_loss: 1.2487 - activation_8_accuracy: 0.4790 - activation_8_macro_f1score: 0.2062 - activation_8_weighted_f1score: 0.0387 - activation_9_accuracy: 0.3750 - activation_9_macro_f1score: 0.1422 - activation_9_weighted_f1score: 0.0282 - prob_accuracy: 0.5242 - prob_macro_f1score: 0.2810 - prob_weighted_f1score: 0.0509 - val_loss: 2.3651 - val_activation_8_loss: 1.3418 - val_activation_9_loss: 1.3914 - val_prob_loss: 1.3102 - val_activation_8_accuracy: 0.4954 - val_activation_8_macro_f1score: 0.2446 - val_activation_8_weighted_f1score: 0.0456 - val_activation_9_accuracy: 0.4726 - val_activation_9_macro_f1score: 0.1921 - val_activation_9_weighted_f1score: 0.0371 - val_prob_accuracy: 0.5169 - val_prob_macro_f1score: 0.2884 - val_prob_weighted_f1score: 0.0525\n",
      "Epoch 63/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.2734 - activation_8_loss: 1.3636 - activation_9_loss: 1.5401 - prob_loss: 1.2462 - activation_8_accuracy: 0.4777 - activation_8_macro_f1score: 0.2092 - activation_8_weighted_f1score: 0.0393 - activation_9_accuracy: 0.3781 - activation_9_macro_f1score: 0.1404 - activation_9_weighted_f1score: 0.0277 - prob_accuracy: 0.5248 - prob_macro_f1score: 0.2853 - prob_weighted_f1score: 0.0515 - val_loss: 2.2139 - val_activation_8_loss: 1.2667 - val_activation_9_loss: 1.3577 - val_prob_loss: 1.1975 - val_activation_8_accuracy: 0.5104 - val_activation_8_macro_f1score: 0.2339 - val_activation_8_weighted_f1score: 0.0425 - val_activation_9_accuracy: 0.4815 - val_activation_9_macro_f1score: 0.1779 - val_activation_9_weighted_f1score: 0.0343 - val_prob_accuracy: 0.5458 - val_prob_macro_f1score: 0.2979 - val_prob_weighted_f1score: 0.0532\n",
      "Epoch 64/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.2512 - activation_8_loss: 1.3516 - activation_9_loss: 1.5357 - prob_loss: 1.2298 - activation_8_accuracy: 0.4815 - activation_8_macro_f1score: 0.2137 - activation_8_weighted_f1score: 0.0400 - activation_9_accuracy: 0.3825 - activation_9_macro_f1score: 0.1407 - activation_9_weighted_f1score: 0.0280 - prob_accuracy: 0.5328 - prob_macro_f1score: 0.2911 - prob_weighted_f1score: 0.0525 - val_loss: 2.2276 - val_activation_8_loss: 1.2624 - val_activation_9_loss: 1.3640 - val_prob_loss: 1.2111 - val_activation_8_accuracy: 0.5071 - val_activation_8_macro_f1score: 0.2504 - val_activation_8_weighted_f1score: 0.0456 - val_activation_9_accuracy: 0.4709 - val_activation_9_macro_f1score: 0.1718 - val_activation_9_weighted_f1score: 0.0328 - val_prob_accuracy: 0.5417 - val_prob_macro_f1score: 0.3021 - val_prob_weighted_f1score: 0.0541\n",
      "Epoch 65/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.2429 - activation_8_loss: 1.3459 - activation_9_loss: 1.5294 - prob_loss: 1.2260 - activation_8_accuracy: 0.4819 - activation_8_macro_f1score: 0.2191 - activation_8_weighted_f1score: 0.0408 - activation_9_accuracy: 0.3824 - activation_9_macro_f1score: 0.1448 - activation_9_weighted_f1score: 0.0286 - prob_accuracy: 0.5323 - prob_macro_f1score: 0.2974 - prob_weighted_f1score: 0.0534 - val_loss: 2.2147 - val_activation_8_loss: 1.2628 - val_activation_9_loss: 1.3686 - val_prob_loss: 1.1980 - val_activation_8_accuracy: 0.5146 - val_activation_8_macro_f1score: 0.2312 - val_activation_8_weighted_f1score: 0.0433 - val_activation_9_accuracy: 0.4781 - val_activation_9_macro_f1score: 0.1775 - val_activation_9_weighted_f1score: 0.0336 - val_prob_accuracy: 0.5380 - val_prob_macro_f1score: 0.3011 - val_prob_weighted_f1score: 0.0540\n",
      "Epoch 66/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.2456 - activation_8_loss: 1.3486 - activation_9_loss: 1.5338 - prob_loss: 1.2274 - activation_8_accuracy: 0.4821 - activation_8_macro_f1score: 0.2175 - activation_8_weighted_f1score: 0.0406 - activation_9_accuracy: 0.3814 - activation_9_macro_f1score: 0.1431 - activation_9_weighted_f1score: 0.0283 - prob_accuracy: 0.5317 - prob_macro_f1score: 0.2983 - prob_weighted_f1score: 0.0537 - val_loss: 2.2172 - val_activation_8_loss: 1.2576 - val_activation_9_loss: 1.3587 - val_prob_loss: 1.2058 - val_activation_8_accuracy: 0.5149 - val_activation_8_macro_f1score: 0.2654 - val_activation_8_weighted_f1score: 0.0487 - val_activation_9_accuracy: 0.4717 - val_activation_9_macro_f1score: 0.1827 - val_activation_9_weighted_f1score: 0.0354 - val_prob_accuracy: 0.5386 - val_prob_macro_f1score: 0.3019 - val_prob_weighted_f1score: 0.0547\n",
      "Epoch 67/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2470 - activation_8_loss: 1.3511 - activation_9_loss: 1.5305 - prob_loss: 1.2297 - activation_8_accuracy: 0.4836 - activation_8_macro_f1score: 0.2152 - activation_8_weighted_f1score: 0.0403 - activation_9_accuracy: 0.3818 - activation_9_macro_f1score: 0.1421 - activation_9_weighted_f1score: 0.0284 - prob_accuracy: 0.5297 - prob_macro_f1score: 0.2975 - prob_weighted_f1score: 0.0535 - val_loss: 2.2098 - val_activation_8_loss: 1.2704 - val_activation_9_loss: 1.3625 - val_prob_loss: 1.1943 - val_activation_8_accuracy: 0.5247 - val_activation_8_macro_f1score: 0.2308 - val_activation_8_weighted_f1score: 0.0425 - val_activation_9_accuracy: 0.4968 - val_activation_9_macro_f1score: 0.1786 - val_activation_9_weighted_f1score: 0.0338 - val_prob_accuracy: 0.5553 - val_prob_macro_f1score: 0.3205 - val_prob_weighted_f1score: 0.0574\n",
      "Epoch 68/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2288 - activation_8_loss: 1.3384 - activation_9_loss: 1.5292 - prob_loss: 1.2164 - activation_8_accuracy: 0.4888 - activation_8_macro_f1score: 0.2234 - activation_8_weighted_f1score: 0.0416 - activation_9_accuracy: 0.3770 - activation_9_macro_f1score: 0.1419 - activation_9_weighted_f1score: 0.0283 - prob_accuracy: 0.5389 - prob_macro_f1score: 0.3040 - prob_weighted_f1score: 0.0547 - val_loss: 2.2177 - val_activation_8_loss: 1.2805 - val_activation_9_loss: 1.3723 - val_prob_loss: 1.1966 - val_activation_8_accuracy: 0.5227 - val_activation_8_macro_f1score: 0.2637 - val_activation_8_weighted_f1score: 0.0488 - val_activation_9_accuracy: 0.4876 - val_activation_9_macro_f1score: 0.1883 - val_activation_9_weighted_f1score: 0.0358 - val_prob_accuracy: 0.5561 - val_prob_macro_f1score: 0.3045 - val_prob_weighted_f1score: 0.0555\n",
      "Epoch 69/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.2325 - activation_8_loss: 1.3434 - activation_9_loss: 1.5283 - prob_loss: 1.2195 - activation_8_accuracy: 0.4873 - activation_8_macro_f1score: 0.2181 - activation_8_weighted_f1score: 0.0410 - activation_9_accuracy: 0.3820 - activation_9_macro_f1score: 0.1422 - activation_9_weighted_f1score: 0.0283 - prob_accuracy: 0.5375 - prob_macro_f1score: 0.2992 - prob_weighted_f1score: 0.0541 - val_loss: 2.2391 - val_activation_8_loss: 1.2435 - val_activation_9_loss: 1.3531 - val_prob_loss: 1.2347 - val_activation_8_accuracy: 0.5015 - val_activation_8_macro_f1score: 0.2655 - val_activation_8_weighted_f1score: 0.0495 - val_activation_9_accuracy: 0.4778 - val_activation_9_macro_f1score: 0.1840 - val_activation_9_weighted_f1score: 0.0351 - val_prob_accuracy: 0.5068 - val_prob_macro_f1score: 0.3149 - val_prob_weighted_f1score: 0.0570\n",
      "Epoch 70/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2413 - activation_8_loss: 1.3462 - activation_9_loss: 1.5299 - prob_loss: 1.2276 - activation_8_accuracy: 0.4859 - activation_8_macro_f1score: 0.2222 - activation_8_weighted_f1score: 0.0412 - activation_9_accuracy: 0.3793 - activation_9_macro_f1score: 0.1420 - activation_9_weighted_f1score: 0.0281 - prob_accuracy: 0.5336 - prob_macro_f1score: 0.2980 - prob_weighted_f1score: 0.0534 - val_loss: 2.2358 - val_activation_8_loss: 1.2519 - val_activation_9_loss: 1.3838 - val_prob_loss: 1.2206 - val_activation_8_accuracy: 0.5118 - val_activation_8_macro_f1score: 0.2405 - val_activation_8_weighted_f1score: 0.0447 - val_activation_9_accuracy: 0.4717 - val_activation_9_macro_f1score: 0.1558 - val_activation_9_weighted_f1score: 0.0314 - val_prob_accuracy: 0.5219 - val_prob_macro_f1score: 0.3104 - val_prob_weighted_f1score: 0.0557\n",
      "Epoch 71/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2282 - activation_8_loss: 1.3382 - activation_9_loss: 1.5258 - prob_loss: 1.2189 - activation_8_accuracy: 0.4937 - activation_8_macro_f1score: 0.2227 - activation_8_weighted_f1score: 0.0415 - activation_9_accuracy: 0.3835 - activation_9_macro_f1score: 0.1446 - activation_9_weighted_f1score: 0.0287 - prob_accuracy: 0.5373 - prob_macro_f1score: 0.3009 - prob_weighted_f1score: 0.0539 - val_loss: 2.1485 - val_activation_8_loss: 1.2184 - val_activation_9_loss: 1.3179 - val_prob_loss: 1.1666 - val_activation_8_accuracy: 0.5322 - val_activation_8_macro_f1score: 0.2772 - val_activation_8_weighted_f1score: 0.0521 - val_activation_9_accuracy: 0.4999 - val_activation_9_macro_f1score: 0.1900 - val_activation_9_weighted_f1score: 0.0376 - val_prob_accuracy: 0.5575 - val_prob_macro_f1score: 0.3409 - val_prob_weighted_f1score: 0.0619\n",
      "Epoch 72/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2186 - activation_8_loss: 1.3361 - activation_9_loss: 1.5225 - prob_loss: 1.2116 - activation_8_accuracy: 0.4930 - activation_8_macro_f1score: 0.2214 - activation_8_weighted_f1score: 0.0414 - activation_9_accuracy: 0.3876 - activation_9_macro_f1score: 0.1436 - activation_9_weighted_f1score: 0.0286 - prob_accuracy: 0.5405 - prob_macro_f1score: 0.3069 - prob_weighted_f1score: 0.0551 - val_loss: 2.3508 - val_activation_8_loss: 1.2882 - val_activation_9_loss: 1.3961 - val_prob_loss: 1.3183 - val_activation_8_accuracy: 0.4929 - val_activation_8_macro_f1score: 0.2413 - val_activation_8_weighted_f1score: 0.0449 - val_activation_9_accuracy: 0.4737 - val_activation_9_macro_f1score: 0.1823 - val_activation_9_weighted_f1score: 0.0349 - val_prob_accuracy: 0.4937 - val_prob_macro_f1score: 0.2818 - val_prob_weighted_f1score: 0.0502\n",
      "Epoch 73/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2245 - activation_8_loss: 1.3347 - activation_9_loss: 1.5273 - prob_loss: 1.2171 - activation_8_accuracy: 0.4924 - activation_8_macro_f1score: 0.2289 - activation_8_weighted_f1score: 0.0425 - activation_9_accuracy: 0.3880 - activation_9_macro_f1score: 0.1427 - activation_9_weighted_f1score: 0.0283 - prob_accuracy: 0.5389 - prob_macro_f1score: 0.3080 - prob_weighted_f1score: 0.0552 - val_loss: 2.2268 - val_activation_8_loss: 1.2597 - val_activation_9_loss: 1.3803 - val_prob_loss: 1.2126 - val_activation_8_accuracy: 0.5222 - val_activation_8_macro_f1score: 0.2387 - val_activation_8_weighted_f1score: 0.0438 - val_activation_9_accuracy: 0.4648 - val_activation_9_macro_f1score: 0.1695 - val_activation_9_weighted_f1score: 0.0342 - val_prob_accuracy: 0.5280 - val_prob_macro_f1score: 0.2762 - val_prob_weighted_f1score: 0.0508\n",
      "Epoch 74/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 2.2122 - activation_8_loss: 1.3280 - activation_9_loss: 1.5250 - prob_loss: 1.2081 - activation_8_accuracy: 0.4960 - activation_8_macro_f1score: 0.2338 - activation_8_weighted_f1score: 0.0432 - activation_9_accuracy: 0.3836 - activation_9_macro_f1score: 0.1440 - activation_9_weighted_f1score: 0.0285 - prob_accuracy: 0.5418 - prob_macro_f1score: 0.3093 - prob_weighted_f1score: 0.0553 - val_loss: 2.1408 - val_activation_8_loss: 1.2098 - val_activation_9_loss: 1.2987 - val_prob_loss: 1.1693 - val_activation_8_accuracy: 0.5347 - val_activation_8_macro_f1score: 0.2891 - val_activation_8_weighted_f1score: 0.0527 - val_activation_9_accuracy: 0.5261 - val_activation_9_macro_f1score: 0.1922 - val_activation_9_weighted_f1score: 0.0371 - val_prob_accuracy: 0.5520 - val_prob_macro_f1score: 0.3494 - val_prob_weighted_f1score: 0.0630\n",
      "Epoch 75/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.2046 - activation_8_loss: 1.3224 - activation_9_loss: 1.5192 - prob_loss: 1.2045 - activation_8_accuracy: 0.4997 - activation_8_macro_f1score: 0.2350 - activation_8_weighted_f1score: 0.0436 - activation_9_accuracy: 0.3869 - activation_9_macro_f1score: 0.1483 - activation_9_weighted_f1score: 0.0291 - prob_accuracy: 0.5410 - prob_macro_f1score: 0.3087 - prob_weighted_f1score: 0.0555 - val_loss: 2.1812 - val_activation_8_loss: 1.2518 - val_activation_9_loss: 1.3307 - val_prob_loss: 1.1868 - val_activation_8_accuracy: 0.5060 - val_activation_8_macro_f1score: 0.2546 - val_activation_8_weighted_f1score: 0.0461 - val_activation_9_accuracy: 0.4987 - val_activation_9_macro_f1score: 0.1819 - val_activation_9_weighted_f1score: 0.0352 - val_prob_accuracy: 0.5517 - val_prob_macro_f1score: 0.3264 - val_prob_weighted_f1score: 0.0576\n",
      "Epoch 76/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.2070 - activation_8_loss: 1.3236 - activation_9_loss: 1.5249 - prob_loss: 1.2053 - activation_8_accuracy: 0.4989 - activation_8_macro_f1score: 0.2328 - activation_8_weighted_f1score: 0.0434 - activation_9_accuracy: 0.3817 - activation_9_macro_f1score: 0.1413 - activation_9_weighted_f1score: 0.0284 - prob_accuracy: 0.5407 - prob_macro_f1score: 0.3105 - prob_weighted_f1score: 0.0557 - val_loss: 2.1343 - val_activation_8_loss: 1.1974 - val_activation_9_loss: 1.3101 - val_prob_loss: 1.1644 - val_activation_8_accuracy: 0.5319 - val_activation_8_macro_f1score: 0.2912 - val_activation_8_weighted_f1score: 0.0534 - val_activation_9_accuracy: 0.5143 - val_activation_9_macro_f1score: 0.1857 - val_activation_9_weighted_f1score: 0.0361 - val_prob_accuracy: 0.5520 - val_prob_macro_f1score: 0.3482 - val_prob_weighted_f1score: 0.0622\n",
      "Epoch 77/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1995 - activation_8_loss: 1.3210 - activation_9_loss: 1.5174 - prob_loss: 1.2014 - activation_8_accuracy: 0.4971 - activation_8_macro_f1score: 0.2340 - activation_8_weighted_f1score: 0.0434 - activation_9_accuracy: 0.3892 - activation_9_macro_f1score: 0.1446 - activation_9_weighted_f1score: 0.0288 - prob_accuracy: 0.5418 - prob_macro_f1score: 0.3083 - prob_weighted_f1score: 0.0553 - val_loss: 2.1633 - val_activation_8_loss: 1.2189 - val_activation_9_loss: 1.3101 - val_prob_loss: 1.1866 - val_activation_8_accuracy: 0.5305 - val_activation_8_macro_f1score: 0.2844 - val_activation_8_weighted_f1score: 0.0511 - val_activation_9_accuracy: 0.5174 - val_activation_9_macro_f1score: 0.1900 - val_activation_9_weighted_f1score: 0.0364 - val_prob_accuracy: 0.5442 - val_prob_macro_f1score: 0.3534 - val_prob_weighted_f1score: 0.0619\n",
      "Epoch 78/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 2.1874 - activation_8_loss: 1.3138 - activation_9_loss: 1.5175 - prob_loss: 1.1920 - activation_8_accuracy: 0.5036 - activation_8_macro_f1score: 0.2413 - activation_8_weighted_f1score: 0.0446 - activation_9_accuracy: 0.3866 - activation_9_macro_f1score: 0.1469 - activation_9_weighted_f1score: 0.0292 - prob_accuracy: 0.5482 - prob_macro_f1score: 0.3198 - prob_weighted_f1score: 0.0572 - val_loss: 2.2582 - val_activation_8_loss: 1.2934 - val_activation_9_loss: 1.3938 - val_prob_loss: 1.2314 - val_activation_8_accuracy: 0.5071 - val_activation_8_macro_f1score: 0.2681 - val_activation_8_weighted_f1score: 0.0498 - val_activation_9_accuracy: 0.4848 - val_activation_9_macro_f1score: 0.1845 - val_activation_9_weighted_f1score: 0.0361 - val_prob_accuracy: 0.5344 - val_prob_macro_f1score: 0.3126 - val_prob_weighted_f1score: 0.0565\n",
      "Epoch 79/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1929 - activation_8_loss: 1.3191 - activation_9_loss: 1.5214 - prob_loss: 1.1951 - activation_8_accuracy: 0.4972 - activation_8_macro_f1score: 0.2422 - activation_8_weighted_f1score: 0.0446 - activation_9_accuracy: 0.3843 - activation_9_macro_f1score: 0.1446 - activation_9_weighted_f1score: 0.0286 - prob_accuracy: 0.5463 - prob_macro_f1score: 0.3172 - prob_weighted_f1score: 0.0568 - val_loss: 2.1563 - val_activation_8_loss: 1.2242 - val_activation_9_loss: 1.3248 - val_prob_loss: 1.1748 - val_activation_8_accuracy: 0.5394 - val_activation_8_macro_f1score: 0.2979 - val_activation_8_weighted_f1score: 0.0538 - val_activation_9_accuracy: 0.5202 - val_activation_9_macro_f1score: 0.1886 - val_activation_9_weighted_f1score: 0.0367 - val_prob_accuracy: 0.5598 - val_prob_macro_f1score: 0.3422 - val_prob_weighted_f1score: 0.0604\n",
      "Epoch 80/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 2.1798 - activation_8_loss: 1.3143 - activation_9_loss: 1.5136 - prob_loss: 1.1863 - activation_8_accuracy: 0.5028 - activation_8_macro_f1score: 0.2430 - activation_8_weighted_f1score: 0.0447 - activation_9_accuracy: 0.3898 - activation_9_macro_f1score: 0.1492 - activation_9_weighted_f1score: 0.0292 - prob_accuracy: 0.5504 - prob_macro_f1score: 0.3237 - prob_weighted_f1score: 0.0576 - val_loss: 2.1994 - val_activation_8_loss: 1.2644 - val_activation_9_loss: 1.3061 - val_prob_loss: 1.2102 - val_activation_8_accuracy: 0.5196 - val_activation_8_macro_f1score: 0.2802 - val_activation_8_weighted_f1score: 0.0528 - val_activation_9_accuracy: 0.5079 - val_activation_9_macro_f1score: 0.1952 - val_activation_9_weighted_f1score: 0.0392 - val_prob_accuracy: 0.5450 - val_prob_macro_f1score: 0.3498 - val_prob_weighted_f1score: 0.0640\n",
      "Epoch 81/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1829 - activation_8_loss: 1.3111 - activation_9_loss: 1.5144 - prob_loss: 1.1904 - activation_8_accuracy: 0.5041 - activation_8_macro_f1score: 0.2488 - activation_8_weighted_f1score: 0.0457 - activation_9_accuracy: 0.3883 - activation_9_macro_f1score: 0.1474 - activation_9_weighted_f1score: 0.0290 - prob_accuracy: 0.5477 - prob_macro_f1score: 0.3221 - prob_weighted_f1score: 0.0575 - val_loss: 2.2173 - val_activation_8_loss: 1.2486 - val_activation_9_loss: 1.3587 - val_prob_loss: 1.2172 - val_activation_8_accuracy: 0.5272 - val_activation_8_macro_f1score: 0.2875 - val_activation_8_weighted_f1score: 0.0520 - val_activation_9_accuracy: 0.5007 - val_activation_9_macro_f1score: 0.1872 - val_activation_9_weighted_f1score: 0.0360 - val_prob_accuracy: 0.5467 - val_prob_macro_f1score: 0.3313 - val_prob_weighted_f1score: 0.0588\n",
      "Epoch 82/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1828 - activation_8_loss: 1.3142 - activation_9_loss: 1.5169 - prob_loss: 1.1892 - activation_8_accuracy: 0.5012 - activation_8_macro_f1score: 0.2446 - activation_8_weighted_f1score: 0.0451 - activation_9_accuracy: 0.3925 - activation_9_macro_f1score: 0.1486 - activation_9_weighted_f1score: 0.0293 - prob_accuracy: 0.5458 - prob_macro_f1score: 0.3202 - prob_weighted_f1score: 0.0572 - val_loss: 2.1663 - val_activation_8_loss: 1.2254 - val_activation_9_loss: 1.3153 - val_prob_loss: 1.1883 - val_activation_8_accuracy: 0.5283 - val_activation_8_macro_f1score: 0.2409 - val_activation_8_weighted_f1score: 0.0458 - val_activation_9_accuracy: 0.5054 - val_activation_9_macro_f1score: 0.1910 - val_activation_9_weighted_f1score: 0.0386 - val_prob_accuracy: 0.5425 - val_prob_macro_f1score: 0.2895 - val_prob_weighted_f1score: 0.0534\n",
      "Epoch 83/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1717 - activation_8_loss: 1.3012 - activation_9_loss: 1.5135 - prob_loss: 1.1834 - activation_8_accuracy: 0.5090 - activation_8_macro_f1score: 0.2478 - activation_8_weighted_f1score: 0.0455 - activation_9_accuracy: 0.3857 - activation_9_macro_f1score: 0.1478 - activation_9_weighted_f1score: 0.0293 - prob_accuracy: 0.5520 - prob_macro_f1score: 0.3271 - prob_weighted_f1score: 0.0580 - val_loss: 2.1490 - val_activation_8_loss: 1.2241 - val_activation_9_loss: 1.3069 - val_prob_loss: 1.1747 - val_activation_8_accuracy: 0.5344 - val_activation_8_macro_f1score: 0.2987 - val_activation_8_weighted_f1score: 0.0536 - val_activation_9_accuracy: 0.5163 - val_activation_9_macro_f1score: 0.1945 - val_activation_9_weighted_f1score: 0.0375 - val_prob_accuracy: 0.5444 - val_prob_macro_f1score: 0.3284 - val_prob_weighted_f1score: 0.0585\n",
      "Epoch 84/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 2.1735 - activation_8_loss: 1.3095 - activation_9_loss: 1.5155 - prob_loss: 1.1825 - activation_8_accuracy: 0.5062 - activation_8_macro_f1score: 0.2452 - activation_8_weighted_f1score: 0.0452 - activation_9_accuracy: 0.3891 - activation_9_macro_f1score: 0.1493 - activation_9_weighted_f1score: 0.0292 - prob_accuracy: 0.5547 - prob_macro_f1score: 0.3264 - prob_weighted_f1score: 0.0584 - val_loss: 2.0965 - val_activation_8_loss: 1.1966 - val_activation_9_loss: 1.3087 - val_prob_loss: 1.1322 - val_activation_8_accuracy: 0.5249 - val_activation_8_macro_f1score: 0.3074 - val_activation_8_weighted_f1score: 0.0551 - val_activation_9_accuracy: 0.5224 - val_activation_9_macro_f1score: 0.2011 - val_activation_9_weighted_f1score: 0.0376 - val_prob_accuracy: 0.5626 - val_prob_macro_f1score: 0.3601 - val_prob_weighted_f1score: 0.0631\n",
      "Epoch 85/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1702 - activation_8_loss: 1.3080 - activation_9_loss: 1.5113 - prob_loss: 1.1815 - activation_8_accuracy: 0.5079 - activation_8_macro_f1score: 0.2480 - activation_8_weighted_f1score: 0.0455 - activation_9_accuracy: 0.3909 - activation_9_macro_f1score: 0.1494 - activation_9_weighted_f1score: 0.0292 - prob_accuracy: 0.5493 - prob_macro_f1score: 0.3282 - prob_weighted_f1score: 0.0583 - val_loss: 2.1368 - val_activation_8_loss: 1.2254 - val_activation_9_loss: 1.3093 - val_prob_loss: 1.1631 - val_activation_8_accuracy: 0.5286 - val_activation_8_macro_f1score: 0.2507 - val_activation_8_weighted_f1score: 0.0475 - val_activation_9_accuracy: 0.5130 - val_activation_9_macro_f1score: 0.1881 - val_activation_9_weighted_f1score: 0.0384 - val_prob_accuracy: 0.5567 - val_prob_macro_f1score: 0.3236 - val_prob_weighted_f1score: 0.0586\n",
      "Epoch 86/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1564 - activation_8_loss: 1.3009 - activation_9_loss: 1.5046 - prob_loss: 1.1723 - activation_8_accuracy: 0.5065 - activation_8_macro_f1score: 0.2471 - activation_8_weighted_f1score: 0.0455 - activation_9_accuracy: 0.3913 - activation_9_macro_f1score: 0.1536 - activation_9_weighted_f1score: 0.0301 - prob_accuracy: 0.5575 - prob_macro_f1score: 0.3337 - prob_weighted_f1score: 0.0593 - val_loss: 2.1408 - val_activation_8_loss: 1.2217 - val_activation_9_loss: 1.3316 - val_prob_loss: 1.1616 - val_activation_8_accuracy: 0.5411 - val_activation_8_macro_f1score: 0.2606 - val_activation_8_weighted_f1score: 0.0481 - val_activation_9_accuracy: 0.5210 - val_activation_9_macro_f1score: 0.1848 - val_activation_9_weighted_f1score: 0.0356 - val_prob_accuracy: 0.5592 - val_prob_macro_f1score: 0.3398 - val_prob_weighted_f1score: 0.0616\n",
      "Epoch 87/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1643 - activation_8_loss: 1.3030 - activation_9_loss: 1.5112 - prob_loss: 1.1780 - activation_8_accuracy: 0.5087 - activation_8_macro_f1score: 0.2551 - activation_8_weighted_f1score: 0.0468 - activation_9_accuracy: 0.3930 - activation_9_macro_f1score: 0.1510 - activation_9_weighted_f1score: 0.0296 - prob_accuracy: 0.5555 - prob_macro_f1score: 0.3328 - prob_weighted_f1score: 0.0590 - val_loss: 2.1616 - val_activation_8_loss: 1.2326 - val_activation_9_loss: 1.3142 - val_prob_loss: 1.1840 - val_activation_8_accuracy: 0.5199 - val_activation_8_macro_f1score: 0.2769 - val_activation_8_weighted_f1score: 0.0496 - val_activation_9_accuracy: 0.5196 - val_activation_9_macro_f1score: 0.2065 - val_activation_9_weighted_f1score: 0.0386 - val_prob_accuracy: 0.5428 - val_prob_macro_f1score: 0.3298 - val_prob_weighted_f1score: 0.0580\n",
      "Epoch 88/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1748 - activation_8_loss: 1.3113 - activation_9_loss: 1.5144 - prob_loss: 1.1854 - activation_8_accuracy: 0.5067 - activation_8_macro_f1score: 0.2502 - activation_8_weighted_f1score: 0.0460 - activation_9_accuracy: 0.3902 - activation_9_macro_f1score: 0.1510 - activation_9_weighted_f1score: 0.0295 - prob_accuracy: 0.5526 - prob_macro_f1score: 0.3302 - prob_weighted_f1score: 0.0583 - val_loss: 2.1413 - val_activation_8_loss: 1.2188 - val_activation_9_loss: 1.2865 - val_prob_loss: 1.1770 - val_activation_8_accuracy: 0.5196 - val_activation_8_macro_f1score: 0.2824 - val_activation_8_weighted_f1score: 0.0534 - val_activation_9_accuracy: 0.5116 - val_activation_9_macro_f1score: 0.2067 - val_activation_9_weighted_f1score: 0.0417 - val_prob_accuracy: 0.5461 - val_prob_macro_f1score: 0.3395 - val_prob_weighted_f1score: 0.0619\n",
      "Epoch 89/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1552 - activation_8_loss: 1.2984 - activation_9_loss: 1.5093 - prob_loss: 1.1715 - activation_8_accuracy: 0.5102 - activation_8_macro_f1score: 0.2557 - activation_8_weighted_f1score: 0.0469 - activation_9_accuracy: 0.3918 - activation_9_macro_f1score: 0.1517 - activation_9_weighted_f1score: 0.0299 - prob_accuracy: 0.5588 - prob_macro_f1score: 0.3391 - prob_weighted_f1score: 0.0598 - val_loss: 2.1601 - val_activation_8_loss: 1.2407 - val_activation_9_loss: 1.3405 - val_prob_loss: 1.1730 - val_activation_8_accuracy: 0.5277 - val_activation_8_macro_f1score: 0.2578 - val_activation_8_weighted_f1score: 0.0458 - val_activation_9_accuracy: 0.5085 - val_activation_9_macro_f1score: 0.1840 - val_activation_9_weighted_f1score: 0.0341 - val_prob_accuracy: 0.5559 - val_prob_macro_f1score: 0.3351 - val_prob_weighted_f1score: 0.0584\n",
      "Epoch 90/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.1482 - activation_8_loss: 1.2941 - activation_9_loss: 1.5073 - prob_loss: 1.1667 - activation_8_accuracy: 0.5128 - activation_8_macro_f1score: 0.2595 - activation_8_weighted_f1score: 0.0474 - activation_9_accuracy: 0.3918 - activation_9_macro_f1score: 0.1532 - activation_9_weighted_f1score: 0.0300 - prob_accuracy: 0.5589 - prob_macro_f1score: 0.3431 - prob_weighted_f1score: 0.0601 - val_loss: 2.1418 - val_activation_8_loss: 1.2119 - val_activation_9_loss: 1.3117 - val_prob_loss: 1.1728 - val_activation_8_accuracy: 0.5422 - val_activation_8_macro_f1score: 0.2877 - val_activation_8_weighted_f1score: 0.0531 - val_activation_9_accuracy: 0.5085 - val_activation_9_macro_f1score: 0.1866 - val_activation_9_weighted_f1score: 0.0374 - val_prob_accuracy: 0.5545 - val_prob_macro_f1score: 0.3396 - val_prob_weighted_f1score: 0.0610\n",
      "Epoch 91/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1501 - activation_8_loss: 1.2936 - activation_9_loss: 1.5089 - prob_loss: 1.1685 - activation_8_accuracy: 0.5156 - activation_8_macro_f1score: 0.2590 - activation_8_weighted_f1score: 0.0474 - activation_9_accuracy: 0.3910 - activation_9_macro_f1score: 0.1496 - activation_9_weighted_f1score: 0.0298 - prob_accuracy: 0.5585 - prob_macro_f1score: 0.3404 - prob_weighted_f1score: 0.0601 - val_loss: 2.0756 - val_activation_8_loss: 1.1735 - val_activation_9_loss: 1.2926 - val_prob_loss: 1.1262 - val_activation_8_accuracy: 0.5489 - val_activation_8_macro_f1score: 0.2981 - val_activation_8_weighted_f1score: 0.0538 - val_activation_9_accuracy: 0.5330 - val_activation_9_macro_f1score: 0.1870 - val_activation_9_weighted_f1score: 0.0356 - val_prob_accuracy: 0.5681 - val_prob_macro_f1score: 0.3675 - val_prob_weighted_f1score: 0.0645\n",
      "Epoch 92/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.1539 - activation_8_loss: 1.2981 - activation_9_loss: 1.5135 - prob_loss: 1.1698 - activation_8_accuracy: 0.5160 - activation_8_macro_f1score: 0.2563 - activation_8_weighted_f1score: 0.0471 - activation_9_accuracy: 0.3883 - activation_9_macro_f1score: 0.1476 - activation_9_weighted_f1score: 0.0293 - prob_accuracy: 0.5567 - prob_macro_f1score: 0.3384 - prob_weighted_f1score: 0.0598 - val_loss: 2.1587 - val_activation_8_loss: 1.2393 - val_activation_9_loss: 1.3376 - val_prob_loss: 1.1735 - val_activation_8_accuracy: 0.5294 - val_activation_8_macro_f1score: 0.2686 - val_activation_8_weighted_f1score: 0.0483 - val_activation_9_accuracy: 0.5169 - val_activation_9_macro_f1score: 0.1948 - val_activation_9_weighted_f1score: 0.0360 - val_prob_accuracy: 0.5559 - val_prob_macro_f1score: 0.3414 - val_prob_weighted_f1score: 0.0597\n",
      "Epoch 93/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.1490 - activation_8_loss: 1.2936 - activation_9_loss: 1.5111 - prob_loss: 1.1673 - activation_8_accuracy: 0.5187 - activation_8_macro_f1score: 0.2643 - activation_8_weighted_f1score: 0.0481 - activation_9_accuracy: 0.3900 - activation_9_macro_f1score: 0.1530 - activation_9_weighted_f1score: 0.0299 - prob_accuracy: 0.5609 - prob_macro_f1score: 0.3401 - prob_weighted_f1score: 0.0602 - val_loss: 2.1994 - val_activation_8_loss: 1.2619 - val_activation_9_loss: 1.3488 - val_prob_loss: 1.2034 - val_activation_8_accuracy: 0.5327 - val_activation_8_macro_f1score: 0.2609 - val_activation_8_weighted_f1score: 0.0475 - val_activation_9_accuracy: 0.5213 - val_activation_9_macro_f1score: 0.1736 - val_activation_9_weighted_f1score: 0.0342 - val_prob_accuracy: 0.5550 - val_prob_macro_f1score: 0.3111 - val_prob_weighted_f1score: 0.0552\n",
      "Epoch 94/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1417 - activation_8_loss: 1.2862 - activation_9_loss: 1.5070 - prob_loss: 1.1638 - activation_8_accuracy: 0.5192 - activation_8_macro_f1score: 0.2632 - activation_8_weighted_f1score: 0.0482 - activation_9_accuracy: 0.3957 - activation_9_macro_f1score: 0.1521 - activation_9_weighted_f1score: 0.0298 - prob_accuracy: 0.5592 - prob_macro_f1score: 0.3391 - prob_weighted_f1score: 0.0602 - val_loss: 2.1324 - val_activation_8_loss: 1.2041 - val_activation_9_loss: 1.3163 - val_prob_loss: 1.1659 - val_activation_8_accuracy: 0.5372 - val_activation_8_macro_f1score: 0.2989 - val_activation_8_weighted_f1score: 0.0545 - val_activation_9_accuracy: 0.5143 - val_activation_9_macro_f1score: 0.1908 - val_activation_9_weighted_f1score: 0.0373 - val_prob_accuracy: 0.5584 - val_prob_macro_f1score: 0.3593 - val_prob_weighted_f1score: 0.0637\n",
      "Epoch 95/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1357 - activation_8_loss: 1.2891 - activation_9_loss: 1.5017 - prob_loss: 1.1589 - activation_8_accuracy: 0.5143 - activation_8_macro_f1score: 0.2630 - activation_8_weighted_f1score: 0.0480 - activation_9_accuracy: 0.3945 - activation_9_macro_f1score: 0.1540 - activation_9_weighted_f1score: 0.0302 - prob_accuracy: 0.5571 - prob_macro_f1score: 0.3446 - prob_weighted_f1score: 0.0609 - val_loss: 2.1180 - val_activation_8_loss: 1.2240 - val_activation_9_loss: 1.3026 - val_prob_loss: 1.1502 - val_activation_8_accuracy: 0.5506 - val_activation_8_macro_f1score: 0.2960 - val_activation_8_weighted_f1score: 0.0541 - val_activation_9_accuracy: 0.5344 - val_activation_9_macro_f1score: 0.1884 - val_activation_9_weighted_f1score: 0.0369 - val_prob_accuracy: 0.5645 - val_prob_macro_f1score: 0.3411 - val_prob_weighted_f1score: 0.0598\n",
      "Epoch 96/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1258 - activation_8_loss: 1.2802 - activation_9_loss: 1.4985 - prob_loss: 1.1529 - activation_8_accuracy: 0.5185 - activation_8_macro_f1score: 0.2630 - activation_8_weighted_f1score: 0.0482 - activation_9_accuracy: 0.3976 - activation_9_macro_f1score: 0.1541 - activation_9_weighted_f1score: 0.0302 - prob_accuracy: 0.5638 - prob_macro_f1score: 0.3486 - prob_weighted_f1score: 0.0614 - val_loss: 2.0592 - val_activation_8_loss: 1.1775 - val_activation_9_loss: 1.2981 - val_prob_loss: 1.1093 - val_activation_8_accuracy: 0.5481 - val_activation_8_macro_f1score: 0.2888 - val_activation_8_weighted_f1score: 0.0522 - val_activation_9_accuracy: 0.5361 - val_activation_9_macro_f1score: 0.1949 - val_activation_9_weighted_f1score: 0.0373 - val_prob_accuracy: 0.5776 - val_prob_macro_f1score: 0.3619 - val_prob_weighted_f1score: 0.0634\n",
      "Epoch 97/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 2.1180 - activation_8_loss: 1.2734 - activation_9_loss: 1.4968 - prob_loss: 1.1480 - activation_8_accuracy: 0.5210 - activation_8_macro_f1score: 0.2668 - activation_8_weighted_f1score: 0.0488 - activation_9_accuracy: 0.3986 - activation_9_macro_f1score: 0.1562 - activation_9_weighted_f1score: 0.0306 - prob_accuracy: 0.5670 - prob_macro_f1score: 0.3532 - prob_weighted_f1score: 0.0621 - val_loss: 2.1570 - val_activation_8_loss: 1.2097 - val_activation_9_loss: 1.3467 - val_prob_loss: 1.1798 - val_activation_8_accuracy: 0.5414 - val_activation_8_macro_f1score: 0.2780 - val_activation_8_weighted_f1score: 0.0487 - val_activation_9_accuracy: 0.5146 - val_activation_9_macro_f1score: 0.1935 - val_activation_9_weighted_f1score: 0.0355 - val_prob_accuracy: 0.5620 - val_prob_macro_f1score: 0.3282 - val_prob_weighted_f1score: 0.0566\n",
      "Epoch 98/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 2.1203 - activation_8_loss: 1.2746 - activation_9_loss: 1.5011 - prob_loss: 1.1489 - activation_8_accuracy: 0.5181 - activation_8_macro_f1score: 0.2657 - activation_8_weighted_f1score: 0.0486 - activation_9_accuracy: 0.3967 - activation_9_macro_f1score: 0.1531 - activation_9_weighted_f1score: 0.0303 - prob_accuracy: 0.5668 - prob_macro_f1score: 0.3552 - prob_weighted_f1score: 0.0626 - val_loss: 2.0951 - val_activation_8_loss: 1.2103 - val_activation_9_loss: 1.2854 - val_prob_loss: 1.1383 - val_activation_8_accuracy: 0.5355 - val_activation_8_macro_f1score: 0.2717 - val_activation_8_weighted_f1score: 0.0502 - val_activation_9_accuracy: 0.5327 - val_activation_9_macro_f1score: 0.1983 - val_activation_9_weighted_f1score: 0.0392 - val_prob_accuracy: 0.5715 - val_prob_macro_f1score: 0.3670 - val_prob_weighted_f1score: 0.0654\n",
      "Epoch 99/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 2.1207 - activation_8_loss: 1.2749 - activation_9_loss: 1.5045 - prob_loss: 1.1484 - activation_8_accuracy: 0.5208 - activation_8_macro_f1score: 0.2687 - activation_8_weighted_f1score: 0.0489 - activation_9_accuracy: 0.3957 - activation_9_macro_f1score: 0.1528 - activation_9_weighted_f1score: 0.0299 - prob_accuracy: 0.5646 - prob_macro_f1score: 0.3562 - prob_weighted_f1score: 0.0622 - val_loss: 2.0728 - val_activation_8_loss: 1.1781 - val_activation_9_loss: 1.2928 - val_prob_loss: 1.1245 - val_activation_8_accuracy: 0.5520 - val_activation_8_macro_f1score: 0.3010 - val_activation_8_weighted_f1score: 0.0544 - val_activation_9_accuracy: 0.5302 - val_activation_9_macro_f1score: 0.1907 - val_activation_9_weighted_f1score: 0.0381 - val_prob_accuracy: 0.5762 - val_prob_macro_f1score: 0.3562 - val_prob_weighted_f1score: 0.0635\n",
      "Epoch 100/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.1328 - activation_8_loss: 1.2836 - activation_9_loss: 1.5071 - prob_loss: 1.1574 - activation_8_accuracy: 0.5168 - activation_8_macro_f1score: 0.2641 - activation_8_weighted_f1score: 0.0481 - activation_9_accuracy: 0.3957 - activation_9_macro_f1score: 0.1538 - activation_9_weighted_f1score: 0.0303 - prob_accuracy: 0.5644 - prob_macro_f1score: 0.3496 - prob_weighted_f1score: 0.0612 - val_loss: 2.0573 - val_activation_8_loss: 1.1874 - val_activation_9_loss: 1.3022 - val_prob_loss: 1.1041 - val_activation_8_accuracy: 0.5467 - val_activation_8_macro_f1score: 0.3037 - val_activation_8_weighted_f1score: 0.0564 - val_activation_9_accuracy: 0.5322 - val_activation_9_macro_f1score: 0.1811 - val_activation_9_weighted_f1score: 0.0355 - val_prob_accuracy: 0.5773 - val_prob_macro_f1score: 0.3725 - val_prob_weighted_f1score: 0.0670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9aa6373f28>"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate_train_for_three(x_train,y_train), steps_per_epoch=len(x_train)/128, validation_data= generate_valid_for_three(x_valid,y_valid), validation_steps=len(x_valid)/128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2715,
     "status": "ok",
     "timestamp": 1583394863182,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "J_pa1ctCrEh6",
    "outputId": "09fce5ca-c940-45f4-ffd3-33026a904772"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 3s 751us/sample - loss: 2.0576 - activation_8_loss: 1.2224 - activation_9_loss: 1.3072 - prob_loss: 1.1487 - activation_8_accuracy: 0.5293 - activation_8_macro_f1score: 0.2894 - activation_8_weighted_f1score: 0.0528 - activation_9_accuracy: 0.5407 - activation_9_macro_f1score: 0.1886 - activation_9_weighted_f1score: 0.0367 - prob_accuracy: 0.5624 - prob_macro_f1score: 0.3679 - prob_weighted_f1score: 0.0634\n",
      "\n",
      "Final Accuracy: 0.5624, Final Macro F1 Score: 0.3679, Final Weighted F1 Score: 0.0634\n"
     ]
    }
   ],
   "source": [
    "*_, acc, mac_f1, wei_f1 = model.evaluate(x_test,[y_test,y_test,y_test],batch_size=128)\n",
    "print(\"\\nFinal Accuracy: {:.4f}, Final Macro F1 Score: {:.4f}, Final Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F4YDGmb9Mq4p"
   },
   "source": [
    "### 3) Epoch = 300 (Exception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8KatDwUlMkSX"
   },
   "outputs": [],
   "source": [
    "model = my_googlenet(input_shape=(48, 48, 3), classes=7, weights_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a7RuoYROMeWf"
   },
   "outputs": [],
   "source": [
    "def decay(epoch, steps=100) : # learning rate decay를 하기 위해 정의한 함수. // step은 왜 100으로 정의하는지 자세히는 모르겠다... LearningRateScheduler에서 필요할지도 모름\n",
    "  initial_lrate=0.01\n",
    "  drop = 0.96\n",
    "  epochs_drop = 8\n",
    "  lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop)) # math.pow 는 거듭제곱 계산으로, 여기서 drop^(math.floor~) 의 형태이다. 입출력이 모두 실수형(double)이다.\n",
    "  return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aj2xzEMxMeeU"
   },
   "outputs": [],
   "source": [
    "initial_lrate = 0.01\n",
    "lr_sc = LearningRateScheduler(decay,verbose=1)\n",
    "sgd = SGD(lr=initial_lrate , momentum=0.9 , nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOVowkiTMecY"
   },
   "outputs": [],
   "source": [
    "# 편의를 위해 Adam으로 해보자.\n",
    "# auxiliary classifier는 regularization의 일종이다. (loss에서 가중치를 주어 계산하는 셈이기 때문.)\n",
    "model.compile(optimizer=sgd, loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], loss_weights=[0.3,0.3,1],\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7487143,
     "status": "ok",
     "timestamp": 1583407804501,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "oc-JsfEQMeaA",
    "outputId": "8add2486-a732-49b4-c6ed-8da12e5fdcce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/300\n",
      "225/224 [==============================] - 39s 174ms/step - loss: 3.2554 - activation_12_loss: 1.8687 - activation_13_loss: 1.8777 - prob_loss: 1.8325 - activation_12_accuracy: 0.2305 - activation_12_macro_f1score: 0.0000e+00 - activation_12_weighted_f1score: 0.0000e+00 - activation_13_accuracy: 0.2348 - activation_13_macro_f1score: 0.0000e+00 - activation_13_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2490 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3283 - val_activation_12_loss: 1.8344 - val_activation_13_loss: 1.8450 - val_prob_loss: 1.8179 - val_activation_12_accuracy: 0.2449 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2449 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2449 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 3.2076 - activation_12_loss: 1.8323 - activation_13_loss: 1.8374 - prob_loss: 1.8131 - activation_12_accuracy: 0.2475 - activation_12_macro_f1score: 0.0000e+00 - activation_12_weighted_f1score: 0.0000e+00 - activation_13_accuracy: 0.2509 - activation_13_macro_f1score: 0.0000e+00 - activation_13_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2513 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.3059 - val_activation_12_loss: 1.8215 - val_activation_13_loss: 1.8282 - val_prob_loss: 1.8105 - val_activation_12_accuracy: 0.2435 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2435 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2435 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 3/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 3.1920 - activation_12_loss: 1.8236 - activation_13_loss: 1.8257 - prob_loss: 1.8087 - activation_12_accuracy: 0.2483 - activation_12_macro_f1score: 0.0000e+00 - activation_12_weighted_f1score: 0.0000e+00 - activation_13_accuracy: 0.2514 - activation_13_macro_f1score: 0.0000e+00 - activation_13_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2514 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2989 - val_activation_12_loss: 1.8198 - val_activation_13_loss: 1.8257 - val_prob_loss: 1.8099 - val_activation_12_accuracy: 0.2513 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2513 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2513 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 4/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 3.1723 - activation_12_loss: 1.8156 - activation_13_loss: 1.8197 - prob_loss: 1.7981 - activation_12_accuracy: 0.2509 - activation_12_macro_f1score: 0.0000e+00 - activation_12_weighted_f1score: 0.0000e+00 - activation_13_accuracy: 0.2514 - activation_13_macro_f1score: 0.0000e+00 - activation_13_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2515 - prob_macro_f1score: 0.0000e+00 - prob_weighted_f1score: 0.0000e+00 - val_loss: 3.2411 - val_activation_12_loss: 1.8014 - val_activation_13_loss: 1.8097 - val_prob_loss: 1.7691 - val_activation_12_accuracy: 0.2405 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2405 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2466 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 5/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 3.1482 - activation_12_loss: 1.8070 - activation_13_loss: 1.8119 - prob_loss: 1.7835 - activation_12_accuracy: 0.2505 - activation_12_macro_f1score: 0.0000e+00 - activation_12_weighted_f1score: 0.0000e+00 - activation_13_accuracy: 0.2514 - activation_13_macro_f1score: 0.0000e+00 - activation_13_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2604 - prob_macro_f1score: 1.0582e-04 - prob_weighted_f1score: 9.0939e-06 - val_loss: 3.2642 - val_activation_12_loss: 1.8058 - val_activation_13_loss: 1.8150 - val_prob_loss: 1.7931 - val_activation_12_accuracy: 0.2438 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2410 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2522 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 6/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 3.1256 - activation_12_loss: 1.7993 - activation_13_loss: 1.8080 - prob_loss: 1.7689 - activation_12_accuracy: 0.2535 - activation_12_macro_f1score: 0.0000e+00 - activation_12_weighted_f1score: 0.0000e+00 - activation_13_accuracy: 0.2524 - activation_13_macro_f1score: 0.0000e+00 - activation_13_weighted_f1score: 0.0000e+00 - prob_accuracy: 0.2706 - prob_macro_f1score: 0.0032 - prob_weighted_f1score: 3.6494e-04 - val_loss: 3.2600 - val_activation_12_loss: 1.7785 - val_activation_13_loss: 1.8014 - val_prob_loss: 1.8055 - val_activation_12_accuracy: 0.2477 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2452 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2463 - val_prob_macro_f1score: 0.0000e+00 - val_prob_weighted_f1score: 0.0000e+00\n",
      "Epoch 7/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 3.0968 - activation_12_loss: 1.7862 - activation_13_loss: 1.8008 - prob_loss: 1.7502 - activation_12_accuracy: 0.2626 - activation_12_macro_f1score: 0.0012 - activation_12_weighted_f1score: 1.1891e-04 - activation_13_accuracy: 0.2592 - activation_13_macro_f1score: 2.2046e-04 - activation_13_weighted_f1score: 2.6937e-05 - prob_accuracy: 0.2816 - prob_macro_f1score: 0.0170 - prob_weighted_f1score: 0.0019 - val_loss: 3.1400 - val_activation_12_loss: 1.7574 - val_activation_13_loss: 1.7831 - val_prob_loss: 1.7054 - val_activation_12_accuracy: 0.2641 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2441 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2884 - val_prob_macro_f1score: 0.0342 - val_prob_weighted_f1score: 0.0041\n",
      "Epoch 8/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 3.0797 - activation_12_loss: 1.7740 - activation_13_loss: 1.7962 - prob_loss: 1.7423 - activation_12_accuracy: 0.2690 - activation_12_macro_f1score: 0.0051 - activation_12_weighted_f1score: 5.5786e-04 - activation_13_accuracy: 0.2604 - activation_13_macro_f1score: 0.0030 - activation_13_weighted_f1score: 3.4708e-04 - prob_accuracy: 0.2830 - prob_macro_f1score: 0.0238 - prob_weighted_f1score: 0.0027 - val_loss: 3.1972 - val_activation_12_loss: 1.7525 - val_activation_13_loss: 1.7922 - val_prob_loss: 1.7637 - val_activation_12_accuracy: 0.2714 - val_activation_12_macro_f1score: 0.0000e+00 - val_activation_12_weighted_f1score: 0.0000e+00 - val_activation_13_accuracy: 0.2446 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2689 - val_prob_macro_f1score: 4.2836e-04 - val_prob_weighted_f1score: 7.3624e-05\n",
      "Epoch 9/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 3.0632 - activation_12_loss: 1.7624 - activation_13_loss: 1.7948 - prob_loss: 1.7339 - activation_12_accuracy: 0.2748 - activation_12_macro_f1score: 0.0120 - activation_12_weighted_f1score: 0.0013 - activation_13_accuracy: 0.2599 - activation_13_macro_f1score: 0.0046 - activation_13_weighted_f1score: 5.3394e-04 - prob_accuracy: 0.2878 - prob_macro_f1score: 0.0251 - prob_weighted_f1score: 0.0028 - val_loss: 3.1258 - val_activation_12_loss: 1.7302 - val_activation_13_loss: 1.7781 - val_prob_loss: 1.7097 - val_activation_12_accuracy: 0.2901 - val_activation_12_macro_f1score: 0.0224 - val_activation_12_weighted_f1score: 0.0027 - val_activation_13_accuracy: 0.2569 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.3029 - val_prob_macro_f1score: 0.0270 - val_prob_weighted_f1score: 0.0032\n",
      "Epoch 10/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 3.0430 - activation_12_loss: 1.7513 - activation_13_loss: 1.7902 - prob_loss: 1.7225 - activation_12_accuracy: 0.2789 - activation_12_macro_f1score: 0.0205 - activation_12_weighted_f1score: 0.0023 - activation_13_accuracy: 0.2603 - activation_13_macro_f1score: 0.0067 - activation_13_weighted_f1score: 7.4581e-04 - prob_accuracy: 0.2904 - prob_macro_f1score: 0.0294 - prob_weighted_f1score: 0.0033 - val_loss: 3.1288 - val_activation_12_loss: 1.7284 - val_activation_13_loss: 1.7746 - val_prob_loss: 1.7182 - val_activation_12_accuracy: 0.2811 - val_activation_12_macro_f1score: 0.0161 - val_activation_12_weighted_f1score: 0.0018 - val_activation_13_accuracy: 0.2419 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2781 - val_prob_macro_f1score: 0.0125 - val_prob_weighted_f1score: 0.0016\n",
      "Epoch 11/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 3.0336 - activation_12_loss: 1.7489 - activation_13_loss: 1.7885 - prob_loss: 1.7183 - activation_12_accuracy: 0.2807 - activation_12_macro_f1score: 0.0220 - activation_12_weighted_f1score: 0.0024 - activation_13_accuracy: 0.2621 - activation_13_macro_f1score: 0.0082 - activation_13_weighted_f1score: 9.3489e-04 - prob_accuracy: 0.2958 - prob_macro_f1score: 0.0344 - prob_weighted_f1score: 0.0039 - val_loss: 3.1208 - val_activation_12_loss: 1.7255 - val_activation_13_loss: 1.7784 - val_prob_loss: 1.7142 - val_activation_12_accuracy: 0.2842 - val_activation_12_macro_f1score: 0.0149 - val_activation_12_weighted_f1score: 0.0016 - val_activation_13_accuracy: 0.2480 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2979 - val_prob_macro_f1score: 0.0143 - val_prob_weighted_f1score: 0.0016\n",
      "Epoch 12/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 3.0261 - activation_12_loss: 1.7456 - activation_13_loss: 1.7884 - prob_loss: 1.7156 - activation_12_accuracy: 0.2804 - activation_12_macro_f1score: 0.0210 - activation_12_weighted_f1score: 0.0024 - activation_13_accuracy: 0.2631 - activation_13_macro_f1score: 0.0093 - activation_13_weighted_f1score: 0.0010 - prob_accuracy: 0.2972 - prob_macro_f1score: 0.0350 - prob_weighted_f1score: 0.0039 - val_loss: 3.0753 - val_activation_12_loss: 1.7037 - val_activation_13_loss: 1.7551 - val_prob_loss: 1.6873 - val_activation_12_accuracy: 0.2850 - val_activation_12_macro_f1score: 0.0337 - val_activation_12_weighted_f1score: 0.0040 - val_activation_13_accuracy: 0.2658 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.2967 - val_prob_macro_f1score: 0.0599 - val_prob_weighted_f1score: 0.0070\n",
      "Epoch 13/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 3.0105 - activation_12_loss: 1.7414 - activation_13_loss: 1.7836 - prob_loss: 1.7063 - activation_12_accuracy: 0.2850 - activation_12_macro_f1score: 0.0242 - activation_12_weighted_f1score: 0.0027 - activation_13_accuracy: 0.2649 - activation_13_macro_f1score: 0.0121 - activation_13_weighted_f1score: 0.0014 - prob_accuracy: 0.3054 - prob_macro_f1score: 0.0396 - prob_weighted_f1score: 0.0044 - val_loss: 3.0723 - val_activation_12_loss: 1.7123 - val_activation_13_loss: 1.7649 - val_prob_loss: 1.6825 - val_activation_12_accuracy: 0.2945 - val_activation_12_macro_f1score: 0.0393 - val_activation_12_weighted_f1score: 0.0046 - val_activation_13_accuracy: 0.2658 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.3098 - val_prob_macro_f1score: 0.0455 - val_prob_weighted_f1score: 0.0053\n",
      "Epoch 14/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.9934 - activation_12_loss: 1.7395 - activation_13_loss: 1.7815 - prob_loss: 1.6940 - activation_12_accuracy: 0.2839 - activation_12_macro_f1score: 0.0267 - activation_12_weighted_f1score: 0.0030 - activation_13_accuracy: 0.2645 - activation_13_macro_f1score: 0.0140 - activation_13_weighted_f1score: 0.0015 - prob_accuracy: 0.3088 - prob_macro_f1score: 0.0465 - prob_weighted_f1score: 0.0053 - val_loss: 3.0519 - val_activation_12_loss: 1.7054 - val_activation_13_loss: 1.7590 - val_prob_loss: 1.6701 - val_activation_12_accuracy: 0.2970 - val_activation_12_macro_f1score: 0.0428 - val_activation_12_weighted_f1score: 0.0050 - val_activation_13_accuracy: 0.2714 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.3232 - val_prob_macro_f1score: 0.0635 - val_prob_weighted_f1score: 0.0075\n",
      "Epoch 15/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.9739 - activation_12_loss: 1.7334 - activation_13_loss: 1.7794 - prob_loss: 1.6804 - activation_12_accuracy: 0.2870 - activation_12_macro_f1score: 0.0285 - activation_12_weighted_f1score: 0.0031 - activation_13_accuracy: 0.2663 - activation_13_macro_f1score: 0.0157 - activation_13_weighted_f1score: 0.0017 - prob_accuracy: 0.3199 - prob_macro_f1score: 0.0572 - prob_weighted_f1score: 0.0075 - val_loss: 2.9821 - val_activation_12_loss: 1.6845 - val_activation_13_loss: 1.7361 - val_prob_loss: 1.6191 - val_activation_12_accuracy: 0.3006 - val_activation_12_macro_f1score: 0.0532 - val_activation_12_weighted_f1score: 0.0070 - val_activation_13_accuracy: 0.2870 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.3422 - val_prob_macro_f1score: 0.0897 - val_prob_weighted_f1score: 0.0136\n",
      "Epoch 16/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.9647 - activation_12_loss: 1.7327 - activation_13_loss: 1.7773 - prob_loss: 1.6752 - activation_12_accuracy: 0.2868 - activation_12_macro_f1score: 0.0275 - activation_12_weighted_f1score: 0.0031 - activation_13_accuracy: 0.2664 - activation_13_macro_f1score: 0.0169 - activation_13_weighted_f1score: 0.0020 - prob_accuracy: 0.3222 - prob_macro_f1score: 0.0660 - prob_weighted_f1score: 0.0103 - val_loss: 3.0202 - val_activation_12_loss: 1.7112 - val_activation_13_loss: 1.7383 - val_prob_loss: 1.6502 - val_activation_12_accuracy: 0.2862 - val_activation_12_macro_f1score: 0.0552 - val_activation_12_weighted_f1score: 0.0060 - val_activation_13_accuracy: 0.2917 - val_activation_13_macro_f1score: 8.2102e-04 - val_activation_13_weighted_f1score: 7.0556e-05 - val_prob_accuracy: 0.3396 - val_prob_macro_f1score: 0.0979 - val_prob_weighted_f1score: 0.0137\n",
      "Epoch 17/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.9113 - activation_12_loss: 1.7185 - activation_13_loss: 1.7664 - prob_loss: 1.6322 - activation_12_accuracy: 0.2962 - activation_12_macro_f1score: 0.0336 - activation_12_weighted_f1score: 0.0037 - activation_13_accuracy: 0.2695 - activation_13_macro_f1score: 0.0234 - activation_13_weighted_f1score: 0.0029 - prob_accuracy: 0.3495 - prob_macro_f1score: 0.0997 - prob_weighted_f1score: 0.0174 - val_loss: 2.9504 - val_activation_12_loss: 1.6958 - val_activation_13_loss: 1.7051 - val_prob_loss: 1.6001 - val_activation_12_accuracy: 0.3020 - val_activation_12_macro_f1score: 0.0670 - val_activation_12_weighted_f1score: 0.0079 - val_activation_13_accuracy: 0.3115 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.3667 - val_prob_macro_f1score: 0.1315 - val_prob_weighted_f1score: 0.0225\n",
      "Epoch 18/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.8887 - activation_12_loss: 1.7120 - activation_13_loss: 1.7599 - prob_loss: 1.6161 - activation_12_accuracy: 0.2996 - activation_12_macro_f1score: 0.0360 - activation_12_weighted_f1score: 0.0041 - activation_13_accuracy: 0.2696 - activation_13_macro_f1score: 0.0276 - activation_13_weighted_f1score: 0.0044 - prob_accuracy: 0.3611 - prob_macro_f1score: 0.1122 - prob_weighted_f1score: 0.0205 - val_loss: 2.8805 - val_activation_12_loss: 1.6692 - val_activation_13_loss: 1.7064 - val_prob_loss: 1.5425 - val_activation_12_accuracy: 0.3070 - val_activation_12_macro_f1score: 0.0428 - val_activation_12_weighted_f1score: 0.0052 - val_activation_13_accuracy: 0.2906 - val_activation_13_macro_f1score: 0.0000e+00 - val_activation_13_weighted_f1score: 0.0000e+00 - val_prob_accuracy: 0.4068 - val_prob_macro_f1score: 0.1333 - val_prob_weighted_f1score: 0.0253\n",
      "Epoch 19/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.8300 - activation_12_loss: 1.6950 - activation_13_loss: 1.7471 - prob_loss: 1.5685 - activation_12_accuracy: 0.3036 - activation_12_macro_f1score: 0.0438 - activation_12_weighted_f1score: 0.0054 - activation_13_accuracy: 0.2727 - activation_13_macro_f1score: 0.0437 - activation_13_weighted_f1score: 0.0081 - prob_accuracy: 0.3849 - prob_macro_f1score: 0.1318 - prob_weighted_f1score: 0.0248 - val_loss: 2.8076 - val_activation_12_loss: 1.6351 - val_activation_13_loss: 1.6645 - val_prob_loss: 1.4969 - val_activation_12_accuracy: 0.3137 - val_activation_12_macro_f1score: 0.0446 - val_activation_12_weighted_f1score: 0.0053 - val_activation_13_accuracy: 0.2870 - val_activation_13_macro_f1score: 0.0330 - val_activation_13_weighted_f1score: 0.0082 - val_prob_accuracy: 0.4207 - val_prob_macro_f1score: 0.1454 - val_prob_weighted_f1score: 0.0304\n",
      "Epoch 20/300\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.7838 - activation_12_loss: 1.6721 - activation_13_loss: 1.7327 - prob_loss: 1.5357 - activation_12_accuracy: 0.3165 - activation_12_macro_f1score: 0.0633 - activation_12_weighted_f1score: 0.0095 - activation_13_accuracy: 0.2739 - activation_13_macro_f1score: 0.0635 - activation_13_weighted_f1score: 0.0125 - prob_accuracy: 0.3995 - prob_macro_f1score: 0.1453 - prob_weighted_f1score: 0.0271 - val_loss: 2.7308 - val_activation_12_loss: 1.5777 - val_activation_13_loss: 1.6515 - val_prob_loss: 1.4460 - val_activation_12_accuracy: 0.3416 - val_activation_12_macro_f1score: 0.1074 - val_activation_12_weighted_f1score: 0.0197 - val_activation_13_accuracy: 0.3045 - val_activation_13_macro_f1score: 0.0392 - val_activation_13_weighted_f1score: 0.0096 - val_prob_accuracy: 0.4430 - val_prob_macro_f1score: 0.1586 - val_prob_weighted_f1score: 0.0319\n",
      "Epoch 21/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.7565 - activation_12_loss: 1.6535 - activation_13_loss: 1.7263 - prob_loss: 1.5180 - activation_12_accuracy: 0.3237 - activation_12_macro_f1score: 0.0853 - activation_12_weighted_f1score: 0.0145 - activation_13_accuracy: 0.2760 - activation_13_macro_f1score: 0.0674 - activation_13_weighted_f1score: 0.0136 - prob_accuracy: 0.4062 - prob_macro_f1score: 0.1521 - prob_weighted_f1score: 0.0287 - val_loss: 2.6815 - val_activation_12_loss: 1.5555 - val_activation_13_loss: 1.6079 - val_prob_loss: 1.4199 - val_activation_12_accuracy: 0.3865 - val_activation_12_macro_f1score: 0.1181 - val_activation_12_weighted_f1score: 0.0201 - val_activation_13_accuracy: 0.3422 - val_activation_13_macro_f1score: 0.0784 - val_activation_13_weighted_f1score: 0.0160 - val_prob_accuracy: 0.4606 - val_prob_macro_f1score: 0.1774 - val_prob_weighted_f1score: 0.0338\n",
      "Epoch 22/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.7028 - activation_12_loss: 1.6303 - activation_13_loss: 1.7063 - prob_loss: 1.4793 - activation_12_accuracy: 0.3318 - activation_12_macro_f1score: 0.1044 - activation_12_weighted_f1score: 0.0186 - activation_13_accuracy: 0.2923 - activation_13_macro_f1score: 0.0838 - activation_13_weighted_f1score: 0.0161 - prob_accuracy: 0.4221 - prob_macro_f1score: 0.1685 - prob_weighted_f1score: 0.0313 - val_loss: 2.6865 - val_activation_12_loss: 1.5527 - val_activation_13_loss: 1.6094 - val_prob_loss: 1.4274 - val_activation_12_accuracy: 0.4071 - val_activation_12_macro_f1score: 0.1420 - val_activation_12_weighted_f1score: 0.0265 - val_activation_13_accuracy: 0.3491 - val_activation_13_macro_f1score: 0.0847 - val_activation_13_weighted_f1score: 0.0193 - val_prob_accuracy: 0.4397 - val_prob_macro_f1score: 0.1741 - val_prob_weighted_f1score: 0.0330\n",
      "Epoch 23/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.6786 - activation_12_loss: 1.6093 - activation_13_loss: 1.6979 - prob_loss: 1.4660 - activation_12_accuracy: 0.3496 - activation_12_macro_f1score: 0.1157 - activation_12_weighted_f1score: 0.0215 - activation_13_accuracy: 0.2969 - activation_13_macro_f1score: 0.0867 - activation_13_weighted_f1score: 0.0170 - prob_accuracy: 0.4289 - prob_macro_f1score: 0.1709 - prob_weighted_f1score: 0.0321 - val_loss: 2.8138 - val_activation_12_loss: 1.5664 - val_activation_13_loss: 1.5651 - val_prob_loss: 1.5617 - val_activation_12_accuracy: 0.3672 - val_activation_12_macro_f1score: 0.1728 - val_activation_12_weighted_f1score: 0.0325 - val_activation_13_accuracy: 0.3422 - val_activation_13_macro_f1score: 0.1416 - val_activation_13_weighted_f1score: 0.0263 - val_prob_accuracy: 0.4090 - val_prob_macro_f1score: 0.1825 - val_prob_weighted_f1score: 0.0355\n",
      "Epoch 24/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.6670 - activation_12_loss: 1.5978 - activation_13_loss: 1.6914 - prob_loss: 1.4618 - activation_12_accuracy: 0.3531 - activation_12_macro_f1score: 0.1231 - activation_12_weighted_f1score: 0.0229 - activation_13_accuracy: 0.3027 - activation_13_macro_f1score: 0.0926 - activation_13_weighted_f1score: 0.0177 - prob_accuracy: 0.4298 - prob_macro_f1score: 0.1738 - prob_weighted_f1score: 0.0325 - val_loss: 2.6182 - val_activation_12_loss: 1.4948 - val_activation_13_loss: 1.5780 - val_prob_loss: 1.3923 - val_activation_12_accuracy: 0.4029 - val_activation_12_macro_f1score: 0.1574 - val_activation_12_weighted_f1score: 0.0301 - val_activation_13_accuracy: 0.3926 - val_activation_13_macro_f1score: 0.0931 - val_activation_13_weighted_f1score: 0.0200 - val_prob_accuracy: 0.4475 - val_prob_macro_f1score: 0.1986 - val_prob_weighted_f1score: 0.0374\n",
      "Epoch 25/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.6429 - activation_12_loss: 1.5878 - activation_13_loss: 1.6873 - prob_loss: 1.4440 - activation_12_accuracy: 0.3588 - activation_12_macro_f1score: 0.1251 - activation_12_weighted_f1score: 0.0235 - activation_13_accuracy: 0.3045 - activation_13_macro_f1score: 0.0933 - activation_13_weighted_f1score: 0.0176 - prob_accuracy: 0.4426 - prob_macro_f1score: 0.1806 - prob_weighted_f1score: 0.0338 - val_loss: 2.5803 - val_activation_12_loss: 1.5019 - val_activation_13_loss: 1.5461 - val_prob_loss: 1.3650 - val_activation_12_accuracy: 0.3915 - val_activation_12_macro_f1score: 0.1699 - val_activation_12_weighted_f1score: 0.0325 - val_activation_13_accuracy: 0.3929 - val_activation_13_macro_f1score: 0.1281 - val_activation_13_weighted_f1score: 0.0250 - val_prob_accuracy: 0.4792 - val_prob_macro_f1score: 0.2177 - val_prob_weighted_f1score: 0.0404\n",
      "Epoch 26/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.6179 - activation_12_loss: 1.5719 - activation_13_loss: 1.6799 - prob_loss: 1.4282 - activation_12_accuracy: 0.3719 - activation_12_macro_f1score: 0.1338 - activation_12_weighted_f1score: 0.0251 - activation_13_accuracy: 0.3070 - activation_13_macro_f1score: 0.0976 - activation_13_weighted_f1score: 0.0187 - prob_accuracy: 0.4494 - prob_macro_f1score: 0.1900 - prob_weighted_f1score: 0.0353 - val_loss: 2.6220 - val_activation_12_loss: 1.4993 - val_activation_13_loss: 1.5542 - val_prob_loss: 1.4060 - val_activation_12_accuracy: 0.4132 - val_activation_12_macro_f1score: 0.1628 - val_activation_12_weighted_f1score: 0.0312 - val_activation_13_accuracy: 0.4101 - val_activation_13_macro_f1score: 0.1243 - val_activation_13_weighted_f1score: 0.0254 - val_prob_accuracy: 0.4614 - val_prob_macro_f1score: 0.2101 - val_prob_weighted_f1score: 0.0390\n",
      "Epoch 27/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.5973 - activation_12_loss: 1.5656 - activation_13_loss: 1.6733 - prob_loss: 1.4136 - activation_12_accuracy: 0.3730 - activation_12_macro_f1score: 0.1347 - activation_12_weighted_f1score: 0.0255 - activation_13_accuracy: 0.3113 - activation_13_macro_f1score: 0.0998 - activation_13_weighted_f1score: 0.0191 - prob_accuracy: 0.4558 - prob_macro_f1score: 0.1964 - prob_weighted_f1score: 0.0366 - val_loss: 2.5152 - val_activation_12_loss: 1.4664 - val_activation_13_loss: 1.5197 - val_prob_loss: 1.3249 - val_activation_12_accuracy: 0.4319 - val_activation_12_macro_f1score: 0.1554 - val_activation_12_weighted_f1score: 0.0292 - val_activation_13_accuracy: 0.4230 - val_activation_13_macro_f1score: 0.1343 - val_activation_13_weighted_f1score: 0.0268 - val_prob_accuracy: 0.4801 - val_prob_macro_f1score: 0.2415 - val_prob_weighted_f1score: 0.0442\n",
      "Epoch 28/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.5895 - activation_12_loss: 1.5590 - activation_13_loss: 1.6732 - prob_loss: 1.4098 - activation_12_accuracy: 0.3809 - activation_12_macro_f1score: 0.1353 - activation_12_weighted_f1score: 0.0258 - activation_13_accuracy: 0.3118 - activation_13_macro_f1score: 0.0975 - activation_13_weighted_f1score: 0.0189 - prob_accuracy: 0.4536 - prob_macro_f1score: 0.1943 - prob_weighted_f1score: 0.0363 - val_loss: 2.6207 - val_activation_12_loss: 1.4957 - val_activation_13_loss: 1.5530 - val_prob_loss: 1.4101 - val_activation_12_accuracy: 0.4218 - val_activation_12_macro_f1score: 0.1648 - val_activation_12_weighted_f1score: 0.0301 - val_activation_13_accuracy: 0.4361 - val_activation_13_macro_f1score: 0.1133 - val_activation_13_weighted_f1score: 0.0223 - val_prob_accuracy: 0.4645 - val_prob_macro_f1score: 0.2285 - val_prob_weighted_f1score: 0.0421\n",
      "Epoch 29/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.5513 - activation_12_loss: 1.5435 - activation_13_loss: 1.6620 - prob_loss: 1.3815 - activation_12_accuracy: 0.3875 - activation_12_macro_f1score: 0.1385 - activation_12_weighted_f1score: 0.0264 - activation_13_accuracy: 0.3179 - activation_13_macro_f1score: 0.1055 - activation_13_weighted_f1score: 0.0201 - prob_accuracy: 0.4694 - prob_macro_f1score: 0.2091 - prob_weighted_f1score: 0.0389 - val_loss: 2.4952 - val_activation_12_loss: 1.4407 - val_activation_13_loss: 1.5057 - val_prob_loss: 1.3215 - val_activation_12_accuracy: 0.4349 - val_activation_12_macro_f1score: 0.1711 - val_activation_12_weighted_f1score: 0.0342 - val_activation_13_accuracy: 0.4221 - val_activation_13_macro_f1score: 0.1240 - val_activation_13_weighted_f1score: 0.0278 - val_prob_accuracy: 0.4843 - val_prob_macro_f1score: 0.2090 - val_prob_weighted_f1score: 0.0407\n",
      "Epoch 30/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.5450 - activation_12_loss: 1.5442 - activation_13_loss: 1.6571 - prob_loss: 1.3783 - activation_12_accuracy: 0.3872 - activation_12_macro_f1score: 0.1388 - activation_12_weighted_f1score: 0.0266 - activation_13_accuracy: 0.3145 - activation_13_macro_f1score: 0.1057 - activation_13_weighted_f1score: 0.0202 - prob_accuracy: 0.4682 - prob_macro_f1score: 0.2094 - prob_weighted_f1score: 0.0388 - val_loss: 2.5400 - val_activation_12_loss: 1.4766 - val_activation_13_loss: 1.5336 - val_prob_loss: 1.3474 - val_activation_12_accuracy: 0.4427 - val_activation_12_macro_f1score: 0.1765 - val_activation_12_weighted_f1score: 0.0335 - val_activation_13_accuracy: 0.4277 - val_activation_13_macro_f1score: 0.1295 - val_activation_13_weighted_f1score: 0.0266 - val_prob_accuracy: 0.4873 - val_prob_macro_f1score: 0.2121 - val_prob_weighted_f1score: 0.0389\n",
      "Epoch 31/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.5312 - activation_12_loss: 1.5374 - activation_13_loss: 1.6588 - prob_loss: 1.3680 - activation_12_accuracy: 0.3901 - activation_12_macro_f1score: 0.1419 - activation_12_weighted_f1score: 0.0270 - activation_13_accuracy: 0.3151 - activation_13_macro_f1score: 0.1062 - activation_13_weighted_f1score: 0.0203 - prob_accuracy: 0.4741 - prob_macro_f1score: 0.2164 - prob_weighted_f1score: 0.0400 - val_loss: 2.5356 - val_activation_12_loss: 1.4918 - val_activation_13_loss: 1.4911 - val_prob_loss: 1.3532 - val_activation_12_accuracy: 0.4179 - val_activation_12_macro_f1score: 0.1849 - val_activation_12_weighted_f1score: 0.0357 - val_activation_13_accuracy: 0.4224 - val_activation_13_macro_f1score: 0.1571 - val_activation_13_weighted_f1score: 0.0321 - val_prob_accuracy: 0.4935 - val_prob_macro_f1score: 0.2420 - val_prob_weighted_f1score: 0.0453\n",
      "Epoch 32/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.5332 - activation_12_loss: 1.5335 - activation_13_loss: 1.6582 - prob_loss: 1.3731 - activation_12_accuracy: 0.3918 - activation_12_macro_f1score: 0.1460 - activation_12_weighted_f1score: 0.0275 - activation_13_accuracy: 0.3177 - activation_13_macro_f1score: 0.1082 - activation_13_weighted_f1score: 0.0203 - prob_accuracy: 0.4740 - prob_macro_f1score: 0.2148 - prob_weighted_f1score: 0.0395 - val_loss: 2.5166 - val_activation_12_loss: 1.4540 - val_activation_13_loss: 1.4883 - val_prob_loss: 1.3487 - val_activation_12_accuracy: 0.4333 - val_activation_12_macro_f1score: 0.1820 - val_activation_12_weighted_f1score: 0.0333 - val_activation_13_accuracy: 0.4349 - val_activation_13_macro_f1score: 0.1471 - val_activation_13_weighted_f1score: 0.0277 - val_prob_accuracy: 0.4709 - val_prob_macro_f1score: 0.2455 - val_prob_weighted_f1score: 0.0453\n",
      "Epoch 33/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.5116 - activation_12_loss: 1.5231 - activation_13_loss: 1.6521 - prob_loss: 1.3581 - activation_12_accuracy: 0.3958 - activation_12_macro_f1score: 0.1462 - activation_12_weighted_f1score: 0.0278 - activation_13_accuracy: 0.3195 - activation_13_macro_f1score: 0.1087 - activation_13_weighted_f1score: 0.0206 - prob_accuracy: 0.4784 - prob_macro_f1score: 0.2202 - prob_weighted_f1score: 0.0405 - val_loss: 2.4701 - val_activation_12_loss: 1.4289 - val_activation_13_loss: 1.5182 - val_prob_loss: 1.3042 - val_activation_12_accuracy: 0.4489 - val_activation_12_macro_f1score: 0.1666 - val_activation_12_weighted_f1score: 0.0340 - val_activation_13_accuracy: 0.4241 - val_activation_13_macro_f1score: 0.1068 - val_activation_13_weighted_f1score: 0.0240 - val_prob_accuracy: 0.5104 - val_prob_macro_f1score: 0.2138 - val_prob_weighted_f1score: 0.0421\n",
      "Epoch 34/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.4922 - activation_12_loss: 1.5212 - activation_13_loss: 1.6493 - prob_loss: 1.3419 - activation_12_accuracy: 0.3985 - activation_12_macro_f1score: 0.1464 - activation_12_weighted_f1score: 0.0279 - activation_13_accuracy: 0.3194 - activation_13_macro_f1score: 0.1102 - activation_13_weighted_f1score: 0.0211 - prob_accuracy: 0.4813 - prob_macro_f1score: 0.2316 - prob_weighted_f1score: 0.0425 - val_loss: 2.4633 - val_activation_12_loss: 1.4264 - val_activation_13_loss: 1.4958 - val_prob_loss: 1.3068 - val_activation_12_accuracy: 0.4397 - val_activation_12_macro_f1score: 0.1795 - val_activation_12_weighted_f1score: 0.0340 - val_activation_13_accuracy: 0.4193 - val_activation_13_macro_f1score: 0.1452 - val_activation_13_weighted_f1score: 0.0300 - val_prob_accuracy: 0.4948 - val_prob_macro_f1score: 0.2384 - val_prob_weighted_f1score: 0.0440\n",
      "Epoch 35/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.4825 - activation_12_loss: 1.5084 - activation_13_loss: 1.6473 - prob_loss: 1.3384 - activation_12_accuracy: 0.4025 - activation_12_macro_f1score: 0.1515 - activation_12_weighted_f1score: 0.0289 - activation_13_accuracy: 0.3184 - activation_13_macro_f1score: 0.1115 - activation_13_weighted_f1score: 0.0211 - prob_accuracy: 0.4842 - prob_macro_f1score: 0.2282 - prob_weighted_f1score: 0.0419 - val_loss: 2.4476 - val_activation_12_loss: 1.4190 - val_activation_13_loss: 1.4803 - val_prob_loss: 1.3002 - val_activation_12_accuracy: 0.4614 - val_activation_12_macro_f1score: 0.1839 - val_activation_12_weighted_f1score: 0.0352 - val_activation_13_accuracy: 0.4386 - val_activation_13_macro_f1score: 0.1357 - val_activation_13_weighted_f1score: 0.0281 - val_prob_accuracy: 0.4962 - val_prob_macro_f1score: 0.2741 - val_prob_weighted_f1score: 0.0503\n",
      "Epoch 36/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.4724 - activation_12_loss: 1.5047 - activation_13_loss: 1.6480 - prob_loss: 1.3310 - activation_12_accuracy: 0.4055 - activation_12_macro_f1score: 0.1537 - activation_12_weighted_f1score: 0.0290 - activation_13_accuracy: 0.3192 - activation_13_macro_f1score: 0.1098 - activation_13_weighted_f1score: 0.0209 - prob_accuracy: 0.4893 - prob_macro_f1score: 0.2331 - prob_weighted_f1score: 0.0426 - val_loss: 2.5045 - val_activation_12_loss: 1.4794 - val_activation_13_loss: 1.4769 - val_prob_loss: 1.3399 - val_activation_12_accuracy: 0.4344 - val_activation_12_macro_f1score: 0.1791 - val_activation_12_weighted_f1score: 0.0335 - val_activation_13_accuracy: 0.4377 - val_activation_13_macro_f1score: 0.1625 - val_activation_13_weighted_f1score: 0.0312 - val_prob_accuracy: 0.4921 - val_prob_macro_f1score: 0.2493 - val_prob_weighted_f1score: 0.0458\n",
      "Epoch 37/300\n",
      "225/224 [==============================] - 32s 143ms/step - loss: 2.4639 - activation_12_loss: 1.5036 - activation_13_loss: 1.6405 - prob_loss: 1.3268 - activation_12_accuracy: 0.4082 - activation_12_macro_f1score: 0.1534 - activation_12_weighted_f1score: 0.0292 - activation_13_accuracy: 0.3220 - activation_13_macro_f1score: 0.1128 - activation_13_weighted_f1score: 0.0215 - prob_accuracy: 0.4924 - prob_macro_f1score: 0.2361 - prob_weighted_f1score: 0.0432 - val_loss: 2.4905 - val_activation_12_loss: 1.4658 - val_activation_13_loss: 1.5048 - val_prob_loss: 1.3235 - val_activation_12_accuracy: 0.4394 - val_activation_12_macro_f1score: 0.1598 - val_activation_12_weighted_f1score: 0.0287 - val_activation_13_accuracy: 0.4455 - val_activation_13_macro_f1score: 0.1207 - val_activation_13_weighted_f1score: 0.0232 - val_prob_accuracy: 0.5024 - val_prob_macro_f1score: 0.2627 - val_prob_weighted_f1score: 0.0468\n",
      "Epoch 38/300\n",
      "225/224 [==============================] - 32s 144ms/step - loss: 2.4595 - activation_12_loss: 1.5087 - activation_13_loss: 1.6425 - prob_loss: 1.3219 - activation_12_accuracy: 0.4089 - activation_12_macro_f1score: 0.1494 - activation_12_weighted_f1score: 0.0286 - activation_13_accuracy: 0.3205 - activation_13_macro_f1score: 0.1124 - activation_13_weighted_f1score: 0.0213 - prob_accuracy: 0.4937 - prob_macro_f1score: 0.2407 - prob_weighted_f1score: 0.0439 - val_loss: 2.4311 - val_activation_12_loss: 1.4035 - val_activation_13_loss: 1.4935 - val_prob_loss: 1.2902 - val_activation_12_accuracy: 0.4698 - val_activation_12_macro_f1score: 0.1870 - val_activation_12_weighted_f1score: 0.0355 - val_activation_13_accuracy: 0.4461 - val_activation_13_macro_f1score: 0.1486 - val_activation_13_weighted_f1score: 0.0282 - val_prob_accuracy: 0.5046 - val_prob_macro_f1score: 0.2656 - val_prob_weighted_f1score: 0.0486\n",
      "Epoch 39/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.4427 - activation_12_loss: 1.4918 - activation_13_loss: 1.6368 - prob_loss: 1.3136 - activation_12_accuracy: 0.4147 - activation_12_macro_f1score: 0.1552 - activation_12_weighted_f1score: 0.0296 - activation_13_accuracy: 0.3180 - activation_13_macro_f1score: 0.1130 - activation_13_weighted_f1score: 0.0218 - prob_accuracy: 0.4958 - prob_macro_f1score: 0.2405 - prob_weighted_f1score: 0.0441 - val_loss: 2.5077 - val_activation_12_loss: 1.4875 - val_activation_13_loss: 1.4916 - val_prob_loss: 1.3414 - val_activation_12_accuracy: 0.4388 - val_activation_12_macro_f1score: 0.1787 - val_activation_12_weighted_f1score: 0.0331 - val_activation_13_accuracy: 0.4285 - val_activation_13_macro_f1score: 0.1536 - val_activation_13_weighted_f1score: 0.0304 - val_prob_accuracy: 0.4954 - val_prob_macro_f1score: 0.2683 - val_prob_weighted_f1score: 0.0485\n",
      "Epoch 40/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.4421 - activation_12_loss: 1.4906 - activation_13_loss: 1.6384 - prob_loss: 1.3146 - activation_12_accuracy: 0.4145 - activation_12_macro_f1score: 0.1568 - activation_12_weighted_f1score: 0.0298 - activation_13_accuracy: 0.3214 - activation_13_macro_f1score: 0.1140 - activation_13_weighted_f1score: 0.0215 - prob_accuracy: 0.4965 - prob_macro_f1score: 0.2439 - prob_weighted_f1score: 0.0444 - val_loss: 2.4213 - val_activation_12_loss: 1.4130 - val_activation_13_loss: 1.4702 - val_prob_loss: 1.2881 - val_activation_12_accuracy: 0.4528 - val_activation_12_macro_f1score: 0.1820 - val_activation_12_weighted_f1score: 0.0352 - val_activation_13_accuracy: 0.4413 - val_activation_13_macro_f1score: 0.1582 - val_activation_13_weighted_f1score: 0.0308 - val_prob_accuracy: 0.5113 - val_prob_macro_f1score: 0.2540 - val_prob_weighted_f1score: 0.0466\n",
      "Epoch 41/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.4243 - activation_12_loss: 1.4812 - activation_13_loss: 1.6353 - prob_loss: 1.3022 - activation_12_accuracy: 0.4193 - activation_12_macro_f1score: 0.1577 - activation_12_weighted_f1score: 0.0302 - activation_13_accuracy: 0.3223 - activation_13_macro_f1score: 0.1147 - activation_13_weighted_f1score: 0.0219 - prob_accuracy: 0.5001 - prob_macro_f1score: 0.2478 - prob_weighted_f1score: 0.0453 - val_loss: 2.4123 - val_activation_12_loss: 1.3720 - val_activation_13_loss: 1.4268 - val_prob_loss: 1.3063 - val_activation_12_accuracy: 0.4514 - val_activation_12_macro_f1score: 0.1925 - val_activation_12_weighted_f1score: 0.0400 - val_activation_13_accuracy: 0.4374 - val_activation_13_macro_f1score: 0.1750 - val_activation_13_weighted_f1score: 0.0372 - val_prob_accuracy: 0.4898 - val_prob_macro_f1score: 0.2702 - val_prob_weighted_f1score: 0.0532\n",
      "Epoch 42/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.4215 - activation_12_loss: 1.4793 - activation_13_loss: 1.6392 - prob_loss: 1.3002 - activation_12_accuracy: 0.4203 - activation_12_macro_f1score: 0.1608 - activation_12_weighted_f1score: 0.0305 - activation_13_accuracy: 0.3197 - activation_13_macro_f1score: 0.1119 - activation_13_weighted_f1score: 0.0214 - prob_accuracy: 0.5001 - prob_macro_f1score: 0.2533 - prob_weighted_f1score: 0.0461 - val_loss: 2.4015 - val_activation_12_loss: 1.4170 - val_activation_13_loss: 1.4625 - val_prob_loss: 1.2730 - val_activation_12_accuracy: 0.4472 - val_activation_12_macro_f1score: 0.1824 - val_activation_12_weighted_f1score: 0.0347 - val_activation_13_accuracy: 0.4458 - val_activation_13_macro_f1score: 0.1569 - val_activation_13_weighted_f1score: 0.0310 - val_prob_accuracy: 0.5135 - val_prob_macro_f1score: 0.2777 - val_prob_weighted_f1score: 0.0513\n",
      "Epoch 43/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.4079 - activation_12_loss: 1.4742 - activation_13_loss: 1.6320 - prob_loss: 1.2917 - activation_12_accuracy: 0.4248 - activation_12_macro_f1score: 0.1584 - activation_12_weighted_f1score: 0.0303 - activation_13_accuracy: 0.3226 - activation_13_macro_f1score: 0.1158 - activation_13_weighted_f1score: 0.0221 - prob_accuracy: 0.5064 - prob_macro_f1score: 0.2543 - prob_weighted_f1score: 0.0463 - val_loss: 2.3769 - val_activation_12_loss: 1.3931 - val_activation_13_loss: 1.4367 - val_prob_loss: 1.2654 - val_activation_12_accuracy: 0.4759 - val_activation_12_macro_f1score: 0.1902 - val_activation_12_weighted_f1score: 0.0366 - val_activation_13_accuracy: 0.4531 - val_activation_13_macro_f1score: 0.1566 - val_activation_13_weighted_f1score: 0.0325 - val_prob_accuracy: 0.5185 - val_prob_macro_f1score: 0.2896 - val_prob_weighted_f1score: 0.0532\n",
      "Epoch 44/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.4129 - activation_12_loss: 1.4761 - activation_13_loss: 1.6339 - prob_loss: 1.2970 - activation_12_accuracy: 0.4231 - activation_12_macro_f1score: 0.1617 - activation_12_weighted_f1score: 0.0308 - activation_13_accuracy: 0.3224 - activation_13_macro_f1score: 0.1148 - activation_13_weighted_f1score: 0.0219 - prob_accuracy: 0.5017 - prob_macro_f1score: 0.2532 - prob_weighted_f1score: 0.0460 - val_loss: 2.4620 - val_activation_12_loss: 1.4169 - val_activation_13_loss: 1.5134 - val_prob_loss: 1.3192 - val_activation_12_accuracy: 0.4411 - val_activation_12_macro_f1score: 0.1650 - val_activation_12_weighted_f1score: 0.0302 - val_activation_13_accuracy: 0.4352 - val_activation_13_macro_f1score: 0.1220 - val_activation_13_weighted_f1score: 0.0229 - val_prob_accuracy: 0.4926 - val_prob_macro_f1score: 0.2558 - val_prob_weighted_f1score: 0.0446\n",
      "Epoch 45/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.3944 - activation_12_loss: 1.4667 - activation_13_loss: 1.6274 - prob_loss: 1.2847 - activation_12_accuracy: 0.4267 - activation_12_macro_f1score: 0.1618 - activation_12_weighted_f1score: 0.0310 - activation_13_accuracy: 0.3211 - activation_13_macro_f1score: 0.1160 - activation_13_weighted_f1score: 0.0221 - prob_accuracy: 0.5074 - prob_macro_f1score: 0.2604 - prob_weighted_f1score: 0.0474 - val_loss: 2.3091 - val_activation_12_loss: 1.3462 - val_activation_13_loss: 1.4236 - val_prob_loss: 1.2209 - val_activation_12_accuracy: 0.4848 - val_activation_12_macro_f1score: 0.1913 - val_activation_12_weighted_f1score: 0.0372 - val_activation_13_accuracy: 0.4464 - val_activation_13_macro_f1score: 0.1579 - val_activation_13_weighted_f1score: 0.0336 - val_prob_accuracy: 0.5272 - val_prob_macro_f1score: 0.2741 - val_prob_weighted_f1score: 0.0515\n",
      "Epoch 46/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3926 - activation_12_loss: 1.4668 - activation_13_loss: 1.6248 - prob_loss: 1.2849 - activation_12_accuracy: 0.4294 - activation_12_macro_f1score: 0.1658 - activation_12_weighted_f1score: 0.0313 - activation_13_accuracy: 0.3204 - activation_13_macro_f1score: 0.1176 - activation_13_weighted_f1score: 0.0224 - prob_accuracy: 0.5098 - prob_macro_f1score: 0.2620 - prob_weighted_f1score: 0.0475 - val_loss: 2.4147 - val_activation_12_loss: 1.4028 - val_activation_13_loss: 1.4718 - val_prob_loss: 1.2927 - val_activation_12_accuracy: 0.4450 - val_activation_12_macro_f1score: 0.1752 - val_activation_12_weighted_f1score: 0.0330 - val_activation_13_accuracy: 0.4191 - val_activation_13_macro_f1score: 0.1566 - val_activation_13_weighted_f1score: 0.0308 - val_prob_accuracy: 0.5010 - val_prob_macro_f1score: 0.2588 - val_prob_weighted_f1score: 0.0474\n",
      "Epoch 47/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.3762 - activation_12_loss: 1.4597 - activation_13_loss: 1.6181 - prob_loss: 1.2740 - activation_12_accuracy: 0.4364 - activation_12_macro_f1score: 0.1676 - activation_12_weighted_f1score: 0.0320 - activation_13_accuracy: 0.3227 - activation_13_macro_f1score: 0.1213 - activation_13_weighted_f1score: 0.0231 - prob_accuracy: 0.5136 - prob_macro_f1score: 0.2657 - prob_weighted_f1score: 0.0482 - val_loss: 2.3517 - val_activation_12_loss: 1.3537 - val_activation_13_loss: 1.4496 - val_prob_loss: 1.2545 - val_activation_12_accuracy: 0.4737 - val_activation_12_macro_f1score: 0.1786 - val_activation_12_weighted_f1score: 0.0360 - val_activation_13_accuracy: 0.4517 - val_activation_13_macro_f1score: 0.1385 - val_activation_13_weighted_f1score: 0.0297 - val_prob_accuracy: 0.5127 - val_prob_macro_f1score: 0.2728 - val_prob_weighted_f1score: 0.0512\n",
      "Epoch 48/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.3736 - activation_12_loss: 1.4617 - activation_13_loss: 1.6029 - prob_loss: 1.2766 - activation_12_accuracy: 0.4325 - activation_12_macro_f1score: 0.1682 - activation_12_weighted_f1score: 0.0319 - activation_13_accuracy: 0.3297 - activation_13_macro_f1score: 0.1285 - activation_13_weighted_f1score: 0.0248 - prob_accuracy: 0.5138 - prob_macro_f1score: 0.2659 - prob_weighted_f1score: 0.0481 - val_loss: 2.3543 - val_activation_12_loss: 1.3815 - val_activation_13_loss: 1.4508 - val_prob_loss: 1.2495 - val_activation_12_accuracy: 0.4636 - val_activation_12_macro_f1score: 0.1808 - val_activation_12_weighted_f1score: 0.0339 - val_activation_13_accuracy: 0.4447 - val_activation_13_macro_f1score: 0.1466 - val_activation_13_weighted_f1score: 0.0300 - val_prob_accuracy: 0.5183 - val_prob_macro_f1score: 0.2805 - val_prob_weighted_f1score: 0.0503\n",
      "Epoch 49/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3664 - activation_12_loss: 1.4559 - activation_13_loss: 1.6064 - prob_loss: 1.2714 - activation_12_accuracy: 0.4346 - activation_12_macro_f1score: 0.1682 - activation_12_weighted_f1score: 0.0320 - activation_13_accuracy: 0.3254 - activation_13_macro_f1score: 0.1258 - activation_13_weighted_f1score: 0.0247 - prob_accuracy: 0.5147 - prob_macro_f1score: 0.2692 - prob_weighted_f1score: 0.0487 - val_loss: 2.3616 - val_activation_12_loss: 1.3790 - val_activation_13_loss: 1.4604 - val_prob_loss: 1.2558 - val_activation_12_accuracy: 0.4784 - val_activation_12_macro_f1score: 0.1854 - val_activation_12_weighted_f1score: 0.0346 - val_activation_13_accuracy: 0.4405 - val_activation_13_macro_f1score: 0.1519 - val_activation_13_weighted_f1score: 0.0300 - val_prob_accuracy: 0.5185 - val_prob_macro_f1score: 0.2761 - val_prob_weighted_f1score: 0.0501\n",
      "Epoch 50/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.3649 - activation_12_loss: 1.4518 - activation_13_loss: 1.6022 - prob_loss: 1.2735 - activation_12_accuracy: 0.4378 - activation_12_macro_f1score: 0.1683 - activation_12_weighted_f1score: 0.0321 - activation_13_accuracy: 0.3257 - activation_13_macro_f1score: 0.1292 - activation_13_weighted_f1score: 0.0254 - prob_accuracy: 0.5130 - prob_macro_f1score: 0.2638 - prob_weighted_f1score: 0.0481 - val_loss: 2.3234 - val_activation_12_loss: 1.3558 - val_activation_13_loss: 1.4198 - val_prob_loss: 1.2391 - val_activation_12_accuracy: 0.4826 - val_activation_12_macro_f1score: 0.1946 - val_activation_12_weighted_f1score: 0.0364 - val_activation_13_accuracy: 0.4480 - val_activation_13_macro_f1score: 0.1615 - val_activation_13_weighted_f1score: 0.0323 - val_prob_accuracy: 0.5163 - val_prob_macro_f1score: 0.2717 - val_prob_weighted_f1score: 0.0491\n",
      "Epoch 51/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.3546 - activation_12_loss: 1.4477 - activation_13_loss: 1.6045 - prob_loss: 1.2650 - activation_12_accuracy: 0.4391 - activation_12_macro_f1score: 0.1718 - activation_12_weighted_f1score: 0.0328 - activation_13_accuracy: 0.3229 - activation_13_macro_f1score: 0.1268 - activation_13_weighted_f1score: 0.0251 - prob_accuracy: 0.5147 - prob_macro_f1score: 0.2723 - prob_weighted_f1score: 0.0495 - val_loss: 2.3341 - val_activation_12_loss: 1.3917 - val_activation_13_loss: 1.4386 - val_prob_loss: 1.2343 - val_activation_12_accuracy: 0.4564 - val_activation_12_macro_f1score: 0.1739 - val_activation_12_weighted_f1score: 0.0322 - val_activation_13_accuracy: 0.4472 - val_activation_13_macro_f1score: 0.1496 - val_activation_13_weighted_f1score: 0.0286 - val_prob_accuracy: 0.5099 - val_prob_macro_f1score: 0.3172 - val_prob_weighted_f1score: 0.0575\n",
      "Epoch 52/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.3486 - activation_12_loss: 1.4517 - activation_13_loss: 1.5969 - prob_loss: 1.2612 - activation_12_accuracy: 0.4356 - activation_12_macro_f1score: 0.1702 - activation_12_weighted_f1score: 0.0325 - activation_13_accuracy: 0.3279 - activation_13_macro_f1score: 0.1328 - activation_13_weighted_f1score: 0.0259 - prob_accuracy: 0.5185 - prob_macro_f1score: 0.2755 - prob_weighted_f1score: 0.0498 - val_loss: 2.3554 - val_activation_12_loss: 1.4107 - val_activation_13_loss: 1.4422 - val_prob_loss: 1.2493 - val_activation_12_accuracy: 0.4597 - val_activation_12_macro_f1score: 0.1840 - val_activation_12_weighted_f1score: 0.0353 - val_activation_13_accuracy: 0.4553 - val_activation_13_macro_f1score: 0.1513 - val_activation_13_weighted_f1score: 0.0313 - val_prob_accuracy: 0.5247 - val_prob_macro_f1score: 0.2948 - val_prob_weighted_f1score: 0.0540\n",
      "Epoch 53/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3400 - activation_12_loss: 1.4438 - activation_13_loss: 1.5987 - prob_loss: 1.2556 - activation_12_accuracy: 0.4414 - activation_12_macro_f1score: 0.1738 - activation_12_weighted_f1score: 0.0330 - activation_13_accuracy: 0.3235 - activation_13_macro_f1score: 0.1281 - activation_13_weighted_f1score: 0.0253 - prob_accuracy: 0.5227 - prob_macro_f1score: 0.2780 - prob_weighted_f1score: 0.0502 - val_loss: 2.3277 - val_activation_12_loss: 1.3554 - val_activation_13_loss: 1.4293 - val_prob_loss: 1.2442 - val_activation_12_accuracy: 0.4873 - val_activation_12_macro_f1score: 0.1912 - val_activation_12_weighted_f1score: 0.0363 - val_activation_13_accuracy: 0.4514 - val_activation_13_macro_f1score: 0.1574 - val_activation_13_weighted_f1score: 0.0315 - val_prob_accuracy: 0.5263 - val_prob_macro_f1score: 0.3090 - val_prob_weighted_f1score: 0.0556\n",
      "Epoch 54/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.3341 - activation_12_loss: 1.4348 - activation_13_loss: 1.6008 - prob_loss: 1.2530 - activation_12_accuracy: 0.4447 - activation_12_macro_f1score: 0.1765 - activation_12_weighted_f1score: 0.0338 - activation_13_accuracy: 0.3264 - activation_13_macro_f1score: 0.1295 - activation_13_weighted_f1score: 0.0256 - prob_accuracy: 0.5203 - prob_macro_f1score: 0.2782 - prob_weighted_f1score: 0.0506 - val_loss: 2.3449 - val_activation_12_loss: 1.3846 - val_activation_13_loss: 1.4491 - val_prob_loss: 1.2474 - val_activation_12_accuracy: 0.4731 - val_activation_12_macro_f1score: 0.2071 - val_activation_12_weighted_f1score: 0.0394 - val_activation_13_accuracy: 0.4433 - val_activation_13_macro_f1score: 0.1374 - val_activation_13_weighted_f1score: 0.0297 - val_prob_accuracy: 0.5283 - val_prob_macro_f1score: 0.2975 - val_prob_weighted_f1score: 0.0541\n",
      "Epoch 55/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3366 - activation_12_loss: 1.4399 - activation_13_loss: 1.5991 - prob_loss: 1.2557 - activation_12_accuracy: 0.4451 - activation_12_macro_f1score: 0.1754 - activation_12_weighted_f1score: 0.0334 - activation_13_accuracy: 0.3270 - activation_13_macro_f1score: 0.1307 - activation_13_weighted_f1score: 0.0255 - prob_accuracy: 0.5231 - prob_macro_f1score: 0.2798 - prob_weighted_f1score: 0.0505 - val_loss: 2.2551 - val_activation_12_loss: 1.3310 - val_activation_13_loss: 1.3981 - val_prob_loss: 1.1929 - val_activation_12_accuracy: 0.4840 - val_activation_12_macro_f1score: 0.1937 - val_activation_12_weighted_f1score: 0.0386 - val_activation_13_accuracy: 0.4575 - val_activation_13_macro_f1score: 0.1697 - val_activation_13_weighted_f1score: 0.0365 - val_prob_accuracy: 0.5319 - val_prob_macro_f1score: 0.2811 - val_prob_weighted_f1score: 0.0530\n",
      "Epoch 56/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3274 - activation_12_loss: 1.4346 - activation_13_loss: 1.5910 - prob_loss: 1.2515 - activation_12_accuracy: 0.4452 - activation_12_macro_f1score: 0.1809 - activation_12_weighted_f1score: 0.0343 - activation_13_accuracy: 0.3314 - activation_13_macro_f1score: 0.1324 - activation_13_weighted_f1score: 0.0257 - prob_accuracy: 0.5223 - prob_macro_f1score: 0.2763 - prob_weighted_f1score: 0.0499 - val_loss: 2.3204 - val_activation_12_loss: 1.3504 - val_activation_13_loss: 1.4534 - val_prob_loss: 1.2348 - val_activation_12_accuracy: 0.4829 - val_activation_12_macro_f1score: 0.1880 - val_activation_12_weighted_f1score: 0.0354 - val_activation_13_accuracy: 0.4400 - val_activation_13_macro_f1score: 0.1331 - val_activation_13_weighted_f1score: 0.0275 - val_prob_accuracy: 0.5194 - val_prob_macro_f1score: 0.3018 - val_prob_weighted_f1score: 0.0553\n",
      "Epoch 57/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3263 - activation_12_loss: 1.4308 - activation_13_loss: 1.5913 - prob_loss: 1.2526 - activation_12_accuracy: 0.4483 - activation_12_macro_f1score: 0.1763 - activation_12_weighted_f1score: 0.0339 - activation_13_accuracy: 0.3293 - activation_13_macro_f1score: 0.1291 - activation_13_weighted_f1score: 0.0257 - prob_accuracy: 0.5225 - prob_macro_f1score: 0.2780 - prob_weighted_f1score: 0.0505 - val_loss: 2.4160 - val_activation_12_loss: 1.4008 - val_activation_13_loss: 1.4641 - val_prob_loss: 1.3099 - val_activation_12_accuracy: 0.4907 - val_activation_12_macro_f1score: 0.2041 - val_activation_12_weighted_f1score: 0.0387 - val_activation_13_accuracy: 0.4519 - val_activation_13_macro_f1score: 0.1583 - val_activation_13_weighted_f1score: 0.0326 - val_prob_accuracy: 0.5183 - val_prob_macro_f1score: 0.2985 - val_prob_weighted_f1score: 0.0532\n",
      "Epoch 58/300\n",
      "225/224 [==============================] - 33s 148ms/step - loss: 2.3194 - activation_12_loss: 1.4281 - activation_13_loss: 1.5888 - prob_loss: 1.2481 - activation_12_accuracy: 0.4486 - activation_12_macro_f1score: 0.1790 - activation_12_weighted_f1score: 0.0339 - activation_13_accuracy: 0.3305 - activation_13_macro_f1score: 0.1321 - activation_13_weighted_f1score: 0.0259 - prob_accuracy: 0.5235 - prob_macro_f1score: 0.2828 - prob_weighted_f1score: 0.0511 - val_loss: 2.3018 - val_activation_12_loss: 1.3365 - val_activation_13_loss: 1.4478 - val_prob_loss: 1.2246 - val_activation_12_accuracy: 0.4909 - val_activation_12_macro_f1score: 0.2011 - val_activation_12_weighted_f1score: 0.0380 - val_activation_13_accuracy: 0.4461 - val_activation_13_macro_f1score: 0.1392 - val_activation_13_weighted_f1score: 0.0290 - val_prob_accuracy: 0.5344 - val_prob_macro_f1score: 0.3057 - val_prob_weighted_f1score: 0.0550\n",
      "Epoch 59/300\n",
      "225/224 [==============================] - 32s 143ms/step - loss: 2.3216 - activation_12_loss: 1.4308 - activation_13_loss: 1.5929 - prob_loss: 1.2493 - activation_12_accuracy: 0.4485 - activation_12_macro_f1score: 0.1780 - activation_12_weighted_f1score: 0.0340 - activation_13_accuracy: 0.3304 - activation_13_macro_f1score: 0.1297 - activation_13_weighted_f1score: 0.0255 - prob_accuracy: 0.5255 - prob_macro_f1score: 0.2827 - prob_weighted_f1score: 0.0512 - val_loss: 2.3040 - val_activation_12_loss: 1.3414 - val_activation_13_loss: 1.4101 - val_prob_loss: 1.2374 - val_activation_12_accuracy: 0.4923 - val_activation_12_macro_f1score: 0.2094 - val_activation_12_weighted_f1score: 0.0399 - val_activation_13_accuracy: 0.4544 - val_activation_13_macro_f1score: 0.1736 - val_activation_13_weighted_f1score: 0.0341 - val_prob_accuracy: 0.5305 - val_prob_macro_f1score: 0.3013 - val_prob_weighted_f1score: 0.0543\n",
      "Epoch 60/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3116 - activation_12_loss: 1.4252 - activation_13_loss: 1.5856 - prob_loss: 1.2440 - activation_12_accuracy: 0.4491 - activation_12_macro_f1score: 0.1798 - activation_12_weighted_f1score: 0.0342 - activation_13_accuracy: 0.3338 - activation_13_macro_f1score: 0.1316 - activation_13_weighted_f1score: 0.0257 - prob_accuracy: 0.5275 - prob_macro_f1score: 0.2886 - prob_weighted_f1score: 0.0520 - val_loss: 2.2784 - val_activation_12_loss: 1.3404 - val_activation_13_loss: 1.4093 - val_prob_loss: 1.2141 - val_activation_12_accuracy: 0.4870 - val_activation_12_macro_f1score: 0.1987 - val_activation_12_weighted_f1score: 0.0373 - val_activation_13_accuracy: 0.4681 - val_activation_13_macro_f1score: 0.1741 - val_activation_13_weighted_f1score: 0.0338 - val_prob_accuracy: 0.5503 - val_prob_macro_f1score: 0.2991 - val_prob_weighted_f1score: 0.0534\n",
      "Epoch 61/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.3077 - activation_12_loss: 1.4279 - activation_13_loss: 1.5824 - prob_loss: 1.2410 - activation_12_accuracy: 0.4484 - activation_12_macro_f1score: 0.1789 - activation_12_weighted_f1score: 0.0340 - activation_13_accuracy: 0.3394 - activation_13_macro_f1score: 0.1364 - activation_13_weighted_f1score: 0.0262 - prob_accuracy: 0.5275 - prob_macro_f1score: 0.2924 - prob_weighted_f1score: 0.0525 - val_loss: 2.2650 - val_activation_12_loss: 1.3359 - val_activation_13_loss: 1.4137 - val_prob_loss: 1.2018 - val_activation_12_accuracy: 0.4923 - val_activation_12_macro_f1score: 0.1939 - val_activation_12_weighted_f1score: 0.0376 - val_activation_13_accuracy: 0.4597 - val_activation_13_macro_f1score: 0.1804 - val_activation_13_weighted_f1score: 0.0357 - val_prob_accuracy: 0.5325 - val_prob_macro_f1score: 0.3168 - val_prob_weighted_f1score: 0.0577\n",
      "Epoch 62/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.2995 - activation_12_loss: 1.4171 - activation_13_loss: 1.5759 - prob_loss: 1.2388 - activation_12_accuracy: 0.4531 - activation_12_macro_f1score: 0.1829 - activation_12_weighted_f1score: 0.0346 - activation_13_accuracy: 0.3410 - activation_13_macro_f1score: 0.1362 - activation_13_weighted_f1score: 0.0265 - prob_accuracy: 0.5299 - prob_macro_f1score: 0.2891 - prob_weighted_f1score: 0.0521 - val_loss: 2.3829 - val_activation_12_loss: 1.3787 - val_activation_13_loss: 1.4551 - val_prob_loss: 1.2914 - val_activation_12_accuracy: 0.4642 - val_activation_12_macro_f1score: 0.2086 - val_activation_12_weighted_f1score: 0.0373 - val_activation_13_accuracy: 0.4405 - val_activation_13_macro_f1score: 0.1851 - val_activation_13_weighted_f1score: 0.0332 - val_prob_accuracy: 0.5205 - val_prob_macro_f1score: 0.2833 - val_prob_weighted_f1score: 0.0499\n",
      "Epoch 63/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.2921 - activation_12_loss: 1.4162 - activation_13_loss: 1.5727 - prob_loss: 1.2335 - activation_12_accuracy: 0.4514 - activation_12_macro_f1score: 0.1845 - activation_12_weighted_f1score: 0.0349 - activation_13_accuracy: 0.3429 - activation_13_macro_f1score: 0.1370 - activation_13_weighted_f1score: 0.0265 - prob_accuracy: 0.5306 - prob_macro_f1score: 0.2917 - prob_weighted_f1score: 0.0525 - val_loss: 2.3107 - val_activation_12_loss: 1.3311 - val_activation_13_loss: 1.4145 - val_prob_loss: 1.2490 - val_activation_12_accuracy: 0.4893 - val_activation_12_macro_f1score: 0.2128 - val_activation_12_weighted_f1score: 0.0400 - val_activation_13_accuracy: 0.4494 - val_activation_13_macro_f1score: 0.1829 - val_activation_13_weighted_f1score: 0.0354 - val_prob_accuracy: 0.5286 - val_prob_macro_f1score: 0.3174 - val_prob_weighted_f1score: 0.0565\n",
      "Epoch 64/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2822 - activation_12_loss: 1.4203 - activation_13_loss: 1.5656 - prob_loss: 1.2253 - activation_12_accuracy: 0.4524 - activation_12_macro_f1score: 0.1805 - activation_12_weighted_f1score: 0.0343 - activation_13_accuracy: 0.3480 - activation_13_macro_f1score: 0.1419 - activation_13_weighted_f1score: 0.0270 - prob_accuracy: 0.5315 - prob_macro_f1score: 0.2978 - prob_weighted_f1score: 0.0535 - val_loss: 2.3010 - val_activation_12_loss: 1.3542 - val_activation_13_loss: 1.4136 - val_prob_loss: 1.2338 - val_activation_12_accuracy: 0.4879 - val_activation_12_macro_f1score: 0.1922 - val_activation_12_weighted_f1score: 0.0361 - val_activation_13_accuracy: 0.4687 - val_activation_13_macro_f1score: 0.1819 - val_activation_13_weighted_f1score: 0.0346 - val_prob_accuracy: 0.5336 - val_prob_macro_f1score: 0.3159 - val_prob_weighted_f1score: 0.0563\n",
      "Epoch 65/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2808 - activation_12_loss: 1.4125 - activation_13_loss: 1.5659 - prob_loss: 1.2271 - activation_12_accuracy: 0.4530 - activation_12_macro_f1score: 0.1864 - activation_12_weighted_f1score: 0.0353 - activation_13_accuracy: 0.3456 - activation_13_macro_f1score: 0.1406 - activation_13_weighted_f1score: 0.0270 - prob_accuracy: 0.5310 - prob_macro_f1score: 0.2993 - prob_weighted_f1score: 0.0539 - val_loss: 2.3163 - val_activation_12_loss: 1.3179 - val_activation_13_loss: 1.3857 - val_prob_loss: 1.2687 - val_activation_12_accuracy: 0.4979 - val_activation_12_macro_f1score: 0.2013 - val_activation_12_weighted_f1score: 0.0394 - val_activation_13_accuracy: 0.4681 - val_activation_13_macro_f1score: 0.1897 - val_activation_13_weighted_f1score: 0.0369 - val_prob_accuracy: 0.5266 - val_prob_macro_f1score: 0.2957 - val_prob_weighted_f1score: 0.0543\n",
      "Epoch 66/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2759 - activation_12_loss: 1.4101 - activation_13_loss: 1.5646 - prob_loss: 1.2240 - activation_12_accuracy: 0.4569 - activation_12_macro_f1score: 0.1884 - activation_12_weighted_f1score: 0.0357 - activation_13_accuracy: 0.3496 - activation_13_macro_f1score: 0.1427 - activation_13_weighted_f1score: 0.0273 - prob_accuracy: 0.5344 - prob_macro_f1score: 0.2935 - prob_weighted_f1score: 0.0532 - val_loss: 2.3538 - val_activation_12_loss: 1.3779 - val_activation_13_loss: 1.4392 - val_prob_loss: 1.2717 - val_activation_12_accuracy: 0.4812 - val_activation_12_macro_f1score: 0.1915 - val_activation_12_weighted_f1score: 0.0368 - val_activation_13_accuracy: 0.4570 - val_activation_13_macro_f1score: 0.1628 - val_activation_13_weighted_f1score: 0.0320 - val_prob_accuracy: 0.5216 - val_prob_macro_f1score: 0.2928 - val_prob_weighted_f1score: 0.0517\n",
      "Epoch 67/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2661 - activation_12_loss: 1.4091 - activation_13_loss: 1.5624 - prob_loss: 1.2160 - activation_12_accuracy: 0.4601 - activation_12_macro_f1score: 0.1850 - activation_12_weighted_f1score: 0.0353 - activation_13_accuracy: 0.3473 - activation_13_macro_f1score: 0.1436 - activation_13_weighted_f1score: 0.0276 - prob_accuracy: 0.5360 - prob_macro_f1score: 0.3059 - prob_weighted_f1score: 0.0549 - val_loss: 2.3520 - val_activation_12_loss: 1.3678 - val_activation_13_loss: 1.4257 - val_prob_loss: 1.2778 - val_activation_12_accuracy: 0.4804 - val_activation_12_macro_f1score: 0.1901 - val_activation_12_weighted_f1score: 0.0367 - val_activation_13_accuracy: 0.4597 - val_activation_13_macro_f1score: 0.1818 - val_activation_13_weighted_f1score: 0.0352 - val_prob_accuracy: 0.5319 - val_prob_macro_f1score: 0.2659 - val_prob_weighted_f1score: 0.0490\n",
      "Epoch 68/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2572 - activation_12_loss: 1.4051 - activation_13_loss: 1.5560 - prob_loss: 1.2110 - activation_12_accuracy: 0.4605 - activation_12_macro_f1score: 0.1930 - activation_12_weighted_f1score: 0.0364 - activation_13_accuracy: 0.3512 - activation_13_macro_f1score: 0.1445 - activation_13_weighted_f1score: 0.0277 - prob_accuracy: 0.5408 - prob_macro_f1score: 0.3031 - prob_weighted_f1score: 0.0545 - val_loss: 2.2840 - val_activation_12_loss: 1.3358 - val_activation_13_loss: 1.4166 - val_prob_loss: 1.2252 - val_activation_12_accuracy: 0.4999 - val_activation_12_macro_f1score: 0.2013 - val_activation_12_weighted_f1score: 0.0375 - val_activation_13_accuracy: 0.4631 - val_activation_13_macro_f1score: 0.1743 - val_activation_13_weighted_f1score: 0.0335 - val_prob_accuracy: 0.5408 - val_prob_macro_f1score: 0.3389 - val_prob_weighted_f1score: 0.0593\n",
      "Epoch 69/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.2667 - activation_12_loss: 1.4082 - activation_13_loss: 1.5621 - prob_loss: 1.2186 - activation_12_accuracy: 0.4586 - activation_12_macro_f1score: 0.1900 - activation_12_weighted_f1score: 0.0360 - activation_13_accuracy: 0.3456 - activation_13_macro_f1score: 0.1392 - activation_13_weighted_f1score: 0.0269 - prob_accuracy: 0.5359 - prob_macro_f1score: 0.3032 - prob_weighted_f1score: 0.0545 - val_loss: 2.1974 - val_activation_12_loss: 1.2919 - val_activation_13_loss: 1.3747 - val_prob_loss: 1.1679 - val_activation_12_accuracy: 0.5068 - val_activation_12_macro_f1score: 0.2028 - val_activation_12_weighted_f1score: 0.0402 - val_activation_13_accuracy: 0.4753 - val_activation_13_macro_f1score: 0.1851 - val_activation_13_weighted_f1score: 0.0369 - val_prob_accuracy: 0.5514 - val_prob_macro_f1score: 0.3150 - val_prob_weighted_f1score: 0.0581\n",
      "Epoch 70/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.2519 - activation_12_loss: 1.3989 - activation_13_loss: 1.5578 - prob_loss: 1.2086 - activation_12_accuracy: 0.4649 - activation_12_macro_f1score: 0.1929 - activation_12_weighted_f1score: 0.0363 - activation_13_accuracy: 0.3492 - activation_13_macro_f1score: 0.1454 - activation_13_weighted_f1score: 0.0276 - prob_accuracy: 0.5417 - prob_macro_f1score: 0.3036 - prob_weighted_f1score: 0.0543 - val_loss: 2.2474 - val_activation_12_loss: 1.3371 - val_activation_13_loss: 1.4041 - val_prob_loss: 1.1946 - val_activation_12_accuracy: 0.4937 - val_activation_12_macro_f1score: 0.1914 - val_activation_12_weighted_f1score: 0.0358 - val_activation_13_accuracy: 0.4661 - val_activation_13_macro_f1score: 0.1792 - val_activation_13_weighted_f1score: 0.0344 - val_prob_accuracy: 0.5442 - val_prob_macro_f1score: 0.3279 - val_prob_weighted_f1score: 0.0578\n",
      "Epoch 71/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.2562 - activation_12_loss: 1.4010 - activation_13_loss: 1.5593 - prob_loss: 1.2125 - activation_12_accuracy: 0.4630 - activation_12_macro_f1score: 0.1937 - activation_12_weighted_f1score: 0.0365 - activation_13_accuracy: 0.3513 - activation_13_macro_f1score: 0.1416 - activation_13_weighted_f1score: 0.0273 - prob_accuracy: 0.5374 - prob_macro_f1score: 0.3091 - prob_weighted_f1score: 0.0555 - val_loss: 2.2582 - val_activation_12_loss: 1.3229 - val_activation_13_loss: 1.3975 - val_prob_loss: 1.2118 - val_activation_12_accuracy: 0.4915 - val_activation_12_macro_f1score: 0.2283 - val_activation_12_weighted_f1score: 0.0432 - val_activation_13_accuracy: 0.4709 - val_activation_13_macro_f1score: 0.1736 - val_activation_13_weighted_f1score: 0.0343 - val_prob_accuracy: 0.5419 - val_prob_macro_f1score: 0.3363 - val_prob_weighted_f1score: 0.0601\n",
      "Epoch 72/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.2526 - activation_12_loss: 1.3960 - activation_13_loss: 1.5568 - prob_loss: 1.2118 - activation_12_accuracy: 0.4603 - activation_12_macro_f1score: 0.1913 - activation_12_weighted_f1score: 0.0364 - activation_13_accuracy: 0.3513 - activation_13_macro_f1score: 0.1427 - activation_13_weighted_f1score: 0.0274 - prob_accuracy: 0.5383 - prob_macro_f1score: 0.3031 - prob_weighted_f1score: 0.0545 - val_loss: 2.2965 - val_activation_12_loss: 1.3267 - val_activation_13_loss: 1.4008 - val_prob_loss: 1.2474 - val_activation_12_accuracy: 0.4926 - val_activation_12_macro_f1score: 0.2251 - val_activation_12_weighted_f1score: 0.0417 - val_activation_13_accuracy: 0.4639 - val_activation_13_macro_f1score: 0.1722 - val_activation_13_weighted_f1score: 0.0333 - val_prob_accuracy: 0.5366 - val_prob_macro_f1score: 0.3211 - val_prob_weighted_f1score: 0.0571\n",
      "Epoch 73/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.2443 - activation_12_loss: 1.3921 - activation_13_loss: 1.5540 - prob_loss: 1.2061 - activation_12_accuracy: 0.4686 - activation_12_macro_f1score: 0.1961 - activation_12_weighted_f1score: 0.0369 - activation_13_accuracy: 0.3535 - activation_13_macro_f1score: 0.1434 - activation_13_weighted_f1score: 0.0275 - prob_accuracy: 0.5422 - prob_macro_f1score: 0.3109 - prob_weighted_f1score: 0.0557 - val_loss: 2.2791 - val_activation_12_loss: 1.3341 - val_activation_13_loss: 1.3920 - val_prob_loss: 1.2317 - val_activation_12_accuracy: 0.4742 - val_activation_12_macro_f1score: 0.2207 - val_activation_12_weighted_f1score: 0.0404 - val_activation_13_accuracy: 0.4709 - val_activation_13_macro_f1score: 0.1845 - val_activation_13_weighted_f1score: 0.0349 - val_prob_accuracy: 0.5336 - val_prob_macro_f1score: 0.2998 - val_prob_weighted_f1score: 0.0544\n",
      "Epoch 74/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2455 - activation_12_loss: 1.3945 - activation_13_loss: 1.5586 - prob_loss: 1.2056 - activation_12_accuracy: 0.4657 - activation_12_macro_f1score: 0.1958 - activation_12_weighted_f1score: 0.0371 - activation_13_accuracy: 0.3478 - activation_13_macro_f1score: 0.1415 - activation_13_weighted_f1score: 0.0272 - prob_accuracy: 0.5425 - prob_macro_f1score: 0.3099 - prob_weighted_f1score: 0.0555 - val_loss: 2.2472 - val_activation_12_loss: 1.3302 - val_activation_13_loss: 1.3898 - val_prob_loss: 1.2029 - val_activation_12_accuracy: 0.4831 - val_activation_12_macro_f1score: 0.2564 - val_activation_12_weighted_f1score: 0.0482 - val_activation_13_accuracy: 0.4728 - val_activation_13_macro_f1score: 0.1699 - val_activation_13_weighted_f1score: 0.0337 - val_prob_accuracy: 0.5327 - val_prob_macro_f1score: 0.3254 - val_prob_weighted_f1score: 0.0588\n",
      "Epoch 75/300\n",
      "225/224 [==============================] - 32s 142ms/step - loss: 2.2346 - activation_12_loss: 1.3862 - activation_13_loss: 1.5529 - prob_loss: 1.1995 - activation_12_accuracy: 0.4662 - activation_12_macro_f1score: 0.1962 - activation_12_weighted_f1score: 0.0372 - activation_13_accuracy: 0.3523 - activation_13_macro_f1score: 0.1420 - activation_13_weighted_f1score: 0.0275 - prob_accuracy: 0.5453 - prob_macro_f1score: 0.3129 - prob_weighted_f1score: 0.0561 - val_loss: 2.2419 - val_activation_12_loss: 1.2950 - val_activation_13_loss: 1.3643 - val_prob_loss: 1.2166 - val_activation_12_accuracy: 0.5010 - val_activation_12_macro_f1score: 0.2360 - val_activation_12_weighted_f1score: 0.0442 - val_activation_13_accuracy: 0.4862 - val_activation_13_macro_f1score: 0.1910 - val_activation_13_weighted_f1score: 0.0361 - val_prob_accuracy: 0.5369 - val_prob_macro_f1score: 0.3400 - val_prob_weighted_f1score: 0.0610\n",
      "Epoch 76/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.2356 - activation_12_loss: 1.3873 - activation_13_loss: 1.5566 - prob_loss: 1.1996 - activation_12_accuracy: 0.4675 - activation_12_macro_f1score: 0.1975 - activation_12_weighted_f1score: 0.0374 - activation_13_accuracy: 0.3521 - activation_13_macro_f1score: 0.1441 - activation_13_weighted_f1score: 0.0277 - prob_accuracy: 0.5443 - prob_macro_f1score: 0.3175 - prob_weighted_f1score: 0.0569 - val_loss: 2.2923 - val_activation_12_loss: 1.3222 - val_activation_13_loss: 1.4128 - val_prob_loss: 1.2432 - val_activation_12_accuracy: 0.4946 - val_activation_12_macro_f1score: 0.2145 - val_activation_12_weighted_f1score: 0.0395 - val_activation_13_accuracy: 0.4728 - val_activation_13_macro_f1score: 0.1885 - val_activation_13_weighted_f1score: 0.0343 - val_prob_accuracy: 0.5339 - val_prob_macro_f1score: 0.3240 - val_prob_weighted_f1score: 0.0568\n",
      "Epoch 77/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.2259 - activation_12_loss: 1.3807 - activation_13_loss: 1.5527 - prob_loss: 1.1936 - activation_12_accuracy: 0.4700 - activation_12_macro_f1score: 0.2029 - activation_12_weighted_f1score: 0.0383 - activation_13_accuracy: 0.3515 - activation_13_macro_f1score: 0.1426 - activation_13_weighted_f1score: 0.0276 - prob_accuracy: 0.5459 - prob_macro_f1score: 0.3148 - prob_weighted_f1score: 0.0563 - val_loss: 2.2962 - val_activation_12_loss: 1.3414 - val_activation_13_loss: 1.4281 - val_prob_loss: 1.2372 - val_activation_12_accuracy: 0.4909 - val_activation_12_macro_f1score: 0.1980 - val_activation_12_weighted_f1score: 0.0357 - val_activation_13_accuracy: 0.4776 - val_activation_13_macro_f1score: 0.1610 - val_activation_13_weighted_f1score: 0.0299 - val_prob_accuracy: 0.5305 - val_prob_macro_f1score: 0.3141 - val_prob_weighted_f1score: 0.0547\n",
      "Epoch 78/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.2321 - activation_12_loss: 1.3864 - activation_13_loss: 1.5487 - prob_loss: 1.1998 - activation_12_accuracy: 0.4668 - activation_12_macro_f1score: 0.1982 - activation_12_weighted_f1score: 0.0374 - activation_13_accuracy: 0.3556 - activation_13_macro_f1score: 0.1442 - activation_13_weighted_f1score: 0.0276 - prob_accuracy: 0.5435 - prob_macro_f1score: 0.3128 - prob_weighted_f1score: 0.0560 - val_loss: 2.2016 - val_activation_12_loss: 1.2843 - val_activation_13_loss: 1.3563 - val_prob_loss: 1.1849 - val_activation_12_accuracy: 0.5102 - val_activation_12_macro_f1score: 0.2259 - val_activation_12_weighted_f1score: 0.0431 - val_activation_13_accuracy: 0.4904 - val_activation_13_macro_f1score: 0.1831 - val_activation_13_weighted_f1score: 0.0369 - val_prob_accuracy: 0.5497 - val_prob_macro_f1score: 0.3606 - val_prob_weighted_f1score: 0.0645\n",
      "Epoch 79/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.2250 - activation_12_loss: 1.3832 - activation_13_loss: 1.5567 - prob_loss: 1.1918 - activation_12_accuracy: 0.4700 - activation_12_macro_f1score: 0.2000 - activation_12_weighted_f1score: 0.0377 - activation_13_accuracy: 0.3481 - activation_13_macro_f1score: 0.1430 - activation_13_weighted_f1score: 0.0275 - prob_accuracy: 0.5496 - prob_macro_f1score: 0.3210 - prob_weighted_f1score: 0.0572 - val_loss: 2.2320 - val_activation_12_loss: 1.2905 - val_activation_13_loss: 1.3909 - val_prob_loss: 1.2026 - val_activation_12_accuracy: 0.5038 - val_activation_12_macro_f1score: 0.2159 - val_activation_12_weighted_f1score: 0.0397 - val_activation_13_accuracy: 0.4829 - val_activation_13_macro_f1score: 0.1683 - val_activation_13_weighted_f1score: 0.0324 - val_prob_accuracy: 0.5444 - val_prob_macro_f1score: 0.3394 - val_prob_weighted_f1score: 0.0597\n",
      "Epoch 80/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2235 - activation_12_loss: 1.3776 - activation_13_loss: 1.5508 - prob_loss: 1.1942 - activation_12_accuracy: 0.4705 - activation_12_macro_f1score: 0.2049 - activation_12_weighted_f1score: 0.0384 - activation_13_accuracy: 0.3533 - activation_13_macro_f1score: 0.1440 - activation_13_weighted_f1score: 0.0275 - prob_accuracy: 0.5484 - prob_macro_f1score: 0.3232 - prob_weighted_f1score: 0.0576 - val_loss: 2.2915 - val_activation_12_loss: 1.3458 - val_activation_13_loss: 1.4360 - val_prob_loss: 1.2305 - val_activation_12_accuracy: 0.4951 - val_activation_12_macro_f1score: 0.2334 - val_activation_12_weighted_f1score: 0.0442 - val_activation_13_accuracy: 0.4533 - val_activation_13_macro_f1score: 0.1712 - val_activation_13_weighted_f1score: 0.0346 - val_prob_accuracy: 0.5380 - val_prob_macro_f1score: 0.3144 - val_prob_weighted_f1score: 0.0568\n",
      "Epoch 81/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2189 - activation_12_loss: 1.3815 - activation_13_loss: 1.5490 - prob_loss: 1.1893 - activation_12_accuracy: 0.4702 - activation_12_macro_f1score: 0.2000 - activation_12_weighted_f1score: 0.0378 - activation_13_accuracy: 0.3529 - activation_13_macro_f1score: 0.1443 - activation_13_weighted_f1score: 0.0277 - prob_accuracy: 0.5468 - prob_macro_f1score: 0.3227 - prob_weighted_f1score: 0.0575 - val_loss: 2.1509 - val_activation_12_loss: 1.2657 - val_activation_13_loss: 1.3555 - val_prob_loss: 1.1432 - val_activation_12_accuracy: 0.5143 - val_activation_12_macro_f1score: 0.2339 - val_activation_12_weighted_f1score: 0.0448 - val_activation_13_accuracy: 0.4890 - val_activation_13_macro_f1score: 0.1816 - val_activation_13_weighted_f1score: 0.0364 - val_prob_accuracy: 0.5617 - val_prob_macro_f1score: 0.3150 - val_prob_weighted_f1score: 0.0581\n",
      "Epoch 82/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2048 - activation_12_loss: 1.3772 - activation_13_loss: 1.5456 - prob_loss: 1.1781 - activation_12_accuracy: 0.4757 - activation_12_macro_f1score: 0.2022 - activation_12_weighted_f1score: 0.0381 - activation_13_accuracy: 0.3572 - activation_13_macro_f1score: 0.1476 - activation_13_weighted_f1score: 0.0281 - prob_accuracy: 0.5528 - prob_macro_f1score: 0.3335 - prob_weighted_f1score: 0.0593 - val_loss: 2.2366 - val_activation_12_loss: 1.2900 - val_activation_13_loss: 1.4082 - val_prob_loss: 1.2036 - val_activation_12_accuracy: 0.5149 - val_activation_12_macro_f1score: 0.2083 - val_activation_12_weighted_f1score: 0.0395 - val_activation_13_accuracy: 0.4533 - val_activation_13_macro_f1score: 0.1713 - val_activation_13_weighted_f1score: 0.0340 - val_prob_accuracy: 0.5394 - val_prob_macro_f1score: 0.3288 - val_prob_weighted_f1score: 0.0588\n",
      "Epoch 83/300\n",
      "225/224 [==============================] - 32s 141ms/step - loss: 2.2194 - activation_12_loss: 1.3787 - activation_13_loss: 1.5534 - prob_loss: 1.1905 - activation_12_accuracy: 0.4707 - activation_12_macro_f1score: 0.2038 - activation_12_weighted_f1score: 0.0381 - activation_13_accuracy: 0.3538 - activation_13_macro_f1score: 0.1444 - activation_13_weighted_f1score: 0.0277 - prob_accuracy: 0.5458 - prob_macro_f1score: 0.3228 - prob_weighted_f1score: 0.0573 - val_loss: 2.2010 - val_activation_12_loss: 1.2833 - val_activation_13_loss: 1.3739 - val_prob_loss: 1.1818 - val_activation_12_accuracy: 0.4932 - val_activation_12_macro_f1score: 0.2450 - val_activation_12_weighted_f1score: 0.0470 - val_activation_13_accuracy: 0.4687 - val_activation_13_macro_f1score: 0.1701 - val_activation_13_weighted_f1score: 0.0352 - val_prob_accuracy: 0.5408 - val_prob_macro_f1score: 0.3343 - val_prob_weighted_f1score: 0.0614\n",
      "Epoch 84/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.2121 - activation_12_loss: 1.3747 - activation_13_loss: 1.5463 - prob_loss: 1.1868 - activation_12_accuracy: 0.4741 - activation_12_macro_f1score: 0.2049 - activation_12_weighted_f1score: 0.0384 - activation_13_accuracy: 0.3541 - activation_13_macro_f1score: 0.1432 - activation_13_weighted_f1score: 0.0275 - prob_accuracy: 0.5496 - prob_macro_f1score: 0.3246 - prob_weighted_f1score: 0.0576 - val_loss: 2.2121 - val_activation_12_loss: 1.3042 - val_activation_13_loss: 1.3694 - val_prob_loss: 1.1878 - val_activation_12_accuracy: 0.5124 - val_activation_12_macro_f1score: 0.2245 - val_activation_12_weighted_f1score: 0.0421 - val_activation_13_accuracy: 0.4882 - val_activation_13_macro_f1score: 0.1862 - val_activation_13_weighted_f1score: 0.0353 - val_prob_accuracy: 0.5430 - val_prob_macro_f1score: 0.3447 - val_prob_weighted_f1score: 0.0622\n",
      "Epoch 85/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.2144 - activation_12_loss: 1.3684 - activation_13_loss: 1.5526 - prob_loss: 1.1895 - activation_12_accuracy: 0.4784 - activation_12_macro_f1score: 0.2056 - activation_12_weighted_f1score: 0.0387 - activation_13_accuracy: 0.3554 - activation_13_macro_f1score: 0.1439 - activation_13_weighted_f1score: 0.0276 - prob_accuracy: 0.5493 - prob_macro_f1score: 0.3189 - prob_weighted_f1score: 0.0570 - val_loss: 2.2836 - val_activation_12_loss: 1.3193 - val_activation_13_loss: 1.3915 - val_prob_loss: 1.2462 - val_activation_12_accuracy: 0.5054 - val_activation_12_macro_f1score: 0.2328 - val_activation_12_weighted_f1score: 0.0448 - val_activation_13_accuracy: 0.4739 - val_activation_13_macro_f1score: 0.1700 - val_activation_13_weighted_f1score: 0.0342 - val_prob_accuracy: 0.5330 - val_prob_macro_f1score: 0.3377 - val_prob_weighted_f1score: 0.0623\n",
      "Epoch 86/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.2052 - activation_12_loss: 1.3752 - activation_13_loss: 1.5448 - prob_loss: 1.1808 - activation_12_accuracy: 0.4724 - activation_12_macro_f1score: 0.2047 - activation_12_weighted_f1score: 0.0385 - activation_13_accuracy: 0.3557 - activation_13_macro_f1score: 0.1441 - activation_13_weighted_f1score: 0.0278 - prob_accuracy: 0.5505 - prob_macro_f1score: 0.3253 - prob_weighted_f1score: 0.0576 - val_loss: 2.2074 - val_activation_12_loss: 1.3068 - val_activation_13_loss: 1.3650 - val_prob_loss: 1.1847 - val_activation_12_accuracy: 0.4868 - val_activation_12_macro_f1score: 0.2190 - val_activation_12_weighted_f1score: 0.0421 - val_activation_13_accuracy: 0.4804 - val_activation_13_macro_f1score: 0.1785 - val_activation_13_weighted_f1score: 0.0357 - val_prob_accuracy: 0.5508 - val_prob_macro_f1score: 0.3120 - val_prob_weighted_f1score: 0.0569\n",
      "Epoch 87/300\n",
      "225/224 [==============================] - 32s 140ms/step - loss: 2.1984 - activation_12_loss: 1.3650 - activation_13_loss: 1.5438 - prob_loss: 1.1779 - activation_12_accuracy: 0.4790 - activation_12_macro_f1score: 0.2084 - activation_12_weighted_f1score: 0.0392 - activation_13_accuracy: 0.3574 - activation_13_macro_f1score: 0.1459 - activation_13_weighted_f1score: 0.0280 - prob_accuracy: 0.5554 - prob_macro_f1score: 0.3295 - prob_weighted_f1score: 0.0586 - val_loss: 2.1923 - val_activation_12_loss: 1.2786 - val_activation_13_loss: 1.3761 - val_prob_loss: 1.1757 - val_activation_12_accuracy: 0.5180 - val_activation_12_macro_f1score: 0.2111 - val_activation_12_weighted_f1score: 0.0399 - val_activation_13_accuracy: 0.4778 - val_activation_13_macro_f1score: 0.1802 - val_activation_13_weighted_f1score: 0.0350 - val_prob_accuracy: 0.5478 - val_prob_macro_f1score: 0.3355 - val_prob_weighted_f1score: 0.0608\n",
      "Epoch 88/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.1912 - activation_12_loss: 1.3639 - activation_13_loss: 1.5432 - prob_loss: 1.1715 - activation_12_accuracy: 0.4797 - activation_12_macro_f1score: 0.2119 - activation_12_weighted_f1score: 0.0394 - activation_13_accuracy: 0.3565 - activation_13_macro_f1score: 0.1472 - activation_13_weighted_f1score: 0.0282 - prob_accuracy: 0.5574 - prob_macro_f1score: 0.3365 - prob_weighted_f1score: 0.0596 - val_loss: 2.1961 - val_activation_12_loss: 1.2860 - val_activation_13_loss: 1.3698 - val_prob_loss: 1.1792 - val_activation_12_accuracy: 0.5091 - val_activation_12_macro_f1score: 0.2367 - val_activation_12_weighted_f1score: 0.0453 - val_activation_13_accuracy: 0.4650 - val_activation_13_macro_f1score: 0.1807 - val_activation_13_weighted_f1score: 0.0363 - val_prob_accuracy: 0.5522 - val_prob_macro_f1score: 0.3310 - val_prob_weighted_f1score: 0.0603\n",
      "Epoch 89/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.1993 - activation_12_loss: 1.3690 - activation_13_loss: 1.5456 - prob_loss: 1.1776 - activation_12_accuracy: 0.4795 - activation_12_macro_f1score: 0.2104 - activation_12_weighted_f1score: 0.0393 - activation_13_accuracy: 0.3577 - activation_13_macro_f1score: 0.1450 - activation_13_weighted_f1score: 0.0279 - prob_accuracy: 0.5508 - prob_macro_f1score: 0.3325 - prob_weighted_f1score: 0.0588 - val_loss: 2.2112 - val_activation_12_loss: 1.2873 - val_activation_13_loss: 1.3756 - val_prob_loss: 1.1919 - val_activation_12_accuracy: 0.5118 - val_activation_12_macro_f1score: 0.2275 - val_activation_12_weighted_f1score: 0.0425 - val_activation_13_accuracy: 0.4870 - val_activation_13_macro_f1score: 0.1781 - val_activation_13_weighted_f1score: 0.0345 - val_prob_accuracy: 0.5495 - val_prob_macro_f1score: 0.3095 - val_prob_weighted_f1score: 0.0563\n",
      "Epoch 90/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.1775 - activation_12_loss: 1.3485 - activation_13_loss: 1.5476 - prob_loss: 1.1616 - activation_12_accuracy: 0.4834 - activation_12_macro_f1score: 0.2199 - activation_12_weighted_f1score: 0.0411 - activation_13_accuracy: 0.3520 - activation_13_macro_f1score: 0.1437 - activation_13_weighted_f1score: 0.0280 - prob_accuracy: 0.5581 - prob_macro_f1score: 0.3376 - prob_weighted_f1score: 0.0600 - val_loss: 2.1783 - val_activation_12_loss: 1.2720 - val_activation_13_loss: 1.3481 - val_prob_loss: 1.1733 - val_activation_12_accuracy: 0.5007 - val_activation_12_macro_f1score: 0.2532 - val_activation_12_weighted_f1score: 0.0475 - val_activation_13_accuracy: 0.4893 - val_activation_13_macro_f1score: 0.1860 - val_activation_13_weighted_f1score: 0.0360 - val_prob_accuracy: 0.5550 - val_prob_macro_f1score: 0.3530 - val_prob_weighted_f1score: 0.0631\n",
      "Epoch 91/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.1897 - activation_12_loss: 1.3592 - activation_13_loss: 1.5474 - prob_loss: 1.1712 - activation_12_accuracy: 0.4843 - activation_12_macro_f1score: 0.2147 - activation_12_weighted_f1score: 0.0401 - activation_13_accuracy: 0.3542 - activation_13_macro_f1score: 0.1468 - activation_13_weighted_f1score: 0.0279 - prob_accuracy: 0.5568 - prob_macro_f1score: 0.3376 - prob_weighted_f1score: 0.0598 - val_loss: 2.2134 - val_activation_12_loss: 1.2865 - val_activation_13_loss: 1.3783 - val_prob_loss: 1.1943 - val_activation_12_accuracy: 0.5113 - val_activation_12_macro_f1score: 0.2271 - val_activation_12_weighted_f1score: 0.0420 - val_activation_13_accuracy: 0.4890 - val_activation_13_macro_f1score: 0.1885 - val_activation_13_weighted_f1score: 0.0356 - val_prob_accuracy: 0.5383 - val_prob_macro_f1score: 0.3406 - val_prob_weighted_f1score: 0.0618\n",
      "Epoch 92/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.1824 - activation_12_loss: 1.3513 - activation_13_loss: 1.5402 - prob_loss: 1.1687 - activation_12_accuracy: 0.4842 - activation_12_macro_f1score: 0.2187 - activation_12_weighted_f1score: 0.0407 - activation_13_accuracy: 0.3669 - activation_13_macro_f1score: 0.1483 - activation_13_weighted_f1score: 0.0282 - prob_accuracy: 0.5570 - prob_macro_f1score: 0.3372 - prob_weighted_f1score: 0.0598 - val_loss: 2.1589 - val_activation_12_loss: 1.2616 - val_activation_13_loss: 1.3493 - val_prob_loss: 1.1581 - val_activation_12_accuracy: 0.5224 - val_activation_12_macro_f1score: 0.2350 - val_activation_12_weighted_f1score: 0.0432 - val_activation_13_accuracy: 0.4868 - val_activation_13_macro_f1score: 0.1975 - val_activation_13_weighted_f1score: 0.0370 - val_prob_accuracy: 0.5589 - val_prob_macro_f1score: 0.3368 - val_prob_weighted_f1score: 0.0590\n",
      "Epoch 93/300\n",
      "225/224 [==============================] - 31s 140ms/step - loss: 2.1833 - activation_12_loss: 1.3554 - activation_13_loss: 1.5435 - prob_loss: 1.1677 - activation_12_accuracy: 0.4822 - activation_12_macro_f1score: 0.2166 - activation_12_weighted_f1score: 0.0405 - activation_13_accuracy: 0.3592 - activation_13_macro_f1score: 0.1459 - activation_13_weighted_f1score: 0.0278 - prob_accuracy: 0.5572 - prob_macro_f1score: 0.3363 - prob_weighted_f1score: 0.0596 - val_loss: 2.1553 - val_activation_12_loss: 1.2727 - val_activation_13_loss: 1.3662 - val_prob_loss: 1.1465 - val_activation_12_accuracy: 0.5152 - val_activation_12_macro_f1score: 0.2328 - val_activation_12_weighted_f1score: 0.0434 - val_activation_13_accuracy: 0.4979 - val_activation_13_macro_f1score: 0.1816 - val_activation_13_weighted_f1score: 0.0338 - val_prob_accuracy: 0.5631 - val_prob_macro_f1score: 0.3530 - val_prob_weighted_f1score: 0.0625\n",
      "Epoch 94/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.1752 - activation_12_loss: 1.3529 - activation_13_loss: 1.5435 - prob_loss: 1.1606 - activation_12_accuracy: 0.4833 - activation_12_macro_f1score: 0.2197 - activation_12_weighted_f1score: 0.0407 - activation_13_accuracy: 0.3589 - activation_13_macro_f1score: 0.1457 - activation_13_weighted_f1score: 0.0279 - prob_accuracy: 0.5596 - prob_macro_f1score: 0.3461 - prob_weighted_f1score: 0.0611 - val_loss: 2.2652 - val_activation_12_loss: 1.2883 - val_activation_13_loss: 1.4173 - val_prob_loss: 1.2329 - val_activation_12_accuracy: 0.5132 - val_activation_12_macro_f1score: 0.2274 - val_activation_12_weighted_f1score: 0.0418 - val_activation_13_accuracy: 0.4595 - val_activation_13_macro_f1score: 0.1559 - val_activation_13_weighted_f1score: 0.0314 - val_prob_accuracy: 0.5305 - val_prob_macro_f1score: 0.2935 - val_prob_weighted_f1score: 0.0528\n",
      "Epoch 95/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.1674 - activation_12_loss: 1.3415 - activation_13_loss: 1.5369 - prob_loss: 1.1583 - activation_12_accuracy: 0.4881 - activation_12_macro_f1score: 0.2237 - activation_12_weighted_f1score: 0.0415 - activation_13_accuracy: 0.3608 - activation_13_macro_f1score: 0.1447 - activation_13_weighted_f1score: 0.0278 - prob_accuracy: 0.5594 - prob_macro_f1score: 0.3460 - prob_weighted_f1score: 0.0610 - val_loss: 2.1842 - val_activation_12_loss: 1.2761 - val_activation_13_loss: 1.3749 - val_prob_loss: 1.1712 - val_activation_12_accuracy: 0.5235 - val_activation_12_macro_f1score: 0.2270 - val_activation_12_weighted_f1score: 0.0416 - val_activation_13_accuracy: 0.4759 - val_activation_13_macro_f1score: 0.1713 - val_activation_13_weighted_f1score: 0.0336 - val_prob_accuracy: 0.5637 - val_prob_macro_f1score: 0.3368 - val_prob_weighted_f1score: 0.0603\n",
      "Epoch 96/300\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 2.1847 - activation_12_loss: 1.3528 - activation_13_loss: 1.5443 - prob_loss: 1.1703 - activation_12_accuracy: 0.4823 - activation_12_macro_f1score: 0.2193 - activation_12_weighted_f1score: 0.0407 - activation_13_accuracy: 0.3565 - activation_13_macro_f1score: 0.1466 - activation_13_weighted_f1score: 0.0280 - prob_accuracy: 0.5547 - prob_macro_f1score: 0.3390 - prob_weighted_f1score: 0.0597 - val_loss: 2.1975 - val_activation_12_loss: 1.2774 - val_activation_13_loss: 1.3969 - val_prob_loss: 1.1774 - val_activation_12_accuracy: 0.5049 - val_activation_12_macro_f1score: 0.2428 - val_activation_12_weighted_f1score: 0.0446 - val_activation_13_accuracy: 0.4854 - val_activation_13_macro_f1score: 0.1656 - val_activation_13_weighted_f1score: 0.0320 - val_prob_accuracy: 0.5525 - val_prob_macro_f1score: 0.3591 - val_prob_weighted_f1score: 0.0627\n",
      "Epoch 97/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.1893 - activation_12_loss: 1.3520 - activation_13_loss: 1.5516 - prob_loss: 1.1733 - activation_12_accuracy: 0.4846 - activation_12_macro_f1score: 0.2155 - activation_12_weighted_f1score: 0.0402 - activation_13_accuracy: 0.3578 - activation_13_macro_f1score: 0.1408 - activation_13_weighted_f1score: 0.0273 - prob_accuracy: 0.5534 - prob_macro_f1score: 0.3306 - prob_weighted_f1score: 0.0587 - val_loss: 2.2175 - val_activation_12_loss: 1.3222 - val_activation_13_loss: 1.3379 - val_prob_loss: 1.2011 - val_activation_12_accuracy: 0.4948 - val_activation_12_macro_f1score: 0.2544 - val_activation_12_weighted_f1score: 0.0498 - val_activation_13_accuracy: 0.4787 - val_activation_13_macro_f1score: 0.1958 - val_activation_13_weighted_f1score: 0.0391 - val_prob_accuracy: 0.5472 - val_prob_macro_f1score: 0.3456 - val_prob_weighted_f1score: 0.0638\n",
      "Epoch 98/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.1771 - activation_12_loss: 1.3529 - activation_13_loss: 1.5409 - prob_loss: 1.1641 - activation_12_accuracy: 0.4864 - activation_12_macro_f1score: 0.2170 - activation_12_weighted_f1score: 0.0406 - activation_13_accuracy: 0.3597 - activation_13_macro_f1score: 0.1452 - activation_13_weighted_f1score: 0.0279 - prob_accuracy: 0.5580 - prob_macro_f1score: 0.3401 - prob_weighted_f1score: 0.0601 - val_loss: 2.1448 - val_activation_12_loss: 1.2469 - val_activation_13_loss: 1.3273 - val_prob_loss: 1.1566 - val_activation_12_accuracy: 0.5174 - val_activation_12_macro_f1score: 0.2576 - val_activation_12_weighted_f1score: 0.0470 - val_activation_13_accuracy: 0.4887 - val_activation_13_macro_f1score: 0.2021 - val_activation_13_weighted_f1score: 0.0385 - val_prob_accuracy: 0.5676 - val_prob_macro_f1score: 0.3721 - val_prob_weighted_f1score: 0.0653\n",
      "Epoch 99/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.1852 - activation_12_loss: 1.3545 - activation_13_loss: 1.5414 - prob_loss: 1.1717 - activation_12_accuracy: 0.4874 - activation_12_macro_f1score: 0.2192 - activation_12_weighted_f1score: 0.0406 - activation_13_accuracy: 0.3585 - activation_13_macro_f1score: 0.1438 - activation_13_weighted_f1score: 0.0278 - prob_accuracy: 0.5556 - prob_macro_f1score: 0.3391 - prob_weighted_f1score: 0.0599 - val_loss: 2.1138 - val_activation_12_loss: 1.2487 - val_activation_13_loss: 1.3374 - val_prob_loss: 1.1234 - val_activation_12_accuracy: 0.5194 - val_activation_12_macro_f1score: 0.2619 - val_activation_12_weighted_f1score: 0.0497 - val_activation_13_accuracy: 0.4845 - val_activation_13_macro_f1score: 0.1879 - val_activation_13_weighted_f1score: 0.0369 - val_prob_accuracy: 0.5653 - val_prob_macro_f1score: 0.3722 - val_prob_weighted_f1score: 0.0667\n",
      "Epoch 100/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.1658 - activation_12_loss: 1.3461 - activation_13_loss: 1.5391 - prob_loss: 1.1558 - activation_12_accuracy: 0.4885 - activation_12_macro_f1score: 0.2223 - activation_12_weighted_f1score: 0.0413 - activation_13_accuracy: 0.3638 - activation_13_macro_f1score: 0.1467 - activation_13_weighted_f1score: 0.0280 - prob_accuracy: 0.5641 - prob_macro_f1score: 0.3490 - prob_weighted_f1score: 0.0615 - val_loss: 2.2390 - val_activation_12_loss: 1.2885 - val_activation_13_loss: 1.4200 - val_prob_loss: 1.2081 - val_activation_12_accuracy: 0.5160 - val_activation_12_macro_f1score: 0.2080 - val_activation_12_weighted_f1score: 0.0389 - val_activation_13_accuracy: 0.4776 - val_activation_13_macro_f1score: 0.1584 - val_activation_13_weighted_f1score: 0.0296 - val_prob_accuracy: 0.5447 - val_prob_macro_f1score: 0.3476 - val_prob_weighted_f1score: 0.0612\n",
      "Epoch 101/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.1652 - activation_12_loss: 1.3429 - activation_13_loss: 1.5357 - prob_loss: 1.1575 - activation_12_accuracy: 0.4861 - activation_12_macro_f1score: 0.2253 - activation_12_weighted_f1score: 0.0418 - activation_13_accuracy: 0.3618 - activation_13_macro_f1score: 0.1496 - activation_13_weighted_f1score: 0.0286 - prob_accuracy: 0.5625 - prob_macro_f1score: 0.3465 - prob_weighted_f1score: 0.0611 - val_loss: 2.1890 - val_activation_12_loss: 1.2680 - val_activation_13_loss: 1.3506 - val_prob_loss: 1.1869 - val_activation_12_accuracy: 0.5071 - val_activation_12_macro_f1score: 0.2481 - val_activation_12_weighted_f1score: 0.0478 - val_activation_13_accuracy: 0.4823 - val_activation_13_macro_f1score: 0.1776 - val_activation_13_weighted_f1score: 0.0375 - val_prob_accuracy: 0.5391 - val_prob_macro_f1score: 0.3388 - val_prob_weighted_f1score: 0.0617\n",
      "Epoch 102/300\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.1788 - activation_12_loss: 1.3526 - activation_13_loss: 1.5446 - prob_loss: 1.1656 - activation_12_accuracy: 0.4873 - activation_12_macro_f1score: 0.2225 - activation_12_weighted_f1score: 0.0413 - activation_13_accuracy: 0.3624 - activation_13_macro_f1score: 0.1448 - activation_13_weighted_f1score: 0.0276 - prob_accuracy: 0.5585 - prob_macro_f1score: 0.3424 - prob_weighted_f1score: 0.0603 - val_loss: 2.2387 - val_activation_12_loss: 1.3290 - val_activation_13_loss: 1.3915 - val_prob_loss: 1.2044 - val_activation_12_accuracy: 0.4996 - val_activation_12_macro_f1score: 0.2441 - val_activation_12_weighted_f1score: 0.0457 - val_activation_13_accuracy: 0.4650 - val_activation_13_macro_f1score: 0.1799 - val_activation_13_weighted_f1score: 0.0354 - val_prob_accuracy: 0.5364 - val_prob_macro_f1score: 0.3281 - val_prob_weighted_f1score: 0.0598\n",
      "Epoch 103/300\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.1564 - activation_12_loss: 1.3425 - activation_13_loss: 1.5355 - prob_loss: 1.1491 - activation_12_accuracy: 0.4914 - activation_12_macro_f1score: 0.2266 - activation_12_weighted_f1score: 0.0420 - activation_13_accuracy: 0.3654 - activation_13_macro_f1score: 0.1483 - activation_13_weighted_f1score: 0.0281 - prob_accuracy: 0.5667 - prob_macro_f1score: 0.3516 - prob_weighted_f1score: 0.0619 - val_loss: 2.1194 - val_activation_12_loss: 1.2442 - val_activation_13_loss: 1.3448 - val_prob_loss: 1.1287 - val_activation_12_accuracy: 0.5202 - val_activation_12_macro_f1score: 0.2458 - val_activation_12_weighted_f1score: 0.0467 - val_activation_13_accuracy: 0.4781 - val_activation_13_macro_f1score: 0.1932 - val_activation_13_weighted_f1score: 0.0380 - val_prob_accuracy: 0.5623 - val_prob_macro_f1score: 0.3738 - val_prob_weighted_f1score: 0.0669\n",
      "Epoch 104/300\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.1541 - activation_12_loss: 1.3372 - activation_13_loss: 1.5328 - prob_loss: 1.1495 - activation_12_accuracy: 0.4936 - activation_12_macro_f1score: 0.2267 - activation_12_weighted_f1score: 0.0422 - activation_13_accuracy: 0.3678 - activation_13_macro_f1score: 0.1487 - activation_13_weighted_f1score: 0.0284 - prob_accuracy: 0.5666 - prob_macro_f1score: 0.3539 - prob_weighted_f1score: 0.0624 - val_loss: 2.2102 - val_activation_12_loss: 1.2852 - val_activation_13_loss: 1.3935 - val_prob_loss: 1.1899 - val_activation_12_accuracy: 0.5071 - val_activation_12_macro_f1score: 0.2337 - val_activation_12_weighted_f1score: 0.0430 - val_activation_13_accuracy: 0.4812 - val_activation_13_macro_f1score: 0.1728 - val_activation_13_weighted_f1score: 0.0324 - val_prob_accuracy: 0.5489 - val_prob_macro_f1score: 0.3421 - val_prob_weighted_f1score: 0.0599\n",
      "Epoch 105/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.1535 - activation_12_loss: 1.3378 - activation_13_loss: 1.5353 - prob_loss: 1.1482 - activation_12_accuracy: 0.4917 - activation_12_macro_f1score: 0.2291 - activation_12_weighted_f1score: 0.0423 - activation_13_accuracy: 0.3657 - activation_13_macro_f1score: 0.1458 - activation_13_weighted_f1score: 0.0279 - prob_accuracy: 0.5623 - prob_macro_f1score: 0.3553 - prob_weighted_f1score: 0.0626 - val_loss: 2.1752 - val_activation_12_loss: 1.2604 - val_activation_13_loss: 1.3572 - val_prob_loss: 1.1746 - val_activation_12_accuracy: 0.5263 - val_activation_12_macro_f1score: 0.2485 - val_activation_12_weighted_f1score: 0.0460 - val_activation_13_accuracy: 0.4909 - val_activation_13_macro_f1score: 0.1847 - val_activation_13_weighted_f1score: 0.0353 - val_prob_accuracy: 0.5525 - val_prob_macro_f1score: 0.3763 - val_prob_weighted_f1score: 0.0657\n",
      "Epoch 106/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.1527 - activation_12_loss: 1.3385 - activation_13_loss: 1.5303 - prob_loss: 1.1488 - activation_12_accuracy: 0.4942 - activation_12_macro_f1score: 0.2302 - activation_12_weighted_f1score: 0.0428 - activation_13_accuracy: 0.3641 - activation_13_macro_f1score: 0.1453 - activation_13_weighted_f1score: 0.0280 - prob_accuracy: 0.5631 - prob_macro_f1score: 0.3564 - prob_weighted_f1score: 0.0625 - val_loss: 2.0930 - val_activation_12_loss: 1.2246 - val_activation_13_loss: 1.3271 - val_prob_loss: 1.1150 - val_activation_12_accuracy: 0.5302 - val_activation_12_macro_f1score: 0.2686 - val_activation_12_weighted_f1score: 0.0513 - val_activation_13_accuracy: 0.4859 - val_activation_13_macro_f1score: 0.1916 - val_activation_13_weighted_f1score: 0.0378 - val_prob_accuracy: 0.5743 - val_prob_macro_f1score: 0.3719 - val_prob_weighted_f1score: 0.0671\n",
      "Epoch 107/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.1461 - activation_12_loss: 1.3332 - activation_13_loss: 1.5343 - prob_loss: 1.1427 - activation_12_accuracy: 0.4940 - activation_12_macro_f1score: 0.2271 - activation_12_weighted_f1score: 0.0421 - activation_13_accuracy: 0.3633 - activation_13_macro_f1score: 0.1472 - activation_13_weighted_f1score: 0.0279 - prob_accuracy: 0.5693 - prob_macro_f1score: 0.3572 - prob_weighted_f1score: 0.0626 - val_loss: 2.2678 - val_activation_12_loss: 1.2892 - val_activation_13_loss: 1.3674 - val_prob_loss: 1.2525 - val_activation_12_accuracy: 0.5208 - val_activation_12_macro_f1score: 0.2591 - val_activation_12_weighted_f1score: 0.0482 - val_activation_13_accuracy: 0.4765 - val_activation_13_macro_f1score: 0.1952 - val_activation_13_weighted_f1score: 0.0371 - val_prob_accuracy: 0.5380 - val_prob_macro_f1score: 0.3456 - val_prob_weighted_f1score: 0.0612\n",
      "Epoch 108/300\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 2.1567 - activation_12_loss: 1.3375 - activation_13_loss: 1.5364 - prob_loss: 1.1514 - activation_12_accuracy: 0.4903 - activation_12_macro_f1score: 0.2285 - activation_12_weighted_f1score: 0.0423 - activation_13_accuracy: 0.3658 - activation_13_macro_f1score: 0.1442 - activation_13_weighted_f1score: 0.0276 - prob_accuracy: 0.5633 - prob_macro_f1score: 0.3532 - prob_weighted_f1score: 0.0622 - val_loss: 2.1427 - val_activation_12_loss: 1.2404 - val_activation_13_loss: 1.3727 - val_prob_loss: 1.1448 - val_activation_12_accuracy: 0.5202 - val_activation_12_macro_f1score: 0.2416 - val_activation_12_weighted_f1score: 0.0443 - val_activation_13_accuracy: 0.4798 - val_activation_13_macro_f1score: 0.1697 - val_activation_13_weighted_f1score: 0.0318 - val_prob_accuracy: 0.5525 - val_prob_macro_f1score: 0.3582 - val_prob_weighted_f1score: 0.0624\n",
      "Epoch 109/300\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.1374 - activation_12_loss: 1.3250 - activation_13_loss: 1.5326 - prob_loss: 1.1372 - activation_12_accuracy: 0.4984 - activation_12_macro_f1score: 0.2352 - activation_12_weighted_f1score: 0.0435 - activation_13_accuracy: 0.3713 - activation_13_macro_f1score: 0.1461 - activation_13_weighted_f1score: 0.0281 - prob_accuracy: 0.5701 - prob_macro_f1score: 0.3614 - prob_weighted_f1score: 0.0634 - val_loss: 2.1263 - val_activation_12_loss: 1.2310 - val_activation_13_loss: 1.3136 - val_prob_loss: 1.1498 - val_activation_12_accuracy: 0.5277 - val_activation_12_macro_f1score: 0.2774 - val_activation_12_weighted_f1score: 0.0525 - val_activation_13_accuracy: 0.4935 - val_activation_13_macro_f1score: 0.2001 - val_activation_13_weighted_f1score: 0.0401 - val_prob_accuracy: 0.5628 - val_prob_macro_f1score: 0.3531 - val_prob_weighted_f1score: 0.0652\n",
      "Epoch 110/300\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 2.1460 - activation_12_loss: 1.3318 - activation_13_loss: 1.5345 - prob_loss: 1.1435 - activation_12_accuracy: 0.4952 - activation_12_macro_f1score: 0.2299 - activation_12_weighted_f1score: 0.0424 - activation_13_accuracy: 0.3675 - activation_13_macro_f1score: 0.1463 - activation_13_weighted_f1score: 0.0280 - prob_accuracy: 0.5662 - prob_macro_f1score: 0.3608 - prob_weighted_f1score: 0.0631 - val_loss: 2.1476 - val_activation_12_loss: 1.2279 - val_activation_13_loss: 1.3593 - val_prob_loss: 1.1578 - val_activation_12_accuracy: 0.5199 - val_activation_12_macro_f1score: 0.2651 - val_activation_12_weighted_f1score: 0.0495 - val_activation_13_accuracy: 0.4923 - val_activation_13_macro_f1score: 0.1804 - val_activation_13_weighted_f1score: 0.0342 - val_prob_accuracy: 0.5514 - val_prob_macro_f1score: 0.3728 - val_prob_weighted_f1score: 0.0665\n",
      "Epoch 111/300\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.1419 - activation_12_loss: 1.3257 - activation_13_loss: 1.5283 - prob_loss: 1.1432 - activation_12_accuracy: 0.4961 - activation_12_macro_f1score: 0.2384 - activation_12_weighted_f1score: 0.0440 - activation_13_accuracy: 0.3726 - activation_13_macro_f1score: 0.1487 - activation_13_weighted_f1score: 0.0285 - prob_accuracy: 0.5640 - prob_macro_f1score: 0.3569 - prob_weighted_f1score: 0.0625 - val_loss: 2.1828 - val_activation_12_loss: 1.2613 - val_activation_13_loss: 1.3836 - val_prob_loss: 1.1747 - val_activation_12_accuracy: 0.5213 - val_activation_12_macro_f1score: 0.2342 - val_activation_12_weighted_f1score: 0.0444 - val_activation_13_accuracy: 0.4795 - val_activation_13_macro_f1score: 0.1674 - val_activation_13_weighted_f1score: 0.0327 - val_prob_accuracy: 0.5536 - val_prob_macro_f1score: 0.3450 - val_prob_weighted_f1score: 0.0621\n",
      "Epoch 112/300\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 2.1390 - activation_12_loss: 1.3270 - activation_13_loss: 1.5305 - prob_loss: 1.1393 - activation_12_accuracy: 0.4964 - activation_12_macro_f1score: 0.2336 - activation_12_weighted_f1score: 0.0434 - activation_13_accuracy: 0.3723 - activation_13_macro_f1score: 0.1478 - activation_13_weighted_f1score: 0.0284 - prob_accuracy: 0.5684 - prob_macro_f1score: 0.3604 - prob_weighted_f1score: 0.0632 - val_loss: 2.1990 - val_activation_12_loss: 1.2638 - val_activation_13_loss: 1.3612 - val_prob_loss: 1.1963 - val_activation_12_accuracy: 0.5222 - val_activation_12_macro_f1score: 0.2654 - val_activation_12_weighted_f1score: 0.0482 - val_activation_13_accuracy: 0.4890 - val_activation_13_macro_f1score: 0.1877 - val_activation_13_weighted_f1score: 0.0350 - val_prob_accuracy: 0.5634 - val_prob_macro_f1score: 0.3649 - val_prob_weighted_f1score: 0.0636\n",
      "Epoch 113/300\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 2.1499 - activation_12_loss: 1.3348 - activation_13_loss: 1.5310 - prob_loss: 1.1478 - activation_12_accuracy: 0.4946 - activation_12_macro_f1score: 0.2314 - activation_12_weighted_f1score: 0.0427 - activation_13_accuracy: 0.3724 - activation_13_macro_f1score: 0.1449 - activation_13_weighted_f1score: 0.0278 - prob_accuracy: 0.5653 - prob_macro_f1score: 0.3548 - prob_weighted_f1score: 0.0622 - val_loss: 2.1964 - val_activation_12_loss: 1.2703 - val_activation_13_loss: 1.3593 - val_prob_loss: 1.1925 - val_activation_12_accuracy: 0.5038 - val_activation_12_macro_f1score: 0.2803 - val_activation_12_weighted_f1score: 0.0504 - val_activation_13_accuracy: 0.4834 - val_activation_13_macro_f1score: 0.2020 - val_activation_13_weighted_f1score: 0.0385 - val_prob_accuracy: 0.5567 - val_prob_macro_f1score: 0.3739 - val_prob_weighted_f1score: 0.0647\n",
      "Epoch 114/300\n",
      " 84/224 [==========>...................] - ETA: 17s - loss: 2.1645 - activation_12_loss: 1.3434 - activation_13_loss: 1.5425 - prob_loss: 1.1564 - activation_12_accuracy: 0.4893 - activation_12_macro_f1score: 0.2307 - activation_12_weighted_f1score: 0.0424 - activation_13_accuracy: 0.3668 - activation_13_macro_f1score: 0.1445 - activation_13_weighted_f1score: 0.0271 - prob_accuracy: 0.5612 - prob_macro_f1score: 0.3524 - prob_weighted_f1score: 0.0615Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "model.fit(generate_train_for_three(x_train,y_train), steps_per_epoch=len(x_train)/128, validation_data= generate_valid_for_three(x_valid,y_valid), validation_steps=len(x_valid)/128, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7480606,
     "status": "ok",
     "timestamp": 1583407807543,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "sbs3Vn60MeUe",
    "outputId": "a7c9f570-1e1f-49ef-9208-cd37c7608a00",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 3s 758us/sample - loss: 2.0611 - activation_12_loss: 1.1994 - activation_13_loss: 1.2719 - prob_loss: 1.1701 - activation_12_accuracy: 0.5396 - activation_12_macro_f1score: 0.3294 - activation_12_weighted_f1score: 0.0580 - activation_13_accuracy: 0.5471 - activation_13_macro_f1score: 0.2155 - activation_13_weighted_f1score: 0.0407 - prob_accuracy: 0.5775 - prob_macro_f1score: 0.4498 - prob_weighted_f1score: 0.0728\n",
      "\n",
      "Final Accuracy: 0.5775, Final Macro F1 Score: 0.4498, Final Weighted F1 Score: 0.0728\n"
     ]
    }
   ],
   "source": [
    "*_, acc, mac_f1, wei_f1 = model.evaluate(x_test,[y_test,y_test,y_test],batch_size=128)\n",
    "print(\"\\nFinal Accuracy: {:.4f}, Final Macro F1 Score: {:.4f}, Final Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "11. FER_Aug_Basic_Models(GoogLeNet - Inception v1) - 2020.02.27(THU).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

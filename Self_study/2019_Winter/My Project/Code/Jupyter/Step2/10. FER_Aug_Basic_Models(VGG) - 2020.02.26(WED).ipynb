{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vwVmRuFcUBkT"
   },
   "source": [
    "# [VGG]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0MMz6DhUBkW"
   },
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ywk25Fr79dWe"
   },
   "source": [
    "### Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KSON5xiR9dWf"
   },
   "source": [
    "1. Almost Original VGG19 & Data Import\n",
    "```\n",
    "1) Data Import\n",
    "2) Data Augmentation\n",
    "3) Almost Original VGG19\n",
    "```\n",
    "2. For Size = 64,\n",
    "```\n",
    "1) My VGG11 (Pretraining)\n",
    "2) My VGG16 (Pretrained)\n",
    "3) My VGG19 (Pretrained)\n",
    "4) My VGG11 (Convergence Speed Comparison)\n",
    "```\n",
    "3. For Size = 48,\n",
    "```\n",
    "1) My VGG11 (Pretraining)\n",
    "2) My VGG16 (Pretrained)\n",
    "3) My VGG19 (Pretrained)\n",
    "4) My VGG11 (Convergence Speed Comparison)\n",
    "```\n",
    "4. For Size = 48, No Early Stopping\n",
    "```\n",
    "1) Epoch = 50\n",
    "      (1) My VGG11\n",
    "      (2) My VGG16\n",
    "      (3) My VGG19\n",
    "2) Epoch = 100\n",
    "      (1) My VGG11\n",
    "      (2) My VGG16\n",
    "      (3) My VGG19\n",
    "```\n",
    "5. Model Save & Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U01q4o40UBkY"
   },
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 953
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 99372,
     "status": "ok",
     "timestamp": 1583363957621,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "gqH6bMFuDntz",
    "outputId": "66b2b23e-2b72-4dff-fd54-f334cd21a6b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
      "\u001b[K     |████████████████████████████████| 421.8MB 36kB/s \n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9MB 41.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 48.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (45.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: tensorboard 1.15.0\n",
      "    Uninstalling tensorboard-1.15.0:\n",
      "      Successfully uninstalled tensorboard-1.15.0\n",
      "  Found existing installation: tensorflow-estimator 1.15.1\n",
      "    Uninstalling tensorflow-estimator-1.15.1:\n",
      "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
      "  Found existing installation: tensorflow 1.15.0\n",
      "    Uninstalling tensorflow-1.15.0:\n",
      "      Successfully uninstalled tensorflow-1.15.0\n",
      "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XjdygsS_UBke"
   },
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 120873,
     "status": "ok",
     "timestamp": 1583363979141,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "o1tpIlBhXG2i",
    "outputId": "8ad2c959-b4c3-4361-b376-640764188352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 122695,
     "status": "ok",
     "timestamp": 1583363980980,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "IJdbC2nRXR6h",
    "outputId": "435e7517-4955-49c0-bcf0-503027b78e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/project\n"
     ]
    }
   ],
   "source": [
    "cd /content/drive/My Drive/Colab Notebooks/project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bCx2JDrkW6sn"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 122676,
     "status": "ok",
     "timestamp": 1583363980982,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "qQKQi4SjY3Ug",
    "outputId": "e67d6dc9-7cfa-4ef2-cfb4-f0df103dfbcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/env/python',\n",
       " '/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/root/.ipython']"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모듈로 받을 경로 확인\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9dGjq6aY3cN"
   },
   "outputs": [],
   "source": [
    "# 내 노트북이 아닌, 전산실 컴퓨터의 colab에서 돌렸으므로, 다시돌리려면 경로 수정할것!\n",
    "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I98omoQ8FF90"
   },
   "outputs": [],
   "source": [
    "from lrn import LRN\n",
    "from f1score import macro_f1score,weighted_f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HKLMWqbuUBkf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,GlobalAveragePooling2D,GlobalMaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import get_file, to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 128516,
     "status": "ok",
     "timestamp": 1583363986851,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "cbiFovMgXTax",
    "outputId": "20d985f3-a00d-49a0-a4a4-b7e4a73c3793"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/project'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEDKbmg5EYHq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 128501,
     "status": "ok",
     "timestamp": 1583363986853,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "VG0fS8Y7DotU",
    "outputId": "ebcb8a43-2427-409e-e738-ebf46002a595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 513,
     "status": "ok",
     "timestamp": 1583368671896,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "dA0XZt7E_xUH",
    "outputId": "30213adc-dd35-44ec-a718-815d83148ed3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OOsm86eVUBko"
   },
   "source": [
    "## 1. Almost Original VGG19 & Data Import\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePlHQehVDgI6"
   },
   "source": [
    "### 1) Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FU8MecfwUBkt"
   },
   "outputs": [],
   "source": [
    "# data import\n",
    "x_train = pd.read_csv(\"mydata/X_train.csv\",header=0,index_col=0)\n",
    "x_valid = pd.read_csv(\"mydata/X_private_test.csv\",header=0,index_col=0)\n",
    "x_test = pd.read_csv(\"mydata/X_public_test.csv\",header=0,index_col=0)\n",
    "y_train = pd.read_csv(\"mydata/y_train.csv\",header=0,index_col=0)\n",
    "y_valid = pd.read_csv(\"mydata/y_private_test.csv\",header=0,index_col=0)\n",
    "y_test = pd.read_csv(\"mydata/y_public_test.csv\",header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2hU5mstozNL"
   },
   "outputs": [],
   "source": [
    "# data handling\n",
    "x_train = np.array(x_train).reshape([-1,48,48,3]) \n",
    "x_valid = np.array(x_valid).reshape([-1,48,48,3]) \n",
    "x_test = np.array(x_test).reshape([-1,48,48,3]) \n",
    "\n",
    "y_train=to_categorical(y_train) # one hot encoding\n",
    "y_valid=to_categorical(y_valid)\n",
    "y_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wuAEBQRtUBk3"
   },
   "outputs": [],
   "source": [
    "# data handling\n",
    "# uint는 부호없는 정수로, 타입을 바꿔줘야함!\n",
    "size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JUh5IzGYUBk-"
   },
   "outputs": [],
   "source": [
    "x_train_zoom = np.zeros([x_train.shape[0],size,size,3],dtype=\"float32\")\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train_zoom[i,:] = cv2.resize(x_train[i,:].astype('uint8'), (size, size),\n",
    "                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jPHUMDkCUBlB"
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3qmmnzNUBlE"
   },
   "outputs": [],
   "source": [
    "x_valid = np.array(x_valid).reshape([-1,48,48,3])\n",
    "x_valid_zoom = np.zeros([x_valid.shape[0],size,size,3],dtype=\"float32\")\n",
    "for i in range(x_valid.shape[0]):\n",
    "    x_valid_zoom[i,:] = cv2.resize(x_valid[i,:].astype('uint8'), (size, size),\n",
    "                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) /255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I3V15xJuUBlH"
   },
   "outputs": [],
   "source": [
    " x_valid = x_valid / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFInNp5RUBlK"
   },
   "outputs": [],
   "source": [
    "x_test = np.array(x_test).reshape([-1,48,48,3])\n",
    "x_test_zoom = np.zeros([x_test.shape[0],size,size,3],dtype=\"float32\")\n",
    "for i in range(x_test.shape[0]):\n",
    "    x_test_zoom[i,:] = cv2.resize(x_test[i,:].astype('uint8'), (size, size),\n",
    "                                  interpolation=cv2.INTER_CUBIC).reshape(size,size,3) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZHAXg5nUBlV"
   },
   "outputs": [],
   "source": [
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sTgX_I1DgJX"
   },
   "source": [
    "### 2) Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lc09PjvsDgJY"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=[0.9,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-ARX0zrDgJb"
   },
   "outputs": [],
   "source": [
    "datagen_val = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vw2bZFTzDgJd"
   },
   "outputs": [],
   "source": [
    "xy_valid_zoom_gen = datagen_val.flow(x_valid_zoom,y_valid,batch_size=128)\n",
    "xy_valid_gen = datagen_val.flow(x_valid,y_valid,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhjqFljBDgJf"
   },
   "source": [
    "### 3) Almost Original VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 180082,
     "status": "ok",
     "timestamp": 1583312705330,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "yzPAEIrUFF-o",
    "outputId": "e578f79c-4035-47d2-e7de-78644b6ba22b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Instantiates the VGG19 architecture.\\n Optionally loads weights pre-trained on ImageNet. Note that when using TensorFlow,\\n for best performance you should set\\n `image_data_format=\"channels_last\"` in your Keras config\\n at ~/.keras/keras.json.\\n The model and the weights are compatible with both\\n TensorFlow and Theano. The data format\\n convention used by the model is the one\\n specified in your Keras config file.\\n\\n # Arguments\\n     include_top: whether to include the 3 fully-connected\\n         layers at the top of the network.\\n     weights: one of `None` (random initialization)\\n         or \"imagenet\" (pre-training on ImageNet).\\n     input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\\n         to use as image input for the model.\\n     input_shape: optional shape tuple, only to be specified\\n         if `include_top` is False (otherwise the input shape\\n         has to be `(224, 224, 3)` (with `channels_last` data format)\\n         or `(3, 224, 244)` (with `channels_first` data format).\\n         It should have exactly 3 inputs channels,\\n         and width and height should be no smaller than 48.\\n         E.g. `(200, 200, 3)` would be one valid value.\\n     pooling: Optional pooling mode for feature extraction\\n         when `include_top` is `False`.\\n         - `None` means that the output of the model will be\\n             the 4D tensor output of the\\n             last convolutional layer.\\n         - `avg` means that global average pooling\\n             will be applied to the output of the\\n             last convolutional layer, and thus\\n             the output of the model will be a 2D tensor.\\n         - `max` means that global max pooling will\\n             be applied.\\n     classes: optional number of classes to classify images\\n         into, only to be specified if `include_top` is True, and\\n         if no `weights` argument is specified.\\n # Returns\\n     A Keras model instance.\\n '"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VGG19 모형과 관련된 초기값이 저장되어 있는 링크. 접속시 바로 다운됨. FC층을 어떻게 처리할 건지에 따라 두가지 초기값들이 있음.\n",
    "# 이 값은 ImageNet 데이터를 가지고 학습한 초기값임.\n",
    "# 내가 쓸 모형은 이 초기값이 필요 없기 때문에, 내가 초기값을 뽑아내는 작업을 해야한다.\n",
    "\n",
    "# 다시한번 얘기하지만, 아래의 두 변수는 내가 아래의 코드에서 쓸 변수는 아님. 나중의 혹시모를 상황을 대비해 남겨놓음.\n",
    "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "'''VGG19 model for Keras.\n",
    "# Reference:\n",
    "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
    "'''\n",
    "('https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "\"\"\"Instantiates the VGG19 architecture.\n",
    " Optionally loads weights pre-trained on ImageNet. Note that when using TensorFlow,\n",
    " for best performance you should set\n",
    " `image_data_format=\"channels_last\"` in your Keras config\n",
    " at ~/.keras/keras.json.\n",
    " The model and the weights are compatible with both\n",
    " TensorFlow and Theano. The data format\n",
    " convention used by the model is the one\n",
    " specified in your Keras config file.\n",
    "\n",
    " # Arguments\n",
    "     include_top: whether to include the 3 fully-connected\n",
    "         layers at the top of the network.\n",
    "     weights: one of `None` (random initialization)\n",
    "         or \"imagenet\" (pre-training on ImageNet).\n",
    "     input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "         to use as image input for the model.\n",
    "     input_shape: optional shape tuple, only to be specified\n",
    "         if `include_top` is False (otherwise the input shape\n",
    "         has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "         or `(3, 224, 244)` (with `channels_first` data format).\n",
    "         It should have exactly 3 inputs channels,\n",
    "         and width and height should be no smaller than 48.\n",
    "         E.g. `(200, 200, 3)` would be one valid value.\n",
    "     pooling: Optional pooling mode for feature extraction\n",
    "         when `include_top` is `False`.\n",
    "         - `None` means that the output of the model will be\n",
    "             the 4D tensor output of the\n",
    "             last convolutional layer.\n",
    "         - `avg` means that global average pooling\n",
    "             will be applied to the output of the\n",
    "             last convolutional layer, and thus\n",
    "             the output of the model will be a 2D tensor.\n",
    "         - `max` means that global max pooling will\n",
    "             be applied.\n",
    "     classes: optional number of classes to classify images\n",
    "         into, only to be specified if `include_top` is True, and\n",
    "         if no `weights` argument is specified.\n",
    " # Returns\n",
    "     A Keras model instance.\n",
    " \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQQSvuzfUBlZ"
   },
   "outputs": [],
   "source": [
    "# VGG19를 최대한 논문에 가깝게 맞춰 모형작성.\n",
    "# 또한, Data Augmentation은 컴퓨터 성능의 한계로 하지 않음.\n",
    "\n",
    "def VGG19(input_shape=(224, 224, 3), classes=7, include_top=True, pooling=None, weights=None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        output = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='vgg19')\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet': # 내 모형에서는 쓸모없다. 다만, 나중의 혹시모를 참고를 위해 코드는 남겨놓는다.\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH, cache_subdir='models', file_hash='cbe5617147190e668d6c5d5026f83318')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP, cache_subdir='models',\n",
    "                                    file_hash='253f8cb515780f3b799900260a226db6')\n",
    "\n",
    "        model.load_weights(weights_path)  # 경로에 있는 초기치 weights가져오기\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKNZkR1NUBlc"
   },
   "outputs": [],
   "source": [
    "model = VGG19(input_shape=(224, 224, 3), classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 182109,
     "status": "ok",
     "timestamp": 1583312707385,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "te4pinumUBle",
    "outputId": "136ea4c5-e9d7-4f53-dd11-9f5d9696010e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 28679     \n",
      "=================================================================\n",
      "Total params: 139,598,919\n",
      "Trainable params: 139,598,919\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhbphHbX9dXr"
   },
   "source": [
    "## 2. For Size = 64,\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kiu3oJRIagkw"
   },
   "source": [
    "### 1) My VGG11 (Pretraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSApK_jeb_Lo"
   },
   "outputs": [],
   "source": [
    "# 논문에서 VGG19 의 FC층은 VGG11로 pretraining하여 얻은 초기치로 설정하였음.\n",
    "# 기존의 VGG11을 개조\n",
    "# Data Augmentation은 컴퓨터 성능의 한계로 못하기 때문에 변형함.\n",
    "\n",
    "# 주의 !!!!기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!!!\n",
    "\n",
    "# 다음의 절차로 모형을 개조한다.\n",
    "\n",
    "# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n",
    "# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n",
    "# 3. Conv의 filter는 1/8로 줄인다.\n",
    "# 4. 다음과 같이 모형을 재구성한다.\n",
    "# 5. 위의 내용은 앞으로 비교될 모형에서도 공통적으로 작용한다.\n",
    "\n",
    "def VGG11(input_shape=(64,64,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu',name='fc1')(x)\n",
    "        x = Dense(256, activation='relu', name='fc2')(x)\n",
    "        output = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='Vgg11_Pretraining')\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BGhZH2FcL4S"
   },
   "outputs": [],
   "source": [
    "#내 데이터 맞춤형 모형\n",
    "model = VGG11(input_shape=(64, 64, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1583364164532,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "TKsFtx5-b_PS",
    "outputId": "289c9de2-b0b6-4b74-a5f7-3cbe3555838f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Vgg11_Pretraining\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 277,943\n",
      "Trainable params: 277,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipySpUqSb_TI"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 813474,
     "status": "ok",
     "timestamp": 1583364981117,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "kDIuXikrb_R2",
    "outputId": "63d33fa6-ab42-4585-917a-3137127c4486",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 41s 184ms/step - loss: 1.8169 - accuracy: 0.2504 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8546 - val_accuracy: 0.2536 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.7427 - accuracy: 0.2892 - macro_f1score: 0.0240 - weighted_f1score: 0.0053 - val_loss: 1.6695 - val_accuracy: 0.3692 - val_macro_f1score: 0.0783 - val_weighted_f1score: 0.0176\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 36s 159ms/step - loss: 1.5996 - accuracy: 0.3667 - macro_f1score: 0.1162 - weighted_f1score: 0.0231 - val_loss: 1.5611 - val_accuracy: 0.4043 - val_macro_f1score: 0.1568 - val_weighted_f1score: 0.0311\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.5066 - accuracy: 0.4094 - macro_f1score: 0.1518 - weighted_f1score: 0.0293 - val_loss: 1.4789 - val_accuracy: 0.4400 - val_macro_f1score: 0.1755 - val_weighted_f1score: 0.0331\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.4314 - accuracy: 0.4408 - macro_f1score: 0.1834 - weighted_f1score: 0.0348 - val_loss: 1.4446 - val_accuracy: 0.4564 - val_macro_f1score: 0.2145 - val_weighted_f1score: 0.0412\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.3756 - accuracy: 0.4656 - macro_f1score: 0.2101 - weighted_f1score: 0.0393 - val_loss: 1.3834 - val_accuracy: 0.4792 - val_macro_f1score: 0.2502 - val_weighted_f1score: 0.0457\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.3295 - accuracy: 0.4869 - macro_f1score: 0.2386 - weighted_f1score: 0.0440 - val_loss: 1.3323 - val_accuracy: 0.5052 - val_macro_f1score: 0.2298 - val_weighted_f1score: 0.0442\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.2887 - accuracy: 0.5036 - macro_f1score: 0.2623 - weighted_f1score: 0.0479 - val_loss: 1.2907 - val_accuracy: 0.5177 - val_macro_f1score: 0.2551 - val_weighted_f1score: 0.0479\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.2562 - accuracy: 0.5167 - macro_f1score: 0.2820 - weighted_f1score: 0.0511 - val_loss: 1.2730 - val_accuracy: 0.5135 - val_macro_f1score: 0.2980 - val_weighted_f1score: 0.0544\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 36s 159ms/step - loss: 1.2397 - accuracy: 0.5234 - macro_f1score: 0.2935 - weighted_f1score: 0.0529 - val_loss: 1.2239 - val_accuracy: 0.5419 - val_macro_f1score: 0.2947 - val_weighted_f1score: 0.0545\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.2095 - accuracy: 0.5368 - macro_f1score: 0.3103 - weighted_f1score: 0.0555 - val_loss: 1.2460 - val_accuracy: 0.5347 - val_macro_f1score: 0.3327 - val_weighted_f1score: 0.0584\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 35s 156ms/step - loss: 1.1935 - accuracy: 0.5447 - macro_f1score: 0.3278 - weighted_f1score: 0.0583 - val_loss: 1.2102 - val_accuracy: 0.5447 - val_macro_f1score: 0.3279 - val_weighted_f1score: 0.0578\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 35s 156ms/step - loss: 1.1738 - accuracy: 0.5524 - macro_f1score: 0.3403 - weighted_f1score: 0.0603 - val_loss: 1.1851 - val_accuracy: 0.5609 - val_macro_f1score: 0.3341 - val_weighted_f1score: 0.0600\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.1591 - accuracy: 0.5571 - macro_f1score: 0.3537 - weighted_f1score: 0.0621 - val_loss: 1.2540 - val_accuracy: 0.5210 - val_macro_f1score: 0.3118 - val_weighted_f1score: 0.0547\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.1490 - accuracy: 0.5615 - macro_f1score: 0.3573 - weighted_f1score: 0.0627 - val_loss: 1.1662 - val_accuracy: 0.5617 - val_macro_f1score: 0.3642 - val_weighted_f1score: 0.0644\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.1390 - accuracy: 0.5637 - macro_f1score: 0.3660 - weighted_f1score: 0.0642 - val_loss: 1.1496 - val_accuracy: 0.5687 - val_macro_f1score: 0.3675 - val_weighted_f1score: 0.0647\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.1209 - accuracy: 0.5728 - macro_f1score: 0.3796 - weighted_f1score: 0.0659 - val_loss: 1.1746 - val_accuracy: 0.5553 - val_macro_f1score: 0.3514 - val_weighted_f1score: 0.0634\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.1153 - accuracy: 0.5742 - macro_f1score: 0.3866 - weighted_f1score: 0.0666 - val_loss: 1.1512 - val_accuracy: 0.5712 - val_macro_f1score: 0.3728 - val_weighted_f1score: 0.0663\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 35s 156ms/step - loss: 1.1077 - accuracy: 0.5779 - macro_f1score: 0.3846 - weighted_f1score: 0.0669 - val_loss: 1.1565 - val_accuracy: 0.5731 - val_macro_f1score: 0.3968 - val_weighted_f1score: 0.0698\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.0996 - accuracy: 0.5806 - macro_f1score: 0.3940 - weighted_f1score: 0.0680 - val_loss: 1.1328 - val_accuracy: 0.5801 - val_macro_f1score: 0.4114 - val_weighted_f1score: 0.0717\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.0870 - accuracy: 0.5845 - macro_f1score: 0.4062 - weighted_f1score: 0.0694 - val_loss: 1.1272 - val_accuracy: 0.5840 - val_macro_f1score: 0.4061 - val_weighted_f1score: 0.0696\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.0844 - accuracy: 0.5885 - macro_f1score: 0.4065 - weighted_f1score: 0.0698 - val_loss: 1.1232 - val_accuracy: 0.5823 - val_macro_f1score: 0.3955 - val_weighted_f1score: 0.0683\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 34s 150ms/step - loss: 1.0778 - accuracy: 0.5912 - macro_f1score: 0.4149 - weighted_f1score: 0.0711 - val_loss: 1.1079 - val_accuracy: 0.5804 - val_macro_f1score: 0.4106 - val_weighted_f1score: 0.0717\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a844bafd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train_zoom,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1288,
     "status": "ok",
     "timestamp": 1583364982420,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "5U1VVM-0FF_x",
    "outputId": "39de716c-12f7-4f1f-b301-dfc3c36a6023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 1s 160us/sample - loss: 1.0969 - accuracy: 0.5766 - macro_f1score: 0.4014 - weighted_f1score: 0.0682\n",
      "\n",
      "Accuracy: 0.5766, Macro F1 Score: 0.4014, Weighted F1 Score: 0.0682\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-aQSDtcLFF_z"
   },
   "outputs": [],
   "source": [
    "# 한층당 W 와 b , 2개씩 있으므로 11개층이라면 22개의 모수 벡터 및 행렬이 출력된다.\n",
    "W = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1583364982423,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "JcKODk4OMp0j",
    "outputId": "bc0c9783-48b5-4d0a-8239-10267e8658b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.20407596, -0.0076126 , -0.31642285, -0.14033513,\n",
       "            0.2834546 ,  0.17670147,  0.18333197, -0.00525202],\n",
       "          [-0.1222116 , -0.00253352, -0.1462644 , -0.12128124,\n",
       "            0.26775965,  0.1779506 ,  0.20969276,  0.0413659 ],\n",
       "          [-0.07989866,  0.27928892, -0.27633652, -0.0575515 ,\n",
       "            0.09372558,  0.2992469 , -0.07647823,  0.14722785]],\n",
       " \n",
       "         [[ 0.02342825, -0.07014901,  0.00285076, -0.23947963,\n",
       "           -0.15778463, -0.07801206, -0.15598541, -0.08965971],\n",
       "          [ 0.13409467,  0.20458865, -0.09732905, -0.14803115,\n",
       "           -0.16993253, -0.14117503, -0.15697259,  0.06676271],\n",
       "          [ 0.34458554,  0.09123912,  0.06526193,  0.17850512,\n",
       "           -0.00704311, -0.0696204 , -0.02253206, -0.24609652]],\n",
       " \n",
       "         [[ 0.07324352, -0.13435145, -0.01040823,  0.06470463,\n",
       "            0.17856698,  0.0033257 , -0.06190493, -0.23788494],\n",
       "          [ 0.22493629, -0.11870138, -0.18789716, -0.18417086,\n",
       "           -0.22343037, -0.04021792, -0.15517718,  0.15642323],\n",
       "          [ 0.25403753,  0.20407079, -0.15775983, -0.06128685,\n",
       "           -0.0306304 ,  0.00637106, -0.20272593,  0.1491268 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.28345504, -0.1721225 ,  0.11658465,  0.13632138,\n",
       "           -0.01797273, -0.05518382,  0.0064924 ,  0.18897536],\n",
       "          [-0.2009701 , -0.2409991 , -0.2096754 , -0.29443717,\n",
       "            0.17237931, -0.07551806,  0.11007676,  0.21130186],\n",
       "          [-0.12923396, -0.10700378, -0.20607877, -0.21614788,\n",
       "            0.03185014,  0.05685909,  0.07223535,  0.11637469]],\n",
       " \n",
       "         [[-0.14405234,  0.03736109,  0.09730621,  0.03400201,\n",
       "           -0.29817122,  0.0294111 ,  0.10537728,  0.10498245],\n",
       "          [ 0.20339312,  0.1004825 ,  0.17429212, -0.12547661,\n",
       "           -0.14337556, -0.04731176, -0.17148328, -0.0038924 ],\n",
       "          [ 0.18524697, -0.23985395,  0.17224374,  0.19652809,\n",
       "           -0.05048783, -0.2729352 ,  0.1538086 ,  0.00743192]],\n",
       " \n",
       "         [[-0.11424674, -0.24939358, -0.0557913 , -0.20197721,\n",
       "           -0.05319946,  0.04061206,  0.00161384, -0.05736644],\n",
       "          [ 0.05767681, -0.14531906, -0.14187573, -0.19707628,\n",
       "           -0.01006328,  0.10277203, -0.25421324,  0.08785586],\n",
       "          [-0.05375228, -0.13022077,  0.20082113,  0.05126536,\n",
       "            0.11759859, -0.15113387,  0.16276918, -0.16742475]]],\n",
       " \n",
       " \n",
       "        [[[-0.14866973, -0.05075754,  0.02050619,  0.05235216,\n",
       "           -0.17970033,  0.04865923,  0.19329637,  0.03585541],\n",
       "          [-0.10386109, -0.10239654,  0.03907063, -0.11828617,\n",
       "            0.02920107, -0.15557998,  0.13490796, -0.09709021],\n",
       "          [-0.19438894, -0.18040624,  0.14746003,  0.11570627,\n",
       "            0.00803062,  0.12866554,  0.03870315, -0.22234063]],\n",
       " \n",
       "         [[-0.04147372, -0.2825322 ,  0.08183165, -0.25633907,\n",
       "           -0.0029715 , -0.0938168 ,  0.1426637 , -0.09144492],\n",
       "          [ 0.04129991,  0.10965732,  0.0761847 , -0.20362762,\n",
       "           -0.21873309,  0.01872263,  0.20315865, -0.07534482],\n",
       "          [-0.16400869, -0.26050574,  0.1659579 , -0.10895947,\n",
       "           -0.0439834 ,  0.0434352 , -0.14225517, -0.38147274]],\n",
       " \n",
       "         [[-0.07470969, -0.00830479,  0.2786317 ,  0.09001424,\n",
       "            0.15519662, -0.03838968,  0.1757615 , -0.2591325 ],\n",
       "          [ 0.19147374,  0.23530056,  0.15367055, -0.18881847,\n",
       "            0.04563609, -0.13187645,  0.10267056, -0.03865632],\n",
       "          [-0.09614272,  0.28822982,  0.13421746, -0.08513387,\n",
       "            0.1920927 , -0.16310443, -0.06185865,  0.06117762]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.07730127,  0.15047254,  0.02648023, -0.05073486,  0.00833079,\n",
       "        -0.02135134, -0.09641013, -0.04680444], dtype=float32),\n",
       " array([[[[-1.88147783e-01, -2.10542157e-01, -3.61554116e-01, ...,\n",
       "            3.96144874e-02, -1.28306687e-01, -9.31893960e-02],\n",
       "          [-5.30292876e-02, -1.42793939e-01,  5.44611961e-02, ...,\n",
       "           -1.70136735e-01, -2.44497806e-01,  4.46163863e-02],\n",
       "          [ 5.28940521e-02, -1.39651194e-01,  8.89326632e-02, ...,\n",
       "           -7.18935451e-04,  9.00823027e-02,  4.88478653e-02],\n",
       "          ...,\n",
       "          [ 1.42464131e-01,  8.51581991e-02,  1.70612298e-02, ...,\n",
       "            1.23285741e-01, -8.84603709e-02,  1.04145512e-01],\n",
       "          [-5.80072366e-02,  1.11874811e-01,  4.26895097e-02, ...,\n",
       "            7.86599219e-02, -7.11378083e-02,  8.75764862e-02],\n",
       "          [-1.03404382e-02, -1.36487201e-01,  7.48250112e-02, ...,\n",
       "           -1.53867612e-02,  4.86405045e-02, -7.53743201e-02]],\n",
       " \n",
       "         [[-2.13976145e-01, -4.59623523e-02,  1.62686273e-01, ...,\n",
       "            2.32868463e-01, -8.79105330e-02, -2.46970192e-01],\n",
       "          [-1.14739724e-01,  5.01294062e-02,  1.71475813e-01, ...,\n",
       "            1.48779139e-01, -5.01922548e-01,  2.05628514e-01],\n",
       "          [ 6.25623539e-02,  9.64995176e-02, -1.30426452e-01, ...,\n",
       "            9.25567076e-02,  2.64500324e-02, -2.82186478e-01],\n",
       "          ...,\n",
       "          [ 7.40338340e-02, -3.58825415e-01, -1.56192392e-01, ...,\n",
       "           -7.24574029e-02, -4.58448231e-02,  1.05300896e-01],\n",
       "          [-2.76748799e-02, -1.68067887e-01, -2.76863992e-01, ...,\n",
       "            1.19953908e-01, -1.61788762e-02,  1.15691155e-01],\n",
       "          [ 3.07706427e-02, -1.07222132e-01,  1.21943183e-01, ...,\n",
       "           -1.68567404e-01,  1.45502895e-01, -1.13336861e-01]],\n",
       " \n",
       "         [[-2.13172883e-02, -6.19860478e-02,  2.32167080e-01, ...,\n",
       "            1.09025963e-01, -1.61381155e-01,  1.48007914e-01],\n",
       "          [-1.75295174e-01,  9.98580903e-02,  1.19590029e-01, ...,\n",
       "           -2.78034527e-02, -1.58321247e-01,  3.82521898e-02],\n",
       "          [-1.29591569e-01,  2.33105645e-02,  5.60068147e-05, ...,\n",
       "           -1.38465837e-01, -1.51850298e-01, -3.78858112e-02],\n",
       "          ...,\n",
       "          [ 2.10265920e-01, -3.74380827e-01,  2.99486250e-01, ...,\n",
       "           -3.06664228e-01, -2.88148850e-01,  4.62797470e-02],\n",
       "          [ 1.96177904e-02, -3.41418684e-02,  8.18810314e-02, ...,\n",
       "           -5.62494174e-02, -1.00145489e-01, -1.89945698e-01],\n",
       "          [ 2.24005468e-02,  4.14995253e-02, -3.06461025e-02, ...,\n",
       "           -6.61209896e-02, -1.53524354e-01, -1.27819136e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 1.89079985e-01, -1.38262898e-01,  7.22211823e-02, ...,\n",
       "           -3.99713814e-02, -3.55062783e-02, -2.47060716e-01],\n",
       "          [ 2.97823139e-02,  6.94772303e-02, -2.61725396e-01, ...,\n",
       "            7.81468228e-02, -1.56291910e-02,  1.49274385e-02],\n",
       "          [ 2.40321364e-02, -2.95824632e-02, -4.85157641e-03, ...,\n",
       "           -1.53215528e-01,  8.81296322e-02,  1.32935829e-02],\n",
       "          ...,\n",
       "          [ 1.46232937e-02, -2.25476265e-01, -5.08688092e-02, ...,\n",
       "           -2.04729125e-01, -1.44287750e-01,  7.34296022e-03],\n",
       "          [ 3.99751179e-02,  1.44093290e-01,  1.74046129e-01, ...,\n",
       "           -7.50395954e-02, -6.95693716e-02, -4.43275608e-02],\n",
       "          [-1.58796236e-01, -4.30204533e-03,  8.95456299e-02, ...,\n",
       "           -1.38991863e-01, -1.10159606e-01,  3.58331949e-02]],\n",
       " \n",
       "         [[ 3.26981753e-01,  3.62940622e-03, -2.48212770e-01, ...,\n",
       "            9.30908471e-02, -1.53040275e-01, -4.65275496e-02],\n",
       "          [ 1.51580468e-01, -3.13764103e-02, -2.16624457e-02, ...,\n",
       "           -9.87337083e-02, -1.67228207e-01,  8.58127885e-03],\n",
       "          [-2.06158474e-01,  1.51303068e-01,  3.70809548e-02, ...,\n",
       "           -2.13265091e-01,  5.72586879e-02, -3.95650342e-02],\n",
       "          ...,\n",
       "          [ 9.51577649e-02, -1.62147790e-01, -1.74296111e-01, ...,\n",
       "           -1.98494382e-02,  4.38753888e-03, -8.44163299e-02],\n",
       "          [-1.48893356e-01, -1.05655836e-02,  1.22822896e-01, ...,\n",
       "            3.95617783e-02,  1.10503733e-01,  7.13735819e-02],\n",
       "          [-2.04343513e-01,  3.31525281e-02,  8.39786232e-02, ...,\n",
       "            1.83600619e-01, -1.21237367e-01, -1.41062558e-01]],\n",
       " \n",
       "         [[-1.16994806e-01, -2.32927110e-02,  2.31826067e-01, ...,\n",
       "           -6.11380674e-03, -3.30755450e-02,  2.77794987e-01],\n",
       "          [ 1.02259805e-02,  1.65272847e-01, -1.42682930e-02, ...,\n",
       "            6.98774755e-02, -3.49702358e-01,  3.05648386e-01],\n",
       "          [ 6.08957037e-02, -7.71624297e-02, -2.98573226e-02, ...,\n",
       "           -1.83180884e-01,  1.56311505e-02,  3.74988168e-02],\n",
       "          ...,\n",
       "          [ 1.88606188e-01, -4.86849733e-02,  2.33027879e-02, ...,\n",
       "           -1.16616778e-01, -6.86828196e-02, -1.30065888e-01],\n",
       "          [-9.68715474e-02,  2.27345247e-02, -1.52299121e-01, ...,\n",
       "           -2.08036810e-01,  9.69791412e-02, -2.32388765e-01],\n",
       "          [ 1.20990351e-01,  1.46504089e-01, -1.96943507e-01, ...,\n",
       "           -1.81741819e-01, -1.58202961e-01,  1.17698379e-01]]],\n",
       " \n",
       " \n",
       "        [[[-4.02306803e-02, -2.77041197e-01,  1.53627306e-01, ...,\n",
       "            1.73698589e-01, -8.00583810e-02, -8.59974697e-02],\n",
       "          [-8.07382166e-02, -7.19581544e-03,  7.56744519e-02, ...,\n",
       "            1.60167404e-02,  1.59497604e-01, -1.34889722e-01],\n",
       "          [ 1.54305801e-01,  1.70483932e-01, -6.40694872e-02, ...,\n",
       "           -2.67946303e-01,  1.79629937e-01, -5.50595112e-02],\n",
       "          ...,\n",
       "          [-1.64362341e-01, -7.86987413e-03, -1.75335810e-01, ...,\n",
       "            8.06891620e-02,  1.19750798e-01, -2.07873046e-01],\n",
       "          [ 2.82198727e-01, -1.67373195e-01,  9.04026926e-02, ...,\n",
       "           -1.56494647e-01,  1.73466712e-01,  1.43592373e-01],\n",
       "          [-8.75240117e-02, -1.34543449e-01,  4.61221524e-02, ...,\n",
       "           -7.52339438e-02, -4.53651696e-02,  1.15004145e-01]],\n",
       " \n",
       "         [[ 1.20903522e-01, -4.16071974e-02, -8.25846344e-02, ...,\n",
       "            9.64023471e-02, -5.14393076e-02, -4.00208235e-02],\n",
       "          [ 1.51979417e-01, -1.03660785e-01, -1.12372048e-01, ...,\n",
       "            3.01114529e-01,  3.09340298e-01, -1.55084893e-01],\n",
       "          [ 1.18031211e-01,  8.90323520e-03,  7.53825605e-02, ...,\n",
       "           -1.42632738e-01, -2.24776063e-02, -3.84441428e-02],\n",
       "          ...,\n",
       "          [-1.37886375e-01, -4.25344380e-03, -1.01411454e-01, ...,\n",
       "           -4.51707281e-02,  9.59538519e-02, -2.89902896e-01],\n",
       "          [-8.82804692e-02,  9.03314725e-02, -7.78852403e-02, ...,\n",
       "           -5.94694428e-02,  1.19339652e-01,  2.78717607e-01],\n",
       "          [ 1.09045960e-01,  3.63049023e-02, -1.49706244e-01, ...,\n",
       "           -1.53799672e-02,  7.50674680e-02,  1.76056251e-02]],\n",
       " \n",
       "         [[ 1.38787076e-01, -1.84466675e-01, -1.12163974e-02, ...,\n",
       "            1.64088592e-01,  1.07613727e-01,  1.30949229e-01],\n",
       "          [ 4.04791474e-01,  3.98205742e-02, -2.90844683e-02, ...,\n",
       "            7.66514987e-02,  1.11490004e-01,  2.80587226e-01],\n",
       "          [-7.16473162e-02, -6.26134425e-02, -1.14033371e-01, ...,\n",
       "            1.71706364e-01,  2.08534315e-01, -1.12927435e-02],\n",
       "          ...,\n",
       "          [ 1.38790896e-02,  1.88167706e-01,  2.89756898e-02, ...,\n",
       "           -8.41761231e-02, -1.01601507e-03, -7.36943036e-02],\n",
       "          [-1.43166274e-01,  2.49132644e-02,  1.53249547e-01, ...,\n",
       "           -1.09648474e-01, -5.37474044e-02, -8.62431750e-02],\n",
       "          [-3.66781652e-02, -1.07306264e-01, -1.26065210e-01, ...,\n",
       "           -5.48288412e-02,  5.97280413e-02,  4.65030596e-02]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.03665204, -0.01650185, -0.03276017,  0.00350491, -0.06839617,\n",
       "        -0.05294834, -0.05656371,  0.05498796, -0.01107319, -0.00016313,\n",
       "        -0.03260319,  0.01564167, -0.00549637,  0.0039014 , -0.00355463,\n",
       "         0.00502246], dtype=float32),\n",
       " array([[[[ 8.80729258e-02,  6.91704899e-02,  1.79006997e-02, ...,\n",
       "            2.53224105e-01, -5.23019247e-02,  1.18011415e-01],\n",
       "          [-4.35922965e-02,  1.10276803e-01,  1.64179709e-02, ...,\n",
       "            6.70297816e-02, -1.32331699e-01,  2.04984754e-01],\n",
       "          [ 8.04258510e-02,  1.38734713e-01,  2.80222371e-02, ...,\n",
       "            2.40424827e-01, -2.89589316e-02,  2.13806733e-01],\n",
       "          ...,\n",
       "          [-2.83896364e-02, -3.72393690e-02,  8.75335261e-02, ...,\n",
       "           -7.24796578e-02, -1.09994970e-01, -1.87806338e-02],\n",
       "          [ 1.03621952e-01,  3.13806236e-02,  8.79491046e-02, ...,\n",
       "           -1.28054276e-01, -2.17541549e-02, -6.32358640e-02],\n",
       "          [ 1.09531276e-01, -1.11619793e-02,  1.37711406e-01, ...,\n",
       "            1.67598695e-01,  1.88304242e-02, -5.01873754e-02]],\n",
       " \n",
       "         [[-9.42940935e-02, -1.56174421e-01, -6.48440793e-02, ...,\n",
       "            2.47216731e-01, -6.57504648e-02,  1.64380640e-01],\n",
       "          [ 8.64909887e-02, -2.77118832e-02,  1.72059938e-01, ...,\n",
       "           -7.52210990e-02, -8.12783092e-02, -4.69936468e-02],\n",
       "          [ 1.15799299e-02, -9.45637971e-02,  2.70206798e-02, ...,\n",
       "            1.86586436e-02,  9.33515653e-02,  1.77068666e-01],\n",
       "          ...,\n",
       "          [ 4.62790541e-02, -2.83919454e-01,  1.32867536e-02, ...,\n",
       "            1.34346470e-01, -9.70245600e-02,  1.91707224e-01],\n",
       "          [ 3.52099389e-02,  1.24150161e-02, -9.04187039e-02, ...,\n",
       "            2.22411081e-02,  1.45785166e-02, -2.02252924e-01],\n",
       "          [ 1.52630312e-02, -1.37789473e-02,  1.10567532e-01, ...,\n",
       "            7.56963901e-03,  1.01023046e-02,  8.82680565e-02]],\n",
       " \n",
       "         [[-2.04224035e-01,  5.09326831e-02, -1.11839166e-02, ...,\n",
       "            1.07214294e-01,  8.29077139e-02, -6.83640167e-02],\n",
       "          [ 5.10324612e-02,  1.92563057e-01,  9.55090001e-02, ...,\n",
       "           -6.29524216e-02,  2.05480177e-02,  3.02997474e-02],\n",
       "          [ 1.97698995e-02, -3.48376185e-02, -5.50672784e-02, ...,\n",
       "           -1.33048445e-01,  1.42596336e-02, -7.37686306e-02],\n",
       "          ...,\n",
       "          [-2.61673871e-02,  1.93990245e-01,  1.68255702e-01, ...,\n",
       "            1.72291353e-01, -1.66540651e-03, -2.25907564e-02],\n",
       "          [-8.32914412e-02,  8.07226915e-03,  8.61665606e-02, ...,\n",
       "            4.42936793e-02, -1.35960057e-01, -8.97453651e-02],\n",
       "          [ 1.03749506e-01, -4.79733162e-02,  5.65136299e-02, ...,\n",
       "           -5.89474700e-02, -1.69212788e-01, -9.04133469e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.14694768e-01, -9.61919576e-02, -2.41672359e-02, ...,\n",
       "           -1.56946689e-01, -8.03963616e-02, -4.56321724e-02],\n",
       "          [ 6.82289386e-03,  1.67049635e-02, -6.72080368e-02, ...,\n",
       "           -3.40450485e-03, -1.35141551e-01, -8.33665282e-02],\n",
       "          [ 5.25813773e-02, -1.16211362e-02,  4.59877886e-02, ...,\n",
       "            1.88925847e-01, -7.34090805e-02,  1.06956670e-02],\n",
       "          ...,\n",
       "          [-2.29296818e-01,  2.10899878e-02, -9.44188386e-02, ...,\n",
       "           -9.66594592e-02, -2.73038242e-02,  2.11687628e-02],\n",
       "          [-3.93634886e-02,  7.50293657e-02,  5.03320768e-02, ...,\n",
       "            1.62452180e-02, -3.45222466e-02,  7.04753026e-02],\n",
       "          [ 2.57885396e-01, -2.06458107e-01,  6.23575449e-02, ...,\n",
       "            1.11102223e-01,  7.87333921e-02,  1.40553759e-02]],\n",
       " \n",
       "         [[ 1.50737375e-01, -2.24321738e-01, -8.98155421e-02, ...,\n",
       "            1.37781044e-02, -7.38961101e-02,  3.99008095e-02],\n",
       "          [ 1.99527582e-04,  1.14796653e-01,  1.05756290e-01, ...,\n",
       "            5.92114739e-02, -6.59033060e-02,  4.16472405e-02],\n",
       "          [ 1.57434940e-01,  1.11790903e-01, -1.24705411e-01, ...,\n",
       "            1.71684413e-04,  7.72841349e-02,  1.51669666e-01],\n",
       "          ...,\n",
       "          [-1.91988260e-01, -2.27455541e-01, -4.44848984e-02, ...,\n",
       "           -7.27456808e-02,  1.02865972e-01,  1.93448722e-01],\n",
       "          [ 1.05917752e-02,  7.66177252e-02, -6.00660779e-02, ...,\n",
       "            4.78286780e-02, -9.51367989e-02, -7.88431540e-02],\n",
       "          [ 7.32918009e-02, -1.37372330e-01, -8.66666716e-03, ...,\n",
       "           -8.31506401e-02, -1.07522331e-01,  2.09729061e-01]],\n",
       " \n",
       "         [[-1.63470984e-01, -3.95444147e-02,  7.14684129e-02, ...,\n",
       "            2.01797664e-01, -1.13970302e-01,  5.36879487e-02],\n",
       "          [ 1.09128103e-01,  4.21745479e-02, -8.81243497e-02, ...,\n",
       "            6.88272566e-02,  9.03178081e-02, -1.82178721e-01],\n",
       "          [-3.65901850e-02,  1.60612792e-01, -5.96494190e-02, ...,\n",
       "           -1.14659913e-01, -1.00550748e-01,  1.55766860e-01],\n",
       "          ...,\n",
       "          [ 1.61529183e-02, -5.18444888e-02,  1.05371855e-01, ...,\n",
       "            3.01720370e-02,  7.38427863e-02, -5.46344630e-02],\n",
       "          [ 3.24497521e-02,  8.19496531e-03, -1.79977715e-01, ...,\n",
       "           -6.11574799e-02,  1.19388290e-02, -2.22807482e-01],\n",
       "          [ 1.10956468e-01,  5.65275326e-02,  8.78927484e-02, ...,\n",
       "           -4.30389047e-02, -1.78411265e-03, -5.45122810e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.42470658e-01, -8.26923475e-02, -1.43517032e-01, ...,\n",
       "            1.04918098e-03, -1.02142878e-01,  3.11786979e-02],\n",
       "          [ 3.44385840e-02, -6.58522546e-02, -3.71599756e-02, ...,\n",
       "            5.32118827e-02,  2.76685730e-02, -8.95325691e-02],\n",
       "          [ 1.17606901e-01,  1.19070448e-01, -1.26663327e-01, ...,\n",
       "            8.20071995e-02, -4.49615605e-02,  4.15941961e-02],\n",
       "          ...,\n",
       "          [-1.50136977e-01,  1.13700949e-01,  6.38411939e-02, ...,\n",
       "            2.06812501e-01,  7.61156827e-02,  2.16070622e-01],\n",
       "          [ 9.12752226e-02,  9.98813435e-02, -1.20496824e-01, ...,\n",
       "           -5.77885285e-02, -3.63204405e-02,  3.03374939e-02],\n",
       "          [-7.20914528e-02,  9.35748592e-02, -1.78747267e-01, ...,\n",
       "            2.90975273e-02,  3.89528321e-03,  1.08856251e-02]],\n",
       " \n",
       "         [[ 1.58911943e-01, -1.94626406e-01, -1.26916915e-01, ...,\n",
       "           -3.38958859e-01, -2.52379477e-02,  8.72443467e-02],\n",
       "          [ 1.10197641e-01,  1.41739130e-01, -1.73953801e-01, ...,\n",
       "            5.03718248e-03,  4.56337519e-02, -1.20243192e-01],\n",
       "          [ 1.14577927e-01, -6.62870239e-03, -2.06026599e-01, ...,\n",
       "            1.09012388e-01, -2.15100735e-01,  8.65744334e-03],\n",
       "          ...,\n",
       "          [-1.09672002e-01, -3.87323089e-02, -1.43189698e-01, ...,\n",
       "           -1.11334413e-01,  2.14176580e-01,  1.98536739e-01],\n",
       "          [ 6.16259761e-02,  1.01091556e-01, -2.18556270e-01, ...,\n",
       "            1.41582653e-01, -1.01461232e-01, -6.75398707e-02],\n",
       "          [ 9.99473333e-02, -2.71994695e-02, -2.13994935e-01, ...,\n",
       "           -4.57917377e-02,  7.46775791e-02, -4.05087173e-02]],\n",
       " \n",
       "         [[ 2.04373873e-03, -5.62337376e-02, -8.47510546e-02, ...,\n",
       "            1.28246099e-02, -2.50646137e-02, -1.40004665e-01],\n",
       "          [ 1.79517642e-01,  8.58059525e-02, -3.59155506e-01, ...,\n",
       "           -5.14287539e-02,  1.47699388e-02,  2.23910585e-02],\n",
       "          [ 2.20186040e-02,  9.22620818e-02, -1.55546352e-01, ...,\n",
       "           -8.16372856e-02,  6.12687320e-02,  2.63206542e-01],\n",
       "          ...,\n",
       "          [ 1.27789691e-01, -6.70180544e-02, -3.59542519e-02, ...,\n",
       "           -8.47531855e-03,  1.84450299e-01,  5.63236028e-02],\n",
       "          [-1.29577309e-01,  1.64748967e-01, -1.94594666e-01, ...,\n",
       "            1.35015592e-01,  1.25587896e-01, -1.08623683e-01],\n",
       "          [ 1.48084819e-01,  1.47463800e-02, -1.50614902e-01, ...,\n",
       "            1.81959867e-02, -2.70470437e-02,  7.61191547e-02]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.05270449,  0.01395325, -0.02614759, -0.0438072 , -0.02251173,\n",
       "         0.02816219,  0.0492787 , -0.02180896, -0.07235964,  0.12015276,\n",
       "         0.02062634,  0.05199396, -0.02929045,  0.01742029,  0.02077341,\n",
       "         0.13627605, -0.04350011, -0.05289906,  0.03851723, -0.04858331,\n",
       "         0.03237765,  0.02886071,  0.06891674,  0.02196848, -0.02640361,\n",
       "         0.060614  , -0.01092822, -0.06552494, -0.02069115,  0.11135875,\n",
       "        -0.132773  ,  0.0057355 ], dtype=float32),\n",
       " array([[[[ 4.64379322e-03, -1.45269139e-02, -4.84507680e-02, ...,\n",
       "            1.62961334e-01, -7.44700283e-02,  1.78417519e-01],\n",
       "          [-7.37560093e-02,  2.40202755e-01, -6.72533512e-02, ...,\n",
       "            9.69463121e-03, -4.32181405e-03,  1.20064072e-01],\n",
       "          [-2.68297084e-02,  7.53340945e-02,  3.19797993e-01, ...,\n",
       "            6.69235662e-02,  8.78632069e-02, -1.49975687e-01],\n",
       "          ...,\n",
       "          [-1.95616018e-02, -4.10775393e-02,  8.92943442e-02, ...,\n",
       "           -3.01985685e-02, -1.01629905e-01, -5.87325264e-03],\n",
       "          [-8.73864070e-02,  4.97032553e-02, -3.87545973e-02, ...,\n",
       "            5.71087003e-03,  2.99372766e-02, -5.64656705e-02],\n",
       "          [-1.08023256e-01,  4.44062352e-02,  2.70296205e-02, ...,\n",
       "           -9.54286568e-03,  2.65732268e-03,  7.89151192e-02]],\n",
       " \n",
       "         [[-8.68887454e-03,  4.77143526e-02, -1.09260976e-02, ...,\n",
       "           -5.09236529e-02, -7.21687600e-02,  1.16386600e-02],\n",
       "          [-2.76444815e-02,  6.74364194e-02,  7.48044476e-02, ...,\n",
       "           -6.59494698e-02, -1.08436674e-01,  2.09535584e-02],\n",
       "          [-1.13169074e-01,  5.45522571e-02,  3.54724526e-01, ...,\n",
       "            2.65830904e-01,  1.35121226e-01, -1.89655989e-01],\n",
       "          ...,\n",
       "          [ 4.38104160e-02, -4.88885455e-02,  5.84785342e-02, ...,\n",
       "            8.56858119e-03,  2.35893615e-02, -1.21577732e-01],\n",
       "          [-1.74198002e-02,  7.86439180e-02, -1.03719383e-01, ...,\n",
       "            2.26053879e-01,  1.28546298e-01, -1.58751324e-01],\n",
       "          [-9.66782868e-02,  8.40935260e-02,  5.96268699e-02, ...,\n",
       "            5.47615588e-02,  7.67558888e-02,  1.39885351e-01]],\n",
       " \n",
       "         [[ 1.00526847e-02, -7.96790570e-02, -1.33060127e-01, ...,\n",
       "           -1.52697518e-01, -1.60175879e-02,  1.51049569e-01],\n",
       "          [-8.83804485e-02,  3.00406944e-02, -7.21299946e-02, ...,\n",
       "           -3.08421534e-02, -7.04520568e-02, -2.43440848e-02],\n",
       "          [-9.37391669e-02,  9.28055868e-02,  9.63269919e-02, ...,\n",
       "            2.04458684e-01,  1.82275474e-02, -8.72628391e-03],\n",
       "          ...,\n",
       "          [ 8.72628689e-02, -1.02523878e-01,  9.73355398e-02, ...,\n",
       "           -8.67058933e-02,  7.36018196e-02, -1.37762027e-02],\n",
       "          [ 6.13179281e-02,  1.65899210e-02, -1.53007060e-01, ...,\n",
       "           -3.46158408e-02,  4.23137285e-02, -1.90994982e-02],\n",
       "          [ 1.40187293e-02, -1.08063146e-01, -1.29391596e-01, ...,\n",
       "           -1.63744271e-01,  1.86932161e-01,  6.85166642e-02]]],\n",
       " \n",
       " \n",
       "        [[[-3.23621184e-02,  1.93647861e-01, -1.49379551e-01, ...,\n",
       "            7.86853675e-03,  5.25130928e-02,  4.76300791e-02],\n",
       "          [ 9.32978019e-02, -2.04162486e-02,  1.59345329e-01, ...,\n",
       "           -1.57479510e-01, -1.00825496e-01,  9.69137698e-02],\n",
       "          [-7.30775669e-02, -1.39120877e-01, -2.30975598e-01, ...,\n",
       "            2.33770251e-01,  1.83124006e-01,  7.61563554e-02],\n",
       "          ...,\n",
       "          [ 5.12192212e-02,  1.79247350e-01, -2.93069240e-03, ...,\n",
       "           -2.28935331e-01,  6.30504042e-02, -3.81062776e-02],\n",
       "          [ 4.56713624e-02,  1.56975444e-03,  5.53036928e-02, ...,\n",
       "           -3.17240916e-02,  4.57149744e-02, -4.85520400e-02],\n",
       "          [-2.41173934e-02,  1.56920761e-01, -1.21411353e-01, ...,\n",
       "           -9.32113752e-02, -6.07272983e-03, -4.60091792e-03]],\n",
       " \n",
       "         [[-9.99224260e-02,  5.45006096e-02, -9.21133012e-02, ...,\n",
       "            1.71993356e-02, -2.17060521e-02,  4.16226387e-02],\n",
       "          [-8.50054771e-02,  1.34404421e-01,  1.24561675e-01, ...,\n",
       "            1.92634598e-03, -9.92434099e-03,  9.17705595e-02],\n",
       "          [ 1.80507619e-02, -3.12535107e-01, -2.03100204e-01, ...,\n",
       "            1.75051168e-01,  1.05700910e-01,  1.43954322e-01],\n",
       "          ...,\n",
       "          [ 5.44689968e-02,  1.94694072e-01,  7.92837217e-02, ...,\n",
       "           -6.23790286e-02,  1.44067511e-01, -5.77038489e-02],\n",
       "          [-7.46005997e-02, -1.97548866e-01,  9.05777514e-02, ...,\n",
       "           -7.58402376e-03,  4.65772226e-02, -3.12358420e-02],\n",
       "          [ 1.91263296e-02,  1.61745429e-01,  1.54018058e-02, ...,\n",
       "           -1.50081702e-02,  1.17122091e-01, -1.43598065e-01]],\n",
       " \n",
       "         [[ 8.42251629e-03, -6.78694993e-02, -6.82576746e-02, ...,\n",
       "           -2.52577066e-01, -3.65878135e-01,  8.51876736e-02],\n",
       "          [ 8.04926753e-02,  1.13890938e-01,  4.69477905e-04, ...,\n",
       "           -1.59243103e-02, -5.87508194e-02,  2.07976648e-03],\n",
       "          [-8.76770820e-03, -2.28006646e-01, -1.52099594e-01, ...,\n",
       "           -5.67340069e-02,  8.03594813e-02,  1.01179026e-01],\n",
       "          ...,\n",
       "          [-5.16568609e-02,  1.08383149e-01,  6.02502711e-02, ...,\n",
       "           -1.95795558e-02,  1.10286601e-01,  3.78263555e-02],\n",
       "          [-1.13216780e-01,  4.62190509e-02, -4.77797203e-02, ...,\n",
       "           -2.66311109e-01,  1.58724859e-02, -6.11043070e-03],\n",
       "          [-2.99961884e-02, -4.90196273e-02, -1.41015882e-02, ...,\n",
       "           -1.05044723e-01,  1.31868720e-01, -3.60448961e-03]]],\n",
       " \n",
       " \n",
       "        [[[-8.56627375e-02,  1.19717717e-01, -2.41109207e-02, ...,\n",
       "            2.08951935e-01, -7.46202767e-02,  6.46004975e-02],\n",
       "          [-4.95939367e-02,  1.09996935e-02, -6.40212744e-03, ...,\n",
       "            1.18166186e-01, -9.48073342e-02, -6.37510121e-02],\n",
       "          [-3.18035185e-02, -3.98015827e-02,  2.94308877e-03, ...,\n",
       "            2.84511268e-01, -1.36580780e-01, -1.01867057e-01],\n",
       "          ...,\n",
       "          [-5.74814826e-02, -1.06346849e-02,  4.98751849e-02, ...,\n",
       "           -1.41160190e-01, -1.42133072e-01,  2.08079834e-02],\n",
       "          [-3.08286231e-02, -1.90179750e-01,  7.32389046e-03, ...,\n",
       "            4.76551875e-02, -4.30757701e-02, -1.29647657e-01],\n",
       "          [-3.27946246e-02, -1.76149548e-03, -8.92831087e-02, ...,\n",
       "           -2.01704293e-01, -1.61241114e-01, -5.08408658e-02]],\n",
       " \n",
       "         [[-9.02605802e-02,  4.99182269e-02, -2.10307743e-02, ...,\n",
       "            2.46490091e-02, -5.29683661e-04,  8.94864425e-02],\n",
       "          [ 9.45859328e-02, -9.25145894e-02,  1.28287047e-01, ...,\n",
       "           -6.91946875e-03, -1.76904604e-01, -9.64344516e-02],\n",
       "          [-3.87359061e-03, -7.09912926e-02, -1.21307380e-01, ...,\n",
       "            9.31505561e-02, -6.16257377e-02,  4.74457676e-03],\n",
       "          ...,\n",
       "          [ 7.91055802e-03,  3.44327129e-02,  4.91381921e-02, ...,\n",
       "           -1.87583249e-02, -1.56002149e-01,  1.14127453e-02],\n",
       "          [-5.32368831e-02, -1.33159161e-01,  1.68336958e-01, ...,\n",
       "           -6.34807274e-02,  2.56546289e-02, -1.52117312e-01],\n",
       "          [-1.00408554e-01,  1.22072130e-01, -2.28105914e-02, ...,\n",
       "            1.00209760e-02, -9.60677713e-02, -1.34388417e-01]],\n",
       " \n",
       "         [[-9.65886563e-02, -6.90659732e-02,  1.59052461e-02, ...,\n",
       "           -1.90828919e-01, -2.66075283e-01, -1.24039397e-01],\n",
       "          [ 3.60579267e-02, -2.23241478e-01,  2.93289088e-02, ...,\n",
       "           -8.58565792e-03, -1.85171068e-01,  6.38070777e-02],\n",
       "          [-4.57979515e-02, -7.26696029e-02, -1.11039188e-02, ...,\n",
       "            4.76859435e-02, -1.39062498e-02, -8.27326626e-02],\n",
       "          ...,\n",
       "          [ 2.60455646e-02,  1.51382275e-02, -3.05068959e-03, ...,\n",
       "           -1.16661213e-01, -1.26574680e-01,  3.68956588e-02],\n",
       "          [-2.60296190e-04,  1.03239842e-01,  7.40754083e-02, ...,\n",
       "           -2.43594959e-01, -1.47546440e-01, -3.08583528e-02],\n",
       "          [-8.11261535e-02, -3.16054046e-01,  3.40960361e-02, ...,\n",
       "            1.61755949e-01,  2.69243047e-02, -1.61380231e-01]]]],\n",
       "       dtype=float32),\n",
       " array([-0.0413467 , -0.02213421, -0.03878728,  0.00331781, -0.01431121,\n",
       "         0.01545241, -0.00885268, -0.02440742, -0.09289605,  0.00080742,\n",
       "        -0.04746261, -0.02913542,  0.05924162, -0.01816259,  0.0414461 ,\n",
       "         0.02897776,  0.01780345, -0.02071539, -0.04745152,  0.01752318,\n",
       "         0.05352394, -0.02129876, -0.06047646, -0.06541996, -0.05828405,\n",
       "         0.05290334,  0.03597396,  0.01732876, -0.05689371, -0.01476592,\n",
       "         0.03187192,  0.04156673], dtype=float32),\n",
       " array([[[[-1.55260442e-02,  4.29699831e-02,  1.60119832e-02, ...,\n",
       "           -1.48435133e-02, -1.09191887e-01,  4.85719647e-03],\n",
       "          [-1.01692349e-01, -5.72299846e-02, -7.91607723e-02, ...,\n",
       "           -5.06544784e-02, -1.97198734e-01, -1.39995553e-02],\n",
       "          [ 9.86888632e-02,  1.10996567e-01, -2.11128704e-02, ...,\n",
       "           -1.49854422e-01, -2.10609268e-02,  1.15452714e-01],\n",
       "          ...,\n",
       "          [-1.65352270e-01,  9.60034654e-02, -6.86216950e-02, ...,\n",
       "           -1.44718915e-01,  1.46373510e-02,  2.39560142e-01],\n",
       "          [-5.41234799e-02,  2.79278141e-02, -1.44884676e-01, ...,\n",
       "            7.82184526e-02,  8.65025595e-02, -6.80617318e-02],\n",
       "          [-1.02015577e-01, -3.78246456e-02,  2.41439510e-02, ...,\n",
       "            5.84357418e-02,  3.77654545e-02, -2.24118307e-02]],\n",
       " \n",
       "         [[ 8.43438432e-02,  7.07714334e-02, -4.38430458e-02, ...,\n",
       "           -5.71902953e-02, -2.68483777e-02, -6.35265857e-02],\n",
       "          [-8.12796876e-02, -1.29017293e-01, -8.45280886e-02, ...,\n",
       "           -3.62162814e-02, -2.75004119e-01, -1.39139146e-01],\n",
       "          [ 2.25514988e-03,  1.30183667e-01,  6.66930303e-02, ...,\n",
       "            1.13263465e-01,  3.05199046e-02,  1.31630957e-01],\n",
       "          ...,\n",
       "          [ 7.33143762e-02, -1.93347573e-01, -2.16192883e-02, ...,\n",
       "           -1.24039590e-01,  1.28351599e-01, -6.35525733e-02],\n",
       "          [ 1.95118040e-02,  1.36334762e-01, -1.06537536e-01, ...,\n",
       "           -2.53194571e-02,  2.72438467e-01, -1.19508967e-01],\n",
       "          [ 1.40881576e-02, -1.12817220e-01, -3.92206758e-02, ...,\n",
       "           -6.17990689e-03, -6.51182383e-02,  4.38196771e-02]],\n",
       " \n",
       "         [[-2.95595154e-02, -4.38136570e-02,  1.54927475e-02, ...,\n",
       "            5.55580221e-02,  4.53650020e-03,  5.08745536e-02],\n",
       "          [ 8.16383287e-02,  4.54428196e-02, -1.00705072e-01, ...,\n",
       "            3.63973491e-02, -3.72342654e-02,  4.73027937e-02],\n",
       "          [ 2.56452784e-02,  1.06612124e-01,  8.81550312e-02, ...,\n",
       "           -1.16155677e-01,  4.23446484e-02,  2.06574038e-01],\n",
       "          ...,\n",
       "          [ 1.99568905e-02, -9.08425748e-02,  2.93703359e-02, ...,\n",
       "           -4.20398712e-02,  6.79147318e-02,  2.61403490e-02],\n",
       "          [-1.85841873e-01,  1.71614140e-02,  1.33328664e-04, ...,\n",
       "           -1.26947705e-02,  2.16211025e-02, -2.46584550e-01],\n",
       "          [-4.01330777e-02, -3.35319079e-02,  1.56518102e-01, ...,\n",
       "           -4.65510823e-02,  3.07045970e-02, -4.65934910e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.58174352e-02,  3.40796709e-02,  1.54100731e-02, ...,\n",
       "            5.36640063e-02,  1.03625832e-02,  7.81157892e-03],\n",
       "          [-2.61465371e-01, -2.35579684e-01, -4.24411707e-02, ...,\n",
       "            2.60087810e-02,  7.70369321e-02,  4.13933769e-02],\n",
       "          [ 8.36879462e-02,  1.99617192e-01,  1.56477705e-01, ...,\n",
       "           -2.33240314e-02, -1.69961154e-01, -1.24596231e-01],\n",
       "          ...,\n",
       "          [ 2.46787053e-02,  1.27480045e-01, -6.50150627e-02, ...,\n",
       "           -1.94203109e-01,  1.05244562e-01,  1.25388071e-01],\n",
       "          [ 8.23443756e-02,  2.95538306e-02, -5.10801189e-02, ...,\n",
       "           -1.04908057e-01, -4.22791056e-02,  6.38689771e-02],\n",
       "          [-6.39429390e-02,  2.92486753e-02, -1.48975343e-01, ...,\n",
       "           -3.10960803e-02, -1.55389346e-02, -5.32930270e-02]],\n",
       " \n",
       "         [[ 2.98501272e-02,  3.46587263e-02, -2.87777781e-02, ...,\n",
       "            7.78037757e-02, -2.94829477e-02,  1.89284254e-02],\n",
       "          [-8.56255740e-02, -2.81484067e-01,  1.11602239e-01, ...,\n",
       "           -6.13619126e-02,  1.43669769e-01,  6.67924061e-02],\n",
       "          [ 2.19868068e-02,  6.76741078e-02,  6.54903576e-02, ...,\n",
       "           -2.19170049e-01,  5.35421707e-02,  7.26847276e-02],\n",
       "          ...,\n",
       "          [ 1.38896450e-01, -2.94335913e-02, -8.79875198e-02, ...,\n",
       "            5.82666919e-02,  7.57076368e-02, -1.43493101e-01],\n",
       "          [ 4.17224169e-02, -5.33872284e-03, -1.49580324e-02, ...,\n",
       "           -1.21009439e-01, -9.93030444e-02, -6.25629425e-02],\n",
       "          [-7.63503090e-02,  2.74207518e-02, -2.18607555e-03, ...,\n",
       "           -3.77042815e-02,  4.78217527e-02,  7.87722506e-03]],\n",
       " \n",
       "         [[ 1.20367119e-02, -1.89105719e-02, -1.50967482e-03, ...,\n",
       "            8.80312175e-02,  6.24406189e-02,  4.84545678e-02],\n",
       "          [ 1.87899787e-02, -5.26941530e-02,  3.99767086e-02, ...,\n",
       "           -1.76918492e-01, -2.10409109e-02, -8.42533633e-02],\n",
       "          [ 3.76352668e-02,  1.75693914e-01,  1.02324128e-01, ...,\n",
       "           -2.10733376e-02,  8.63311887e-02,  9.67567563e-02],\n",
       "          ...,\n",
       "          [ 2.50629280e-02, -2.93976385e-02, -6.41312078e-02, ...,\n",
       "           -1.80634141e-01,  4.81217392e-02, -1.34608850e-01],\n",
       "          [-1.44351333e-01,  1.33738339e-01,  1.37978554e-01, ...,\n",
       "           -2.91961342e-01, -1.21868722e-01,  2.11303547e-01],\n",
       "          [-2.41972625e-01, -5.38284667e-02,  1.31732360e-01, ...,\n",
       "            7.14666843e-02,  9.31823775e-02, -1.30289420e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 4.91104275e-02,  1.48632079e-02,  8.46529379e-02, ...,\n",
       "           -8.97717699e-02,  6.74520358e-02, -7.20037031e-04],\n",
       "          [ 1.34767890e-01,  5.33240885e-02,  2.62424164e-02, ...,\n",
       "           -7.05319196e-02, -3.28131504e-02, -6.82030097e-02],\n",
       "          [ 3.97861563e-03,  1.87480927e-01, -1.87772721e-01, ...,\n",
       "           -8.82136747e-02, -9.20305178e-02, -1.38884887e-01],\n",
       "          ...,\n",
       "          [ 1.90383643e-02,  1.32553279e-01, -1.91076454e-02, ...,\n",
       "           -9.97537971e-02,  1.53835323e-02,  9.03435573e-02],\n",
       "          [ 4.09041485e-03, -5.12963645e-02, -2.17673302e-01, ...,\n",
       "           -2.34425813e-02,  9.12181213e-02,  1.18830547e-01],\n",
       "          [ 1.19216301e-01,  3.19285728e-02, -1.29479691e-01, ...,\n",
       "            1.95338670e-02, -3.89465019e-02, -1.47845661e-02]],\n",
       " \n",
       "         [[ 2.17889640e-02,  6.76762760e-02, -7.27587119e-02, ...,\n",
       "           -1.72292814e-02, -3.88269424e-02,  4.28501703e-02],\n",
       "          [ 1.96654692e-01, -1.00219831e-01,  5.05155558e-03, ...,\n",
       "           -2.41288096e-02,  1.69370119e-02, -1.92805380e-01],\n",
       "          [ 8.90902877e-02, -3.24614495e-02, -5.00755850e-04, ...,\n",
       "            2.63251327e-02,  5.70382066e-02,  3.34162004e-02],\n",
       "          ...,\n",
       "          [ 3.31057757e-02, -2.46718153e-02, -2.69965619e-01, ...,\n",
       "            9.38228704e-03, -6.00121357e-02, -1.09594926e-01],\n",
       "          [ 5.34251914e-04,  3.30792144e-02, -1.66965112e-01, ...,\n",
       "            3.94431241e-02,  5.98418154e-03, -2.36703530e-02],\n",
       "          [ 8.06164965e-02,  3.83278243e-02, -1.77812263e-01, ...,\n",
       "            1.07119106e-01,  2.19678041e-02,  6.98172450e-02]],\n",
       " \n",
       "         [[ 2.08380744e-02, -5.92145287e-02, -7.73972571e-02, ...,\n",
       "           -2.15836260e-02,  2.55488383e-04,  1.97653612e-03],\n",
       "          [ 8.94577876e-02, -1.24435551e-01,  1.13445051e-01, ...,\n",
       "           -2.54187435e-01, -1.26135185e-01,  9.93003044e-03],\n",
       "          [-3.01501118e-02, -1.53820813e-01, -9.81429741e-02, ...,\n",
       "           -8.42024311e-02, -5.17022498e-02,  3.64217050e-02],\n",
       "          ...,\n",
       "          [-4.08996828e-02,  1.01675279e-02, -1.37654737e-01, ...,\n",
       "           -3.80442180e-02, -4.54430878e-02, -1.45688608e-01],\n",
       "          [ 6.88124523e-02,  7.42973909e-02,  5.23839779e-02, ...,\n",
       "           -1.63105484e-02,  1.60576075e-01,  1.89609434e-02],\n",
       "          [ 8.28203261e-02, -1.53993303e-02,  1.27629578e-01, ...,\n",
       "           -6.11413233e-02,  4.81018052e-02, -3.96746136e-02]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.00644488, -0.0009889 , -0.01926991,  0.04922472,  0.01101981,\n",
       "        -0.08647145,  0.01695867, -0.03984115,  0.01700874, -0.06200489,\n",
       "         0.04640476, -0.02281157,  0.05040006, -0.02048568,  0.05746902,\n",
       "         0.01716051, -0.09430824,  0.05759108,  0.00701321, -0.081028  ,\n",
       "         0.00409516,  0.04275201,  0.03777223,  0.0638419 ,  0.0613466 ,\n",
       "         0.03727576,  0.05711206, -0.02072546,  0.05306051, -0.04563944,\n",
       "         0.00594788,  0.01413954, -0.03463731, -0.04147057, -0.05280029,\n",
       "         0.11506597, -0.01788523, -0.02690724,  0.05896826,  0.07454587,\n",
       "         0.06924745, -0.02799801,  0.0402174 , -0.04252565,  0.10278998,\n",
       "        -0.02171258, -0.03265955, -0.00962048, -0.0289375 ,  0.03448914,\n",
       "         0.07435044,  0.03247574, -0.00278036,  0.02613997,  0.02704436,\n",
       "         0.00623662,  0.02770756, -0.04701415,  0.07123421, -0.04090777,\n",
       "         0.0187374 ,  0.03120983, -0.00839418,  0.1013013 ], dtype=float32),\n",
       " array([[[[ 4.24578004e-02, -1.75770652e-02, -2.90819854e-02, ...,\n",
       "            1.99400373e-02, -5.63298799e-02,  4.65091690e-02],\n",
       "          [ 1.88729256e-01, -6.94331378e-02, -1.58620298e-01, ...,\n",
       "            5.46928681e-02, -1.58007637e-01, -9.17410105e-03],\n",
       "          [-3.61039527e-02, -2.10561845e-02, -1.30729631e-01, ...,\n",
       "           -7.12873712e-02, -1.56044349e-01,  8.65158159e-03],\n",
       "          ...,\n",
       "          [ 1.36892334e-01,  6.61565224e-03,  1.80915609e-01, ...,\n",
       "            8.61502194e-04,  4.79017347e-02, -1.82719022e-01],\n",
       "          [ 1.59171000e-02, -4.98292670e-02,  1.36028498e-01, ...,\n",
       "           -6.75545959e-03, -1.66032314e-01, -4.56679240e-02],\n",
       "          [ 8.08104202e-02, -1.86303805e-04, -1.14193909e-01, ...,\n",
       "           -1.09851025e-01,  1.15293168e-01,  1.36717826e-01]],\n",
       " \n",
       "         [[-5.71764493e-03, -7.28269219e-02, -5.01319207e-02, ...,\n",
       "            4.04930636e-02, -1.74753293e-02,  1.15090637e-02],\n",
       "          [ 1.48684485e-02, -4.88123447e-02,  6.96073025e-02, ...,\n",
       "            8.78620893e-02, -1.56944126e-01, -1.22817464e-01],\n",
       "          [ 3.25117670e-02,  9.77435242e-03,  5.94617203e-02, ...,\n",
       "           -3.23082991e-02, -1.41032070e-01, -9.96516123e-02],\n",
       "          ...,\n",
       "          [ 1.07921720e-01,  1.96037907e-02,  1.92916334e-01, ...,\n",
       "            7.25218430e-02, -6.88662976e-02,  5.52506652e-03],\n",
       "          [-1.25471562e-01, -1.63140073e-02,  1.06339402e-01, ...,\n",
       "            3.40647176e-02,  7.62391165e-02, -3.07666492e-02],\n",
       "          [ 7.44641721e-02, -7.61170611e-02,  5.59923984e-02, ...,\n",
       "           -2.69584488e-02, -3.87564227e-02, -6.75129443e-02]],\n",
       " \n",
       "         [[-5.33289649e-02,  2.20705359e-03,  6.94814464e-03, ...,\n",
       "           -8.28707777e-03,  1.00393988e-01, -7.91420043e-02],\n",
       "          [-4.25940081e-02,  1.03364186e-02,  1.56637896e-02, ...,\n",
       "           -1.67747051e-01, -2.41265465e-02, -8.28794390e-02],\n",
       "          [ 5.48668467e-02,  1.79644451e-02,  9.05189738e-02, ...,\n",
       "            3.41599844e-02, -1.79267630e-01, -1.15916498e-01],\n",
       "          ...,\n",
       "          [ 2.06728414e-01, -7.65093416e-02, -2.56201774e-02, ...,\n",
       "           -2.58253701e-02, -1.94545425e-02,  2.01311603e-01],\n",
       "          [-2.13605016e-02,  2.36527901e-02, -1.20268784e-01, ...,\n",
       "            6.19929321e-02,  1.48018792e-01,  4.15837727e-02],\n",
       "          [ 8.35622400e-02, -2.08124332e-02, -2.45578215e-02, ...,\n",
       "            5.34244929e-04, -2.16673180e-01,  1.76254332e-01]]],\n",
       " \n",
       " \n",
       "        [[[-2.81704701e-02, -5.93524501e-02,  6.91832900e-02, ...,\n",
       "           -1.15532607e-01,  3.89551483e-02,  6.53217360e-02],\n",
       "          [ 1.18493669e-01, -6.39767870e-02, -1.17735609e-01, ...,\n",
       "           -1.06945904e-02, -7.25259557e-02, -4.88508493e-03],\n",
       "          [-4.72042412e-02,  8.44193529e-03, -1.01277620e-01, ...,\n",
       "            3.02905235e-02, -1.47504911e-01, -8.72067362e-02],\n",
       "          ...,\n",
       "          [ 9.61360708e-02, -2.08878648e-02,  8.68890360e-02, ...,\n",
       "            4.29710150e-02, -4.43516299e-02, -1.34230778e-01],\n",
       "          [ 2.17915215e-02,  8.08770210e-03,  1.23898737e-01, ...,\n",
       "           -4.19038273e-02, -8.11931491e-02, -7.92077705e-02],\n",
       "          [-3.15871462e-02,  1.68255679e-02,  8.97265822e-02, ...,\n",
       "           -4.75924201e-02, -1.13151874e-02, -2.11271673e-01]],\n",
       " \n",
       "         [[-9.61157158e-02,  2.07652035e-03, -1.18906572e-02, ...,\n",
       "           -1.48137286e-01, -2.88417153e-02, -1.54403178e-02],\n",
       "          [-1.64383613e-02, -1.00682331e-02, -4.84895296e-02, ...,\n",
       "           -3.09029929e-02, -1.21208742e-01,  2.57574301e-02],\n",
       "          [-1.59537140e-02, -6.56181574e-02,  1.79032087e-02, ...,\n",
       "           -5.09976642e-03,  9.56381932e-02, -1.06115118e-01],\n",
       "          ...,\n",
       "          [-2.96069738e-02,  5.94289340e-02,  1.26474828e-01, ...,\n",
       "           -1.15655005e-01, -9.39308628e-02, -1.73443347e-01],\n",
       "          [-5.64778857e-02, -3.29900198e-02, -3.81661877e-02, ...,\n",
       "           -2.41612196e-02,  3.07460912e-02,  1.30784139e-02],\n",
       "          [ 1.57297313e-01, -4.75221723e-02,  5.28436387e-03, ...,\n",
       "           -4.50239852e-02, -9.17492621e-03, -9.56255049e-02]],\n",
       " \n",
       "         [[-1.29592912e-02, -5.47712222e-02, -1.96599234e-02, ...,\n",
       "           -8.11030865e-02, -6.54871538e-02, -1.98262542e-01],\n",
       "          [-8.86658505e-02, -4.09569591e-02, -7.70300329e-02, ...,\n",
       "           -1.71357710e-02, -2.19572112e-02, -1.71180025e-01],\n",
       "          [ 2.87549384e-02,  1.77047476e-02,  8.50377977e-02, ...,\n",
       "            2.34249886e-03, -1.03126638e-01,  6.81732967e-02],\n",
       "          ...,\n",
       "          [ 7.90483207e-02,  2.23884154e-02, -8.94823149e-02, ...,\n",
       "            5.95031641e-02, -1.38808265e-01,  1.37963563e-01],\n",
       "          [-7.39530474e-02,  1.07094208e-02, -1.48754373e-01, ...,\n",
       "           -1.13167152e-01,  7.89940059e-02, -8.76660123e-02],\n",
       "          [-1.92332715e-01, -1.07432611e-01, -4.06589620e-02, ...,\n",
       "           -7.05562308e-02, -6.26894385e-02,  3.70870158e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 7.08800927e-02,  1.94087848e-02, -1.03260212e-01, ...,\n",
       "            4.17516828e-02, -3.09266825e-03, -1.86366081e-01],\n",
       "          [-3.29714008e-02, -5.33525459e-02, -3.45356278e-02, ...,\n",
       "            5.35259172e-02, -3.02253701e-02, -1.33139014e-01],\n",
       "          [ 3.72600891e-02,  2.50905976e-02,  5.93923815e-02, ...,\n",
       "            3.01604765e-03, -2.84412708e-02,  7.53894746e-02],\n",
       "          ...,\n",
       "          [-5.20710982e-02,  1.83026660e-02,  7.03121051e-02, ...,\n",
       "           -8.11204240e-02, -7.84040391e-02,  5.74284839e-03],\n",
       "          [-9.42620039e-02, -5.75948954e-02,  1.10628381e-01, ...,\n",
       "            5.16734086e-02,  7.35791912e-03, -4.27877046e-02],\n",
       "          [ 5.92914596e-02, -4.15624268e-02, -3.17830667e-02, ...,\n",
       "            6.45765662e-02,  7.40219057e-02, -1.31967321e-01]],\n",
       " \n",
       "         [[ 1.25796258e-01, -4.45860922e-02, -1.09691724e-01, ...,\n",
       "           -8.94974470e-02, -4.78925966e-02,  4.35603596e-02],\n",
       "          [-4.50489819e-02, -4.83673159e-03, -4.84934673e-02, ...,\n",
       "           -3.08078527e-02,  6.27667382e-02, -6.17965683e-02],\n",
       "          [ 1.11282291e-02,  2.35093012e-02, -1.61266685e-01, ...,\n",
       "            2.68352237e-02,  8.56143609e-02, -9.60228145e-02],\n",
       "          ...,\n",
       "          [ 1.46397024e-01, -6.71163574e-02, -3.38651962e-03, ...,\n",
       "           -1.05778528e-02, -1.99623499e-02, -5.98649159e-02],\n",
       "          [-3.66176367e-02, -6.25772923e-02, -5.12801260e-02, ...,\n",
       "            6.71397056e-03, -4.96060550e-02,  1.64318740e-01],\n",
       "          [-1.33912131e-01, -1.30044490e-01,  1.61156550e-01, ...,\n",
       "           -6.04911745e-02, -4.11760285e-02, -1.99544579e-01]],\n",
       " \n",
       "         [[ 8.25285539e-02, -5.05311638e-02, -1.83054745e-01, ...,\n",
       "           -1.10174581e-01, -3.53274643e-02,  1.12451009e-01],\n",
       "          [-6.90533295e-02,  1.58779565e-02, -2.94374973e-02, ...,\n",
       "            7.88041651e-02,  4.36685234e-02, -2.80106775e-02],\n",
       "          [ 2.52607781e-02, -3.17940526e-02, -1.68588728e-01, ...,\n",
       "           -2.33467240e-02, -7.19077364e-02, -5.64123690e-02],\n",
       "          ...,\n",
       "          [ 1.42310336e-01, -3.51484939e-02,  2.14985646e-02, ...,\n",
       "            1.27954520e-02, -1.25590131e-01, -5.15063712e-03],\n",
       "          [-9.00147334e-02,  2.70881355e-02, -3.45693268e-02, ...,\n",
       "           -8.38263780e-02, -5.30232564e-02,  8.02567974e-02],\n",
       "          [ 1.05718393e-02, -4.28539887e-02, -3.76852266e-02, ...,\n",
       "            3.43133807e-02, -1.01722650e-01, -4.84579317e-02]]]],\n",
       "       dtype=float32),\n",
       " array([-0.05508831, -0.02229997, -0.00968769, -0.04550084, -0.08126123,\n",
       "        -0.06106194,  0.04114856, -0.07398009,  0.01655144,  0.01704807,\n",
       "         0.01706564, -0.02488142,  0.02469777, -0.05407058,  0.06100659,\n",
       "        -0.05116475,  0.03189244, -0.05246597,  0.0456571 , -0.034254  ,\n",
       "        -0.03421891,  0.01601542, -0.0542433 , -0.07828677, -0.06263974,\n",
       "        -0.06685408,  0.00972797,  0.01769793, -0.03878922, -0.00928182,\n",
       "         0.08949172,  0.06537419, -0.00275765, -0.04346859, -0.03405137,\n",
       "        -0.029438  , -0.00160752,  0.07819726, -0.02971126,  0.05516427,\n",
       "        -0.00649754,  0.00546295,  0.00720266,  0.02218678, -0.03890484,\n",
       "        -0.04867972, -0.01160888,  0.02855054, -0.01984016,  0.04463401,\n",
       "        -0.04189594, -0.0640877 ,  0.00249633, -0.02166294,  0.03098443,\n",
       "         0.00145819, -0.04559668,  0.11386611, -0.05620257, -0.03088859,\n",
       "        -0.01919293, -0.05160645,  0.01690348,  0.01923154], dtype=float32),\n",
       " array([[[[-0.1422553 ,  0.0424499 , -0.07919364, ..., -0.21113713,\n",
       "            0.06674153,  0.13860978],\n",
       "          [-0.00503725,  0.00543488,  0.03989067, ...,  0.06014969,\n",
       "            0.00288037, -0.03462701],\n",
       "          [ 0.06315015, -0.01280621, -0.06093239, ...,  0.04726558,\n",
       "           -0.03742386, -0.09197612],\n",
       "          ...,\n",
       "          [ 0.01135268, -0.06274094,  0.06931488, ...,  0.08945943,\n",
       "            0.06484699, -0.05187508],\n",
       "          [ 0.06495129,  0.02441073, -0.08091202, ..., -0.05865206,\n",
       "           -0.05687386, -0.07834969],\n",
       "          [-0.16280586,  0.08647921, -0.04635988, ..., -0.067531  ,\n",
       "            0.01079056, -0.073209  ]],\n",
       " \n",
       "         [[-0.00690095,  0.11754296, -0.06102476, ..., -0.0977354 ,\n",
       "           -0.00161432, -0.0755766 ],\n",
       "          [-0.04904108,  0.03551738,  0.0642871 , ...,  0.01677295,\n",
       "            0.02373739, -0.0096953 ],\n",
       "          [ 0.03983833,  0.00590315,  0.03051326, ...,  0.11809801,\n",
       "            0.01050968,  0.08381465],\n",
       "          ...,\n",
       "          [-0.01775621, -0.0866277 ,  0.017793  , ...,  0.06046921,\n",
       "           -0.06163331,  0.00315664],\n",
       "          [ 0.0506989 ,  0.03944599, -0.05104249, ..., -0.01835539,\n",
       "           -0.0455513 ,  0.20095962],\n",
       "          [-0.0167858 ,  0.0707287 , -0.0654647 , ..., -0.13890219,\n",
       "            0.05564101, -0.01104713]],\n",
       " \n",
       "         [[-0.01772178, -0.04022823, -0.02024106, ..., -0.17257066,\n",
       "           -0.05299857, -0.04002355],\n",
       "          [ 0.03689537, -0.01600626, -0.04057588, ...,  0.0228039 ,\n",
       "            0.00555241, -0.05370576],\n",
       "          [-0.05246757,  0.07733803, -0.07779012, ..., -0.00261572,\n",
       "           -0.070543  , -0.09320086],\n",
       "          ...,\n",
       "          [-0.04375305, -0.06380259,  0.01337154, ...,  0.00317137,\n",
       "           -0.07844234, -0.04654114],\n",
       "          [ 0.08322644,  0.01918203,  0.00948095, ..., -0.01446415,\n",
       "           -0.09318421,  0.13901778],\n",
       "          [-0.06969796, -0.02247805,  0.03578528, ..., -0.16004382,\n",
       "            0.00194635,  0.07372496]]],\n",
       " \n",
       " \n",
       "        [[[-0.16614349,  0.03049465, -0.09252732, ...,  0.07985432,\n",
       "            0.08750661, -0.0373314 ],\n",
       "          [-0.0538897 ,  0.05107099,  0.01355999, ..., -0.07327428,\n",
       "            0.00339818, -0.043625  ],\n",
       "          [ 0.0062867 ,  0.0297691 , -0.09834417, ..., -0.07789819,\n",
       "           -0.04954934, -0.07388887],\n",
       "          ...,\n",
       "          [-0.06464076, -0.0365188 , -0.00842475, ..., -0.05632182,\n",
       "           -0.05509927,  0.05120765],\n",
       "          [ 0.055375  ,  0.06642758,  0.01293218, ...,  0.1670015 ,\n",
       "            0.04472586, -0.08083431],\n",
       "          [-0.09562883, -0.03994085,  0.01795914, ..., -0.06492851,\n",
       "           -0.0105214 ,  0.00391571]],\n",
       " \n",
       "         [[ 0.06818967, -0.06122873, -0.11429592, ..., -0.15207487,\n",
       "           -0.00252483,  0.0297398 ],\n",
       "          [-0.07139028, -0.09561235, -0.03584033, ..., -0.02504474,\n",
       "           -0.06419486, -0.05054204],\n",
       "          [-0.03190281,  0.09772506, -0.02762709, ...,  0.10535488,\n",
       "           -0.03603587,  0.03941749],\n",
       "          ...,\n",
       "          [-0.08466697, -0.00739886,  0.0037795 , ..., -0.08924358,\n",
       "           -0.08027039, -0.05090454],\n",
       "          [-0.08673776, -0.04655749, -0.02554302, ...,  0.09857798,\n",
       "           -0.06428079,  0.1647197 ],\n",
       "          [ 0.0570705 , -0.15234071, -0.0745059 , ..., -0.07697646,\n",
       "            0.03622343, -0.10072663]],\n",
       " \n",
       "         [[ 0.02185728, -0.0078348 ,  0.03563417, ...,  0.03778759,\n",
       "           -0.02365005, -0.09148222],\n",
       "          [-0.05790542, -0.03077646, -0.04779737, ...,  0.00394884,\n",
       "            0.02763583, -0.04678613],\n",
       "          [-0.08804923,  0.08556707, -0.06178867, ...,  0.13181832,\n",
       "            0.00482399, -0.1306037 ],\n",
       "          ...,\n",
       "          [ 0.02982816, -0.07952379, -0.02244077, ...,  0.02695922,\n",
       "           -0.07691156, -0.034744  ],\n",
       "          [ 0.04778855, -0.02710531, -0.0432464 , ...,  0.00636136,\n",
       "           -0.1078032 , -0.15201133],\n",
       "          [-0.09873018,  0.02443835, -0.07302126, ...,  0.11610997,\n",
       "           -0.06278247, -0.00902274]]],\n",
       " \n",
       " \n",
       "        [[[-0.22386016,  0.07000735,  0.00485258, ...,  0.14561813,\n",
       "            0.03127479, -0.11301986],\n",
       "          [ 0.0003089 , -0.00285955, -0.03435775, ..., -0.0485347 ,\n",
       "            0.02897569, -0.02001834],\n",
       "          [-0.06552529, -0.05339441, -0.03869858, ...,  0.08242392,\n",
       "            0.09493494,  0.0294857 ],\n",
       "          ...,\n",
       "          [-0.00986913, -0.03103998, -0.00253469, ..., -0.04717474,\n",
       "            0.07735202,  0.01903544],\n",
       "          [-0.1269988 , -0.03393587, -0.07315817, ..., -0.05057814,\n",
       "            0.04845335, -0.09063698],\n",
       "          [-0.2385755 ,  0.03022406, -0.10001194, ...,  0.0550352 ,\n",
       "           -0.01299428, -0.07805812]],\n",
       " \n",
       "         [[ 0.12441973, -0.06004163, -0.03266684, ...,  0.01299784,\n",
       "            0.09403169, -0.08488452],\n",
       "          [ 0.0421348 , -0.00498301, -0.00078236, ...,  0.03947644,\n",
       "            0.06970536, -0.0352056 ],\n",
       "          [ 0.04029804, -0.05994754, -0.10557733, ...,  0.00102571,\n",
       "           -0.04660452,  0.02734558],\n",
       "          ...,\n",
       "          [ 0.01843495,  0.00943983,  0.04105777, ...,  0.01035342,\n",
       "            0.09569399,  0.00568119],\n",
       "          [ 0.04569033,  0.0671237 , -0.01576436, ...,  0.09169772,\n",
       "           -0.0062779 ,  0.00187051],\n",
       "          [ 0.00359002, -0.09669246, -0.02995438, ..., -0.05156672,\n",
       "           -0.04408593, -0.10370971]],\n",
       " \n",
       "         [[ 0.03887335, -0.10842989,  0.00228014, ...,  0.16743103,\n",
       "           -0.06906919, -0.03505373],\n",
       "          [ 0.03698336, -0.0389303 , -0.02801064, ..., -0.0368383 ,\n",
       "           -0.05054613, -0.0512674 ],\n",
       "          [ 0.04962284,  0.02542456, -0.04409701, ..., -0.09852308,\n",
       "           -0.04399989,  0.00437901],\n",
       "          ...,\n",
       "          [ 0.02469145,  0.04852621, -0.05209327, ..., -0.07214226,\n",
       "           -0.01561269,  0.06338191],\n",
       "          [ 0.08553455,  0.03087647, -0.00442368, ..., -0.00418479,\n",
       "           -0.10636108, -0.17545167],\n",
       "          [ 0.02023296,  0.05076781, -0.08708315, ...,  0.12207841,\n",
       "           -0.22265653,  0.07619552]]]], dtype=float32),\n",
       " array([ 0.0595068 , -0.0603712 , -0.07698315,  0.13510379,  0.04413344,\n",
       "        -0.08165768, -0.04322824,  0.12375004,  0.05881825,  0.10918986,\n",
       "        -0.05438923, -0.02365148,  0.09199361,  0.01757854,  0.07617085,\n",
       "        -0.06261701, -0.00881808,  0.03276246,  0.12103041,  0.11188766,\n",
       "         0.06723686, -0.04903414, -0.00895702,  0.03586979,  0.02131132,\n",
       "         0.10907961,  0.08083378,  0.0212861 ,  0.03732964, -0.06524978,\n",
       "        -0.02178268,  0.06984692,  0.04708476,  0.06286582,  0.07663121,\n",
       "        -0.12034389,  0.11184014, -0.03485242, -0.09014326,  0.08391567,\n",
       "        -0.04031896, -0.08584298,  0.05832936, -0.02844102,  0.06863864,\n",
       "         0.09748392,  0.0089277 , -0.08512256,  0.04644008, -0.03234119,\n",
       "        -0.00809813,  0.09589204, -0.04547838, -0.03439233,  0.01345738,\n",
       "        -0.07121105, -0.06517407,  0.10602689,  0.04499425, -0.05244399,\n",
       "         0.00297821,  0.01832838,  0.00209699,  0.01703199], dtype=float32),\n",
       " array([[[[-0.05016839,  0.101923  ,  0.03364868, ..., -0.04420444,\n",
       "            0.03320104,  0.09343241],\n",
       "          [ 0.12055507,  0.07442542,  0.03758006, ...,  0.04410111,\n",
       "           -0.03557306, -0.1045952 ],\n",
       "          [-0.05869082, -0.01355597, -0.04206403, ...,  0.00486867,\n",
       "           -0.03309868, -0.07977667],\n",
       "          ...,\n",
       "          [-0.11701395, -0.13084024, -0.01718805, ..., -0.09705681,\n",
       "           -0.0879768 , -0.07683472],\n",
       "          [ 0.00665491, -0.05166163,  0.00312962, ..., -0.08554384,\n",
       "            0.17844608, -0.18861425],\n",
       "          [-0.06103267,  0.0248702 , -0.01943201, ..., -0.1304591 ,\n",
       "            0.10332444,  0.08536258]],\n",
       " \n",
       "         [[-0.08285408,  0.01569911, -0.00905626, ..., -0.09662335,\n",
       "            0.03023752, -0.08454923],\n",
       "          [ 0.07309613, -0.131608  , -0.00090295, ..., -0.02255353,\n",
       "            0.04875733, -0.28783852],\n",
       "          [ 0.00437537,  0.0396351 ,  0.04733235, ...,  0.00560301,\n",
       "           -0.00883341,  0.0012329 ],\n",
       "          ...,\n",
       "          [ 0.05137626, -0.04549007, -0.02549268, ...,  0.00927179,\n",
       "           -0.00719637, -0.0845494 ],\n",
       "          [ 0.02036292, -0.06039025, -0.07469512, ..., -0.06596202,\n",
       "           -0.07857096, -0.01811719],\n",
       "          [-0.04844438, -0.01631501,  0.0385968 , ...,  0.23401603,\n",
       "           -0.01770693,  0.16060986]],\n",
       " \n",
       "         [[ 0.06023682,  0.07907397, -0.05548333, ...,  0.10731944,\n",
       "           -0.07796887, -0.06789821],\n",
       "          [-0.11494996, -0.1046385 ,  0.01903802, ...,  0.01004436,\n",
       "            0.01354032, -0.07723995],\n",
       "          [ 0.06174294, -0.01808945, -0.04252006, ..., -0.05146782,\n",
       "            0.02554784, -0.03597006],\n",
       "          ...,\n",
       "          [-0.02070895, -0.06576853, -0.04381523, ..., -0.10473705,\n",
       "           -0.02462663,  0.09921013],\n",
       "          [-0.16711514, -0.02939066,  0.00057102, ...,  0.01688676,\n",
       "            0.12857187,  0.07430968],\n",
       "          [ 0.03292206,  0.07249909,  0.04586134, ...,  0.17287825,\n",
       "           -0.15022315, -0.1231757 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03824165,  0.05172352, -0.05956583, ..., -0.02680102,\n",
       "            0.02130567, -0.00724404],\n",
       "          [-0.03353064, -0.06238594, -0.06502562, ..., -0.03154963,\n",
       "            0.24740578,  0.11347643],\n",
       "          [ 0.05675915,  0.02651221,  0.03815316, ..., -0.0146399 ,\n",
       "           -0.14371485,  0.01700954],\n",
       "          ...,\n",
       "          [-0.06063228, -0.16077882,  0.03836474, ..., -0.15725516,\n",
       "            0.19104113, -0.16090414],\n",
       "          [-0.04058751, -0.07125086, -0.05111338, ..., -0.05671268,\n",
       "            0.05822259, -0.03189227],\n",
       "          [-0.04868272,  0.03184446,  0.10728403, ..., -0.02820296,\n",
       "            0.14454836,  0.23991433]],\n",
       " \n",
       "         [[ 0.00356734,  0.0694048 , -0.00840101, ..., -0.03610129,\n",
       "            0.02612507, -0.03929599],\n",
       "          [ 0.05210905, -0.12585   , -0.07376626, ..., -0.1750361 ,\n",
       "           -0.01354646,  0.10521748],\n",
       "          [ 0.04202605, -0.07662473,  0.06213441, ..., -0.00354817,\n",
       "            0.03663892, -0.07264499],\n",
       "          ...,\n",
       "          [ 0.04001263,  0.00611611, -0.06308353, ..., -0.04432395,\n",
       "            0.00589254, -0.1316887 ],\n",
       "          [-0.11151492,  0.02875116, -0.04308467, ...,  0.04374658,\n",
       "           -0.0173231 , -0.03147582],\n",
       "          [ 0.02053884,  0.0784087 ,  0.05401681, ..., -0.10966658,\n",
       "            0.02236472,  0.12452649]],\n",
       " \n",
       "         [[ 0.05377747, -0.01726137, -0.00551502, ...,  0.02962224,\n",
       "           -0.12821724,  0.01136671],\n",
       "          [-0.03423538, -0.01913082, -0.03727417, ...,  0.0422889 ,\n",
       "           -0.03134911,  0.04659434],\n",
       "          [ 0.0638734 , -0.03726088,  0.0673721 , ...,  0.01946406,\n",
       "            0.00383004,  0.03408413],\n",
       "          ...,\n",
       "          [-0.12363655,  0.07076716, -0.06280306, ...,  0.02289652,\n",
       "           -0.04114541, -0.16446373],\n",
       "          [ 0.00305402,  0.1263347 , -0.03552651, ...,  0.01126759,\n",
       "           -0.02013587,  0.00936322],\n",
       "          [-0.06342339,  0.10017683,  0.03378446, ...,  0.07385163,\n",
       "            0.11518797, -0.13352004]]],\n",
       " \n",
       " \n",
       "        [[[-0.04963022, -0.01391675,  0.010642  , ..., -0.00798595,\n",
       "            0.02365189,  0.06363084],\n",
       "          [-0.00651092, -0.06995865,  0.01432812, ...,  0.05151549,\n",
       "           -0.01186081,  0.00082902],\n",
       "          [-0.03121994, -0.03528045,  0.03358718, ...,  0.02525585,\n",
       "           -0.12301067, -0.08459418],\n",
       "          ...,\n",
       "          [ 0.1506794 ,  0.06919577, -0.03546919, ...,  0.05044999,\n",
       "            0.02901866,  0.01385736],\n",
       "          [-0.15109757,  0.09541852, -0.10832898, ..., -0.06560248,\n",
       "           -0.11010189, -0.07816622],\n",
       "          [ 0.07658862,  0.05193828,  0.00150132, ...,  0.00878222,\n",
       "           -0.1337294 , -0.12001781]],\n",
       " \n",
       "         [[ 0.04337974, -0.07468735,  0.0071526 , ...,  0.02374668,\n",
       "           -0.00738512,  0.04777736],\n",
       "          [-0.04570596, -0.06633577, -0.08706616, ...,  0.03516884,\n",
       "            0.1628125 ,  0.0179832 ],\n",
       "          [ 0.01818756, -0.00402441, -0.00737866, ...,  0.0029101 ,\n",
       "           -0.05341384,  0.05757606],\n",
       "          ...,\n",
       "          [-0.08868402, -0.2127196 ,  0.02079703, ...,  0.03783715,\n",
       "           -0.20406583,  0.02024021],\n",
       "          [-0.11497599,  0.01098245, -0.08272528, ..., -0.09054031,\n",
       "           -0.07844195, -0.02965992],\n",
       "          [ 0.05025201, -0.10298611, -0.0284661 , ..., -0.14180827,\n",
       "           -0.04015013, -0.19605568]],\n",
       " \n",
       "         [[-0.00357291, -0.09657378,  0.04767715, ...,  0.06596185,\n",
       "           -0.04144634,  0.0344835 ],\n",
       "          [-0.19311343,  0.17298634, -0.07819428, ...,  0.08419067,\n",
       "           -0.12465863, -0.00410661],\n",
       "          [-0.14762379,  0.01917036, -0.02955645, ...,  0.04038593,\n",
       "           -0.00526437,  0.01635644],\n",
       "          ...,\n",
       "          [-0.17093073, -0.01427715, -0.07742327, ...,  0.03432609,\n",
       "           -0.1287307 , -0.00070478],\n",
       "          [ 0.08028453,  0.06778247, -0.04008727, ..., -0.07014482,\n",
       "           -0.01752861,  0.04486094],\n",
       "          [-0.13655858,  0.08612641, -0.02415027, ...,  0.03469587,\n",
       "            0.10259575,  0.01832152]]]], dtype=float32),\n",
       " array([ 0.03519373,  0.0283941 , -0.06144152, -0.1723273 , -0.00385332,\n",
       "         0.08581679, -0.05711399, -0.0602427 , -0.04173074,  0.07262771,\n",
       "        -0.00780725, -0.0433057 ,  0.07137303,  0.0613054 ,  0.0804925 ,\n",
       "         0.0138241 ,  0.01272641,  0.02586458,  0.04718261, -0.06985585,\n",
       "        -0.03904306,  0.0978395 ,  0.03572677, -0.03901838,  0.05525077,\n",
       "         0.07649741,  0.10738534,  0.05764117,  0.0102045 ,  0.03900284,\n",
       "         0.04087793,  0.09398682,  0.0027296 , -0.08734977,  0.05601458,\n",
       "        -0.03146032,  0.06358831, -0.06334798,  0.03441515,  0.07125542,\n",
       "         0.09809331,  0.00693313, -0.06256812, -0.09712574,  0.03110361,\n",
       "        -0.01416072, -0.04345967, -0.00716852, -0.04950478, -0.02542713,\n",
       "         0.00733205, -0.06964107,  0.07984493, -0.01698235,  0.03064718,\n",
       "        -0.00580896,  0.11522706, -0.11153056,  0.02998259, -0.03358921,\n",
       "         0.07589207,  0.05250577, -0.01579349, -0.01921326], dtype=float32),\n",
       " array([[ 0.11108889,  0.1080604 , -0.04647898, ...,  0.00769033,\n",
       "          0.11855712, -0.01307744],\n",
       "        [-0.03443013,  0.16754216, -0.10509261, ...,  0.03715432,\n",
       "         -0.02292426, -0.13653111],\n",
       "        [ 0.0966467 ,  0.07816032,  0.0565265 , ..., -0.06499745,\n",
       "          0.02752406,  0.08789308],\n",
       "        ...,\n",
       "        [-0.0811187 , -0.18691806,  0.00178231, ...,  0.0430593 ,\n",
       "         -0.07470497, -0.14071783],\n",
       "        [ 0.03422713, -0.08263074, -0.09880038, ...,  0.03013248,\n",
       "         -0.1958706 , -0.08146317],\n",
       "        [ 0.12366121,  0.07778819, -0.14055303, ..., -0.09809786,\n",
       "         -0.03672226, -0.0691555 ]], dtype=float32),\n",
       " array([-2.29999293e-02,  4.93218452e-02, -3.88150513e-02,  5.05717807e-02,\n",
       "        -2.75451839e-02,  1.36176929e-01, -1.23293670e-02, -8.20840150e-03,\n",
       "        -4.34227921e-02, -7.53755569e-02,  9.29285809e-02,  6.88706562e-02,\n",
       "         6.69046491e-02,  1.57068688e-02, -2.23197769e-02,  1.33285485e-02,\n",
       "         2.40447037e-02, -1.77079327e-02, -3.05999871e-02,  7.09217135e-03,\n",
       "         4.89452332e-02, -6.60292730e-02,  5.37706306e-03,  1.29032835e-01,\n",
       "        -3.87749635e-02, -2.38703992e-02, -2.00492200e-02, -2.49741692e-02,\n",
       "        -2.98978221e-02,  1.93786044e-02, -3.31108421e-02,  8.32142234e-02,\n",
       "        -5.77688497e-03,  3.95471267e-02, -1.59715842e-02, -3.93985808e-02,\n",
       "         4.66459915e-02,  2.36009881e-02,  1.31784096e-01,  2.61161532e-02,\n",
       "        -2.15667281e-02, -4.93886061e-02, -1.06867179e-02,  4.24723811e-02,\n",
       "        -1.04167648e-02,  4.25757878e-02, -1.19991768e-02, -7.05313403e-03,\n",
       "        -5.17209955e-02,  4.57565822e-02, -4.02057208e-02, -5.39668910e-02,\n",
       "        -1.22639053e-02,  6.84586912e-02,  1.15657844e-01,  1.02640159e-01,\n",
       "        -4.49848324e-02,  1.80729982e-02, -3.10199745e-02,  9.20904726e-02,\n",
       "        -1.37653584e-02, -2.85132285e-02, -5.78667857e-02,  1.10977516e-01,\n",
       "         1.21263720e-01,  7.08187222e-02, -4.11734022e-02, -2.33837590e-02,\n",
       "         3.02692764e-02,  1.06627464e-01,  6.55442700e-02, -7.24976743e-03,\n",
       "        -1.64371300e-02,  1.53757678e-02, -4.28118365e-05, -3.28735448e-02,\n",
       "         4.20969948e-02, -1.89260934e-02, -3.53078693e-02, -4.71591055e-02,\n",
       "        -5.29652871e-02, -1.86765566e-02, -3.42026129e-02, -3.06831729e-02,\n",
       "        -5.07496484e-02, -5.52054085e-02,  7.51589015e-02, -3.66463140e-02,\n",
       "        -4.03906107e-02, -1.31107392e-02, -4.10065949e-02, -1.57703608e-02,\n",
       "         6.66315332e-02,  5.02193607e-02, -5.19458018e-02, -1.61609966e-02,\n",
       "         7.18716532e-03, -3.33016515e-02, -2.32383069e-02, -3.55008617e-02,\n",
       "        -4.24048677e-03, -4.42258641e-02,  3.38444486e-02,  3.75499413e-03,\n",
       "         3.83124165e-02,  4.49759997e-02,  6.34306669e-02,  8.77345130e-02,\n",
       "        -3.76853086e-02, -4.44952957e-02, -6.53092191e-02,  3.59191783e-02,\n",
       "        -3.06889936e-02,  2.81302519e-02, -5.39866574e-02, -4.84774709e-02,\n",
       "        -1.12117361e-02, -1.82053763e-02,  8.75734165e-03,  1.95047185e-02,\n",
       "         1.99892856e-02, -3.00914086e-02, -1.97489876e-02, -8.08010697e-02,\n",
       "        -2.85115708e-02,  5.62435910e-02, -2.85136830e-02, -4.57156971e-02,\n",
       "         1.26043513e-01,  9.80161950e-02, -3.21561880e-02, -1.53881349e-02,\n",
       "        -4.33639772e-02, -5.58727421e-02, -7.22683147e-02, -8.93775001e-03,\n",
       "         9.07672346e-02,  6.60682619e-02, -5.85274026e-02,  1.10147242e-02,\n",
       "         8.06924179e-02, -2.19387040e-02,  3.48145440e-02,  1.07737362e-01,\n",
       "        -5.18619418e-02, -2.42796466e-02,  8.75593424e-02,  6.80942535e-02,\n",
       "        -2.31920741e-02,  4.89439555e-02,  1.01331905e-01, -3.07072420e-02,\n",
       "        -2.18058322e-02,  1.35151714e-01,  9.45271179e-03,  9.10579879e-03,\n",
       "        -4.68587913e-02,  2.48413673e-03, -2.91439556e-02,  9.88920704e-02,\n",
       "        -9.26691443e-02, -4.16689329e-02,  8.25334266e-02,  1.08141281e-01,\n",
       "        -1.98613945e-02,  3.21347751e-02, -5.37197553e-02, -3.85908261e-02,\n",
       "        -3.16506512e-02,  2.53249868e-03, -4.84687313e-02,  8.88214707e-02,\n",
       "         6.51169121e-02, -3.22646014e-02,  8.67267847e-02,  4.62533832e-02,\n",
       "        -2.39193868e-02,  5.23025841e-02,  7.49817193e-02, -1.39217693e-02,\n",
       "        -6.81358352e-02, -1.81480497e-02, -2.79956385e-02, -3.41161154e-02,\n",
       "         8.55037645e-02,  1.74171105e-01,  1.41197983e-02,  4.01684968e-03,\n",
       "         1.09590083e-01, -3.84793840e-02, -4.96733934e-02, -1.75696462e-02,\n",
       "         4.29421812e-02, -3.24293002e-02, -2.00239252e-02,  1.20534770e-01,\n",
       "        -1.22288102e-02,  6.98957369e-02, -4.69233990e-02, -2.64742263e-02,\n",
       "        -3.52404565e-02,  3.65493936e-03, -1.03291441e-02, -2.73453817e-02,\n",
       "        -4.09949496e-02, -4.80758734e-02, -6.13344684e-02,  3.26238610e-02,\n",
       "        -2.41383687e-02, -4.42121327e-02,  8.07956979e-02, -2.54815556e-02,\n",
       "         2.22295318e-02,  1.08697684e-02, -1.19486911e-04,  1.05928019e-01,\n",
       "         4.66094464e-02, -4.93296273e-02,  4.49011177e-02,  2.87599005e-02,\n",
       "        -4.98145036e-02, -5.10800742e-02, -4.32897098e-02, -3.91025133e-02,\n",
       "        -7.85392225e-02, -3.12053207e-02,  4.68905233e-02, -5.98880425e-02,\n",
       "         6.49962127e-02, -2.24623028e-02, -4.67668399e-02,  8.07371289e-02,\n",
       "        -4.11001444e-02, -2.44139116e-02, -2.35857517e-02, -2.11326778e-02,\n",
       "         1.23685986e-01,  1.09980337e-01,  7.34817460e-02,  1.38671726e-01,\n",
       "         6.90941364e-02,  7.36757219e-02, -9.17865336e-03, -8.30606297e-02,\n",
       "        -3.12496368e-02, -2.94859298e-02, -3.50325108e-02,  8.11938494e-02,\n",
       "        -3.36228199e-02, -3.11035514e-02, -2.15862989e-02,  1.64953377e-02,\n",
       "         1.56329330e-02,  5.27264699e-02,  3.02982368e-02, -1.59710292e-02],\n",
       "       dtype=float32),\n",
       " array([[ 0.10422126, -0.00436004, -0.0885362 , ...,  0.08726107,\n",
       "          0.0226812 ,  0.01061968],\n",
       "        [-0.01006778, -0.14013216,  0.00536632, ...,  0.00533592,\n",
       "          0.10625472, -0.06652485],\n",
       "        [ 0.07606226, -0.08395116,  0.07243425, ...,  0.07726823,\n",
       "         -0.04462661,  0.07354439],\n",
       "        ...,\n",
       "        [ 0.07843801, -0.11090923, -0.13559452, ..., -0.07508439,\n",
       "          0.03687672, -0.10297375],\n",
       "        [ 0.04187905,  0.03026938, -0.04604226, ..., -0.09716535,\n",
       "         -0.1392014 ,  0.08694177],\n",
       "        [ 0.00153353,  0.02554185,  0.07848554, ..., -0.00926094,\n",
       "         -0.07279555,  0.09410766]], dtype=float32),\n",
       " array([-0.01574362, -0.040222  , -0.03218333, -0.05065988, -0.03259269,\n",
       "        -0.02322254, -0.01521936, -0.0346391 ,  0.04536863,  0.03387468,\n",
       "         0.05354015,  0.02903001, -0.01281121,  0.07152613, -0.04878447,\n",
       "        -0.00783614, -0.04954181, -0.05297875, -0.01731099, -0.00802049,\n",
       "        -0.01712857,  0.03296098, -0.05205019,  0.05771303,  0.01347392,\n",
       "         0.04429061,  0.05609405, -0.0150586 ,  0.12042524,  0.04730006,\n",
       "        -0.05970311,  0.03935371,  0.02579949,  0.101284  , -0.0263517 ,\n",
       "         0.08888666,  0.04868988,  0.03488645, -0.06125127,  0.0338187 ,\n",
       "        -0.0444032 , -0.03614333,  0.01795783, -0.03004492,  0.02991092,\n",
       "        -0.03235912, -0.05328749, -0.03789184, -0.03477605, -0.05826829,\n",
       "         0.06591965, -0.02782024,  0.12069875,  0.01700936,  0.0548174 ,\n",
       "        -0.04482516,  0.06628585, -0.05426   , -0.03942791,  0.04092336,\n",
       "        -0.04990866, -0.02034941,  0.03781505, -0.05388661,  0.12427855,\n",
       "        -0.05843167, -0.05318525, -0.04049265, -0.06901308,  0.05950931,\n",
       "         0.0669238 , -0.06074972, -0.05758285, -0.04541292, -0.02927574,\n",
       "         0.03348418, -0.03762947, -0.05662847, -0.03693933,  0.08287327,\n",
       "        -0.00788343,  0.09230999,  0.07649568, -0.01269631, -0.03936285,\n",
       "         0.03579028, -0.02973092, -0.00759312, -0.02740522, -0.05238008,\n",
       "        -0.04752769, -0.0220021 ,  0.04709851,  0.02786404,  0.06054585,\n",
       "        -0.00555286, -0.007172  , -0.02448808, -0.02307783,  0.00758669,\n",
       "         0.1229722 , -0.02801672,  0.09357674, -0.03260669, -0.01524671,\n",
       "        -0.00919764, -0.02574312,  0.05975514, -0.04671847,  0.0995429 ,\n",
       "        -0.03936668, -0.01169552,  0.07210721, -0.01916891,  0.04124656,\n",
       "        -0.01374382, -0.01233033, -0.05763467,  0.04902367,  0.02794578,\n",
       "         0.07527835,  0.10971788, -0.0155539 ,  0.02675003, -0.02818773,\n",
       "         0.09247745,  0.01776876,  0.00676591, -0.05486313, -0.13808708,\n",
       "         0.03993065, -0.02123067, -0.03698248, -0.05351229,  0.0419159 ,\n",
       "         0.03802657, -0.01699727,  0.07485296,  0.08117723,  0.04957137,\n",
       "         0.07650762, -0.01215426,  0.03161801,  0.01980526, -0.02806372,\n",
       "        -0.02633436,  0.02690898,  0.08349597, -0.0173491 , -0.01035852,\n",
       "        -0.00175997, -0.14663678,  0.07427026,  0.06696983, -0.04158256,\n",
       "         0.13401012, -0.06720763, -0.03333159,  0.12591662, -0.00208412,\n",
       "        -0.019369  , -0.03336564, -0.01165554,  0.04331687, -0.04242297,\n",
       "        -0.02144806,  0.11548   , -0.05291732,  0.03612136, -0.03200267,\n",
       "        -0.01906202, -0.05606548,  0.03503446,  0.01837852, -0.00921446,\n",
       "        -0.04919617, -0.01120814,  0.05723337,  0.05048174, -0.03987342,\n",
       "         0.03714115, -0.04471384,  0.06171601,  0.00111426, -0.04736387,\n",
       "         0.02377566, -0.00975306, -0.03916458, -0.01474284,  0.00510026,\n",
       "         0.00059445,  0.04224448, -0.02957946, -0.04118024,  0.01221989,\n",
       "        -0.02211752, -0.0418609 , -0.0293846 , -0.0208945 ,  0.12498151,\n",
       "         0.08637693,  0.03506672,  0.08621687, -0.04109164,  0.03300017,\n",
       "         0.02420207,  0.10709602,  0.02871416, -0.01063452, -0.03564642,\n",
       "         0.09478869, -0.04872134,  0.03182257, -0.04373272,  0.02506937,\n",
       "         0.03779823, -0.03858022, -0.04178613,  0.02852313,  0.04455091,\n",
       "        -0.03146244, -0.0346996 , -0.04173939,  0.04850921, -0.04252441,\n",
       "        -0.00661232,  0.05995017, -0.03733085, -0.02223299,  0.12048814,\n",
       "        -0.03020397, -0.04016134, -0.06657618,  0.03711422,  0.02175772,\n",
       "        -0.01960708,  0.00017908,  0.0323743 , -0.0356214 , -0.05611023,\n",
       "        -0.01010466, -0.05852582,  0.0727739 , -0.04153602,  0.03903103,\n",
       "         0.13758676, -0.02259499, -0.01485799,  0.03357668, -0.03584721,\n",
       "         0.05492065,  0.05322056, -0.02568186, -0.01023871, -0.0393678 ,\n",
       "        -0.01269843], dtype=float32),\n",
       " array([[ 0.00591451,  0.08097838,  0.10125832, ..., -0.12204257,\n",
       "          0.08777641, -0.02440059],\n",
       "        [-0.05131669,  0.10206467, -0.12577209, ..., -0.09787108,\n",
       "          0.11699505, -0.02661926],\n",
       "        [ 0.09030411,  0.01418484,  0.09865837, ..., -0.07622065,\n",
       "          0.02036201, -0.0668716 ],\n",
       "        ...,\n",
       "        [-0.00641467, -0.00679523, -0.14161496, ..., -0.01283569,\n",
       "         -0.0590564 ,  0.04486234],\n",
       "        [-0.10530996, -0.01560416, -0.08541199, ..., -0.16877915,\n",
       "         -0.09159677, -0.20565455],\n",
       "        [ 0.08365846,  0.09449974, -0.08606588, ..., -0.07190637,\n",
       "         -0.15142587, -0.07219777]], dtype=float32),\n",
       " array([ 0.00039637, -0.05205476,  0.02772587,  0.02080639,  0.03271028,\n",
       "        -0.06111097,  0.01673721], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1583364982425,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "UHOLUf9LFF_4",
    "outputId": "c0d62565-837f-4b1b-a8c2-49e7073ae286"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'block1_conv1_1/kernel:0' shape=(3, 3, 3, 8) dtype=float32, numpy=\n",
       " array([[[[ 0.20407596, -0.0076126 , -0.31642285, -0.14033513,\n",
       "            0.2834546 ,  0.17670147,  0.18333197, -0.00525202],\n",
       "          [-0.1222116 , -0.00253352, -0.1462644 , -0.12128124,\n",
       "            0.26775965,  0.1779506 ,  0.20969276,  0.0413659 ],\n",
       "          [-0.07989866,  0.27928892, -0.27633652, -0.0575515 ,\n",
       "            0.09372558,  0.2992469 , -0.07647823,  0.14722785]],\n",
       " \n",
       "         [[ 0.02342825, -0.07014901,  0.00285076, -0.23947963,\n",
       "           -0.15778463, -0.07801206, -0.15598541, -0.08965971],\n",
       "          [ 0.13409467,  0.20458865, -0.09732905, -0.14803115,\n",
       "           -0.16993253, -0.14117503, -0.15697259,  0.06676271],\n",
       "          [ 0.34458554,  0.09123912,  0.06526193,  0.17850512,\n",
       "           -0.00704311, -0.0696204 , -0.02253206, -0.24609652]],\n",
       " \n",
       "         [[ 0.07324352, -0.13435145, -0.01040823,  0.06470463,\n",
       "            0.17856698,  0.0033257 , -0.06190493, -0.23788494],\n",
       "          [ 0.22493629, -0.11870138, -0.18789716, -0.18417086,\n",
       "           -0.22343037, -0.04021792, -0.15517718,  0.15642323],\n",
       "          [ 0.25403753,  0.20407079, -0.15775983, -0.06128685,\n",
       "           -0.0306304 ,  0.00637106, -0.20272593,  0.1491268 ]]],\n",
       " \n",
       " \n",
       "        [[[-0.28345504, -0.1721225 ,  0.11658465,  0.13632138,\n",
       "           -0.01797273, -0.05518382,  0.0064924 ,  0.18897536],\n",
       "          [-0.2009701 , -0.2409991 , -0.2096754 , -0.29443717,\n",
       "            0.17237931, -0.07551806,  0.11007676,  0.21130186],\n",
       "          [-0.12923396, -0.10700378, -0.20607877, -0.21614788,\n",
       "            0.03185014,  0.05685909,  0.07223535,  0.11637469]],\n",
       " \n",
       "         [[-0.14405234,  0.03736109,  0.09730621,  0.03400201,\n",
       "           -0.29817122,  0.0294111 ,  0.10537728,  0.10498245],\n",
       "          [ 0.20339312,  0.1004825 ,  0.17429212, -0.12547661,\n",
       "           -0.14337556, -0.04731176, -0.17148328, -0.0038924 ],\n",
       "          [ 0.18524697, -0.23985395,  0.17224374,  0.19652809,\n",
       "           -0.05048783, -0.2729352 ,  0.1538086 ,  0.00743192]],\n",
       " \n",
       "         [[-0.11424674, -0.24939358, -0.0557913 , -0.20197721,\n",
       "           -0.05319946,  0.04061206,  0.00161384, -0.05736644],\n",
       "          [ 0.05767681, -0.14531906, -0.14187573, -0.19707628,\n",
       "           -0.01006328,  0.10277203, -0.25421324,  0.08785586],\n",
       "          [-0.05375228, -0.13022077,  0.20082113,  0.05126536,\n",
       "            0.11759859, -0.15113387,  0.16276918, -0.16742475]]],\n",
       " \n",
       " \n",
       "        [[[-0.14866973, -0.05075754,  0.02050619,  0.05235216,\n",
       "           -0.17970033,  0.04865923,  0.19329637,  0.03585541],\n",
       "          [-0.10386109, -0.10239654,  0.03907063, -0.11828617,\n",
       "            0.02920107, -0.15557998,  0.13490796, -0.09709021],\n",
       "          [-0.19438894, -0.18040624,  0.14746003,  0.11570627,\n",
       "            0.00803062,  0.12866554,  0.03870315, -0.22234063]],\n",
       " \n",
       "         [[-0.04147372, -0.2825322 ,  0.08183165, -0.25633907,\n",
       "           -0.0029715 , -0.0938168 ,  0.1426637 , -0.09144492],\n",
       "          [ 0.04129991,  0.10965732,  0.0761847 , -0.20362762,\n",
       "           -0.21873309,  0.01872263,  0.20315865, -0.07534482],\n",
       "          [-0.16400869, -0.26050574,  0.1659579 , -0.10895947,\n",
       "           -0.0439834 ,  0.0434352 , -0.14225517, -0.38147274]],\n",
       " \n",
       "         [[-0.07470969, -0.00830479,  0.2786317 ,  0.09001424,\n",
       "            0.15519662, -0.03838968,  0.1757615 , -0.2591325 ],\n",
       "          [ 0.19147374,  0.23530056,  0.15367055, -0.18881847,\n",
       "            0.04563609, -0.13187645,  0.10267056, -0.03865632],\n",
       "          [-0.09614272,  0.28822982,  0.13421746, -0.08513387,\n",
       "            0.1920927 , -0.16310443, -0.06185865,  0.06117762]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block1_conv1_1/bias:0' shape=(8,) dtype=float32, numpy=\n",
       " array([ 0.07730127,  0.15047254,  0.02648023, -0.05073486,  0.00833079,\n",
       "        -0.02135134, -0.09641013, -0.04680444], dtype=float32)>,\n",
       " <tf.Variable 'block2_conv1_1/kernel:0' shape=(3, 3, 8, 16) dtype=float32, numpy=\n",
       " array([[[[-1.88147783e-01, -2.10542157e-01, -3.61554116e-01, ...,\n",
       "            3.96144874e-02, -1.28306687e-01, -9.31893960e-02],\n",
       "          [-5.30292876e-02, -1.42793939e-01,  5.44611961e-02, ...,\n",
       "           -1.70136735e-01, -2.44497806e-01,  4.46163863e-02],\n",
       "          [ 5.28940521e-02, -1.39651194e-01,  8.89326632e-02, ...,\n",
       "           -7.18935451e-04,  9.00823027e-02,  4.88478653e-02],\n",
       "          ...,\n",
       "          [ 1.42464131e-01,  8.51581991e-02,  1.70612298e-02, ...,\n",
       "            1.23285741e-01, -8.84603709e-02,  1.04145512e-01],\n",
       "          [-5.80072366e-02,  1.11874811e-01,  4.26895097e-02, ...,\n",
       "            7.86599219e-02, -7.11378083e-02,  8.75764862e-02],\n",
       "          [-1.03404382e-02, -1.36487201e-01,  7.48250112e-02, ...,\n",
       "           -1.53867612e-02,  4.86405045e-02, -7.53743201e-02]],\n",
       " \n",
       "         [[-2.13976145e-01, -4.59623523e-02,  1.62686273e-01, ...,\n",
       "            2.32868463e-01, -8.79105330e-02, -2.46970192e-01],\n",
       "          [-1.14739724e-01,  5.01294062e-02,  1.71475813e-01, ...,\n",
       "            1.48779139e-01, -5.01922548e-01,  2.05628514e-01],\n",
       "          [ 6.25623539e-02,  9.64995176e-02, -1.30426452e-01, ...,\n",
       "            9.25567076e-02,  2.64500324e-02, -2.82186478e-01],\n",
       "          ...,\n",
       "          [ 7.40338340e-02, -3.58825415e-01, -1.56192392e-01, ...,\n",
       "           -7.24574029e-02, -4.58448231e-02,  1.05300896e-01],\n",
       "          [-2.76748799e-02, -1.68067887e-01, -2.76863992e-01, ...,\n",
       "            1.19953908e-01, -1.61788762e-02,  1.15691155e-01],\n",
       "          [ 3.07706427e-02, -1.07222132e-01,  1.21943183e-01, ...,\n",
       "           -1.68567404e-01,  1.45502895e-01, -1.13336861e-01]],\n",
       " \n",
       "         [[-2.13172883e-02, -6.19860478e-02,  2.32167080e-01, ...,\n",
       "            1.09025963e-01, -1.61381155e-01,  1.48007914e-01],\n",
       "          [-1.75295174e-01,  9.98580903e-02,  1.19590029e-01, ...,\n",
       "           -2.78034527e-02, -1.58321247e-01,  3.82521898e-02],\n",
       "          [-1.29591569e-01,  2.33105645e-02,  5.60068147e-05, ...,\n",
       "           -1.38465837e-01, -1.51850298e-01, -3.78858112e-02],\n",
       "          ...,\n",
       "          [ 2.10265920e-01, -3.74380827e-01,  2.99486250e-01, ...,\n",
       "           -3.06664228e-01, -2.88148850e-01,  4.62797470e-02],\n",
       "          [ 1.96177904e-02, -3.41418684e-02,  8.18810314e-02, ...,\n",
       "           -5.62494174e-02, -1.00145489e-01, -1.89945698e-01],\n",
       "          [ 2.24005468e-02,  4.14995253e-02, -3.06461025e-02, ...,\n",
       "           -6.61209896e-02, -1.53524354e-01, -1.27819136e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 1.89079985e-01, -1.38262898e-01,  7.22211823e-02, ...,\n",
       "           -3.99713814e-02, -3.55062783e-02, -2.47060716e-01],\n",
       "          [ 2.97823139e-02,  6.94772303e-02, -2.61725396e-01, ...,\n",
       "            7.81468228e-02, -1.56291910e-02,  1.49274385e-02],\n",
       "          [ 2.40321364e-02, -2.95824632e-02, -4.85157641e-03, ...,\n",
       "           -1.53215528e-01,  8.81296322e-02,  1.32935829e-02],\n",
       "          ...,\n",
       "          [ 1.46232937e-02, -2.25476265e-01, -5.08688092e-02, ...,\n",
       "           -2.04729125e-01, -1.44287750e-01,  7.34296022e-03],\n",
       "          [ 3.99751179e-02,  1.44093290e-01,  1.74046129e-01, ...,\n",
       "           -7.50395954e-02, -6.95693716e-02, -4.43275608e-02],\n",
       "          [-1.58796236e-01, -4.30204533e-03,  8.95456299e-02, ...,\n",
       "           -1.38991863e-01, -1.10159606e-01,  3.58331949e-02]],\n",
       " \n",
       "         [[ 3.26981753e-01,  3.62940622e-03, -2.48212770e-01, ...,\n",
       "            9.30908471e-02, -1.53040275e-01, -4.65275496e-02],\n",
       "          [ 1.51580468e-01, -3.13764103e-02, -2.16624457e-02, ...,\n",
       "           -9.87337083e-02, -1.67228207e-01,  8.58127885e-03],\n",
       "          [-2.06158474e-01,  1.51303068e-01,  3.70809548e-02, ...,\n",
       "           -2.13265091e-01,  5.72586879e-02, -3.95650342e-02],\n",
       "          ...,\n",
       "          [ 9.51577649e-02, -1.62147790e-01, -1.74296111e-01, ...,\n",
       "           -1.98494382e-02,  4.38753888e-03, -8.44163299e-02],\n",
       "          [-1.48893356e-01, -1.05655836e-02,  1.22822896e-01, ...,\n",
       "            3.95617783e-02,  1.10503733e-01,  7.13735819e-02],\n",
       "          [-2.04343513e-01,  3.31525281e-02,  8.39786232e-02, ...,\n",
       "            1.83600619e-01, -1.21237367e-01, -1.41062558e-01]],\n",
       " \n",
       "         [[-1.16994806e-01, -2.32927110e-02,  2.31826067e-01, ...,\n",
       "           -6.11380674e-03, -3.30755450e-02,  2.77794987e-01],\n",
       "          [ 1.02259805e-02,  1.65272847e-01, -1.42682930e-02, ...,\n",
       "            6.98774755e-02, -3.49702358e-01,  3.05648386e-01],\n",
       "          [ 6.08957037e-02, -7.71624297e-02, -2.98573226e-02, ...,\n",
       "           -1.83180884e-01,  1.56311505e-02,  3.74988168e-02],\n",
       "          ...,\n",
       "          [ 1.88606188e-01, -4.86849733e-02,  2.33027879e-02, ...,\n",
       "           -1.16616778e-01, -6.86828196e-02, -1.30065888e-01],\n",
       "          [-9.68715474e-02,  2.27345247e-02, -1.52299121e-01, ...,\n",
       "           -2.08036810e-01,  9.69791412e-02, -2.32388765e-01],\n",
       "          [ 1.20990351e-01,  1.46504089e-01, -1.96943507e-01, ...,\n",
       "           -1.81741819e-01, -1.58202961e-01,  1.17698379e-01]]],\n",
       " \n",
       " \n",
       "        [[[-4.02306803e-02, -2.77041197e-01,  1.53627306e-01, ...,\n",
       "            1.73698589e-01, -8.00583810e-02, -8.59974697e-02],\n",
       "          [-8.07382166e-02, -7.19581544e-03,  7.56744519e-02, ...,\n",
       "            1.60167404e-02,  1.59497604e-01, -1.34889722e-01],\n",
       "          [ 1.54305801e-01,  1.70483932e-01, -6.40694872e-02, ...,\n",
       "           -2.67946303e-01,  1.79629937e-01, -5.50595112e-02],\n",
       "          ...,\n",
       "          [-1.64362341e-01, -7.86987413e-03, -1.75335810e-01, ...,\n",
       "            8.06891620e-02,  1.19750798e-01, -2.07873046e-01],\n",
       "          [ 2.82198727e-01, -1.67373195e-01,  9.04026926e-02, ...,\n",
       "           -1.56494647e-01,  1.73466712e-01,  1.43592373e-01],\n",
       "          [-8.75240117e-02, -1.34543449e-01,  4.61221524e-02, ...,\n",
       "           -7.52339438e-02, -4.53651696e-02,  1.15004145e-01]],\n",
       " \n",
       "         [[ 1.20903522e-01, -4.16071974e-02, -8.25846344e-02, ...,\n",
       "            9.64023471e-02, -5.14393076e-02, -4.00208235e-02],\n",
       "          [ 1.51979417e-01, -1.03660785e-01, -1.12372048e-01, ...,\n",
       "            3.01114529e-01,  3.09340298e-01, -1.55084893e-01],\n",
       "          [ 1.18031211e-01,  8.90323520e-03,  7.53825605e-02, ...,\n",
       "           -1.42632738e-01, -2.24776063e-02, -3.84441428e-02],\n",
       "          ...,\n",
       "          [-1.37886375e-01, -4.25344380e-03, -1.01411454e-01, ...,\n",
       "           -4.51707281e-02,  9.59538519e-02, -2.89902896e-01],\n",
       "          [-8.82804692e-02,  9.03314725e-02, -7.78852403e-02, ...,\n",
       "           -5.94694428e-02,  1.19339652e-01,  2.78717607e-01],\n",
       "          [ 1.09045960e-01,  3.63049023e-02, -1.49706244e-01, ...,\n",
       "           -1.53799672e-02,  7.50674680e-02,  1.76056251e-02]],\n",
       " \n",
       "         [[ 1.38787076e-01, -1.84466675e-01, -1.12163974e-02, ...,\n",
       "            1.64088592e-01,  1.07613727e-01,  1.30949229e-01],\n",
       "          [ 4.04791474e-01,  3.98205742e-02, -2.90844683e-02, ...,\n",
       "            7.66514987e-02,  1.11490004e-01,  2.80587226e-01],\n",
       "          [-7.16473162e-02, -6.26134425e-02, -1.14033371e-01, ...,\n",
       "            1.71706364e-01,  2.08534315e-01, -1.12927435e-02],\n",
       "          ...,\n",
       "          [ 1.38790896e-02,  1.88167706e-01,  2.89756898e-02, ...,\n",
       "           -8.41761231e-02, -1.01601507e-03, -7.36943036e-02],\n",
       "          [-1.43166274e-01,  2.49132644e-02,  1.53249547e-01, ...,\n",
       "           -1.09648474e-01, -5.37474044e-02, -8.62431750e-02],\n",
       "          [-3.66781652e-02, -1.07306264e-01, -1.26065210e-01, ...,\n",
       "           -5.48288412e-02,  5.97280413e-02,  4.65030596e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block2_conv1_1/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([ 0.03665204, -0.01650185, -0.03276017,  0.00350491, -0.06839617,\n",
       "        -0.05294834, -0.05656371,  0.05498796, -0.01107319, -0.00016313,\n",
       "        -0.03260319,  0.01564167, -0.00549637,  0.0039014 , -0.00355463,\n",
       "         0.00502246], dtype=float32)>,\n",
       " <tf.Variable 'block3_conv1_1/kernel:0' shape=(3, 3, 16, 32) dtype=float32, numpy=\n",
       " array([[[[ 8.80729258e-02,  6.91704899e-02,  1.79006997e-02, ...,\n",
       "            2.53224105e-01, -5.23019247e-02,  1.18011415e-01],\n",
       "          [-4.35922965e-02,  1.10276803e-01,  1.64179709e-02, ...,\n",
       "            6.70297816e-02, -1.32331699e-01,  2.04984754e-01],\n",
       "          [ 8.04258510e-02,  1.38734713e-01,  2.80222371e-02, ...,\n",
       "            2.40424827e-01, -2.89589316e-02,  2.13806733e-01],\n",
       "          ...,\n",
       "          [-2.83896364e-02, -3.72393690e-02,  8.75335261e-02, ...,\n",
       "           -7.24796578e-02, -1.09994970e-01, -1.87806338e-02],\n",
       "          [ 1.03621952e-01,  3.13806236e-02,  8.79491046e-02, ...,\n",
       "           -1.28054276e-01, -2.17541549e-02, -6.32358640e-02],\n",
       "          [ 1.09531276e-01, -1.11619793e-02,  1.37711406e-01, ...,\n",
       "            1.67598695e-01,  1.88304242e-02, -5.01873754e-02]],\n",
       " \n",
       "         [[-9.42940935e-02, -1.56174421e-01, -6.48440793e-02, ...,\n",
       "            2.47216731e-01, -6.57504648e-02,  1.64380640e-01],\n",
       "          [ 8.64909887e-02, -2.77118832e-02,  1.72059938e-01, ...,\n",
       "           -7.52210990e-02, -8.12783092e-02, -4.69936468e-02],\n",
       "          [ 1.15799299e-02, -9.45637971e-02,  2.70206798e-02, ...,\n",
       "            1.86586436e-02,  9.33515653e-02,  1.77068666e-01],\n",
       "          ...,\n",
       "          [ 4.62790541e-02, -2.83919454e-01,  1.32867536e-02, ...,\n",
       "            1.34346470e-01, -9.70245600e-02,  1.91707224e-01],\n",
       "          [ 3.52099389e-02,  1.24150161e-02, -9.04187039e-02, ...,\n",
       "            2.22411081e-02,  1.45785166e-02, -2.02252924e-01],\n",
       "          [ 1.52630312e-02, -1.37789473e-02,  1.10567532e-01, ...,\n",
       "            7.56963901e-03,  1.01023046e-02,  8.82680565e-02]],\n",
       " \n",
       "         [[-2.04224035e-01,  5.09326831e-02, -1.11839166e-02, ...,\n",
       "            1.07214294e-01,  8.29077139e-02, -6.83640167e-02],\n",
       "          [ 5.10324612e-02,  1.92563057e-01,  9.55090001e-02, ...,\n",
       "           -6.29524216e-02,  2.05480177e-02,  3.02997474e-02],\n",
       "          [ 1.97698995e-02, -3.48376185e-02, -5.50672784e-02, ...,\n",
       "           -1.33048445e-01,  1.42596336e-02, -7.37686306e-02],\n",
       "          ...,\n",
       "          [-2.61673871e-02,  1.93990245e-01,  1.68255702e-01, ...,\n",
       "            1.72291353e-01, -1.66540651e-03, -2.25907564e-02],\n",
       "          [-8.32914412e-02,  8.07226915e-03,  8.61665606e-02, ...,\n",
       "            4.42936793e-02, -1.35960057e-01, -8.97453651e-02],\n",
       "          [ 1.03749506e-01, -4.79733162e-02,  5.65136299e-02, ...,\n",
       "           -5.89474700e-02, -1.69212788e-01, -9.04133469e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.14694768e-01, -9.61919576e-02, -2.41672359e-02, ...,\n",
       "           -1.56946689e-01, -8.03963616e-02, -4.56321724e-02],\n",
       "          [ 6.82289386e-03,  1.67049635e-02, -6.72080368e-02, ...,\n",
       "           -3.40450485e-03, -1.35141551e-01, -8.33665282e-02],\n",
       "          [ 5.25813773e-02, -1.16211362e-02,  4.59877886e-02, ...,\n",
       "            1.88925847e-01, -7.34090805e-02,  1.06956670e-02],\n",
       "          ...,\n",
       "          [-2.29296818e-01,  2.10899878e-02, -9.44188386e-02, ...,\n",
       "           -9.66594592e-02, -2.73038242e-02,  2.11687628e-02],\n",
       "          [-3.93634886e-02,  7.50293657e-02,  5.03320768e-02, ...,\n",
       "            1.62452180e-02, -3.45222466e-02,  7.04753026e-02],\n",
       "          [ 2.57885396e-01, -2.06458107e-01,  6.23575449e-02, ...,\n",
       "            1.11102223e-01,  7.87333921e-02,  1.40553759e-02]],\n",
       " \n",
       "         [[ 1.50737375e-01, -2.24321738e-01, -8.98155421e-02, ...,\n",
       "            1.37781044e-02, -7.38961101e-02,  3.99008095e-02],\n",
       "          [ 1.99527582e-04,  1.14796653e-01,  1.05756290e-01, ...,\n",
       "            5.92114739e-02, -6.59033060e-02,  4.16472405e-02],\n",
       "          [ 1.57434940e-01,  1.11790903e-01, -1.24705411e-01, ...,\n",
       "            1.71684413e-04,  7.72841349e-02,  1.51669666e-01],\n",
       "          ...,\n",
       "          [-1.91988260e-01, -2.27455541e-01, -4.44848984e-02, ...,\n",
       "           -7.27456808e-02,  1.02865972e-01,  1.93448722e-01],\n",
       "          [ 1.05917752e-02,  7.66177252e-02, -6.00660779e-02, ...,\n",
       "            4.78286780e-02, -9.51367989e-02, -7.88431540e-02],\n",
       "          [ 7.32918009e-02, -1.37372330e-01, -8.66666716e-03, ...,\n",
       "           -8.31506401e-02, -1.07522331e-01,  2.09729061e-01]],\n",
       " \n",
       "         [[-1.63470984e-01, -3.95444147e-02,  7.14684129e-02, ...,\n",
       "            2.01797664e-01, -1.13970302e-01,  5.36879487e-02],\n",
       "          [ 1.09128103e-01,  4.21745479e-02, -8.81243497e-02, ...,\n",
       "            6.88272566e-02,  9.03178081e-02, -1.82178721e-01],\n",
       "          [-3.65901850e-02,  1.60612792e-01, -5.96494190e-02, ...,\n",
       "           -1.14659913e-01, -1.00550748e-01,  1.55766860e-01],\n",
       "          ...,\n",
       "          [ 1.61529183e-02, -5.18444888e-02,  1.05371855e-01, ...,\n",
       "            3.01720370e-02,  7.38427863e-02, -5.46344630e-02],\n",
       "          [ 3.24497521e-02,  8.19496531e-03, -1.79977715e-01, ...,\n",
       "           -6.11574799e-02,  1.19388290e-02, -2.22807482e-01],\n",
       "          [ 1.10956468e-01,  5.65275326e-02,  8.78927484e-02, ...,\n",
       "           -4.30389047e-02, -1.78411265e-03, -5.45122810e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.42470658e-01, -8.26923475e-02, -1.43517032e-01, ...,\n",
       "            1.04918098e-03, -1.02142878e-01,  3.11786979e-02],\n",
       "          [ 3.44385840e-02, -6.58522546e-02, -3.71599756e-02, ...,\n",
       "            5.32118827e-02,  2.76685730e-02, -8.95325691e-02],\n",
       "          [ 1.17606901e-01,  1.19070448e-01, -1.26663327e-01, ...,\n",
       "            8.20071995e-02, -4.49615605e-02,  4.15941961e-02],\n",
       "          ...,\n",
       "          [-1.50136977e-01,  1.13700949e-01,  6.38411939e-02, ...,\n",
       "            2.06812501e-01,  7.61156827e-02,  2.16070622e-01],\n",
       "          [ 9.12752226e-02,  9.98813435e-02, -1.20496824e-01, ...,\n",
       "           -5.77885285e-02, -3.63204405e-02,  3.03374939e-02],\n",
       "          [-7.20914528e-02,  9.35748592e-02, -1.78747267e-01, ...,\n",
       "            2.90975273e-02,  3.89528321e-03,  1.08856251e-02]],\n",
       " \n",
       "         [[ 1.58911943e-01, -1.94626406e-01, -1.26916915e-01, ...,\n",
       "           -3.38958859e-01, -2.52379477e-02,  8.72443467e-02],\n",
       "          [ 1.10197641e-01,  1.41739130e-01, -1.73953801e-01, ...,\n",
       "            5.03718248e-03,  4.56337519e-02, -1.20243192e-01],\n",
       "          [ 1.14577927e-01, -6.62870239e-03, -2.06026599e-01, ...,\n",
       "            1.09012388e-01, -2.15100735e-01,  8.65744334e-03],\n",
       "          ...,\n",
       "          [-1.09672002e-01, -3.87323089e-02, -1.43189698e-01, ...,\n",
       "           -1.11334413e-01,  2.14176580e-01,  1.98536739e-01],\n",
       "          [ 6.16259761e-02,  1.01091556e-01, -2.18556270e-01, ...,\n",
       "            1.41582653e-01, -1.01461232e-01, -6.75398707e-02],\n",
       "          [ 9.99473333e-02, -2.71994695e-02, -2.13994935e-01, ...,\n",
       "           -4.57917377e-02,  7.46775791e-02, -4.05087173e-02]],\n",
       " \n",
       "         [[ 2.04373873e-03, -5.62337376e-02, -8.47510546e-02, ...,\n",
       "            1.28246099e-02, -2.50646137e-02, -1.40004665e-01],\n",
       "          [ 1.79517642e-01,  8.58059525e-02, -3.59155506e-01, ...,\n",
       "           -5.14287539e-02,  1.47699388e-02,  2.23910585e-02],\n",
       "          [ 2.20186040e-02,  9.22620818e-02, -1.55546352e-01, ...,\n",
       "           -8.16372856e-02,  6.12687320e-02,  2.63206542e-01],\n",
       "          ...,\n",
       "          [ 1.27789691e-01, -6.70180544e-02, -3.59542519e-02, ...,\n",
       "           -8.47531855e-03,  1.84450299e-01,  5.63236028e-02],\n",
       "          [-1.29577309e-01,  1.64748967e-01, -1.94594666e-01, ...,\n",
       "            1.35015592e-01,  1.25587896e-01, -1.08623683e-01],\n",
       "          [ 1.48084819e-01,  1.47463800e-02, -1.50614902e-01, ...,\n",
       "            1.81959867e-02, -2.70470437e-02,  7.61191547e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block3_conv1_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([ 0.05270449,  0.01395325, -0.02614759, -0.0438072 , -0.02251173,\n",
       "         0.02816219,  0.0492787 , -0.02180896, -0.07235964,  0.12015276,\n",
       "         0.02062634,  0.05199396, -0.02929045,  0.01742029,  0.02077341,\n",
       "         0.13627605, -0.04350011, -0.05289906,  0.03851723, -0.04858331,\n",
       "         0.03237765,  0.02886071,  0.06891674,  0.02196848, -0.02640361,\n",
       "         0.060614  , -0.01092822, -0.06552494, -0.02069115,  0.11135875,\n",
       "        -0.132773  ,  0.0057355 ], dtype=float32)>,\n",
       " <tf.Variable 'block3_conv2_1/kernel:0' shape=(3, 3, 32, 32) dtype=float32, numpy=\n",
       " array([[[[ 4.64379322e-03, -1.45269139e-02, -4.84507680e-02, ...,\n",
       "            1.62961334e-01, -7.44700283e-02,  1.78417519e-01],\n",
       "          [-7.37560093e-02,  2.40202755e-01, -6.72533512e-02, ...,\n",
       "            9.69463121e-03, -4.32181405e-03,  1.20064072e-01],\n",
       "          [-2.68297084e-02,  7.53340945e-02,  3.19797993e-01, ...,\n",
       "            6.69235662e-02,  8.78632069e-02, -1.49975687e-01],\n",
       "          ...,\n",
       "          [-1.95616018e-02, -4.10775393e-02,  8.92943442e-02, ...,\n",
       "           -3.01985685e-02, -1.01629905e-01, -5.87325264e-03],\n",
       "          [-8.73864070e-02,  4.97032553e-02, -3.87545973e-02, ...,\n",
       "            5.71087003e-03,  2.99372766e-02, -5.64656705e-02],\n",
       "          [-1.08023256e-01,  4.44062352e-02,  2.70296205e-02, ...,\n",
       "           -9.54286568e-03,  2.65732268e-03,  7.89151192e-02]],\n",
       " \n",
       "         [[-8.68887454e-03,  4.77143526e-02, -1.09260976e-02, ...,\n",
       "           -5.09236529e-02, -7.21687600e-02,  1.16386600e-02],\n",
       "          [-2.76444815e-02,  6.74364194e-02,  7.48044476e-02, ...,\n",
       "           -6.59494698e-02, -1.08436674e-01,  2.09535584e-02],\n",
       "          [-1.13169074e-01,  5.45522571e-02,  3.54724526e-01, ...,\n",
       "            2.65830904e-01,  1.35121226e-01, -1.89655989e-01],\n",
       "          ...,\n",
       "          [ 4.38104160e-02, -4.88885455e-02,  5.84785342e-02, ...,\n",
       "            8.56858119e-03,  2.35893615e-02, -1.21577732e-01],\n",
       "          [-1.74198002e-02,  7.86439180e-02, -1.03719383e-01, ...,\n",
       "            2.26053879e-01,  1.28546298e-01, -1.58751324e-01],\n",
       "          [-9.66782868e-02,  8.40935260e-02,  5.96268699e-02, ...,\n",
       "            5.47615588e-02,  7.67558888e-02,  1.39885351e-01]],\n",
       " \n",
       "         [[ 1.00526847e-02, -7.96790570e-02, -1.33060127e-01, ...,\n",
       "           -1.52697518e-01, -1.60175879e-02,  1.51049569e-01],\n",
       "          [-8.83804485e-02,  3.00406944e-02, -7.21299946e-02, ...,\n",
       "           -3.08421534e-02, -7.04520568e-02, -2.43440848e-02],\n",
       "          [-9.37391669e-02,  9.28055868e-02,  9.63269919e-02, ...,\n",
       "            2.04458684e-01,  1.82275474e-02, -8.72628391e-03],\n",
       "          ...,\n",
       "          [ 8.72628689e-02, -1.02523878e-01,  9.73355398e-02, ...,\n",
       "           -8.67058933e-02,  7.36018196e-02, -1.37762027e-02],\n",
       "          [ 6.13179281e-02,  1.65899210e-02, -1.53007060e-01, ...,\n",
       "           -3.46158408e-02,  4.23137285e-02, -1.90994982e-02],\n",
       "          [ 1.40187293e-02, -1.08063146e-01, -1.29391596e-01, ...,\n",
       "           -1.63744271e-01,  1.86932161e-01,  6.85166642e-02]]],\n",
       " \n",
       " \n",
       "        [[[-3.23621184e-02,  1.93647861e-01, -1.49379551e-01, ...,\n",
       "            7.86853675e-03,  5.25130928e-02,  4.76300791e-02],\n",
       "          [ 9.32978019e-02, -2.04162486e-02,  1.59345329e-01, ...,\n",
       "           -1.57479510e-01, -1.00825496e-01,  9.69137698e-02],\n",
       "          [-7.30775669e-02, -1.39120877e-01, -2.30975598e-01, ...,\n",
       "            2.33770251e-01,  1.83124006e-01,  7.61563554e-02],\n",
       "          ...,\n",
       "          [ 5.12192212e-02,  1.79247350e-01, -2.93069240e-03, ...,\n",
       "           -2.28935331e-01,  6.30504042e-02, -3.81062776e-02],\n",
       "          [ 4.56713624e-02,  1.56975444e-03,  5.53036928e-02, ...,\n",
       "           -3.17240916e-02,  4.57149744e-02, -4.85520400e-02],\n",
       "          [-2.41173934e-02,  1.56920761e-01, -1.21411353e-01, ...,\n",
       "           -9.32113752e-02, -6.07272983e-03, -4.60091792e-03]],\n",
       " \n",
       "         [[-9.99224260e-02,  5.45006096e-02, -9.21133012e-02, ...,\n",
       "            1.71993356e-02, -2.17060521e-02,  4.16226387e-02],\n",
       "          [-8.50054771e-02,  1.34404421e-01,  1.24561675e-01, ...,\n",
       "            1.92634598e-03, -9.92434099e-03,  9.17705595e-02],\n",
       "          [ 1.80507619e-02, -3.12535107e-01, -2.03100204e-01, ...,\n",
       "            1.75051168e-01,  1.05700910e-01,  1.43954322e-01],\n",
       "          ...,\n",
       "          [ 5.44689968e-02,  1.94694072e-01,  7.92837217e-02, ...,\n",
       "           -6.23790286e-02,  1.44067511e-01, -5.77038489e-02],\n",
       "          [-7.46005997e-02, -1.97548866e-01,  9.05777514e-02, ...,\n",
       "           -7.58402376e-03,  4.65772226e-02, -3.12358420e-02],\n",
       "          [ 1.91263296e-02,  1.61745429e-01,  1.54018058e-02, ...,\n",
       "           -1.50081702e-02,  1.17122091e-01, -1.43598065e-01]],\n",
       " \n",
       "         [[ 8.42251629e-03, -6.78694993e-02, -6.82576746e-02, ...,\n",
       "           -2.52577066e-01, -3.65878135e-01,  8.51876736e-02],\n",
       "          [ 8.04926753e-02,  1.13890938e-01,  4.69477905e-04, ...,\n",
       "           -1.59243103e-02, -5.87508194e-02,  2.07976648e-03],\n",
       "          [-8.76770820e-03, -2.28006646e-01, -1.52099594e-01, ...,\n",
       "           -5.67340069e-02,  8.03594813e-02,  1.01179026e-01],\n",
       "          ...,\n",
       "          [-5.16568609e-02,  1.08383149e-01,  6.02502711e-02, ...,\n",
       "           -1.95795558e-02,  1.10286601e-01,  3.78263555e-02],\n",
       "          [-1.13216780e-01,  4.62190509e-02, -4.77797203e-02, ...,\n",
       "           -2.66311109e-01,  1.58724859e-02, -6.11043070e-03],\n",
       "          [-2.99961884e-02, -4.90196273e-02, -1.41015882e-02, ...,\n",
       "           -1.05044723e-01,  1.31868720e-01, -3.60448961e-03]]],\n",
       " \n",
       " \n",
       "        [[[-8.56627375e-02,  1.19717717e-01, -2.41109207e-02, ...,\n",
       "            2.08951935e-01, -7.46202767e-02,  6.46004975e-02],\n",
       "          [-4.95939367e-02,  1.09996935e-02, -6.40212744e-03, ...,\n",
       "            1.18166186e-01, -9.48073342e-02, -6.37510121e-02],\n",
       "          [-3.18035185e-02, -3.98015827e-02,  2.94308877e-03, ...,\n",
       "            2.84511268e-01, -1.36580780e-01, -1.01867057e-01],\n",
       "          ...,\n",
       "          [-5.74814826e-02, -1.06346849e-02,  4.98751849e-02, ...,\n",
       "           -1.41160190e-01, -1.42133072e-01,  2.08079834e-02],\n",
       "          [-3.08286231e-02, -1.90179750e-01,  7.32389046e-03, ...,\n",
       "            4.76551875e-02, -4.30757701e-02, -1.29647657e-01],\n",
       "          [-3.27946246e-02, -1.76149548e-03, -8.92831087e-02, ...,\n",
       "           -2.01704293e-01, -1.61241114e-01, -5.08408658e-02]],\n",
       " \n",
       "         [[-9.02605802e-02,  4.99182269e-02, -2.10307743e-02, ...,\n",
       "            2.46490091e-02, -5.29683661e-04,  8.94864425e-02],\n",
       "          [ 9.45859328e-02, -9.25145894e-02,  1.28287047e-01, ...,\n",
       "           -6.91946875e-03, -1.76904604e-01, -9.64344516e-02],\n",
       "          [-3.87359061e-03, -7.09912926e-02, -1.21307380e-01, ...,\n",
       "            9.31505561e-02, -6.16257377e-02,  4.74457676e-03],\n",
       "          ...,\n",
       "          [ 7.91055802e-03,  3.44327129e-02,  4.91381921e-02, ...,\n",
       "           -1.87583249e-02, -1.56002149e-01,  1.14127453e-02],\n",
       "          [-5.32368831e-02, -1.33159161e-01,  1.68336958e-01, ...,\n",
       "           -6.34807274e-02,  2.56546289e-02, -1.52117312e-01],\n",
       "          [-1.00408554e-01,  1.22072130e-01, -2.28105914e-02, ...,\n",
       "            1.00209760e-02, -9.60677713e-02, -1.34388417e-01]],\n",
       " \n",
       "         [[-9.65886563e-02, -6.90659732e-02,  1.59052461e-02, ...,\n",
       "           -1.90828919e-01, -2.66075283e-01, -1.24039397e-01],\n",
       "          [ 3.60579267e-02, -2.23241478e-01,  2.93289088e-02, ...,\n",
       "           -8.58565792e-03, -1.85171068e-01,  6.38070777e-02],\n",
       "          [-4.57979515e-02, -7.26696029e-02, -1.11039188e-02, ...,\n",
       "            4.76859435e-02, -1.39062498e-02, -8.27326626e-02],\n",
       "          ...,\n",
       "          [ 2.60455646e-02,  1.51382275e-02, -3.05068959e-03, ...,\n",
       "           -1.16661213e-01, -1.26574680e-01,  3.68956588e-02],\n",
       "          [-2.60296190e-04,  1.03239842e-01,  7.40754083e-02, ...,\n",
       "           -2.43594959e-01, -1.47546440e-01, -3.08583528e-02],\n",
       "          [-8.11261535e-02, -3.16054046e-01,  3.40960361e-02, ...,\n",
       "            1.61755949e-01,  2.69243047e-02, -1.61380231e-01]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block3_conv2_1/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.0413467 , -0.02213421, -0.03878728,  0.00331781, -0.01431121,\n",
       "         0.01545241, -0.00885268, -0.02440742, -0.09289605,  0.00080742,\n",
       "        -0.04746261, -0.02913542,  0.05924162, -0.01816259,  0.0414461 ,\n",
       "         0.02897776,  0.01780345, -0.02071539, -0.04745152,  0.01752318,\n",
       "         0.05352394, -0.02129876, -0.06047646, -0.06541996, -0.05828405,\n",
       "         0.05290334,  0.03597396,  0.01732876, -0.05689371, -0.01476592,\n",
       "         0.03187192,  0.04156673], dtype=float32)>,\n",
       " <tf.Variable 'block4_conv1_1/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
       " array([[[[-1.55260442e-02,  4.29699831e-02,  1.60119832e-02, ...,\n",
       "           -1.48435133e-02, -1.09191887e-01,  4.85719647e-03],\n",
       "          [-1.01692349e-01, -5.72299846e-02, -7.91607723e-02, ...,\n",
       "           -5.06544784e-02, -1.97198734e-01, -1.39995553e-02],\n",
       "          [ 9.86888632e-02,  1.10996567e-01, -2.11128704e-02, ...,\n",
       "           -1.49854422e-01, -2.10609268e-02,  1.15452714e-01],\n",
       "          ...,\n",
       "          [-1.65352270e-01,  9.60034654e-02, -6.86216950e-02, ...,\n",
       "           -1.44718915e-01,  1.46373510e-02,  2.39560142e-01],\n",
       "          [-5.41234799e-02,  2.79278141e-02, -1.44884676e-01, ...,\n",
       "            7.82184526e-02,  8.65025595e-02, -6.80617318e-02],\n",
       "          [-1.02015577e-01, -3.78246456e-02,  2.41439510e-02, ...,\n",
       "            5.84357418e-02,  3.77654545e-02, -2.24118307e-02]],\n",
       " \n",
       "         [[ 8.43438432e-02,  7.07714334e-02, -4.38430458e-02, ...,\n",
       "           -5.71902953e-02, -2.68483777e-02, -6.35265857e-02],\n",
       "          [-8.12796876e-02, -1.29017293e-01, -8.45280886e-02, ...,\n",
       "           -3.62162814e-02, -2.75004119e-01, -1.39139146e-01],\n",
       "          [ 2.25514988e-03,  1.30183667e-01,  6.66930303e-02, ...,\n",
       "            1.13263465e-01,  3.05199046e-02,  1.31630957e-01],\n",
       "          ...,\n",
       "          [ 7.33143762e-02, -1.93347573e-01, -2.16192883e-02, ...,\n",
       "           -1.24039590e-01,  1.28351599e-01, -6.35525733e-02],\n",
       "          [ 1.95118040e-02,  1.36334762e-01, -1.06537536e-01, ...,\n",
       "           -2.53194571e-02,  2.72438467e-01, -1.19508967e-01],\n",
       "          [ 1.40881576e-02, -1.12817220e-01, -3.92206758e-02, ...,\n",
       "           -6.17990689e-03, -6.51182383e-02,  4.38196771e-02]],\n",
       " \n",
       "         [[-2.95595154e-02, -4.38136570e-02,  1.54927475e-02, ...,\n",
       "            5.55580221e-02,  4.53650020e-03,  5.08745536e-02],\n",
       "          [ 8.16383287e-02,  4.54428196e-02, -1.00705072e-01, ...,\n",
       "            3.63973491e-02, -3.72342654e-02,  4.73027937e-02],\n",
       "          [ 2.56452784e-02,  1.06612124e-01,  8.81550312e-02, ...,\n",
       "           -1.16155677e-01,  4.23446484e-02,  2.06574038e-01],\n",
       "          ...,\n",
       "          [ 1.99568905e-02, -9.08425748e-02,  2.93703359e-02, ...,\n",
       "           -4.20398712e-02,  6.79147318e-02,  2.61403490e-02],\n",
       "          [-1.85841873e-01,  1.71614140e-02,  1.33328664e-04, ...,\n",
       "           -1.26947705e-02,  2.16211025e-02, -2.46584550e-01],\n",
       "          [-4.01330777e-02, -3.35319079e-02,  1.56518102e-01, ...,\n",
       "           -4.65510823e-02,  3.07045970e-02, -4.65934910e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.58174352e-02,  3.40796709e-02,  1.54100731e-02, ...,\n",
       "            5.36640063e-02,  1.03625832e-02,  7.81157892e-03],\n",
       "          [-2.61465371e-01, -2.35579684e-01, -4.24411707e-02, ...,\n",
       "            2.60087810e-02,  7.70369321e-02,  4.13933769e-02],\n",
       "          [ 8.36879462e-02,  1.99617192e-01,  1.56477705e-01, ...,\n",
       "           -2.33240314e-02, -1.69961154e-01, -1.24596231e-01],\n",
       "          ...,\n",
       "          [ 2.46787053e-02,  1.27480045e-01, -6.50150627e-02, ...,\n",
       "           -1.94203109e-01,  1.05244562e-01,  1.25388071e-01],\n",
       "          [ 8.23443756e-02,  2.95538306e-02, -5.10801189e-02, ...,\n",
       "           -1.04908057e-01, -4.22791056e-02,  6.38689771e-02],\n",
       "          [-6.39429390e-02,  2.92486753e-02, -1.48975343e-01, ...,\n",
       "           -3.10960803e-02, -1.55389346e-02, -5.32930270e-02]],\n",
       " \n",
       "         [[ 2.98501272e-02,  3.46587263e-02, -2.87777781e-02, ...,\n",
       "            7.78037757e-02, -2.94829477e-02,  1.89284254e-02],\n",
       "          [-8.56255740e-02, -2.81484067e-01,  1.11602239e-01, ...,\n",
       "           -6.13619126e-02,  1.43669769e-01,  6.67924061e-02],\n",
       "          [ 2.19868068e-02,  6.76741078e-02,  6.54903576e-02, ...,\n",
       "           -2.19170049e-01,  5.35421707e-02,  7.26847276e-02],\n",
       "          ...,\n",
       "          [ 1.38896450e-01, -2.94335913e-02, -8.79875198e-02, ...,\n",
       "            5.82666919e-02,  7.57076368e-02, -1.43493101e-01],\n",
       "          [ 4.17224169e-02, -5.33872284e-03, -1.49580324e-02, ...,\n",
       "           -1.21009439e-01, -9.93030444e-02, -6.25629425e-02],\n",
       "          [-7.63503090e-02,  2.74207518e-02, -2.18607555e-03, ...,\n",
       "           -3.77042815e-02,  4.78217527e-02,  7.87722506e-03]],\n",
       " \n",
       "         [[ 1.20367119e-02, -1.89105719e-02, -1.50967482e-03, ...,\n",
       "            8.80312175e-02,  6.24406189e-02,  4.84545678e-02],\n",
       "          [ 1.87899787e-02, -5.26941530e-02,  3.99767086e-02, ...,\n",
       "           -1.76918492e-01, -2.10409109e-02, -8.42533633e-02],\n",
       "          [ 3.76352668e-02,  1.75693914e-01,  1.02324128e-01, ...,\n",
       "           -2.10733376e-02,  8.63311887e-02,  9.67567563e-02],\n",
       "          ...,\n",
       "          [ 2.50629280e-02, -2.93976385e-02, -6.41312078e-02, ...,\n",
       "           -1.80634141e-01,  4.81217392e-02, -1.34608850e-01],\n",
       "          [-1.44351333e-01,  1.33738339e-01,  1.37978554e-01, ...,\n",
       "           -2.91961342e-01, -1.21868722e-01,  2.11303547e-01],\n",
       "          [-2.41972625e-01, -5.38284667e-02,  1.31732360e-01, ...,\n",
       "            7.14666843e-02,  9.31823775e-02, -1.30289420e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 4.91104275e-02,  1.48632079e-02,  8.46529379e-02, ...,\n",
       "           -8.97717699e-02,  6.74520358e-02, -7.20037031e-04],\n",
       "          [ 1.34767890e-01,  5.33240885e-02,  2.62424164e-02, ...,\n",
       "           -7.05319196e-02, -3.28131504e-02, -6.82030097e-02],\n",
       "          [ 3.97861563e-03,  1.87480927e-01, -1.87772721e-01, ...,\n",
       "           -8.82136747e-02, -9.20305178e-02, -1.38884887e-01],\n",
       "          ...,\n",
       "          [ 1.90383643e-02,  1.32553279e-01, -1.91076454e-02, ...,\n",
       "           -9.97537971e-02,  1.53835323e-02,  9.03435573e-02],\n",
       "          [ 4.09041485e-03, -5.12963645e-02, -2.17673302e-01, ...,\n",
       "           -2.34425813e-02,  9.12181213e-02,  1.18830547e-01],\n",
       "          [ 1.19216301e-01,  3.19285728e-02, -1.29479691e-01, ...,\n",
       "            1.95338670e-02, -3.89465019e-02, -1.47845661e-02]],\n",
       " \n",
       "         [[ 2.17889640e-02,  6.76762760e-02, -7.27587119e-02, ...,\n",
       "           -1.72292814e-02, -3.88269424e-02,  4.28501703e-02],\n",
       "          [ 1.96654692e-01, -1.00219831e-01,  5.05155558e-03, ...,\n",
       "           -2.41288096e-02,  1.69370119e-02, -1.92805380e-01],\n",
       "          [ 8.90902877e-02, -3.24614495e-02, -5.00755850e-04, ...,\n",
       "            2.63251327e-02,  5.70382066e-02,  3.34162004e-02],\n",
       "          ...,\n",
       "          [ 3.31057757e-02, -2.46718153e-02, -2.69965619e-01, ...,\n",
       "            9.38228704e-03, -6.00121357e-02, -1.09594926e-01],\n",
       "          [ 5.34251914e-04,  3.30792144e-02, -1.66965112e-01, ...,\n",
       "            3.94431241e-02,  5.98418154e-03, -2.36703530e-02],\n",
       "          [ 8.06164965e-02,  3.83278243e-02, -1.77812263e-01, ...,\n",
       "            1.07119106e-01,  2.19678041e-02,  6.98172450e-02]],\n",
       " \n",
       "         [[ 2.08380744e-02, -5.92145287e-02, -7.73972571e-02, ...,\n",
       "           -2.15836260e-02,  2.55488383e-04,  1.97653612e-03],\n",
       "          [ 8.94577876e-02, -1.24435551e-01,  1.13445051e-01, ...,\n",
       "           -2.54187435e-01, -1.26135185e-01,  9.93003044e-03],\n",
       "          [-3.01501118e-02, -1.53820813e-01, -9.81429741e-02, ...,\n",
       "           -8.42024311e-02, -5.17022498e-02,  3.64217050e-02],\n",
       "          ...,\n",
       "          [-4.08996828e-02,  1.01675279e-02, -1.37654737e-01, ...,\n",
       "           -3.80442180e-02, -4.54430878e-02, -1.45688608e-01],\n",
       "          [ 6.88124523e-02,  7.42973909e-02,  5.23839779e-02, ...,\n",
       "           -1.63105484e-02,  1.60576075e-01,  1.89609434e-02],\n",
       "          [ 8.28203261e-02, -1.53993303e-02,  1.27629578e-01, ...,\n",
       "           -6.11413233e-02,  4.81018052e-02, -3.96746136e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block4_conv1_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.00644488, -0.0009889 , -0.01926991,  0.04922472,  0.01101981,\n",
       "        -0.08647145,  0.01695867, -0.03984115,  0.01700874, -0.06200489,\n",
       "         0.04640476, -0.02281157,  0.05040006, -0.02048568,  0.05746902,\n",
       "         0.01716051, -0.09430824,  0.05759108,  0.00701321, -0.081028  ,\n",
       "         0.00409516,  0.04275201,  0.03777223,  0.0638419 ,  0.0613466 ,\n",
       "         0.03727576,  0.05711206, -0.02072546,  0.05306051, -0.04563944,\n",
       "         0.00594788,  0.01413954, -0.03463731, -0.04147057, -0.05280029,\n",
       "         0.11506597, -0.01788523, -0.02690724,  0.05896826,  0.07454587,\n",
       "         0.06924745, -0.02799801,  0.0402174 , -0.04252565,  0.10278998,\n",
       "        -0.02171258, -0.03265955, -0.00962048, -0.0289375 ,  0.03448914,\n",
       "         0.07435044,  0.03247574, -0.00278036,  0.02613997,  0.02704436,\n",
       "         0.00623662,  0.02770756, -0.04701415,  0.07123421, -0.04090777,\n",
       "         0.0187374 ,  0.03120983, -0.00839418,  0.1013013 ], dtype=float32)>,\n",
       " <tf.Variable 'block4_conv2_1/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
       " array([[[[ 4.24578004e-02, -1.75770652e-02, -2.90819854e-02, ...,\n",
       "            1.99400373e-02, -5.63298799e-02,  4.65091690e-02],\n",
       "          [ 1.88729256e-01, -6.94331378e-02, -1.58620298e-01, ...,\n",
       "            5.46928681e-02, -1.58007637e-01, -9.17410105e-03],\n",
       "          [-3.61039527e-02, -2.10561845e-02, -1.30729631e-01, ...,\n",
       "           -7.12873712e-02, -1.56044349e-01,  8.65158159e-03],\n",
       "          ...,\n",
       "          [ 1.36892334e-01,  6.61565224e-03,  1.80915609e-01, ...,\n",
       "            8.61502194e-04,  4.79017347e-02, -1.82719022e-01],\n",
       "          [ 1.59171000e-02, -4.98292670e-02,  1.36028498e-01, ...,\n",
       "           -6.75545959e-03, -1.66032314e-01, -4.56679240e-02],\n",
       "          [ 8.08104202e-02, -1.86303805e-04, -1.14193909e-01, ...,\n",
       "           -1.09851025e-01,  1.15293168e-01,  1.36717826e-01]],\n",
       " \n",
       "         [[-5.71764493e-03, -7.28269219e-02, -5.01319207e-02, ...,\n",
       "            4.04930636e-02, -1.74753293e-02,  1.15090637e-02],\n",
       "          [ 1.48684485e-02, -4.88123447e-02,  6.96073025e-02, ...,\n",
       "            8.78620893e-02, -1.56944126e-01, -1.22817464e-01],\n",
       "          [ 3.25117670e-02,  9.77435242e-03,  5.94617203e-02, ...,\n",
       "           -3.23082991e-02, -1.41032070e-01, -9.96516123e-02],\n",
       "          ...,\n",
       "          [ 1.07921720e-01,  1.96037907e-02,  1.92916334e-01, ...,\n",
       "            7.25218430e-02, -6.88662976e-02,  5.52506652e-03],\n",
       "          [-1.25471562e-01, -1.63140073e-02,  1.06339402e-01, ...,\n",
       "            3.40647176e-02,  7.62391165e-02, -3.07666492e-02],\n",
       "          [ 7.44641721e-02, -7.61170611e-02,  5.59923984e-02, ...,\n",
       "           -2.69584488e-02, -3.87564227e-02, -6.75129443e-02]],\n",
       " \n",
       "         [[-5.33289649e-02,  2.20705359e-03,  6.94814464e-03, ...,\n",
       "           -8.28707777e-03,  1.00393988e-01, -7.91420043e-02],\n",
       "          [-4.25940081e-02,  1.03364186e-02,  1.56637896e-02, ...,\n",
       "           -1.67747051e-01, -2.41265465e-02, -8.28794390e-02],\n",
       "          [ 5.48668467e-02,  1.79644451e-02,  9.05189738e-02, ...,\n",
       "            3.41599844e-02, -1.79267630e-01, -1.15916498e-01],\n",
       "          ...,\n",
       "          [ 2.06728414e-01, -7.65093416e-02, -2.56201774e-02, ...,\n",
       "           -2.58253701e-02, -1.94545425e-02,  2.01311603e-01],\n",
       "          [-2.13605016e-02,  2.36527901e-02, -1.20268784e-01, ...,\n",
       "            6.19929321e-02,  1.48018792e-01,  4.15837727e-02],\n",
       "          [ 8.35622400e-02, -2.08124332e-02, -2.45578215e-02, ...,\n",
       "            5.34244929e-04, -2.16673180e-01,  1.76254332e-01]]],\n",
       " \n",
       " \n",
       "        [[[-2.81704701e-02, -5.93524501e-02,  6.91832900e-02, ...,\n",
       "           -1.15532607e-01,  3.89551483e-02,  6.53217360e-02],\n",
       "          [ 1.18493669e-01, -6.39767870e-02, -1.17735609e-01, ...,\n",
       "           -1.06945904e-02, -7.25259557e-02, -4.88508493e-03],\n",
       "          [-4.72042412e-02,  8.44193529e-03, -1.01277620e-01, ...,\n",
       "            3.02905235e-02, -1.47504911e-01, -8.72067362e-02],\n",
       "          ...,\n",
       "          [ 9.61360708e-02, -2.08878648e-02,  8.68890360e-02, ...,\n",
       "            4.29710150e-02, -4.43516299e-02, -1.34230778e-01],\n",
       "          [ 2.17915215e-02,  8.08770210e-03,  1.23898737e-01, ...,\n",
       "           -4.19038273e-02, -8.11931491e-02, -7.92077705e-02],\n",
       "          [-3.15871462e-02,  1.68255679e-02,  8.97265822e-02, ...,\n",
       "           -4.75924201e-02, -1.13151874e-02, -2.11271673e-01]],\n",
       " \n",
       "         [[-9.61157158e-02,  2.07652035e-03, -1.18906572e-02, ...,\n",
       "           -1.48137286e-01, -2.88417153e-02, -1.54403178e-02],\n",
       "          [-1.64383613e-02, -1.00682331e-02, -4.84895296e-02, ...,\n",
       "           -3.09029929e-02, -1.21208742e-01,  2.57574301e-02],\n",
       "          [-1.59537140e-02, -6.56181574e-02,  1.79032087e-02, ...,\n",
       "           -5.09976642e-03,  9.56381932e-02, -1.06115118e-01],\n",
       "          ...,\n",
       "          [-2.96069738e-02,  5.94289340e-02,  1.26474828e-01, ...,\n",
       "           -1.15655005e-01, -9.39308628e-02, -1.73443347e-01],\n",
       "          [-5.64778857e-02, -3.29900198e-02, -3.81661877e-02, ...,\n",
       "           -2.41612196e-02,  3.07460912e-02,  1.30784139e-02],\n",
       "          [ 1.57297313e-01, -4.75221723e-02,  5.28436387e-03, ...,\n",
       "           -4.50239852e-02, -9.17492621e-03, -9.56255049e-02]],\n",
       " \n",
       "         [[-1.29592912e-02, -5.47712222e-02, -1.96599234e-02, ...,\n",
       "           -8.11030865e-02, -6.54871538e-02, -1.98262542e-01],\n",
       "          [-8.86658505e-02, -4.09569591e-02, -7.70300329e-02, ...,\n",
       "           -1.71357710e-02, -2.19572112e-02, -1.71180025e-01],\n",
       "          [ 2.87549384e-02,  1.77047476e-02,  8.50377977e-02, ...,\n",
       "            2.34249886e-03, -1.03126638e-01,  6.81732967e-02],\n",
       "          ...,\n",
       "          [ 7.90483207e-02,  2.23884154e-02, -8.94823149e-02, ...,\n",
       "            5.95031641e-02, -1.38808265e-01,  1.37963563e-01],\n",
       "          [-7.39530474e-02,  1.07094208e-02, -1.48754373e-01, ...,\n",
       "           -1.13167152e-01,  7.89940059e-02, -8.76660123e-02],\n",
       "          [-1.92332715e-01, -1.07432611e-01, -4.06589620e-02, ...,\n",
       "           -7.05562308e-02, -6.26894385e-02,  3.70870158e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 7.08800927e-02,  1.94087848e-02, -1.03260212e-01, ...,\n",
       "            4.17516828e-02, -3.09266825e-03, -1.86366081e-01],\n",
       "          [-3.29714008e-02, -5.33525459e-02, -3.45356278e-02, ...,\n",
       "            5.35259172e-02, -3.02253701e-02, -1.33139014e-01],\n",
       "          [ 3.72600891e-02,  2.50905976e-02,  5.93923815e-02, ...,\n",
       "            3.01604765e-03, -2.84412708e-02,  7.53894746e-02],\n",
       "          ...,\n",
       "          [-5.20710982e-02,  1.83026660e-02,  7.03121051e-02, ...,\n",
       "           -8.11204240e-02, -7.84040391e-02,  5.74284839e-03],\n",
       "          [-9.42620039e-02, -5.75948954e-02,  1.10628381e-01, ...,\n",
       "            5.16734086e-02,  7.35791912e-03, -4.27877046e-02],\n",
       "          [ 5.92914596e-02, -4.15624268e-02, -3.17830667e-02, ...,\n",
       "            6.45765662e-02,  7.40219057e-02, -1.31967321e-01]],\n",
       " \n",
       "         [[ 1.25796258e-01, -4.45860922e-02, -1.09691724e-01, ...,\n",
       "           -8.94974470e-02, -4.78925966e-02,  4.35603596e-02],\n",
       "          [-4.50489819e-02, -4.83673159e-03, -4.84934673e-02, ...,\n",
       "           -3.08078527e-02,  6.27667382e-02, -6.17965683e-02],\n",
       "          [ 1.11282291e-02,  2.35093012e-02, -1.61266685e-01, ...,\n",
       "            2.68352237e-02,  8.56143609e-02, -9.60228145e-02],\n",
       "          ...,\n",
       "          [ 1.46397024e-01, -6.71163574e-02, -3.38651962e-03, ...,\n",
       "           -1.05778528e-02, -1.99623499e-02, -5.98649159e-02],\n",
       "          [-3.66176367e-02, -6.25772923e-02, -5.12801260e-02, ...,\n",
       "            6.71397056e-03, -4.96060550e-02,  1.64318740e-01],\n",
       "          [-1.33912131e-01, -1.30044490e-01,  1.61156550e-01, ...,\n",
       "           -6.04911745e-02, -4.11760285e-02, -1.99544579e-01]],\n",
       " \n",
       "         [[ 8.25285539e-02, -5.05311638e-02, -1.83054745e-01, ...,\n",
       "           -1.10174581e-01, -3.53274643e-02,  1.12451009e-01],\n",
       "          [-6.90533295e-02,  1.58779565e-02, -2.94374973e-02, ...,\n",
       "            7.88041651e-02,  4.36685234e-02, -2.80106775e-02],\n",
       "          [ 2.52607781e-02, -3.17940526e-02, -1.68588728e-01, ...,\n",
       "           -2.33467240e-02, -7.19077364e-02, -5.64123690e-02],\n",
       "          ...,\n",
       "          [ 1.42310336e-01, -3.51484939e-02,  2.14985646e-02, ...,\n",
       "            1.27954520e-02, -1.25590131e-01, -5.15063712e-03],\n",
       "          [-9.00147334e-02,  2.70881355e-02, -3.45693268e-02, ...,\n",
       "           -8.38263780e-02, -5.30232564e-02,  8.02567974e-02],\n",
       "          [ 1.05718393e-02, -4.28539887e-02, -3.76852266e-02, ...,\n",
       "            3.43133807e-02, -1.01722650e-01, -4.84579317e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block4_conv2_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.05508831, -0.02229997, -0.00968769, -0.04550084, -0.08126123,\n",
       "        -0.06106194,  0.04114856, -0.07398009,  0.01655144,  0.01704807,\n",
       "         0.01706564, -0.02488142,  0.02469777, -0.05407058,  0.06100659,\n",
       "        -0.05116475,  0.03189244, -0.05246597,  0.0456571 , -0.034254  ,\n",
       "        -0.03421891,  0.01601542, -0.0542433 , -0.07828677, -0.06263974,\n",
       "        -0.06685408,  0.00972797,  0.01769793, -0.03878922, -0.00928182,\n",
       "         0.08949172,  0.06537419, -0.00275765, -0.04346859, -0.03405137,\n",
       "        -0.029438  , -0.00160752,  0.07819726, -0.02971126,  0.05516427,\n",
       "        -0.00649754,  0.00546295,  0.00720266,  0.02218678, -0.03890484,\n",
       "        -0.04867972, -0.01160888,  0.02855054, -0.01984016,  0.04463401,\n",
       "        -0.04189594, -0.0640877 ,  0.00249633, -0.02166294,  0.03098443,\n",
       "         0.00145819, -0.04559668,  0.11386611, -0.05620257, -0.03088859,\n",
       "        -0.01919293, -0.05160645,  0.01690348,  0.01923154], dtype=float32)>,\n",
       " <tf.Variable 'block5_conv1_1/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
       " array([[[[-0.1422553 ,  0.0424499 , -0.07919364, ..., -0.21113713,\n",
       "            0.06674153,  0.13860978],\n",
       "          [-0.00503725,  0.00543488,  0.03989067, ...,  0.06014969,\n",
       "            0.00288037, -0.03462701],\n",
       "          [ 0.06315015, -0.01280621, -0.06093239, ...,  0.04726558,\n",
       "           -0.03742386, -0.09197612],\n",
       "          ...,\n",
       "          [ 0.01135268, -0.06274094,  0.06931488, ...,  0.08945943,\n",
       "            0.06484699, -0.05187508],\n",
       "          [ 0.06495129,  0.02441073, -0.08091202, ..., -0.05865206,\n",
       "           -0.05687386, -0.07834969],\n",
       "          [-0.16280586,  0.08647921, -0.04635988, ..., -0.067531  ,\n",
       "            0.01079056, -0.073209  ]],\n",
       " \n",
       "         [[-0.00690095,  0.11754296, -0.06102476, ..., -0.0977354 ,\n",
       "           -0.00161432, -0.0755766 ],\n",
       "          [-0.04904108,  0.03551738,  0.0642871 , ...,  0.01677295,\n",
       "            0.02373739, -0.0096953 ],\n",
       "          [ 0.03983833,  0.00590315,  0.03051326, ...,  0.11809801,\n",
       "            0.01050968,  0.08381465],\n",
       "          ...,\n",
       "          [-0.01775621, -0.0866277 ,  0.017793  , ...,  0.06046921,\n",
       "           -0.06163331,  0.00315664],\n",
       "          [ 0.0506989 ,  0.03944599, -0.05104249, ..., -0.01835539,\n",
       "           -0.0455513 ,  0.20095962],\n",
       "          [-0.0167858 ,  0.0707287 , -0.0654647 , ..., -0.13890219,\n",
       "            0.05564101, -0.01104713]],\n",
       " \n",
       "         [[-0.01772178, -0.04022823, -0.02024106, ..., -0.17257066,\n",
       "           -0.05299857, -0.04002355],\n",
       "          [ 0.03689537, -0.01600626, -0.04057588, ...,  0.0228039 ,\n",
       "            0.00555241, -0.05370576],\n",
       "          [-0.05246757,  0.07733803, -0.07779012, ..., -0.00261572,\n",
       "           -0.070543  , -0.09320086],\n",
       "          ...,\n",
       "          [-0.04375305, -0.06380259,  0.01337154, ...,  0.00317137,\n",
       "           -0.07844234, -0.04654114],\n",
       "          [ 0.08322644,  0.01918203,  0.00948095, ..., -0.01446415,\n",
       "           -0.09318421,  0.13901778],\n",
       "          [-0.06969796, -0.02247805,  0.03578528, ..., -0.16004382,\n",
       "            0.00194635,  0.07372496]]],\n",
       " \n",
       " \n",
       "        [[[-0.16614349,  0.03049465, -0.09252732, ...,  0.07985432,\n",
       "            0.08750661, -0.0373314 ],\n",
       "          [-0.0538897 ,  0.05107099,  0.01355999, ..., -0.07327428,\n",
       "            0.00339818, -0.043625  ],\n",
       "          [ 0.0062867 ,  0.0297691 , -0.09834417, ..., -0.07789819,\n",
       "           -0.04954934, -0.07388887],\n",
       "          ...,\n",
       "          [-0.06464076, -0.0365188 , -0.00842475, ..., -0.05632182,\n",
       "           -0.05509927,  0.05120765],\n",
       "          [ 0.055375  ,  0.06642758,  0.01293218, ...,  0.1670015 ,\n",
       "            0.04472586, -0.08083431],\n",
       "          [-0.09562883, -0.03994085,  0.01795914, ..., -0.06492851,\n",
       "           -0.0105214 ,  0.00391571]],\n",
       " \n",
       "         [[ 0.06818967, -0.06122873, -0.11429592, ..., -0.15207487,\n",
       "           -0.00252483,  0.0297398 ],\n",
       "          [-0.07139028, -0.09561235, -0.03584033, ..., -0.02504474,\n",
       "           -0.06419486, -0.05054204],\n",
       "          [-0.03190281,  0.09772506, -0.02762709, ...,  0.10535488,\n",
       "           -0.03603587,  0.03941749],\n",
       "          ...,\n",
       "          [-0.08466697, -0.00739886,  0.0037795 , ..., -0.08924358,\n",
       "           -0.08027039, -0.05090454],\n",
       "          [-0.08673776, -0.04655749, -0.02554302, ...,  0.09857798,\n",
       "           -0.06428079,  0.1647197 ],\n",
       "          [ 0.0570705 , -0.15234071, -0.0745059 , ..., -0.07697646,\n",
       "            0.03622343, -0.10072663]],\n",
       " \n",
       "         [[ 0.02185728, -0.0078348 ,  0.03563417, ...,  0.03778759,\n",
       "           -0.02365005, -0.09148222],\n",
       "          [-0.05790542, -0.03077646, -0.04779737, ...,  0.00394884,\n",
       "            0.02763583, -0.04678613],\n",
       "          [-0.08804923,  0.08556707, -0.06178867, ...,  0.13181832,\n",
       "            0.00482399, -0.1306037 ],\n",
       "          ...,\n",
       "          [ 0.02982816, -0.07952379, -0.02244077, ...,  0.02695922,\n",
       "           -0.07691156, -0.034744  ],\n",
       "          [ 0.04778855, -0.02710531, -0.0432464 , ...,  0.00636136,\n",
       "           -0.1078032 , -0.15201133],\n",
       "          [-0.09873018,  0.02443835, -0.07302126, ...,  0.11610997,\n",
       "           -0.06278247, -0.00902274]]],\n",
       " \n",
       " \n",
       "        [[[-0.22386016,  0.07000735,  0.00485258, ...,  0.14561813,\n",
       "            0.03127479, -0.11301986],\n",
       "          [ 0.0003089 , -0.00285955, -0.03435775, ..., -0.0485347 ,\n",
       "            0.02897569, -0.02001834],\n",
       "          [-0.06552529, -0.05339441, -0.03869858, ...,  0.08242392,\n",
       "            0.09493494,  0.0294857 ],\n",
       "          ...,\n",
       "          [-0.00986913, -0.03103998, -0.00253469, ..., -0.04717474,\n",
       "            0.07735202,  0.01903544],\n",
       "          [-0.1269988 , -0.03393587, -0.07315817, ..., -0.05057814,\n",
       "            0.04845335, -0.09063698],\n",
       "          [-0.2385755 ,  0.03022406, -0.10001194, ...,  0.0550352 ,\n",
       "           -0.01299428, -0.07805812]],\n",
       " \n",
       "         [[ 0.12441973, -0.06004163, -0.03266684, ...,  0.01299784,\n",
       "            0.09403169, -0.08488452],\n",
       "          [ 0.0421348 , -0.00498301, -0.00078236, ...,  0.03947644,\n",
       "            0.06970536, -0.0352056 ],\n",
       "          [ 0.04029804, -0.05994754, -0.10557733, ...,  0.00102571,\n",
       "           -0.04660452,  0.02734558],\n",
       "          ...,\n",
       "          [ 0.01843495,  0.00943983,  0.04105777, ...,  0.01035342,\n",
       "            0.09569399,  0.00568119],\n",
       "          [ 0.04569033,  0.0671237 , -0.01576436, ...,  0.09169772,\n",
       "           -0.0062779 ,  0.00187051],\n",
       "          [ 0.00359002, -0.09669246, -0.02995438, ..., -0.05156672,\n",
       "           -0.04408593, -0.10370971]],\n",
       " \n",
       "         [[ 0.03887335, -0.10842989,  0.00228014, ...,  0.16743103,\n",
       "           -0.06906919, -0.03505373],\n",
       "          [ 0.03698336, -0.0389303 , -0.02801064, ..., -0.0368383 ,\n",
       "           -0.05054613, -0.0512674 ],\n",
       "          [ 0.04962284,  0.02542456, -0.04409701, ..., -0.09852308,\n",
       "           -0.04399989,  0.00437901],\n",
       "          ...,\n",
       "          [ 0.02469145,  0.04852621, -0.05209327, ..., -0.07214226,\n",
       "           -0.01561269,  0.06338191],\n",
       "          [ 0.08553455,  0.03087647, -0.00442368, ..., -0.00418479,\n",
       "           -0.10636108, -0.17545167],\n",
       "          [ 0.02023296,  0.05076781, -0.08708315, ...,  0.12207841,\n",
       "           -0.22265653,  0.07619552]]]], dtype=float32)>,\n",
       " <tf.Variable 'block5_conv1_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.0595068 , -0.0603712 , -0.07698315,  0.13510379,  0.04413344,\n",
       "        -0.08165768, -0.04322824,  0.12375004,  0.05881825,  0.10918986,\n",
       "        -0.05438923, -0.02365148,  0.09199361,  0.01757854,  0.07617085,\n",
       "        -0.06261701, -0.00881808,  0.03276246,  0.12103041,  0.11188766,\n",
       "         0.06723686, -0.04903414, -0.00895702,  0.03586979,  0.02131132,\n",
       "         0.10907961,  0.08083378,  0.0212861 ,  0.03732964, -0.06524978,\n",
       "        -0.02178268,  0.06984692,  0.04708476,  0.06286582,  0.07663121,\n",
       "        -0.12034389,  0.11184014, -0.03485242, -0.09014326,  0.08391567,\n",
       "        -0.04031896, -0.08584298,  0.05832936, -0.02844102,  0.06863864,\n",
       "         0.09748392,  0.0089277 , -0.08512256,  0.04644008, -0.03234119,\n",
       "        -0.00809813,  0.09589204, -0.04547838, -0.03439233,  0.01345738,\n",
       "        -0.07121105, -0.06517407,  0.10602689,  0.04499425, -0.05244399,\n",
       "         0.00297821,  0.01832838,  0.00209699,  0.01703199], dtype=float32)>,\n",
       " <tf.Variable 'block5_conv2_1/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
       " array([[[[-0.05016839,  0.101923  ,  0.03364868, ..., -0.04420444,\n",
       "            0.03320104,  0.09343241],\n",
       "          [ 0.12055507,  0.07442542,  0.03758006, ...,  0.04410111,\n",
       "           -0.03557306, -0.1045952 ],\n",
       "          [-0.05869082, -0.01355597, -0.04206403, ...,  0.00486867,\n",
       "           -0.03309868, -0.07977667],\n",
       "          ...,\n",
       "          [-0.11701395, -0.13084024, -0.01718805, ..., -0.09705681,\n",
       "           -0.0879768 , -0.07683472],\n",
       "          [ 0.00665491, -0.05166163,  0.00312962, ..., -0.08554384,\n",
       "            0.17844608, -0.18861425],\n",
       "          [-0.06103267,  0.0248702 , -0.01943201, ..., -0.1304591 ,\n",
       "            0.10332444,  0.08536258]],\n",
       " \n",
       "         [[-0.08285408,  0.01569911, -0.00905626, ..., -0.09662335,\n",
       "            0.03023752, -0.08454923],\n",
       "          [ 0.07309613, -0.131608  , -0.00090295, ..., -0.02255353,\n",
       "            0.04875733, -0.28783852],\n",
       "          [ 0.00437537,  0.0396351 ,  0.04733235, ...,  0.00560301,\n",
       "           -0.00883341,  0.0012329 ],\n",
       "          ...,\n",
       "          [ 0.05137626, -0.04549007, -0.02549268, ...,  0.00927179,\n",
       "           -0.00719637, -0.0845494 ],\n",
       "          [ 0.02036292, -0.06039025, -0.07469512, ..., -0.06596202,\n",
       "           -0.07857096, -0.01811719],\n",
       "          [-0.04844438, -0.01631501,  0.0385968 , ...,  0.23401603,\n",
       "           -0.01770693,  0.16060986]],\n",
       " \n",
       "         [[ 0.06023682,  0.07907397, -0.05548333, ...,  0.10731944,\n",
       "           -0.07796887, -0.06789821],\n",
       "          [-0.11494996, -0.1046385 ,  0.01903802, ...,  0.01004436,\n",
       "            0.01354032, -0.07723995],\n",
       "          [ 0.06174294, -0.01808945, -0.04252006, ..., -0.05146782,\n",
       "            0.02554784, -0.03597006],\n",
       "          ...,\n",
       "          [-0.02070895, -0.06576853, -0.04381523, ..., -0.10473705,\n",
       "           -0.02462663,  0.09921013],\n",
       "          [-0.16711514, -0.02939066,  0.00057102, ...,  0.01688676,\n",
       "            0.12857187,  0.07430968],\n",
       "          [ 0.03292206,  0.07249909,  0.04586134, ...,  0.17287825,\n",
       "           -0.15022315, -0.1231757 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.03824165,  0.05172352, -0.05956583, ..., -0.02680102,\n",
       "            0.02130567, -0.00724404],\n",
       "          [-0.03353064, -0.06238594, -0.06502562, ..., -0.03154963,\n",
       "            0.24740578,  0.11347643],\n",
       "          [ 0.05675915,  0.02651221,  0.03815316, ..., -0.0146399 ,\n",
       "           -0.14371485,  0.01700954],\n",
       "          ...,\n",
       "          [-0.06063228, -0.16077882,  0.03836474, ..., -0.15725516,\n",
       "            0.19104113, -0.16090414],\n",
       "          [-0.04058751, -0.07125086, -0.05111338, ..., -0.05671268,\n",
       "            0.05822259, -0.03189227],\n",
       "          [-0.04868272,  0.03184446,  0.10728403, ..., -0.02820296,\n",
       "            0.14454836,  0.23991433]],\n",
       " \n",
       "         [[ 0.00356734,  0.0694048 , -0.00840101, ..., -0.03610129,\n",
       "            0.02612507, -0.03929599],\n",
       "          [ 0.05210905, -0.12585   , -0.07376626, ..., -0.1750361 ,\n",
       "           -0.01354646,  0.10521748],\n",
       "          [ 0.04202605, -0.07662473,  0.06213441, ..., -0.00354817,\n",
       "            0.03663892, -0.07264499],\n",
       "          ...,\n",
       "          [ 0.04001263,  0.00611611, -0.06308353, ..., -0.04432395,\n",
       "            0.00589254, -0.1316887 ],\n",
       "          [-0.11151492,  0.02875116, -0.04308467, ...,  0.04374658,\n",
       "           -0.0173231 , -0.03147582],\n",
       "          [ 0.02053884,  0.0784087 ,  0.05401681, ..., -0.10966658,\n",
       "            0.02236472,  0.12452649]],\n",
       " \n",
       "         [[ 0.05377747, -0.01726137, -0.00551502, ...,  0.02962224,\n",
       "           -0.12821724,  0.01136671],\n",
       "          [-0.03423538, -0.01913082, -0.03727417, ...,  0.0422889 ,\n",
       "           -0.03134911,  0.04659434],\n",
       "          [ 0.0638734 , -0.03726088,  0.0673721 , ...,  0.01946406,\n",
       "            0.00383004,  0.03408413],\n",
       "          ...,\n",
       "          [-0.12363655,  0.07076716, -0.06280306, ...,  0.02289652,\n",
       "           -0.04114541, -0.16446373],\n",
       "          [ 0.00305402,  0.1263347 , -0.03552651, ...,  0.01126759,\n",
       "           -0.02013587,  0.00936322],\n",
       "          [-0.06342339,  0.10017683,  0.03378446, ...,  0.07385163,\n",
       "            0.11518797, -0.13352004]]],\n",
       " \n",
       " \n",
       "        [[[-0.04963022, -0.01391675,  0.010642  , ..., -0.00798595,\n",
       "            0.02365189,  0.06363084],\n",
       "          [-0.00651092, -0.06995865,  0.01432812, ...,  0.05151549,\n",
       "           -0.01186081,  0.00082902],\n",
       "          [-0.03121994, -0.03528045,  0.03358718, ...,  0.02525585,\n",
       "           -0.12301067, -0.08459418],\n",
       "          ...,\n",
       "          [ 0.1506794 ,  0.06919577, -0.03546919, ...,  0.05044999,\n",
       "            0.02901866,  0.01385736],\n",
       "          [-0.15109757,  0.09541852, -0.10832898, ..., -0.06560248,\n",
       "           -0.11010189, -0.07816622],\n",
       "          [ 0.07658862,  0.05193828,  0.00150132, ...,  0.00878222,\n",
       "           -0.1337294 , -0.12001781]],\n",
       " \n",
       "         [[ 0.04337974, -0.07468735,  0.0071526 , ...,  0.02374668,\n",
       "           -0.00738512,  0.04777736],\n",
       "          [-0.04570596, -0.06633577, -0.08706616, ...,  0.03516884,\n",
       "            0.1628125 ,  0.0179832 ],\n",
       "          [ 0.01818756, -0.00402441, -0.00737866, ...,  0.0029101 ,\n",
       "           -0.05341384,  0.05757606],\n",
       "          ...,\n",
       "          [-0.08868402, -0.2127196 ,  0.02079703, ...,  0.03783715,\n",
       "           -0.20406583,  0.02024021],\n",
       "          [-0.11497599,  0.01098245, -0.08272528, ..., -0.09054031,\n",
       "           -0.07844195, -0.02965992],\n",
       "          [ 0.05025201, -0.10298611, -0.0284661 , ..., -0.14180827,\n",
       "           -0.04015013, -0.19605568]],\n",
       " \n",
       "         [[-0.00357291, -0.09657378,  0.04767715, ...,  0.06596185,\n",
       "           -0.04144634,  0.0344835 ],\n",
       "          [-0.19311343,  0.17298634, -0.07819428, ...,  0.08419067,\n",
       "           -0.12465863, -0.00410661],\n",
       "          [-0.14762379,  0.01917036, -0.02955645, ...,  0.04038593,\n",
       "           -0.00526437,  0.01635644],\n",
       "          ...,\n",
       "          [-0.17093073, -0.01427715, -0.07742327, ...,  0.03432609,\n",
       "           -0.1287307 , -0.00070478],\n",
       "          [ 0.08028453,  0.06778247, -0.04008727, ..., -0.07014482,\n",
       "           -0.01752861,  0.04486094],\n",
       "          [-0.13655858,  0.08612641, -0.02415027, ...,  0.03469587,\n",
       "            0.10259575,  0.01832152]]]], dtype=float32)>,\n",
       " <tf.Variable 'block5_conv2_1/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.03519373,  0.0283941 , -0.06144152, -0.1723273 , -0.00385332,\n",
       "         0.08581679, -0.05711399, -0.0602427 , -0.04173074,  0.07262771,\n",
       "        -0.00780725, -0.0433057 ,  0.07137303,  0.0613054 ,  0.0804925 ,\n",
       "         0.0138241 ,  0.01272641,  0.02586458,  0.04718261, -0.06985585,\n",
       "        -0.03904306,  0.0978395 ,  0.03572677, -0.03901838,  0.05525077,\n",
       "         0.07649741,  0.10738534,  0.05764117,  0.0102045 ,  0.03900284,\n",
       "         0.04087793,  0.09398682,  0.0027296 , -0.08734977,  0.05601458,\n",
       "        -0.03146032,  0.06358831, -0.06334798,  0.03441515,  0.07125542,\n",
       "         0.09809331,  0.00693313, -0.06256812, -0.09712574,  0.03110361,\n",
       "        -0.01416072, -0.04345967, -0.00716852, -0.04950478, -0.02542713,\n",
       "         0.00733205, -0.06964107,  0.07984493, -0.01698235,  0.03064718,\n",
       "        -0.00580896,  0.11522706, -0.11153056,  0.02998259, -0.03358921,\n",
       "         0.07589207,  0.05250577, -0.01579349, -0.01921326], dtype=float32)>,\n",
       " <tf.Variable 'fc1_1/kernel:0' shape=(256, 256) dtype=float32, numpy=\n",
       " array([[ 0.11108889,  0.1080604 , -0.04647898, ...,  0.00769033,\n",
       "          0.11855712, -0.01307744],\n",
       "        [-0.03443013,  0.16754216, -0.10509261, ...,  0.03715432,\n",
       "         -0.02292426, -0.13653111],\n",
       "        [ 0.0966467 ,  0.07816032,  0.0565265 , ..., -0.06499745,\n",
       "          0.02752406,  0.08789308],\n",
       "        ...,\n",
       "        [-0.0811187 , -0.18691806,  0.00178231, ...,  0.0430593 ,\n",
       "         -0.07470497, -0.14071783],\n",
       "        [ 0.03422713, -0.08263074, -0.09880038, ...,  0.03013248,\n",
       "         -0.1958706 , -0.08146317],\n",
       "        [ 0.12366121,  0.07778819, -0.14055303, ..., -0.09809786,\n",
       "         -0.03672226, -0.0691555 ]], dtype=float32)>,\n",
       " <tf.Variable 'fc1_1/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([-2.29999293e-02,  4.93218452e-02, -3.88150513e-02,  5.05717807e-02,\n",
       "        -2.75451839e-02,  1.36176929e-01, -1.23293670e-02, -8.20840150e-03,\n",
       "        -4.34227921e-02, -7.53755569e-02,  9.29285809e-02,  6.88706562e-02,\n",
       "         6.69046491e-02,  1.57068688e-02, -2.23197769e-02,  1.33285485e-02,\n",
       "         2.40447037e-02, -1.77079327e-02, -3.05999871e-02,  7.09217135e-03,\n",
       "         4.89452332e-02, -6.60292730e-02,  5.37706306e-03,  1.29032835e-01,\n",
       "        -3.87749635e-02, -2.38703992e-02, -2.00492200e-02, -2.49741692e-02,\n",
       "        -2.98978221e-02,  1.93786044e-02, -3.31108421e-02,  8.32142234e-02,\n",
       "        -5.77688497e-03,  3.95471267e-02, -1.59715842e-02, -3.93985808e-02,\n",
       "         4.66459915e-02,  2.36009881e-02,  1.31784096e-01,  2.61161532e-02,\n",
       "        -2.15667281e-02, -4.93886061e-02, -1.06867179e-02,  4.24723811e-02,\n",
       "        -1.04167648e-02,  4.25757878e-02, -1.19991768e-02, -7.05313403e-03,\n",
       "        -5.17209955e-02,  4.57565822e-02, -4.02057208e-02, -5.39668910e-02,\n",
       "        -1.22639053e-02,  6.84586912e-02,  1.15657844e-01,  1.02640159e-01,\n",
       "        -4.49848324e-02,  1.80729982e-02, -3.10199745e-02,  9.20904726e-02,\n",
       "        -1.37653584e-02, -2.85132285e-02, -5.78667857e-02,  1.10977516e-01,\n",
       "         1.21263720e-01,  7.08187222e-02, -4.11734022e-02, -2.33837590e-02,\n",
       "         3.02692764e-02,  1.06627464e-01,  6.55442700e-02, -7.24976743e-03,\n",
       "        -1.64371300e-02,  1.53757678e-02, -4.28118365e-05, -3.28735448e-02,\n",
       "         4.20969948e-02, -1.89260934e-02, -3.53078693e-02, -4.71591055e-02,\n",
       "        -5.29652871e-02, -1.86765566e-02, -3.42026129e-02, -3.06831729e-02,\n",
       "        -5.07496484e-02, -5.52054085e-02,  7.51589015e-02, -3.66463140e-02,\n",
       "        -4.03906107e-02, -1.31107392e-02, -4.10065949e-02, -1.57703608e-02,\n",
       "         6.66315332e-02,  5.02193607e-02, -5.19458018e-02, -1.61609966e-02,\n",
       "         7.18716532e-03, -3.33016515e-02, -2.32383069e-02, -3.55008617e-02,\n",
       "        -4.24048677e-03, -4.42258641e-02,  3.38444486e-02,  3.75499413e-03,\n",
       "         3.83124165e-02,  4.49759997e-02,  6.34306669e-02,  8.77345130e-02,\n",
       "        -3.76853086e-02, -4.44952957e-02, -6.53092191e-02,  3.59191783e-02,\n",
       "        -3.06889936e-02,  2.81302519e-02, -5.39866574e-02, -4.84774709e-02,\n",
       "        -1.12117361e-02, -1.82053763e-02,  8.75734165e-03,  1.95047185e-02,\n",
       "         1.99892856e-02, -3.00914086e-02, -1.97489876e-02, -8.08010697e-02,\n",
       "        -2.85115708e-02,  5.62435910e-02, -2.85136830e-02, -4.57156971e-02,\n",
       "         1.26043513e-01,  9.80161950e-02, -3.21561880e-02, -1.53881349e-02,\n",
       "        -4.33639772e-02, -5.58727421e-02, -7.22683147e-02, -8.93775001e-03,\n",
       "         9.07672346e-02,  6.60682619e-02, -5.85274026e-02,  1.10147242e-02,\n",
       "         8.06924179e-02, -2.19387040e-02,  3.48145440e-02,  1.07737362e-01,\n",
       "        -5.18619418e-02, -2.42796466e-02,  8.75593424e-02,  6.80942535e-02,\n",
       "        -2.31920741e-02,  4.89439555e-02,  1.01331905e-01, -3.07072420e-02,\n",
       "        -2.18058322e-02,  1.35151714e-01,  9.45271179e-03,  9.10579879e-03,\n",
       "        -4.68587913e-02,  2.48413673e-03, -2.91439556e-02,  9.88920704e-02,\n",
       "        -9.26691443e-02, -4.16689329e-02,  8.25334266e-02,  1.08141281e-01,\n",
       "        -1.98613945e-02,  3.21347751e-02, -5.37197553e-02, -3.85908261e-02,\n",
       "        -3.16506512e-02,  2.53249868e-03, -4.84687313e-02,  8.88214707e-02,\n",
       "         6.51169121e-02, -3.22646014e-02,  8.67267847e-02,  4.62533832e-02,\n",
       "        -2.39193868e-02,  5.23025841e-02,  7.49817193e-02, -1.39217693e-02,\n",
       "        -6.81358352e-02, -1.81480497e-02, -2.79956385e-02, -3.41161154e-02,\n",
       "         8.55037645e-02,  1.74171105e-01,  1.41197983e-02,  4.01684968e-03,\n",
       "         1.09590083e-01, -3.84793840e-02, -4.96733934e-02, -1.75696462e-02,\n",
       "         4.29421812e-02, -3.24293002e-02, -2.00239252e-02,  1.20534770e-01,\n",
       "        -1.22288102e-02,  6.98957369e-02, -4.69233990e-02, -2.64742263e-02,\n",
       "        -3.52404565e-02,  3.65493936e-03, -1.03291441e-02, -2.73453817e-02,\n",
       "        -4.09949496e-02, -4.80758734e-02, -6.13344684e-02,  3.26238610e-02,\n",
       "        -2.41383687e-02, -4.42121327e-02,  8.07956979e-02, -2.54815556e-02,\n",
       "         2.22295318e-02,  1.08697684e-02, -1.19486911e-04,  1.05928019e-01,\n",
       "         4.66094464e-02, -4.93296273e-02,  4.49011177e-02,  2.87599005e-02,\n",
       "        -4.98145036e-02, -5.10800742e-02, -4.32897098e-02, -3.91025133e-02,\n",
       "        -7.85392225e-02, -3.12053207e-02,  4.68905233e-02, -5.98880425e-02,\n",
       "         6.49962127e-02, -2.24623028e-02, -4.67668399e-02,  8.07371289e-02,\n",
       "        -4.11001444e-02, -2.44139116e-02, -2.35857517e-02, -2.11326778e-02,\n",
       "         1.23685986e-01,  1.09980337e-01,  7.34817460e-02,  1.38671726e-01,\n",
       "         6.90941364e-02,  7.36757219e-02, -9.17865336e-03, -8.30606297e-02,\n",
       "        -3.12496368e-02, -2.94859298e-02, -3.50325108e-02,  8.11938494e-02,\n",
       "        -3.36228199e-02, -3.11035514e-02, -2.15862989e-02,  1.64953377e-02,\n",
       "         1.56329330e-02,  5.27264699e-02,  3.02982368e-02, -1.59710292e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'fc2_1/kernel:0' shape=(256, 256) dtype=float32, numpy=\n",
       " array([[ 0.10422126, -0.00436004, -0.0885362 , ...,  0.08726107,\n",
       "          0.0226812 ,  0.01061968],\n",
       "        [-0.01006778, -0.14013216,  0.00536632, ...,  0.00533592,\n",
       "          0.10625472, -0.06652485],\n",
       "        [ 0.07606226, -0.08395116,  0.07243425, ...,  0.07726823,\n",
       "         -0.04462661,  0.07354439],\n",
       "        ...,\n",
       "        [ 0.07843801, -0.11090923, -0.13559452, ..., -0.07508439,\n",
       "          0.03687672, -0.10297375],\n",
       "        [ 0.04187905,  0.03026938, -0.04604226, ..., -0.09716535,\n",
       "         -0.1392014 ,  0.08694177],\n",
       "        [ 0.00153353,  0.02554185,  0.07848554, ..., -0.00926094,\n",
       "         -0.07279555,  0.09410766]], dtype=float32)>,\n",
       " <tf.Variable 'fc2_1/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([-0.01574362, -0.040222  , -0.03218333, -0.05065988, -0.03259269,\n",
       "        -0.02322254, -0.01521936, -0.0346391 ,  0.04536863,  0.03387468,\n",
       "         0.05354015,  0.02903001, -0.01281121,  0.07152613, -0.04878447,\n",
       "        -0.00783614, -0.04954181, -0.05297875, -0.01731099, -0.00802049,\n",
       "        -0.01712857,  0.03296098, -0.05205019,  0.05771303,  0.01347392,\n",
       "         0.04429061,  0.05609405, -0.0150586 ,  0.12042524,  0.04730006,\n",
       "        -0.05970311,  0.03935371,  0.02579949,  0.101284  , -0.0263517 ,\n",
       "         0.08888666,  0.04868988,  0.03488645, -0.06125127,  0.0338187 ,\n",
       "        -0.0444032 , -0.03614333,  0.01795783, -0.03004492,  0.02991092,\n",
       "        -0.03235912, -0.05328749, -0.03789184, -0.03477605, -0.05826829,\n",
       "         0.06591965, -0.02782024,  0.12069875,  0.01700936,  0.0548174 ,\n",
       "        -0.04482516,  0.06628585, -0.05426   , -0.03942791,  0.04092336,\n",
       "        -0.04990866, -0.02034941,  0.03781505, -0.05388661,  0.12427855,\n",
       "        -0.05843167, -0.05318525, -0.04049265, -0.06901308,  0.05950931,\n",
       "         0.0669238 , -0.06074972, -0.05758285, -0.04541292, -0.02927574,\n",
       "         0.03348418, -0.03762947, -0.05662847, -0.03693933,  0.08287327,\n",
       "        -0.00788343,  0.09230999,  0.07649568, -0.01269631, -0.03936285,\n",
       "         0.03579028, -0.02973092, -0.00759312, -0.02740522, -0.05238008,\n",
       "        -0.04752769, -0.0220021 ,  0.04709851,  0.02786404,  0.06054585,\n",
       "        -0.00555286, -0.007172  , -0.02448808, -0.02307783,  0.00758669,\n",
       "         0.1229722 , -0.02801672,  0.09357674, -0.03260669, -0.01524671,\n",
       "        -0.00919764, -0.02574312,  0.05975514, -0.04671847,  0.0995429 ,\n",
       "        -0.03936668, -0.01169552,  0.07210721, -0.01916891,  0.04124656,\n",
       "        -0.01374382, -0.01233033, -0.05763467,  0.04902367,  0.02794578,\n",
       "         0.07527835,  0.10971788, -0.0155539 ,  0.02675003, -0.02818773,\n",
       "         0.09247745,  0.01776876,  0.00676591, -0.05486313, -0.13808708,\n",
       "         0.03993065, -0.02123067, -0.03698248, -0.05351229,  0.0419159 ,\n",
       "         0.03802657, -0.01699727,  0.07485296,  0.08117723,  0.04957137,\n",
       "         0.07650762, -0.01215426,  0.03161801,  0.01980526, -0.02806372,\n",
       "        -0.02633436,  0.02690898,  0.08349597, -0.0173491 , -0.01035852,\n",
       "        -0.00175997, -0.14663678,  0.07427026,  0.06696983, -0.04158256,\n",
       "         0.13401012, -0.06720763, -0.03333159,  0.12591662, -0.00208412,\n",
       "        -0.019369  , -0.03336564, -0.01165554,  0.04331687, -0.04242297,\n",
       "        -0.02144806,  0.11548   , -0.05291732,  0.03612136, -0.03200267,\n",
       "        -0.01906202, -0.05606548,  0.03503446,  0.01837852, -0.00921446,\n",
       "        -0.04919617, -0.01120814,  0.05723337,  0.05048174, -0.03987342,\n",
       "         0.03714115, -0.04471384,  0.06171601,  0.00111426, -0.04736387,\n",
       "         0.02377566, -0.00975306, -0.03916458, -0.01474284,  0.00510026,\n",
       "         0.00059445,  0.04224448, -0.02957946, -0.04118024,  0.01221989,\n",
       "        -0.02211752, -0.0418609 , -0.0293846 , -0.0208945 ,  0.12498151,\n",
       "         0.08637693,  0.03506672,  0.08621687, -0.04109164,  0.03300017,\n",
       "         0.02420207,  0.10709602,  0.02871416, -0.01063452, -0.03564642,\n",
       "         0.09478869, -0.04872134,  0.03182257, -0.04373272,  0.02506937,\n",
       "         0.03779823, -0.03858022, -0.04178613,  0.02852313,  0.04455091,\n",
       "        -0.03146244, -0.0346996 , -0.04173939,  0.04850921, -0.04252441,\n",
       "        -0.00661232,  0.05995017, -0.03733085, -0.02223299,  0.12048814,\n",
       "        -0.03020397, -0.04016134, -0.06657618,  0.03711422,  0.02175772,\n",
       "        -0.01960708,  0.00017908,  0.0323743 , -0.0356214 , -0.05611023,\n",
       "        -0.01010466, -0.05852582,  0.0727739 , -0.04153602,  0.03903103,\n",
       "         0.13758676, -0.02259499, -0.01485799,  0.03357668, -0.03584721,\n",
       "         0.05492065,  0.05322056, -0.02568186, -0.01023871, -0.0393678 ,\n",
       "        -0.01269843], dtype=float32)>,\n",
       " <tf.Variable 'predictions_1/kernel:0' shape=(256, 7) dtype=float32, numpy=\n",
       " array([[ 0.00591451,  0.08097838,  0.10125832, ..., -0.12204257,\n",
       "          0.08777641, -0.02440059],\n",
       "        [-0.05131669,  0.10206467, -0.12577209, ..., -0.09787108,\n",
       "          0.11699505, -0.02661926],\n",
       "        [ 0.09030411,  0.01418484,  0.09865837, ..., -0.07622065,\n",
       "          0.02036201, -0.0668716 ],\n",
       "        ...,\n",
       "        [-0.00641467, -0.00679523, -0.14161496, ..., -0.01283569,\n",
       "         -0.0590564 ,  0.04486234],\n",
       "        [-0.10530996, -0.01560416, -0.08541199, ..., -0.16877915,\n",
       "         -0.09159677, -0.20565455],\n",
       "        [ 0.08365846,  0.09449974, -0.08606588, ..., -0.07190637,\n",
       "         -0.15142587, -0.07219777]], dtype=float32)>,\n",
       " <tf.Variable 'predictions_1/bias:0' shape=(7,) dtype=float32, numpy=\n",
       " array([ 0.00039637, -0.05205476,  0.02772587,  0.02080639,  0.03271028,\n",
       "        -0.06111097,  0.01673721], dtype=float32)>]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights # 참고. get_weights()와 weights는 다른 매서드임을 알자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1583364982427,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "BAO4_6HJFF__",
    "outputId": "1ad7c495-dc7c-45ac-c554-3ec96f1932a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태는 이렇게 생김\n",
    "np.array(W).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-90tcTlCFGAC"
   },
   "source": [
    "### 2) My VGG16 (Pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcS0I-HoZVk3"
   },
   "outputs": [],
   "source": [
    "# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n",
    "# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n",
    "# 3. Conv의 filter는 1/8로 줄인다.\n",
    "# 4. 다음과 같이 모형을 재구성한다.\n",
    "# 5. 위의 내용은 앞으로 비교될 모형에서도 공통적으로 작용한다.\n",
    "\n",
    "\n",
    "def VGG16(input_shape=(64,64,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n",
    "        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='vgg19')\n",
    "\n",
    "    # Load weights.\n",
    "    # 내 모형에서는 쓸모없다. 다만, 나중의 혹시모를 참고를 위해 코드는 남겨놓는다.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,cache_subdir='models',file_hash='cbe5617147190e668d6c5d5026f83318')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,cache_subdir='models',file_hash='253f8cb515780f3b799900260a226db6')\n",
    "\n",
    "        model.load_weights(weights_path) #경로에 있는 초기치 weights가져오기\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wcZln93ZVsF"
   },
   "outputs": [],
   "source": [
    "model = VGG16(input_shape=(64, 64, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1625,
     "status": "ok",
     "timestamp": 1583364982789,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "16xkrOFIZVzK",
    "outputId": "369274dd-639f-4c2f-93e9-6a01e654df4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 8)         584       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 363,951\n",
      "Trainable params: 363,951\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5SxMkHcZV5t"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 846627,
     "status": "ok",
     "timestamp": 1583365827796,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "d64FCl-pZpIN",
    "outputId": "1e5191fb-2076-4254-ef9f-7e9a50ddefad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 36s 160ms/step - loss: 1.8086 - accuracy: 0.2496 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8744 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.7427 - accuracy: 0.2839 - macro_f1score: 0.0215 - weighted_f1score: 0.0026 - val_loss: 1.7383 - val_accuracy: 0.3260 - val_macro_f1score: 0.0053 - val_weighted_f1score: 7.8795e-04\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.6157 - accuracy: 0.3614 - macro_f1score: 0.1100 - weighted_f1score: 0.0207 - val_loss: 1.5534 - val_accuracy: 0.4199 - val_macro_f1score: 0.1524 - val_weighted_f1score: 0.0289\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.5183 - accuracy: 0.4059 - macro_f1score: 0.1505 - weighted_f1score: 0.0286 - val_loss: 1.4774 - val_accuracy: 0.4505 - val_macro_f1score: 0.1564 - val_weighted_f1score: 0.0312\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 35s 156ms/step - loss: 1.4359 - accuracy: 0.4413 - macro_f1score: 0.1855 - weighted_f1score: 0.0348 - val_loss: 1.4125 - val_accuracy: 0.4656 - val_macro_f1score: 0.2144 - val_weighted_f1score: 0.0402\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.3689 - accuracy: 0.4700 - macro_f1score: 0.2179 - weighted_f1score: 0.0403 - val_loss: 1.3822 - val_accuracy: 0.4742 - val_macro_f1score: 0.2363 - val_weighted_f1score: 0.0448\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.3165 - accuracy: 0.4926 - macro_f1score: 0.2411 - weighted_f1score: 0.0444 - val_loss: 1.3208 - val_accuracy: 0.4960 - val_macro_f1score: 0.2520 - val_weighted_f1score: 0.0483\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.2807 - accuracy: 0.5074 - macro_f1score: 0.2645 - weighted_f1score: 0.0480 - val_loss: 1.2810 - val_accuracy: 0.5021 - val_macro_f1score: 0.2839 - val_weighted_f1score: 0.0524\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.2532 - accuracy: 0.5221 - macro_f1score: 0.2826 - weighted_f1score: 0.0510 - val_loss: 1.2640 - val_accuracy: 0.5185 - val_macro_f1score: 0.2914 - val_weighted_f1score: 0.0530\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.2209 - accuracy: 0.5304 - macro_f1score: 0.3020 - weighted_f1score: 0.0541 - val_loss: 1.2161 - val_accuracy: 0.5439 - val_macro_f1score: 0.2981 - val_weighted_f1score: 0.0548\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.2003 - accuracy: 0.5422 - macro_f1score: 0.3146 - weighted_f1score: 0.0562 - val_loss: 1.2135 - val_accuracy: 0.5419 - val_macro_f1score: 0.3225 - val_weighted_f1score: 0.0585\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.1786 - accuracy: 0.5520 - macro_f1score: 0.3401 - weighted_f1score: 0.0602 - val_loss: 1.1966 - val_accuracy: 0.5575 - val_macro_f1score: 0.3409 - val_weighted_f1score: 0.0613\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 36s 159ms/step - loss: 1.1695 - accuracy: 0.5529 - macro_f1score: 0.3422 - weighted_f1score: 0.0604 - val_loss: 1.1508 - val_accuracy: 0.5670 - val_macro_f1score: 0.3762 - val_weighted_f1score: 0.0665\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 36s 160ms/step - loss: 1.1464 - accuracy: 0.5647 - macro_f1score: 0.3598 - weighted_f1score: 0.0634 - val_loss: 1.1742 - val_accuracy: 0.5514 - val_macro_f1score: 0.3585 - val_weighted_f1score: 0.0640\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.1386 - accuracy: 0.5653 - macro_f1score: 0.3619 - weighted_f1score: 0.0635 - val_loss: 1.1742 - val_accuracy: 0.5581 - val_macro_f1score: 0.3329 - val_weighted_f1score: 0.0590\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 36s 158ms/step - loss: 1.1221 - accuracy: 0.5708 - macro_f1score: 0.3719 - weighted_f1score: 0.0650 - val_loss: 1.1402 - val_accuracy: 0.5770 - val_macro_f1score: 0.3779 - val_weighted_f1score: 0.0670\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.1148 - accuracy: 0.5772 - macro_f1score: 0.3765 - weighted_f1score: 0.0655 - val_loss: 1.1309 - val_accuracy: 0.5759 - val_macro_f1score: 0.3916 - val_weighted_f1score: 0.0687\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.0965 - accuracy: 0.5851 - macro_f1score: 0.3949 - weighted_f1score: 0.0683 - val_loss: 1.1222 - val_accuracy: 0.5815 - val_macro_f1score: 0.4005 - val_weighted_f1score: 0.0704\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 35s 153ms/step - loss: 1.0976 - accuracy: 0.5844 - macro_f1score: 0.3946 - weighted_f1score: 0.0685 - val_loss: 1.1234 - val_accuracy: 0.5756 - val_macro_f1score: 0.3682 - val_weighted_f1score: 0.0664\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.0809 - accuracy: 0.5888 - macro_f1score: 0.4126 - weighted_f1score: 0.0702 - val_loss: 1.1272 - val_accuracy: 0.5687 - val_macro_f1score: 0.3797 - val_weighted_f1score: 0.0682\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.0761 - accuracy: 0.5921 - macro_f1score: 0.4064 - weighted_f1score: 0.0698 - val_loss: 1.0979 - val_accuracy: 0.5904 - val_macro_f1score: 0.4284 - val_weighted_f1score: 0.0731\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.0728 - accuracy: 0.5946 - macro_f1score: 0.4112 - weighted_f1score: 0.0706 - val_loss: 1.1223 - val_accuracy: 0.5790 - val_macro_f1score: 0.3963 - val_weighted_f1score: 0.0699\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 35s 156ms/step - loss: 1.0584 - accuracy: 0.5986 - macro_f1score: 0.4173 - weighted_f1score: 0.0715 - val_loss: 1.1115 - val_accuracy: 0.5899 - val_macro_f1score: 0.4008 - val_weighted_f1score: 0.0705\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.0626 - accuracy: 0.5997 - macro_f1score: 0.4276 - weighted_f1score: 0.0725 - val_loss: 1.1137 - val_accuracy: 0.5854 - val_macro_f1score: 0.3986 - val_weighted_f1score: 0.0697\n",
      "Epoch 00024: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a81dc5978>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train_zoom,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 847128,
     "status": "ok",
     "timestamp": 1583365828300,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "LehU2TtdZpGb",
    "outputId": "30800093-09a1-43e7-8351-5d91cbc477a6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 1s 142us/sample - loss: 1.1246 - accuracy: 0.5889 - macro_f1score: 0.4036 - weighted_f1score: 0.0678\n",
      "\n",
      "Accuracy: 0.5889, Macro F1 Score: 0.4036, Weighted F1 Score: 0.0678\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HfFU1neyAlHb"
   },
   "source": [
    "### 3) My VGG19 (Pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyydh1DtFGAD"
   },
   "outputs": [],
   "source": [
    "# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n",
    "# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n",
    "# 3. Conv의 filter는 1/8로 줄인다.\n",
    "# 4. 다음과 같이 모형을 재구성한다.\n",
    "# 5. 위의 내용은 앞으로 비교될 모형에서도 공통적으로 작용한다.\n",
    "\n",
    "\n",
    "def VGG19(input_shape=(64,64,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n",
    "        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='vgg19')\n",
    "\n",
    "    # Load weights.\n",
    "    # 내 모형에서는 쓸모없다. 다만, 나중의 혹시모를 참고를 위해 코드는 남겨놓는다.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,cache_subdir='models',file_hash='cbe5617147190e668d6c5d5026f83318')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,cache_subdir='models',file_hash='253f8cb515780f3b799900260a226db6')\n",
    "\n",
    "        model.load_weights(weights_path) #경로에 있는 초기치 weights가져오기\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nlEzxXOEFGAG"
   },
   "outputs": [],
   "source": [
    "#내 데이터 맞춤형 모형\n",
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "\n",
    "model = VGG19(input_shape=(64, 64, 3), classes=7, include_top=True,pooling=None, weights = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 847374,
     "status": "ok",
     "timestamp": 1583365828555,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "8CZVWIEEFGAJ",
    "outputId": "cda4ac24-f7db-41da-c657-88d8c31a314a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 64, 8)         584       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 447,055\n",
      "Trainable params: 447,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ja2z67kvFGAP"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1711254,
     "status": "ok",
     "timestamp": 1583366692440,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "Etwx_7QkFGAV",
    "outputId": "a665708c-b135-43b5-ca3a-83c0259c32eb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 36s 162ms/step - loss: 1.7821 - accuracy: 0.2614 - macro_f1score: 0.0061 - weighted_f1score: 6.9450e-04 - val_loss: 1.7594 - val_accuracy: 0.3015 - val_macro_f1score: 0.0300 - val_weighted_f1score: 0.0035\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.6484 - accuracy: 0.3422 - macro_f1score: 0.0870 - weighted_f1score: 0.0157 - val_loss: 1.5930 - val_accuracy: 0.3906 - val_macro_f1score: 0.1479 - val_weighted_f1score: 0.0292\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 35s 153ms/step - loss: 1.5287 - accuracy: 0.3982 - macro_f1score: 0.1461 - weighted_f1score: 0.0279 - val_loss: 1.4913 - val_accuracy: 0.4372 - val_macro_f1score: 0.1676 - val_weighted_f1score: 0.0326\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.4516 - accuracy: 0.4300 - macro_f1score: 0.1728 - weighted_f1score: 0.0329 - val_loss: 1.4479 - val_accuracy: 0.4511 - val_macro_f1score: 0.1823 - val_weighted_f1score: 0.0359\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.3964 - accuracy: 0.4529 - macro_f1score: 0.1904 - weighted_f1score: 0.0361 - val_loss: 1.3717 - val_accuracy: 0.4882 - val_macro_f1score: 0.2614 - val_weighted_f1score: 0.0482\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.3473 - accuracy: 0.4773 - macro_f1score: 0.2217 - weighted_f1score: 0.0411 - val_loss: 1.3257 - val_accuracy: 0.5046 - val_macro_f1score: 0.2836 - val_weighted_f1score: 0.0521\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.2999 - accuracy: 0.5000 - macro_f1score: 0.2510 - weighted_f1score: 0.0458 - val_loss: 1.3204 - val_accuracy: 0.4943 - val_macro_f1score: 0.2847 - val_weighted_f1score: 0.0517\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.2750 - accuracy: 0.5089 - macro_f1score: 0.2662 - weighted_f1score: 0.0485 - val_loss: 1.2895 - val_accuracy: 0.5143 - val_macro_f1score: 0.2642 - val_weighted_f1score: 0.0489\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.2494 - accuracy: 0.5208 - macro_f1score: 0.2814 - weighted_f1score: 0.0508 - val_loss: 1.2610 - val_accuracy: 0.5297 - val_macro_f1score: 0.2850 - val_weighted_f1score: 0.0527\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 34s 151ms/step - loss: 1.2296 - accuracy: 0.5299 - macro_f1score: 0.2954 - weighted_f1score: 0.0533 - val_loss: 1.2571 - val_accuracy: 0.5224 - val_macro_f1score: 0.3073 - val_weighted_f1score: 0.0554\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.2037 - accuracy: 0.5399 - macro_f1score: 0.3087 - weighted_f1score: 0.0552 - val_loss: 1.2230 - val_accuracy: 0.5400 - val_macro_f1score: 0.3111 - val_weighted_f1score: 0.0555\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.1899 - accuracy: 0.5448 - macro_f1score: 0.3250 - weighted_f1score: 0.0579 - val_loss: 1.2155 - val_accuracy: 0.5536 - val_macro_f1score: 0.3496 - val_weighted_f1score: 0.0623\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.1786 - accuracy: 0.5504 - macro_f1score: 0.3291 - weighted_f1score: 0.0587 - val_loss: 1.2050 - val_accuracy: 0.5508 - val_macro_f1score: 0.3513 - val_weighted_f1score: 0.0629\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.1619 - accuracy: 0.5562 - macro_f1score: 0.3459 - weighted_f1score: 0.0612 - val_loss: 1.1935 - val_accuracy: 0.5467 - val_macro_f1score: 0.3417 - val_weighted_f1score: 0.0611\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.1523 - accuracy: 0.5597 - macro_f1score: 0.3460 - weighted_f1score: 0.0615 - val_loss: 1.1834 - val_accuracy: 0.5561 - val_macro_f1score: 0.3577 - val_weighted_f1score: 0.0639\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.1371 - accuracy: 0.5644 - macro_f1score: 0.3569 - weighted_f1score: 0.0629 - val_loss: 1.1475 - val_accuracy: 0.5720 - val_macro_f1score: 0.3618 - val_weighted_f1score: 0.0646\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.1270 - accuracy: 0.5693 - macro_f1score: 0.3696 - weighted_f1score: 0.0648 - val_loss: 1.1805 - val_accuracy: 0.5581 - val_macro_f1score: 0.3687 - val_weighted_f1score: 0.0661\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 35s 154ms/step - loss: 1.1230 - accuracy: 0.5722 - macro_f1score: 0.3692 - weighted_f1score: 0.0649 - val_loss: 1.1471 - val_accuracy: 0.5712 - val_macro_f1score: 0.3667 - val_weighted_f1score: 0.0650\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.1181 - accuracy: 0.5742 - macro_f1score: 0.3758 - weighted_f1score: 0.0656 - val_loss: 1.1726 - val_accuracy: 0.5698 - val_macro_f1score: 0.3718 - val_weighted_f1score: 0.0663\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.1128 - accuracy: 0.5791 - macro_f1score: 0.3870 - weighted_f1score: 0.0666 - val_loss: 1.1844 - val_accuracy: 0.5637 - val_macro_f1score: 0.3862 - val_weighted_f1score: 0.0678\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 34s 151ms/step - loss: 1.0962 - accuracy: 0.5810 - macro_f1score: 0.3874 - weighted_f1score: 0.0677 - val_loss: 1.1323 - val_accuracy: 0.5787 - val_macro_f1score: 0.4034 - val_weighted_f1score: 0.0701\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.0844 - accuracy: 0.5882 - macro_f1score: 0.3975 - weighted_f1score: 0.0685 - val_loss: 1.1076 - val_accuracy: 0.5871 - val_macro_f1score: 0.4278 - val_weighted_f1score: 0.0714\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.0814 - accuracy: 0.5900 - macro_f1score: 0.4054 - weighted_f1score: 0.0698 - val_loss: 1.1173 - val_accuracy: 0.5846 - val_macro_f1score: 0.3956 - val_weighted_f1score: 0.0701\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.0693 - accuracy: 0.5968 - macro_f1score: 0.4129 - weighted_f1score: 0.0710 - val_loss: 1.1101 - val_accuracy: 0.5801 - val_macro_f1score: 0.4047 - val_weighted_f1score: 0.0715\n",
      "Epoch 25/100\n",
      "225/224 [==============================] - 35s 153ms/step - loss: 1.0645 - accuracy: 0.5971 - macro_f1score: 0.4176 - weighted_f1score: 0.0717 - val_loss: 1.0976 - val_accuracy: 0.5999 - val_macro_f1score: 0.4238 - val_weighted_f1score: 0.0733\n",
      "Epoch 00025: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a80861a20>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train_zoom,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1711800,
     "status": "ok",
     "timestamp": 1583366692990,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "DSysccApFGAY",
    "outputId": "218d7d9d-6779-4800-86cf-3180e39fea87",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 1s 147us/sample - loss: 1.1117 - accuracy: 0.5828 - macro_f1score: 0.4091 - weighted_f1score: 0.0695\n",
      "\n",
      "Accuracy: 0.5828, Macro F1 Score: 0.4091, Weighted F1 Score: 0.0695\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWNbFhqE9dZM"
   },
   "source": [
    "### 4) My VGG11 (Convergence Speed Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWW3kpm2bWlK"
   },
   "outputs": [],
   "source": [
    "# Vgg11에서, pretraining 된 fc층을 가지고 VGG 11을 재학습 시킬때, 얼마나 적은 epoch만에 수렴하는지를 보기 위해 만들었다.\n",
    "\n",
    "\n",
    "# 1. 224의 대략 1/4 연산인 64로 이미지사이즈를 재조정한다.\n",
    "# 2. 모수와 관련이 가장 깊은 fc층에서, 기존의 4096개의 노드를 1/16 (비율) 배 만큼, 즉 256개로줄인다.\n",
    "# 3. Conv의 filter는 1/8로 줄인다.\n",
    "# 4. 다음과 같이 모형을 재구성한다.\n",
    "# 5. 위의 내용은 앞으로 비교될 모형에서도 공통적으로 작용한다.\n",
    "\n",
    "def VGG11_init(input_shape=(64,64,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n",
    "        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='Vgg11_Pretrained')\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EvBrMct5bWjY"
   },
   "outputs": [],
   "source": [
    "model = VGG11_init(input_shape=(64, 64, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1712030,
     "status": "ok",
     "timestamp": 1583366693229,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "sulu852DbWhl",
    "outputId": "dbc0861d-d252-46b6-f328-bb1d2cfcf1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Vgg11_Pretrained\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 64, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 32, 32, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 277,943\n",
      "Trainable params: 277,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfN21xkIbWf1"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2701632,
     "status": "ok",
     "timestamp": 1583367682838,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "DrKVEKlYbWd5",
    "outputId": "408a6d34-c755-456a-88e8-35ba8ad2c9b3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 35s 158ms/step - loss: 1.7632 - accuracy: 0.2705 - macro_f1score: 0.0097 - weighted_f1score: 0.0011 - val_loss: 1.6794 - val_accuracy: 0.3697 - val_macro_f1score: 0.0633 - val_weighted_f1score: 0.0100\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.5749 - accuracy: 0.3792 - macro_f1score: 0.1248 - weighted_f1score: 0.0237 - val_loss: 1.5179 - val_accuracy: 0.4177 - val_macro_f1score: 0.1683 - val_weighted_f1score: 0.0327\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.4681 - accuracy: 0.4253 - macro_f1score: 0.1660 - weighted_f1score: 0.0313 - val_loss: 1.4500 - val_accuracy: 0.4539 - val_macro_f1score: 0.1841 - val_weighted_f1score: 0.0365\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.3793 - accuracy: 0.4630 - macro_f1score: 0.2112 - weighted_f1score: 0.0392 - val_loss: 1.3816 - val_accuracy: 0.4834 - val_macro_f1score: 0.2256 - val_weighted_f1score: 0.0424\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.3157 - accuracy: 0.4922 - macro_f1score: 0.2465 - weighted_f1score: 0.0448 - val_loss: 1.2951 - val_accuracy: 0.5183 - val_macro_f1score: 0.2622 - val_weighted_f1score: 0.0482\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 34s 151ms/step - loss: 1.2663 - accuracy: 0.5099 - macro_f1score: 0.2720 - weighted_f1score: 0.0492 - val_loss: 1.2623 - val_accuracy: 0.5361 - val_macro_f1score: 0.2702 - val_weighted_f1score: 0.0484\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 34s 150ms/step - loss: 1.2328 - accuracy: 0.5266 - macro_f1score: 0.2947 - weighted_f1score: 0.0530 - val_loss: 1.2565 - val_accuracy: 0.5269 - val_macro_f1score: 0.3097 - val_weighted_f1score: 0.0554\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 34s 151ms/step - loss: 1.2040 - accuracy: 0.5359 - macro_f1score: 0.3156 - weighted_f1score: 0.0562 - val_loss: 1.2546 - val_accuracy: 0.5419 - val_macro_f1score: 0.3278 - val_weighted_f1score: 0.0581\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 35s 156ms/step - loss: 1.1851 - accuracy: 0.5457 - macro_f1score: 0.3298 - weighted_f1score: 0.0584 - val_loss: 1.2173 - val_accuracy: 0.5414 - val_macro_f1score: 0.3372 - val_weighted_f1score: 0.0606\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 35s 156ms/step - loss: 1.1611 - accuracy: 0.5572 - macro_f1score: 0.3491 - weighted_f1score: 0.0616 - val_loss: 1.2051 - val_accuracy: 0.5517 - val_macro_f1score: 0.3522 - val_weighted_f1score: 0.0635\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.1507 - accuracy: 0.5608 - macro_f1score: 0.3541 - weighted_f1score: 0.0623 - val_loss: 1.1554 - val_accuracy: 0.5737 - val_macro_f1score: 0.3792 - val_weighted_f1score: 0.0674\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.1301 - accuracy: 0.5679 - macro_f1score: 0.3705 - weighted_f1score: 0.0648 - val_loss: 1.1624 - val_accuracy: 0.5690 - val_macro_f1score: 0.3451 - val_weighted_f1score: 0.0616\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 35s 155ms/step - loss: 1.1239 - accuracy: 0.5720 - macro_f1score: 0.3799 - weighted_f1score: 0.0659 - val_loss: 1.1730 - val_accuracy: 0.5614 - val_macro_f1score: 0.3535 - val_weighted_f1score: 0.0625\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.1152 - accuracy: 0.5731 - macro_f1score: 0.3858 - weighted_f1score: 0.0665 - val_loss: 1.1189 - val_accuracy: 0.5854 - val_macro_f1score: 0.3997 - val_weighted_f1score: 0.0695\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 33s 148ms/step - loss: 1.0981 - accuracy: 0.5823 - macro_f1score: 0.3970 - weighted_f1score: 0.0684 - val_loss: 1.1186 - val_accuracy: 0.5832 - val_macro_f1score: 0.4015 - val_weighted_f1score: 0.0706\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 34s 150ms/step - loss: 1.0872 - accuracy: 0.5850 - macro_f1score: 0.4053 - weighted_f1score: 0.0693 - val_loss: 1.1246 - val_accuracy: 0.5787 - val_macro_f1score: 0.3938 - val_weighted_f1score: 0.0694\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 34s 150ms/step - loss: 1.0871 - accuracy: 0.5851 - macro_f1score: 0.4076 - weighted_f1score: 0.0697 - val_loss: 1.1274 - val_accuracy: 0.5848 - val_macro_f1score: 0.4244 - val_weighted_f1score: 0.0733\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 34s 150ms/step - loss: 1.0784 - accuracy: 0.5919 - macro_f1score: 0.4127 - weighted_f1score: 0.0702 - val_loss: 1.1139 - val_accuracy: 0.5837 - val_macro_f1score: 0.4102 - val_weighted_f1score: 0.0725\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 34s 152ms/step - loss: 1.0677 - accuracy: 0.5948 - macro_f1score: 0.4282 - weighted_f1score: 0.0718 - val_loss: 1.1306 - val_accuracy: 0.5731 - val_macro_f1score: 0.3860 - val_weighted_f1score: 0.0672\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 34s 150ms/step - loss: 1.0556 - accuracy: 0.6005 - macro_f1score: 0.4272 - weighted_f1score: 0.0725 - val_loss: 1.1236 - val_accuracy: 0.5868 - val_macro_f1score: 0.4318 - val_weighted_f1score: 0.0731\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 34s 149ms/step - loss: 1.0494 - accuracy: 0.5991 - macro_f1score: 0.4348 - weighted_f1score: 0.0729 - val_loss: 1.1129 - val_accuracy: 0.5837 - val_macro_f1score: 0.4141 - val_weighted_f1score: 0.0727\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 33s 146ms/step - loss: 1.0446 - accuracy: 0.6011 - macro_f1score: 0.4427 - weighted_f1score: 0.0741 - val_loss: 1.1153 - val_accuracy: 0.5862 - val_macro_f1score: 0.4175 - val_weighted_f1score: 0.0732\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 33s 145ms/step - loss: 1.0448 - accuracy: 0.6007 - macro_f1score: 0.4353 - weighted_f1score: 0.0734 - val_loss: 1.0898 - val_accuracy: 0.5918 - val_macro_f1score: 0.4352 - val_weighted_f1score: 0.0739\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 32s 144ms/step - loss: 1.0380 - accuracy: 0.6061 - macro_f1score: 0.4457 - weighted_f1score: 0.0740 - val_loss: 1.0775 - val_accuracy: 0.5999 - val_macro_f1score: 0.4361 - val_weighted_f1score: 0.0749\n",
      "Epoch 25/100\n",
      "225/224 [==============================] - 33s 145ms/step - loss: 1.0289 - accuracy: 0.6093 - macro_f1score: 0.4505 - weighted_f1score: 0.0749 - val_loss: 1.0934 - val_accuracy: 0.5885 - val_macro_f1score: 0.4214 - val_weighted_f1score: 0.0733\n",
      "Epoch 26/100\n",
      "225/224 [==============================] - 33s 149ms/step - loss: 1.0210 - accuracy: 0.6129 - macro_f1score: 0.4559 - weighted_f1score: 0.0755 - val_loss: 1.0896 - val_accuracy: 0.5968 - val_macro_f1score: 0.4427 - val_weighted_f1score: 0.0752\n",
      "Epoch 27/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.0195 - accuracy: 0.6137 - macro_f1score: 0.4606 - weighted_f1score: 0.0763 - val_loss: 1.1079 - val_accuracy: 0.5926 - val_macro_f1score: 0.4397 - val_weighted_f1score: 0.0731\n",
      "Epoch 28/100\n",
      "225/224 [==============================] - 35s 157ms/step - loss: 1.0089 - accuracy: 0.6173 - macro_f1score: 0.4654 - weighted_f1score: 0.0768 - val_loss: 1.0964 - val_accuracy: 0.5940 - val_macro_f1score: 0.4415 - val_weighted_f1score: 0.0737\n",
      "Epoch 29/100\n",
      "225/224 [==============================] - 34s 153ms/step - loss: 1.0095 - accuracy: 0.6162 - macro_f1score: 0.4703 - weighted_f1score: 0.0770 - val_loss: 1.0660 - val_accuracy: 0.6032 - val_macro_f1score: 0.4250 - val_weighted_f1score: 0.0743\n",
      "Epoch 00029: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a7db583c8>"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train_zoom,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_zoom_gen, validation_steps=len(x_valid_zoom)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2702203,
     "status": "ok",
     "timestamp": 1583367683413,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "md4YhH7xbWca",
    "outputId": "b7aabd10-1686-4fa2-e4f8-b106069e8eb4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 0s 120us/sample - loss: 1.0887 - accuracy: 0.5878 - macro_f1score: 0.4361 - weighted_f1score: 0.0717\n",
      "\n",
      "Accuracy: 0.5878, Macro F1 Score: 0.4361, Weighted F1 Score: 0.0717\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test_zoom,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_44ReAz9dZe"
   },
   "source": [
    "## 3. For Size =48,\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHJl3jbr9dZf"
   },
   "source": [
    "### 1) My VGG11 (Pretraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lbmiiqjr9dZg"
   },
   "outputs": [],
   "source": [
    "# 오리지널 데이터에 대해 다루어본다.\n",
    "\n",
    "def VGG11(input_shape=(48,48,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(3, 3), name='block5_pool')(x)\n",
    "    # 데이터 size = 48로 하므로써, 전체를 maxpooling 하는 것으로 바꿈.\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu',name='fc1')(x)\n",
    "        x = Dense(256, activation='relu', name='fc2')(x)\n",
    "        output = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='Vgg11_Pretraining')\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QiYnsfxH9dZi"
   },
   "outputs": [],
   "source": [
    "#내 데이터 맞춤형 모형\n",
    "model = VGG11(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2702441,
     "status": "ok",
     "timestamp": 1583367683660,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "4PuUC6OM9dZk",
    "outputId": "e3ad853d-9194-4d9a-cb05-a3d72edaca63",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Vgg11_Pretraining\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 228,791\n",
      "Trainable params: 228,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bVw85Z49dZm"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3457779,
     "status": "ok",
     "timestamp": 1583368439003,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "UmsKJ9kt9dZq",
    "outputId": "a0916f90-a602-492e-dda3-35bddbcbfa17",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.8133 - accuracy: 0.2516 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8679 - val_accuracy: 0.2519 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.7794 - accuracy: 0.2607 - macro_f1score: 5.5400e-04 - weighted_f1score: 5.8114e-05 - val_loss: 1.8071 - val_accuracy: 0.2845 - val_macro_f1score: 0.0018 - val_weighted_f1score: 2.1687e-04\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.6926 - accuracy: 0.3138 - macro_f1score: 0.0499 - weighted_f1score: 0.0087 - val_loss: 1.6125 - val_accuracy: 0.3842 - val_macro_f1score: 0.1314 - val_weighted_f1score: 0.0246\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.5602 - accuracy: 0.3864 - macro_f1score: 0.1355 - weighted_f1score: 0.0257 - val_loss: 1.4945 - val_accuracy: 0.4330 - val_macro_f1score: 0.1749 - val_weighted_f1score: 0.0327\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 27s 121ms/step - loss: 1.4611 - accuracy: 0.4283 - macro_f1score: 0.1764 - weighted_f1score: 0.0331 - val_loss: 1.4520 - val_accuracy: 0.4575 - val_macro_f1score: 0.1825 - val_weighted_f1score: 0.0338\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.3919 - accuracy: 0.4583 - macro_f1score: 0.2045 - weighted_f1score: 0.0381 - val_loss: 1.4606 - val_accuracy: 0.4589 - val_macro_f1score: 0.1835 - val_weighted_f1score: 0.0335\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.3532 - accuracy: 0.4733 - macro_f1score: 0.2186 - weighted_f1score: 0.0404 - val_loss: 1.3627 - val_accuracy: 0.4868 - val_macro_f1score: 0.2744 - val_weighted_f1score: 0.0496\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.3202 - accuracy: 0.4891 - macro_f1score: 0.2410 - weighted_f1score: 0.0443 - val_loss: 1.3395 - val_accuracy: 0.5024 - val_macro_f1score: 0.2592 - val_weighted_f1score: 0.0463\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.2896 - accuracy: 0.5057 - macro_f1score: 0.2636 - weighted_f1score: 0.0479 - val_loss: 1.3041 - val_accuracy: 0.5116 - val_macro_f1score: 0.3011 - val_weighted_f1score: 0.0546\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.2602 - accuracy: 0.5168 - macro_f1score: 0.2803 - weighted_f1score: 0.0505 - val_loss: 1.2931 - val_accuracy: 0.5169 - val_macro_f1score: 0.2849 - val_weighted_f1score: 0.0515\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.2445 - accuracy: 0.5237 - macro_f1score: 0.2913 - weighted_f1score: 0.0524 - val_loss: 1.2620 - val_accuracy: 0.5208 - val_macro_f1score: 0.2918 - val_weighted_f1score: 0.0531\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.2236 - accuracy: 0.5310 - macro_f1score: 0.3061 - weighted_f1score: 0.0548 - val_loss: 1.2645 - val_accuracy: 0.5308 - val_macro_f1score: 0.3254 - val_weighted_f1score: 0.0581\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.2125 - accuracy: 0.5385 - macro_f1score: 0.3221 - weighted_f1score: 0.0571 - val_loss: 1.2347 - val_accuracy: 0.5394 - val_macro_f1score: 0.3374 - val_weighted_f1score: 0.0606\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.1928 - accuracy: 0.5440 - macro_f1score: 0.3292 - weighted_f1score: 0.0584 - val_loss: 1.1950 - val_accuracy: 0.5587 - val_macro_f1score: 0.3484 - val_weighted_f1score: 0.0615\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.1869 - accuracy: 0.5478 - macro_f1score: 0.3389 - weighted_f1score: 0.0597 - val_loss: 1.2215 - val_accuracy: 0.5517 - val_macro_f1score: 0.3552 - val_weighted_f1score: 0.0620\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.1713 - accuracy: 0.5535 - macro_f1score: 0.3511 - weighted_f1score: 0.0617 - val_loss: 1.2128 - val_accuracy: 0.5453 - val_macro_f1score: 0.3544 - val_weighted_f1score: 0.0620\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.1606 - accuracy: 0.5567 - macro_f1score: 0.3585 - weighted_f1score: 0.0627 - val_loss: 1.2048 - val_accuracy: 0.5489 - val_macro_f1score: 0.3751 - val_weighted_f1score: 0.0654\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.1441 - accuracy: 0.5630 - macro_f1score: 0.3679 - weighted_f1score: 0.0640 - val_loss: 1.2109 - val_accuracy: 0.5623 - val_macro_f1score: 0.3518 - val_weighted_f1score: 0.0628\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.1433 - accuracy: 0.5644 - macro_f1score: 0.3684 - weighted_f1score: 0.0642 - val_loss: 1.2342 - val_accuracy: 0.5411 - val_macro_f1score: 0.3709 - val_weighted_f1score: 0.0644\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.1367 - accuracy: 0.5673 - macro_f1score: 0.3774 - weighted_f1score: 0.0654 - val_loss: 1.2095 - val_accuracy: 0.5559 - val_macro_f1score: 0.3775 - val_weighted_f1score: 0.0646\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.1336 - accuracy: 0.5680 - macro_f1score: 0.3777 - weighted_f1score: 0.0654 - val_loss: 1.1661 - val_accuracy: 0.5731 - val_macro_f1score: 0.3989 - val_weighted_f1score: 0.0700\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.1195 - accuracy: 0.5736 - macro_f1score: 0.3879 - weighted_f1score: 0.0669 - val_loss: 1.1843 - val_accuracy: 0.5684 - val_macro_f1score: 0.3915 - val_weighted_f1score: 0.0688\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.1136 - accuracy: 0.5749 - macro_f1score: 0.3908 - weighted_f1score: 0.0672 - val_loss: 1.1617 - val_accuracy: 0.5559 - val_macro_f1score: 0.3814 - val_weighted_f1score: 0.0662\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.1082 - accuracy: 0.5758 - macro_f1score: 0.3964 - weighted_f1score: 0.0677 - val_loss: 1.1565 - val_accuracy: 0.5701 - val_macro_f1score: 0.4020 - val_weighted_f1score: 0.0693\n",
      "Epoch 25/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.0953 - accuracy: 0.5814 - macro_f1score: 0.4085 - weighted_f1score: 0.0691 - val_loss: 1.1575 - val_accuracy: 0.5704 - val_macro_f1score: 0.3938 - val_weighted_f1score: 0.0671\n",
      "Epoch 26/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.0919 - accuracy: 0.5882 - macro_f1score: 0.4107 - weighted_f1score: 0.0694 - val_loss: 1.2055 - val_accuracy: 0.5534 - val_macro_f1score: 0.3727 - val_weighted_f1score: 0.0640\n",
      "Epoch 27/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.0886 - accuracy: 0.5827 - macro_f1score: 0.4186 - weighted_f1score: 0.0697 - val_loss: 1.1576 - val_accuracy: 0.5648 - val_macro_f1score: 0.3840 - val_weighted_f1score: 0.0664\n",
      "Epoch 00027: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a7c6bf748>"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3458521,
     "status": "ok",
     "timestamp": 1583368439747,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "s1MHxxJW9dZs",
    "outputId": "2d20cffa-1950-4c87-e814-9ae5694702be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 0s 130us/sample - loss: 1.1217 - accuracy: 0.5730 - macro_f1score: 0.3803 - weighted_f1score: 0.0648\n",
      "\n",
      "Accuracy: 0.5730, Macro F1 Score: 0.3803, Weighted F1 Score: 0.0648\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-72M2H7K9dZv"
   },
   "outputs": [],
   "source": [
    "# 한층당 W 와 b , 2개씩 있으므로 11개층이라면 22개의 모수 벡터 및 행렬이 출력된다.\n",
    "W = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3458520,
     "status": "ok",
     "timestamp": 1583368439752,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "XiHS3PGl9dZx",
    "outputId": "97bac794-12b1-4374-94d2-6d02fb0503cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.00603382,  0.02733675, -0.0172347 ,  0.09976361,\n",
       "            0.03591269,  0.06154356, -0.27886167,  0.1747594 ],\n",
       "          [ 0.00335163, -0.21710117,  0.22996181,  0.1251715 ,\n",
       "           -0.10697839,  0.04452933,  0.0711987 ,  0.24787195],\n",
       "          [-0.07506111, -0.25114205,  0.15309526, -0.13634756,\n",
       "           -0.23240252, -0.12852968, -0.19172572,  0.19764704]],\n",
       " \n",
       "         [[-0.13800357, -0.18231395,  0.20344728, -0.17242506,\n",
       "            0.11104856,  0.23513095,  0.2379421 ,  0.11059583],\n",
       "          [-0.01358065, -0.20922793, -0.12049043, -0.09114791,\n",
       "            0.10302974,  0.17773746,  0.13409042, -0.02881867],\n",
       "          [ 0.09041117,  0.12680635, -0.14835255,  0.17584477,\n",
       "           -0.04743635, -0.10408151,  0.18776798, -0.00561239]],\n",
       " \n",
       "         [[ 0.3224108 ,  0.17165905,  0.19499454,  0.1848479 ,\n",
       "           -0.1850659 ,  0.09877757,  0.12642926,  0.09629154],\n",
       "          [-0.08099049, -0.19010457, -0.24314374,  0.13739224,\n",
       "           -0.23073164, -0.15595315, -0.10505022,  0.23872627],\n",
       "          [ 0.2949158 ,  0.18146883, -0.11703736,  0.02088875,\n",
       "            0.12034092,  0.06131832, -0.13638397,  0.20617306]]],\n",
       " \n",
       " \n",
       "        [[[ 0.14390136,  0.02255549,  0.15099195, -0.15663514,\n",
       "           -0.20148638,  0.13729177,  0.14790572, -0.05563233],\n",
       "          [-0.23266317,  0.20376082,  0.17019546,  0.02213419,\n",
       "           -0.14938834,  0.129486  ,  0.26194936, -0.2612618 ],\n",
       "          [-0.17847311,  0.05046068, -0.09711666,  0.22367404,\n",
       "            0.15154496, -0.2226492 ,  0.15439132,  0.1874107 ]],\n",
       " \n",
       "         [[-0.12999332, -0.27157617, -0.0746493 ,  0.28626436,\n",
       "            0.00802611,  0.18102853,  0.08650177, -0.25682238],\n",
       "          [ 0.00236887, -0.25989476,  0.11261756,  0.15957089,\n",
       "           -0.15067421,  0.19178282,  0.07425978, -0.05045439],\n",
       "          [-0.32724887,  0.09075861, -0.07879164, -0.0406656 ,\n",
       "           -0.05084138,  0.08268551,  0.06491712,  0.16362567]],\n",
       " \n",
       "         [[ 0.22760785, -0.1606229 ,  0.00182603, -0.09692313,\n",
       "            0.17681736,  0.13392045, -0.12996991, -0.16853431],\n",
       "          [ 0.15501958, -0.06931265, -0.18702918, -0.05046604,\n",
       "           -0.02657708, -0.10703979, -0.20348774,  0.2452514 ],\n",
       "          [-0.14294216, -0.26179785, -0.1247303 ,  0.2152401 ,\n",
       "           -0.1999745 , -0.11956681,  0.1580587 , -0.05183174]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0463778 ,  0.15794536,  0.08718105, -0.18647462,\n",
       "            0.01997402, -0.1044628 ,  0.26774874,  0.07900577],\n",
       "          [ 0.18544467,  0.2029835 ,  0.2410161 , -0.33955285,\n",
       "           -0.1696537 , -0.14821795, -0.17839555, -0.17431775],\n",
       "          [ 0.3510389 ,  0.08707972,  0.14933644, -0.29324698,\n",
       "            0.07587474, -0.01801753, -0.18301743, -0.16747463]],\n",
       " \n",
       "         [[-0.03232954, -0.09872362, -0.28128403, -0.29610914,\n",
       "           -0.10361303, -0.08023351,  0.18639196,  0.12318122],\n",
       "          [-0.18624018,  0.1465452 , -0.24335548, -0.31235218,\n",
       "            0.04614091, -0.07980105, -0.02252934, -0.19698575],\n",
       "          [-0.1639724 , -0.23319146, -0.28928515, -0.04402482,\n",
       "           -0.1956669 ,  0.24395432,  0.04115193, -0.06133353]],\n",
       " \n",
       "         [[-0.11495397, -0.07915482,  0.19376482, -0.3448626 ,\n",
       "           -0.18085499,  0.10769568, -0.25932384, -0.26828653],\n",
       "          [-0.02276716,  0.03116356,  0.07748909, -0.17826904,\n",
       "            0.15718913,  0.05887273, -0.29387018, -0.30037868],\n",
       "          [-0.02176248,  0.15595059,  0.0601938 , -0.37433693,\n",
       "           -0.04333544, -0.17437622, -0.20748682, -0.08367284]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.02399732,  0.11352762,  0.02819213, -0.04454377, -0.04555851,\n",
       "        -0.10611806,  0.01442339,  0.07321067], dtype=float32),\n",
       " array([[[[ 2.06540346e-01, -1.18424661e-01,  1.08434081e-01, ...,\n",
       "           -3.83783877e-01,  1.00764044e-01,  8.29290152e-02],\n",
       "          [ 2.58913226e-02, -1.60666630e-01, -1.26505387e-03, ...,\n",
       "           -5.07018343e-02, -9.10111964e-02,  7.25806050e-04],\n",
       "          [ 4.47452329e-02, -2.06653342e-01, -1.39011264e-01, ...,\n",
       "           -1.94398537e-01, -1.37901038e-01, -1.60178453e-01],\n",
       "          ...,\n",
       "          [ 1.24931885e-02,  1.29274903e-02,  3.83977741e-02, ...,\n",
       "           -2.44372878e-02,  1.37937337e-01,  1.52112171e-01],\n",
       "          [ 6.18398637e-02, -8.12761635e-02, -8.02649185e-02, ...,\n",
       "            1.17274456e-01,  9.32490751e-02,  7.20130503e-02],\n",
       "          [ 1.68992519e-01,  1.57976389e-01,  1.19262256e-01, ...,\n",
       "           -6.33500144e-02,  1.42351985e-01,  1.59025431e-01]],\n",
       " \n",
       "         [[ 3.61674249e-01, -2.93896478e-02, -4.10937667e-02, ...,\n",
       "            2.50360399e-01,  7.87253454e-02,  1.49435356e-01],\n",
       "          [-8.50377455e-02,  7.36844689e-02, -1.90407008e-01, ...,\n",
       "           -8.34347308e-02, -1.43581524e-01,  4.63960245e-02],\n",
       "          [ 4.72939834e-02,  5.07887602e-02, -8.77184421e-02, ...,\n",
       "            1.40916646e-01, -3.61017823e-01, -6.77586421e-02],\n",
       "          ...,\n",
       "          [-2.12533951e-01,  3.16351131e-02,  3.18807364e-02, ...,\n",
       "           -1.18869692e-01,  2.04549238e-01,  3.97095084e-02],\n",
       "          [ 6.39308169e-02, -1.92798860e-02, -7.73901716e-02, ...,\n",
       "            1.23222984e-01, -1.90017253e-01,  7.27005079e-02],\n",
       "          [ 1.50187850e-01,  2.15586238e-02,  1.76882949e-02, ...,\n",
       "            1.46519661e-01,  1.08710811e-01,  1.67550415e-01]],\n",
       " \n",
       "         [[-5.97396977e-02, -7.26968572e-02, -1.15285031e-01, ...,\n",
       "            1.47696272e-01, -1.88449785e-01, -1.82645217e-01],\n",
       "          [-8.62514079e-02,  2.49854222e-01, -7.38166645e-02, ...,\n",
       "           -2.67714374e-02, -3.66780683e-02, -1.04297757e-01],\n",
       "          [-1.76367108e-02, -1.81888163e-01, -7.82052726e-02, ...,\n",
       "           -1.91755593e-01, -3.58185291e-01,  1.65636446e-02],\n",
       "          ...,\n",
       "          [-5.80308251e-02,  1.86771415e-02,  1.96203113e-01, ...,\n",
       "            1.66332528e-01,  7.09093586e-02, -1.03012174e-01],\n",
       "          [-9.03179962e-03, -2.04380304e-01, -3.81354094e-02, ...,\n",
       "           -3.02880615e-01, -1.28867269e-01,  6.09541647e-02],\n",
       "          [ 1.37092173e-01,  8.56672898e-02, -2.92938538e-02, ...,\n",
       "           -1.41246796e-01,  3.84981893e-02,  1.88461691e-01]]],\n",
       " \n",
       " \n",
       "        [[[-1.48166507e-01, -2.32947856e-01,  9.19488668e-02, ...,\n",
       "           -2.43239310e-02, -2.67441794e-02, -7.31982440e-02],\n",
       "          [ 1.71585992e-01, -1.64472610e-01,  1.19473889e-01, ...,\n",
       "           -1.32472470e-01,  2.55152881e-02, -3.56808528e-02],\n",
       "          [-8.02106112e-02,  1.54103329e-02,  2.07292035e-01, ...,\n",
       "           -3.11164781e-02, -6.65329248e-02,  1.26231745e-01],\n",
       "          ...,\n",
       "          [ 1.34003401e-01,  1.11013956e-01,  9.22526196e-02, ...,\n",
       "            4.45513353e-02, -2.82073207e-02, -8.44719261e-02],\n",
       "          [-1.48118958e-01,  2.14017227e-01,  2.97302473e-02, ...,\n",
       "            4.56601568e-02,  3.04279663e-02,  1.43430680e-02],\n",
       "          [-2.43759036e-01,  1.25119001e-01, -1.17644127e-02, ...,\n",
       "           -7.56949559e-02,  1.77595541e-02,  1.52695417e-01]],\n",
       " \n",
       "         [[-4.42650206e-02, -1.73595265e-01,  2.13067368e-01, ...,\n",
       "            3.12038381e-02,  4.71478514e-02, -3.60295594e-01],\n",
       "          [ 2.42227823e-01, -1.73412681e-01,  1.70129105e-01, ...,\n",
       "            6.11637533e-02, -2.28411362e-01,  1.16427923e-02],\n",
       "          [-7.93063566e-02, -1.19299799e-01, -2.03592218e-02, ...,\n",
       "            3.49199593e-01, -6.96261004e-02,  3.83692533e-02],\n",
       "          ...,\n",
       "          [ 5.28779998e-02,  5.14093935e-02, -9.32108760e-02, ...,\n",
       "           -6.64626881e-02,  9.75931287e-02, -7.96833411e-02],\n",
       "          [-6.55213417e-03, -7.68246576e-02,  1.02623723e-01, ...,\n",
       "           -3.25715020e-02,  6.54411502e-03, -1.75132066e-01],\n",
       "          [-1.19670577e-01, -1.75645247e-01,  2.21322462e-01, ...,\n",
       "            3.43742333e-02,  1.39532104e-01,  5.56434505e-02]],\n",
       " \n",
       "         [[ 3.93675178e-01, -2.66155750e-01,  2.52021939e-01, ...,\n",
       "            3.57565522e-01,  1.12786748e-01, -7.50721022e-02],\n",
       "          [ 5.28132804e-02,  2.43274458e-02,  3.10964882e-02, ...,\n",
       "            9.24569592e-02, -1.47924749e-02, -3.38339098e-02],\n",
       "          [-6.04897179e-02, -5.32875769e-02, -7.86412954e-02, ...,\n",
       "           -1.08052805e-01, -3.87131989e-01, -1.62856042e-01],\n",
       "          ...,\n",
       "          [-1.77524060e-01,  3.50688919e-02, -1.70593247e-01, ...,\n",
       "            6.91021001e-03, -3.54190730e-02,  1.42596997e-02],\n",
       "          [-3.89849767e-02,  1.21587783e-01,  1.31809415e-04, ...,\n",
       "           -1.61117807e-01, -2.37209082e-01, -1.13220438e-01],\n",
       "          [-1.18532171e-02, -5.85566051e-02,  3.61773580e-01, ...,\n",
       "           -4.21188362e-02, -1.09387919e-01, -1.43556818e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 1.14404358e-01, -2.06373245e-01, -2.05144798e-03, ...,\n",
       "           -9.54879972e-04, -1.09918170e-01, -1.26407713e-01],\n",
       "          [ 1.02297753e-01, -1.92841202e-01,  1.81002825e-01, ...,\n",
       "           -5.62217459e-02, -4.50758711e-02, -1.36766881e-01],\n",
       "          [-1.87779382e-01,  3.69631827e-01, -9.97374430e-02, ...,\n",
       "            1.28995940e-01,  1.28756359e-01, -1.46616012e-01],\n",
       "          ...,\n",
       "          [-1.06222369e-02, -1.37573481e-01,  2.02611852e-02, ...,\n",
       "            1.06145449e-01, -1.78802744e-01, -5.86445481e-02],\n",
       "          [ 1.43400118e-01,  1.74940810e-01, -8.61760229e-02, ...,\n",
       "           -5.00135757e-02,  3.74950841e-02, -1.31937250e-01],\n",
       "          [ 1.16220951e-01, -7.21186250e-02, -1.23047672e-01, ...,\n",
       "            3.51483412e-02,  7.23087490e-02, -2.07084313e-01]],\n",
       " \n",
       "         [[-5.16066663e-02, -1.36299124e-02, -7.74968117e-02, ...,\n",
       "            1.44212127e-01, -6.60840247e-04, -2.63840295e-02],\n",
       "          [-4.19109538e-02,  2.59528030e-02,  4.88506034e-02, ...,\n",
       "           -5.35576791e-02, -1.09948190e-02, -2.86448598e-01],\n",
       "          [ 2.00326778e-02, -1.85233355e-01, -2.26302017e-02, ...,\n",
       "            2.76258171e-01,  2.07795218e-01, -1.37298450e-01],\n",
       "          ...,\n",
       "          [ 2.29789004e-01,  3.08641768e-03, -9.51521248e-02, ...,\n",
       "            7.04694837e-02, -1.73488483e-02, -3.12889032e-02],\n",
       "          [-1.21090129e-01,  1.37573481e-01, -1.40957311e-01, ...,\n",
       "           -1.40346408e-01,  1.31845772e-01,  1.04456797e-01],\n",
       "          [-1.71392620e-01, -3.14140469e-02, -1.54812708e-01, ...,\n",
       "            2.32169665e-02,  4.50073704e-02,  3.16943265e-02]],\n",
       " \n",
       "         [[-4.02186751e-01, -2.08079159e-01, -1.11051477e-01, ...,\n",
       "            1.90282524e-01,  2.28467479e-01, -1.71678178e-02],\n",
       "          [-1.44725502e-03, -1.60784319e-01,  6.99788183e-02, ...,\n",
       "            1.22079030e-01, -5.83543517e-02, -8.20426941e-02],\n",
       "          [ 1.96054548e-01,  4.07485217e-01, -2.73529161e-02, ...,\n",
       "            3.75546776e-02, -1.03775449e-01,  1.02188915e-01],\n",
       "          ...,\n",
       "          [-1.18326517e-02,  4.72393818e-02, -4.30666879e-02, ...,\n",
       "           -1.04629107e-01, -2.80541390e-01,  3.33029814e-02],\n",
       "          [ 8.33922550e-02,  5.38190231e-02, -6.27427176e-02, ...,\n",
       "            1.76683396e-01, -8.74961615e-02,  6.41657487e-02],\n",
       "          [-2.58210033e-01, -1.49141073e-01, -4.46995907e-02, ...,\n",
       "           -7.24463463e-02,  1.03477299e-01,  5.13813198e-02]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.01833524, -0.01445881, -0.01649386,  0.06888404,  0.00547507,\n",
       "        -0.01283514, -0.07502608,  0.00405113,  0.04417066,  0.03485512,\n",
       "         0.00379645,  0.03810407, -0.0514663 , -0.03813543,  0.00283697,\n",
       "         0.03908774], dtype=float32),\n",
       " array([[[[ 0.0725465 ,  0.08346659,  0.1389515 , ..., -0.01214667,\n",
       "            0.15775391,  0.09101051],\n",
       "          [ 0.18733516, -0.05447257,  0.01843798, ..., -0.00181525,\n",
       "            0.1695754 , -0.04312797],\n",
       "          [ 0.04524791, -0.11170965, -0.04869152, ...,  0.01752904,\n",
       "           -0.23016542,  0.02141981],\n",
       "          ...,\n",
       "          [-0.12539057, -0.07321429, -0.10357224, ...,  0.01031399,\n",
       "           -0.0792853 , -0.02706369],\n",
       "          [ 0.10155221, -0.02860574,  0.02134464, ..., -0.06815719,\n",
       "           -0.11782052, -0.06182927],\n",
       "          [ 0.2790902 ,  0.097188  ,  0.11980236, ...,  0.1796938 ,\n",
       "            0.01548037, -0.06085362]],\n",
       " \n",
       "         [[ 0.14141394, -0.23664719, -0.1452798 , ..., -0.08162767,\n",
       "            0.12927076, -0.04609618],\n",
       "          [-0.0027603 , -0.01965904,  0.17695042, ...,  0.06130121,\n",
       "            0.09080233, -0.00725866],\n",
       "          [ 0.15145548, -0.17468289, -0.12750238, ...,  0.03896593,\n",
       "           -0.3796673 , -0.10276213],\n",
       "          ...,\n",
       "          [ 0.03984097, -0.02368789, -0.0764083 , ..., -0.04939689,\n",
       "           -0.14129318, -0.17490387],\n",
       "          [-0.05300451,  0.02882075,  0.10067081, ..., -0.1561241 ,\n",
       "           -0.07744673, -0.01456369],\n",
       "          [-0.07092842,  0.02296062,  0.14223471, ...,  0.20469129,\n",
       "           -0.21451312, -0.06175361]],\n",
       " \n",
       "         [[ 0.11034079, -0.01429263,  0.03016585, ..., -0.09992111,\n",
       "           -0.13093872, -0.00183891],\n",
       "          [-0.14373559,  0.14267461,  0.1435725 , ..., -0.04657228,\n",
       "            0.11852447, -0.03284363],\n",
       "          [ 0.07516598, -0.15797916,  0.13618124, ..., -0.13771307,\n",
       "           -0.08281846,  0.23807132],\n",
       "          ...,\n",
       "          [ 0.1476031 ,  0.00670265,  0.11003633, ..., -0.05102078,\n",
       "           -0.08171322,  0.11524157],\n",
       "          [ 0.13401476,  0.02644526,  0.10297979, ...,  0.01810102,\n",
       "           -0.0196732 ,  0.13199851],\n",
       "          [-0.06743717, -0.07542243,  0.09759843, ...,  0.11849485,\n",
       "           -0.16701226,  0.02170074]]],\n",
       " \n",
       " \n",
       "        [[[ 0.12536737, -0.18763302, -0.24850433, ...,  0.03411254,\n",
       "            0.01809458,  0.10241981],\n",
       "          [ 0.07838625, -0.02279037,  0.01871604, ..., -0.02748411,\n",
       "           -0.0117006 , -0.15489015],\n",
       "          [ 0.13642211, -0.16218936, -0.2645016 , ...,  0.01152935,\n",
       "            0.26941317,  0.00588287],\n",
       "          ...,\n",
       "          [-0.08709716,  0.03240003,  0.0823167 , ...,  0.02005941,\n",
       "           -0.09870876,  0.11012278],\n",
       "          [ 0.01985045, -0.1108795 ,  0.09100088, ..., -0.00538041,\n",
       "            0.07278319,  0.1436455 ],\n",
       "          [ 0.06420154,  0.03654482, -0.06337821, ...,  0.01601561,\n",
       "            0.05893555, -0.21531303]],\n",
       " \n",
       "         [[-0.00512927, -0.09871963, -0.23759525, ...,  0.09008355,\n",
       "           -0.1215563 , -0.1358222 ],\n",
       "          [ 0.13645588, -0.04438855, -0.02934168, ..., -0.01616454,\n",
       "            0.12782298, -0.09733514],\n",
       "          [-0.05264794, -0.03380599, -0.29884148, ...,  0.05665144,\n",
       "           -0.17088892,  0.01005459],\n",
       "          ...,\n",
       "          [-0.08062832,  0.14236327, -0.07733118, ...,  0.0624993 ,\n",
       "           -0.23749536,  0.0293261 ],\n",
       "          [-0.09548747,  0.10205629,  0.02664781, ..., -0.15963565,\n",
       "            0.05649604,  0.16880585],\n",
       "          [-0.06896815,  0.08576199, -0.12778777, ..., -0.02374643,\n",
       "           -0.17995593, -0.14280228]],\n",
       " \n",
       "         [[-0.03026338, -0.14359896, -0.03800713, ...,  0.01401201,\n",
       "           -0.04464285, -0.14622603],\n",
       "          [-0.18965739,  0.13143049,  0.0445314 , ...,  0.13520154,\n",
       "            0.01203876,  0.20170054],\n",
       "          [-0.10061578,  0.01230982,  0.12942198, ...,  0.01728374,\n",
       "           -0.3653313 , -0.00575524],\n",
       "          ...,\n",
       "          [ 0.05889606,  0.03306264,  0.08648226, ..., -0.00666181,\n",
       "            0.01740932,  0.1098759 ],\n",
       "          [-0.04999932, -0.00686395,  0.24440934, ..., -0.2542327 ,\n",
       "           -0.22737868,  0.1623936 ],\n",
       "          [-0.03351363, -0.02043667,  0.06345484, ...,  0.09237426,\n",
       "           -0.21036708, -0.09741583]]],\n",
       " \n",
       " \n",
       "        [[[-0.25201285, -0.10944207,  0.05728775, ...,  0.10335352,\n",
       "            0.24092032,  0.09935754],\n",
       "          [ 0.10276414,  0.06082936,  0.08536608, ..., -0.08097107,\n",
       "            0.05513493,  0.00404322],\n",
       "          [-0.00355542,  0.02407267, -0.18154319, ...,  0.04782899,\n",
       "            0.05123577, -0.0184078 ],\n",
       "          ...,\n",
       "          [-0.26197383, -0.00948343,  0.20430624, ...,  0.00369381,\n",
       "           -0.12119769,  0.00373289],\n",
       "          [-0.03948703,  0.08687253,  0.06226939, ...,  0.19372338,\n",
       "            0.06284981,  0.07318896],\n",
       "          [-0.13832377,  0.11389042, -0.0457679 , ..., -0.02817739,\n",
       "           -0.00317499, -0.03204745]],\n",
       " \n",
       "         [[ 0.04359232,  0.09559507, -0.28630206, ...,  0.02161167,\n",
       "            0.00734612,  0.14280854],\n",
       "          [ 0.06883519,  0.04349172,  0.05548784, ...,  0.06604509,\n",
       "           -0.09117954,  0.03638939],\n",
       "          [-0.0708422 ,  0.05530958, -0.26090693, ..., -0.01067341,\n",
       "           -0.2421372 ,  0.02866258],\n",
       "          ...,\n",
       "          [ 0.02184799,  0.19306177,  0.04778832, ..., -0.26380542,\n",
       "           -0.49257365,  0.01472627],\n",
       "          [-0.04714994, -0.01014166, -0.16919681, ..., -0.02999623,\n",
       "           -0.06808145,  0.02027502],\n",
       "          [-0.09161057, -0.1287028 , -0.42182365, ..., -0.00314977,\n",
       "           -0.17185952,  0.03758449]],\n",
       " \n",
       "         [[ 0.04070688,  0.0048851 ,  0.06693037, ..., -0.05684924,\n",
       "            0.00880093, -0.06885187],\n",
       "          [-0.04704131,  0.17214188, -0.19990253, ...,  0.13474819,\n",
       "           -0.03551356,  0.093321  ],\n",
       "          [ 0.005892  ,  0.13668196,  0.18486951, ..., -0.13254152,\n",
       "           -0.14159082, -0.13848177],\n",
       "          ...,\n",
       "          [ 0.02104789,  0.14570566,  0.11722764, ..., -0.3351071 ,\n",
       "           -0.20488709, -0.02724919],\n",
       "          [-0.13517886,  0.18321304,  0.07094335, ..., -0.10675164,\n",
       "            0.00539574, -0.17623624],\n",
       "          [-0.04589065, -0.02996734, -0.14256087, ...,  0.12115508,\n",
       "           -0.12921064,  0.13437091]]]], dtype=float32),\n",
       " array([-0.15484741, -0.06252424,  0.0766439 ,  0.05978486,  0.03480628,\n",
       "         0.08197206,  0.09707367, -0.03904669,  0.0285302 , -0.04642882,\n",
       "         0.13650316,  0.02215963,  0.066216  ,  0.01946565, -0.02507489,\n",
       "         0.10085054, -0.01085287,  0.06533812,  0.01362276,  0.03919302,\n",
       "         0.03922914,  0.09382238,  0.08097375,  0.01496687,  0.07309191,\n",
       "         0.04143219,  0.00123729,  0.05446931,  0.11656909,  0.06771113,\n",
       "         0.06133033,  0.02251646], dtype=float32),\n",
       " array([[[[-0.01513063, -0.04862227,  0.13865836, ...,  0.02455333,\n",
       "            0.10692064, -0.09880172],\n",
       "          [ 0.03122072, -0.10170542,  0.12052013, ..., -0.05108332,\n",
       "           -0.06783529, -0.07429724],\n",
       "          [-0.16957957,  0.05338782,  0.1412804 , ..., -0.04467365,\n",
       "            0.25199756,  0.03631617],\n",
       "          ...,\n",
       "          [ 0.01458191, -0.20451654,  0.17212316, ..., -0.06337702,\n",
       "           -0.09165251, -0.00933322],\n",
       "          [ 0.00083731,  0.13760191, -0.17598912, ...,  0.03119347,\n",
       "            0.12490631, -0.1412599 ],\n",
       "          [-0.13440719, -0.09249908, -0.09546541, ...,  0.09152023,\n",
       "           -0.01785727, -0.14997894]],\n",
       " \n",
       "         [[ 0.20015457,  0.04984206,  0.07891876, ...,  0.06265697,\n",
       "           -0.02792909, -0.15315756],\n",
       "          [ 0.07146785,  0.02465041,  0.12238267, ..., -0.10004909,\n",
       "            0.0473012 , -0.08857654],\n",
       "          [-0.13044158, -0.14520028,  0.00562192, ..., -0.24333446,\n",
       "            0.21263817, -0.03228731],\n",
       "          ...,\n",
       "          [ 0.1590245 , -0.2043857 ,  0.00105339, ..., -0.05389934,\n",
       "           -0.13255909, -0.0659525 ],\n",
       "          [-0.023637  ,  0.02622456, -0.16019928, ...,  0.17444445,\n",
       "           -0.0215502 ,  0.09973491],\n",
       "          [-0.04638829, -0.03357984,  0.03969058, ...,  0.18728991,\n",
       "           -0.06695957, -0.02610408]],\n",
       " \n",
       "         [[-0.12610972,  0.09890357,  0.07563017, ...,  0.12320165,\n",
       "           -0.04378276, -0.02902511],\n",
       "          [ 0.03187706, -0.10497668, -0.04646737, ...,  0.0493187 ,\n",
       "            0.04522759,  0.04901936],\n",
       "          [-0.05959829, -0.06199139, -0.04421965, ..., -0.03828646,\n",
       "            0.08683793, -0.14493378],\n",
       "          ...,\n",
       "          [ 0.05214632, -0.18696532,  0.12063458, ..., -0.05430499,\n",
       "           -0.06897146, -0.12915336],\n",
       "          [ 0.08983935, -0.06368084,  0.03413767, ..., -0.05010463,\n",
       "           -0.00287913,  0.16710274],\n",
       "          [-0.04046388,  0.05793923, -0.06252434, ..., -0.04248429,\n",
       "           -0.10894772,  0.07931216]]],\n",
       " \n",
       " \n",
       "        [[[ 0.07747605, -0.04100625, -0.08554148, ...,  0.08802913,\n",
       "            0.02294118, -0.1521742 ],\n",
       "          [-0.03928396, -0.08845329, -0.12712602, ..., -0.15738629,\n",
       "           -0.05423476, -0.0918092 ],\n",
       "          [-0.06056822,  0.13019499,  0.10682499, ..., -0.21935463,\n",
       "            0.17862934,  0.09632214],\n",
       "          ...,\n",
       "          [ 0.09495218,  0.01553531, -0.00284604, ...,  0.12797496,\n",
       "            0.00138074, -0.02415473],\n",
       "          [-0.05182264, -0.03932034, -0.12945138, ..., -0.02335605,\n",
       "            0.39308354, -0.20065016],\n",
       "          [-0.21563835,  0.05759921, -0.25829476, ...,  0.00995958,\n",
       "           -0.03368217, -0.21426651]],\n",
       " \n",
       "         [[ 0.02737994,  0.06032746, -0.04974093, ...,  0.05779359,\n",
       "           -0.05900361,  0.09244609],\n",
       "          [-0.04199873, -0.07504296, -0.2333641 , ..., -0.14492543,\n",
       "           -0.06587053, -0.32257673],\n",
       "          [-0.06276832,  0.01351512,  0.10116667, ..., -0.06218731,\n",
       "           -0.05907742, -0.17392914],\n",
       "          ...,\n",
       "          [ 0.15606807,  0.0654626 ,  0.19540629, ..., -0.02629406,\n",
       "           -0.1634767 ,  0.02308211],\n",
       "          [-0.06432243, -0.11512457, -0.10743095, ...,  0.03623068,\n",
       "            0.18999761, -0.16550118],\n",
       "          [-0.06554364,  0.12951188, -0.4056509 , ...,  0.09873155,\n",
       "           -0.00843794, -0.07525419]],\n",
       " \n",
       "         [[-0.1962517 ,  0.07187799,  0.04974776, ...,  0.08682942,\n",
       "            0.11748827, -0.08191408],\n",
       "          [ 0.12642619, -0.02716351, -0.24070126, ...,  0.1399176 ,\n",
       "           -0.02359308, -0.03616526],\n",
       "          [ 0.03226882,  0.10212188, -0.04335919, ...,  0.09196645,\n",
       "           -0.07789373, -0.05742345],\n",
       "          ...,\n",
       "          [ 0.10989371, -0.03522003,  0.07579759, ..., -0.04310738,\n",
       "           -0.13511465,  0.03194493],\n",
       "          [ 0.15667287,  0.08304536,  0.0248075 , ..., -0.0028005 ,\n",
       "            0.10632947,  0.02789945],\n",
       "          [-0.02519399, -0.02757921, -0.28079116, ..., -0.17570159,\n",
       "           -0.22881405,  0.13410324]]],\n",
       " \n",
       " \n",
       "        [[[-0.00067574,  0.04037515, -0.00873634, ...,  0.17088707,\n",
       "            0.01977108, -0.03226915],\n",
       "          [ 0.00254923,  0.04281643,  0.00904447, ..., -0.16183276,\n",
       "           -0.04426852, -0.06851221],\n",
       "          [ 0.00657754,  0.0692651 , -0.15493985, ..., -0.07220098,\n",
       "           -0.14714086, -0.02413881],\n",
       "          ...,\n",
       "          [-0.07531752,  0.15006137, -0.234193  , ...,  0.19047022,\n",
       "           -0.04636411,  0.10451167],\n",
       "          [ 0.13585271, -0.1342312 , -0.12448166, ..., -0.12016331,\n",
       "           -0.08911368,  0.1325007 ],\n",
       "          [ 0.01359652, -0.13252595,  0.13986766, ..., -0.1764996 ,\n",
       "            0.11956269, -0.0125646 ]],\n",
       " \n",
       "         [[-0.1616466 , -0.1819952 ,  0.01725365, ..., -0.20428592,\n",
       "           -0.1709551 ,  0.06150475],\n",
       "          [ 0.1473588 , -0.00925221, -0.0290093 , ..., -0.00320259,\n",
       "           -0.12884441,  0.02692149],\n",
       "          [ 0.03173043,  0.19909337, -0.04486019, ...,  0.02669746,\n",
       "           -0.28829753, -0.28209132],\n",
       "          ...,\n",
       "          [ 0.02205753,  0.06915452, -0.13900582, ..., -0.11355002,\n",
       "           -0.05551716,  0.09450689],\n",
       "          [ 0.17454085, -0.17232637, -0.1583292 , ..., -0.02961154,\n",
       "           -0.09480074,  0.1553686 ],\n",
       "          [-0.02209046, -0.18213733,  0.12683609, ..., -0.04002179,\n",
       "            0.03499347,  0.02010596]],\n",
       " \n",
       "         [[-0.22708547, -0.1632408 ,  0.13831335, ..., -0.17160232,\n",
       "           -0.16925019, -0.09345769],\n",
       "          [ 0.17057191, -0.07002714,  0.08143594, ...,  0.07670254,\n",
       "            0.0528126 , -0.06977096],\n",
       "          [-0.12771468,  0.10692632, -0.16512956, ...,  0.19480824,\n",
       "           -0.20975572, -0.01236591],\n",
       "          ...,\n",
       "          [ 0.00900698, -0.07017161, -0.19146205, ..., -0.15621626,\n",
       "            0.09944035,  0.05963947],\n",
       "          [ 0.18536177, -0.1095983 , -0.26176906, ...,  0.09028251,\n",
       "           -0.10708776, -0.14553809],\n",
       "          [ 0.17170186, -0.08118528,  0.14571083, ..., -0.11659718,\n",
       "           -0.14848457,  0.03128488]]]], dtype=float32),\n",
       " array([ 0.06717017,  0.08732106, -0.02496137, -0.06616404,  0.03496521,\n",
       "         0.00995503,  0.03494661, -0.04670615, -0.01390091,  0.01316897,\n",
       "         0.03426657,  0.02123792, -0.03652127, -0.0571823 , -0.00736364,\n",
       "        -0.03720619, -0.02925509,  0.09610537, -0.10303104,  0.10256828,\n",
       "         0.04494863,  0.00425685, -0.10346117,  0.04127326,  0.04959923,\n",
       "        -0.00407151,  0.00815153,  0.02602067, -0.07866612, -0.03125947,\n",
       "         0.02634396,  0.06384747], dtype=float32),\n",
       " array([[[[-2.85969004e-02, -1.07216779e-02,  5.21045271e-03, ...,\n",
       "           -1.41374364e-01,  5.61290942e-02,  2.54200753e-02],\n",
       "          [-3.47477533e-02,  9.60312933e-02, -1.31017063e-02, ...,\n",
       "           -6.17263913e-02, -5.56175299e-02, -1.29811555e-01],\n",
       "          [-1.51880398e-01,  1.90692365e-01,  1.31672826e-02, ...,\n",
       "           -3.14794451e-01, -1.20081626e-01,  2.94405990e-03],\n",
       "          ...,\n",
       "          [-1.09443121e-01,  1.01847149e-01, -1.47430733e-01, ...,\n",
       "           -3.30685288e-01, -4.51211929e-02, -1.38276979e-01],\n",
       "          [-1.30816743e-01, -8.69368240e-02,  1.40282333e-01, ...,\n",
       "           -9.11826938e-02,  3.53392251e-02, -8.26159194e-02],\n",
       "          [-4.63965572e-02, -7.38564730e-02,  4.87823710e-02, ...,\n",
       "            1.26591459e-01, -1.35180354e-01, -1.64516538e-01]],\n",
       " \n",
       "         [[ 3.89708355e-02, -8.12037587e-02, -1.21906004e-03, ...,\n",
       "            1.70201790e-02,  4.88948002e-02, -4.33160588e-02],\n",
       "          [-6.62467070e-03,  4.82112877e-02, -1.40505031e-01, ...,\n",
       "            2.40753125e-02, -1.59849212e-01, -1.42701808e-02],\n",
       "          [ 2.51776376e-03,  1.22252911e-01, -1.15869686e-01, ...,\n",
       "           -1.17270663e-01, -6.85491189e-02, -1.93125047e-02],\n",
       "          ...,\n",
       "          [-5.48589379e-02,  5.58731444e-02, -2.66651046e-02, ...,\n",
       "           -1.84607327e-01, -1.06464177e-01, -3.59825343e-02],\n",
       "          [ 2.13687465e-01, -2.50034809e-01, -1.05503644e-03, ...,\n",
       "            5.38570508e-02, -1.24177136e-01, -1.80101514e-01],\n",
       "          [-9.90788862e-02, -1.65274423e-02,  1.58967108e-01, ...,\n",
       "            2.85869837e-02,  1.30285889e-01, -2.38372665e-02]],\n",
       " \n",
       "         [[-1.74239520e-02, -9.53062698e-02,  1.16328411e-01, ...,\n",
       "           -8.14004019e-02, -3.08357142e-02, -5.26834801e-02],\n",
       "          [ 8.44304413e-02,  5.19085117e-02, -3.61732207e-02, ...,\n",
       "           -8.92907605e-02, -2.90260594e-02, -1.34926870e-01],\n",
       "          [ 5.64690270e-02,  1.11723974e-01, -2.22821251e-01, ...,\n",
       "            8.12877435e-03,  2.46416591e-02, -9.71030071e-02],\n",
       "          ...,\n",
       "          [ 6.50730133e-02, -1.29864216e-02, -8.28818530e-02, ...,\n",
       "           -6.10503070e-02,  1.27063310e-02, -6.74089268e-02],\n",
       "          [ 2.34335244e-01, -1.03668593e-01, -1.19255580e-01, ...,\n",
       "            1.55621111e-01,  1.59882195e-02, -1.19877778e-01],\n",
       "          [ 2.10859954e-01,  5.01967482e-02,  1.99088338e-03, ...,\n",
       "            5.47726266e-02,  2.78715249e-02, -5.10161854e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 5.51686846e-02, -1.76377017e-02, -4.86796023e-03, ...,\n",
       "           -3.53047997e-02,  1.24763567e-02,  6.40233932e-03],\n",
       "          [ 1.63479783e-02, -4.02480774e-02,  2.21602008e-01, ...,\n",
       "           -1.92862302e-02,  2.22779304e-01, -1.22252367e-01],\n",
       "          [ 2.21250746e-02,  4.18869779e-02, -1.21289253e-01, ...,\n",
       "           -5.45574799e-02, -2.61950254e-01, -6.36507524e-03],\n",
       "          ...,\n",
       "          [-2.29679868e-01, -3.46059352e-02, -1.95179299e-01, ...,\n",
       "            8.68200660e-02,  4.13194112e-02, -6.69589862e-02],\n",
       "          [-1.10340446e-01, -2.17693239e-01, -6.97236881e-02, ...,\n",
       "           -1.03149369e-01, -2.21647695e-02, -5.55002363e-03],\n",
       "          [ 3.25768776e-02, -2.15336278e-01, -4.04945463e-02, ...,\n",
       "            8.30711573e-02, -6.53926879e-02,  9.62547883e-02]],\n",
       " \n",
       "         [[ 8.11495930e-02,  1.95540160e-01, -1.27213240e-01, ...,\n",
       "           -2.70065963e-02,  2.78577432e-02,  1.31813779e-01],\n",
       "          [-6.17225654e-02, -4.59690504e-02,  2.32850716e-01, ...,\n",
       "            9.36890170e-02, -9.73901972e-02, -8.70541558e-02],\n",
       "          [-5.85592464e-02,  1.13327324e-01,  6.35203905e-03, ...,\n",
       "            1.58126764e-02, -1.38221115e-01, -3.84555832e-02],\n",
       "          ...,\n",
       "          [-1.90689620e-02, -8.90405942e-03, -4.86934707e-02, ...,\n",
       "           -7.94674158e-02, -4.02867086e-02, -2.34811619e-01],\n",
       "          [ 9.90656242e-02, -6.09520823e-02, -7.65060559e-02, ...,\n",
       "           -1.41233712e-01, -1.00688830e-01, -2.12159753e-01],\n",
       "          [ 2.02225591e-03,  1.01002276e-01,  1.22842036e-01, ...,\n",
       "            1.03150330e-01, -2.72645596e-02, -4.21293005e-02]],\n",
       " \n",
       "         [[-1.10193416e-01, -1.44263521e-01,  8.51422995e-02, ...,\n",
       "            1.62879433e-02,  1.28599986e-01, -2.50947922e-02],\n",
       "          [ 2.48838402e-02,  2.70658731e-01,  3.58441286e-03, ...,\n",
       "           -1.09513365e-01, -3.72496396e-01,  3.53210643e-02],\n",
       "          [ 6.76845387e-02,  5.70219681e-02, -1.30889550e-01, ...,\n",
       "           -1.21004447e-01, -1.65227205e-01, -1.03574365e-01],\n",
       "          ...,\n",
       "          [ 1.02472141e-01,  5.14683835e-02, -9.53472685e-03, ...,\n",
       "           -7.07501620e-02, -1.36984751e-01, -2.47807428e-02],\n",
       "          [ 4.94699329e-02, -8.79250988e-02,  7.42610693e-02, ...,\n",
       "           -3.12322795e-01,  7.52000213e-02, -1.84042320e-01],\n",
       "          [ 1.75117597e-01,  1.77100272e-04,  7.25610852e-02, ...,\n",
       "            4.50482480e-02, -1.11472398e-01, -1.36519343e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 1.63766176e-01, -1.83037698e-01,  3.06089539e-02, ...,\n",
       "           -1.44092068e-01,  4.07979861e-02, -4.57205474e-02],\n",
       "          [-6.26345947e-02, -9.90209579e-02, -4.88584638e-02, ...,\n",
       "            2.87830699e-02,  1.44177720e-01, -1.45336732e-01],\n",
       "          [ 6.30883649e-02, -1.46248147e-01,  1.09623345e-02, ...,\n",
       "            1.20007388e-01, -9.72094312e-02, -7.40410611e-02],\n",
       "          ...,\n",
       "          [ 8.08315799e-02,  2.69716624e-02,  4.49733576e-03, ...,\n",
       "            1.40347689e-01,  1.85604066e-01, -5.83582632e-02],\n",
       "          [-7.54465302e-03, -3.14734015e-03, -6.01421949e-03, ...,\n",
       "            1.08072516e-02,  1.26273602e-01, -1.60248369e-01],\n",
       "          [ 1.24172159e-01, -1.37659028e-01, -2.01820582e-01, ...,\n",
       "            5.29635847e-02,  9.50931907e-02, -6.68565854e-02]],\n",
       " \n",
       "         [[ 8.54842961e-02,  2.36158207e-01, -1.39706582e-01, ...,\n",
       "           -4.24024928e-03, -1.67078063e-01,  6.21402711e-02],\n",
       "          [ 4.38682325e-02, -1.15302004e-01,  9.07342136e-02, ...,\n",
       "           -7.95204341e-02,  1.14430385e-02, -4.82070027e-03],\n",
       "          [-1.23805396e-04,  7.91520551e-02,  1.96515396e-01, ...,\n",
       "           -6.45926297e-02, -4.98119555e-02, -4.01551500e-02],\n",
       "          ...,\n",
       "          [-3.03754620e-02, -6.50579557e-02, -7.03768060e-02, ...,\n",
       "           -9.36303884e-02, -4.23746556e-03, -3.15795213e-01],\n",
       "          [-1.84830844e-01, -1.21593848e-01,  1.04578212e-01, ...,\n",
       "           -2.69633392e-03, -5.58978170e-02, -1.48219585e-01],\n",
       "          [-6.90598786e-02,  1.05996460e-01,  3.66605818e-02, ...,\n",
       "           -8.11663829e-03, -2.54985765e-02, -1.54000893e-01]],\n",
       " \n",
       "         [[-1.85066998e-01, -1.13235034e-01, -1.83945358e-01, ...,\n",
       "            3.64733525e-02,  6.29345849e-02, -1.90564498e-01],\n",
       "          [ 1.93506747e-01,  1.23072453e-01, -2.44010910e-02, ...,\n",
       "            1.11675449e-01, -2.42512926e-01, -2.13113353e-01],\n",
       "          [ 1.98679253e-01, -1.33707784e-02, -8.63543823e-02, ...,\n",
       "            1.69502765e-01, -1.30187139e-01, -7.10118860e-02],\n",
       "          ...,\n",
       "          [ 8.48091915e-02, -2.48277448e-02, -6.80771917e-02, ...,\n",
       "            1.07793495e-01, -7.35159591e-02, -1.20320998e-01],\n",
       "          [-8.05981010e-02, -1.47565886e-01, -2.23606993e-02, ...,\n",
       "           -1.41163260e-01, -8.73482078e-02, -1.94796070e-01],\n",
       "          [ 2.33709011e-02, -1.10983372e-01,  7.98931122e-02, ...,\n",
       "            2.68037207e-02, -7.31863678e-02, -4.03082445e-02]]]],\n",
       "       dtype=float32),\n",
       " array([-0.02061274, -0.02360253, -0.05459574,  0.03130476,  0.03517974,\n",
       "        -0.06966298,  0.05116604, -0.0086432 ,  0.04415346, -0.01630963,\n",
       "        -0.05479279,  0.09635   , -0.0417104 ,  0.06772787, -0.07089088,\n",
       "         0.03087839,  0.12115099,  0.00168544,  0.02962834, -0.07386225,\n",
       "         0.05120674,  0.01593411,  0.02122129,  0.07978033, -0.03693098,\n",
       "        -0.04572721, -0.00650184,  0.00686211,  0.07961646,  0.03133691,\n",
       "         0.01704139,  0.02725413, -0.0328    ,  0.11205161,  0.05875481,\n",
       "        -0.01275448, -0.02219463,  0.03146242, -0.11532915,  0.04128096,\n",
       "        -0.05021863,  0.01688473, -0.06306124,  0.07697988,  0.09902595,\n",
       "        -0.02155839,  0.01287565, -0.08260431,  0.00519016,  0.03265589,\n",
       "         0.02387811,  0.02417001,  0.00429774,  0.02401014, -0.020933  ,\n",
       "        -0.06063441,  0.08039304, -0.06076749,  0.09786135,  0.06192409,\n",
       "         0.06262877,  0.0906016 ,  0.13076206, -0.06415122], dtype=float32),\n",
       " array([[[[ 0.15517583, -0.12411087, -0.02711235, ...,  0.04628432,\n",
       "           -0.07760491,  0.04823203],\n",
       "          [ 0.15427113,  0.00554184,  0.12442375, ...,  0.03618246,\n",
       "           -0.13827252, -0.03428236],\n",
       "          [ 0.1899301 , -0.2850972 , -0.21835689, ...,  0.01603995,\n",
       "           -0.15831155,  0.2135666 ],\n",
       "          ...,\n",
       "          [ 0.13901669,  0.02922038, -0.07263207, ..., -0.09258412,\n",
       "            0.04297095,  0.12013708],\n",
       "          [-0.11757725, -0.12031741,  0.10133862, ..., -0.13535483,\n",
       "            0.03513   ,  0.08599398],\n",
       "          [ 0.10043123,  0.00115581,  0.10821374, ..., -0.04685861,\n",
       "           -0.02736132, -0.09223089]],\n",
       " \n",
       "         [[ 0.13138208, -0.2088721 ,  0.11312982, ..., -0.10680146,\n",
       "           -0.01560453,  0.06226289],\n",
       "          [ 0.11461202,  0.09658216,  0.01408696, ...,  0.01183313,\n",
       "            0.10835605,  0.0486048 ],\n",
       "          [ 0.15747093, -0.17442875, -0.05498003, ..., -0.0274874 ,\n",
       "           -0.12696439,  0.00546248],\n",
       "          ...,\n",
       "          [-0.02654479,  0.00309927, -0.11106626, ...,  0.21548788,\n",
       "           -0.09714489,  0.09297863],\n",
       "          [-0.10840186,  0.05517175, -0.05997511, ...,  0.05826068,\n",
       "            0.02509197,  0.11640014],\n",
       "          [-0.01878252, -0.02497624, -0.01333266, ...,  0.00850125,\n",
       "           -0.02637762, -0.07404487]],\n",
       " \n",
       "         [[ 0.04106837,  0.04243252, -0.1222437 , ..., -0.09072214,\n",
       "           -0.03637537, -0.00432907],\n",
       "          [ 0.08094874, -0.03623834, -0.01853321, ...,  0.0743726 ,\n",
       "           -0.13299328,  0.14105868],\n",
       "          [ 0.20019397, -0.10472691,  0.14440417, ...,  0.01482759,\n",
       "           -0.13134949, -0.05095596],\n",
       "          ...,\n",
       "          [-0.01517695, -0.11878387, -0.02569292, ...,  0.30704227,\n",
       "            0.09548267, -0.15179408],\n",
       "          [-0.06879283,  0.13133305, -0.03880754, ..., -0.0277403 ,\n",
       "            0.04955456, -0.20638342],\n",
       "          [ 0.10450422, -0.11504131, -0.02280677, ...,  0.15774699,\n",
       "            0.00316907, -0.1266084 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0487374 , -0.05568007, -0.10565618, ...,  0.15422812,\n",
       "            0.00034919,  0.02900046],\n",
       "          [ 0.00403841,  0.01310872,  0.02166575, ..., -0.08982203,\n",
       "           -0.01033458, -0.12480845],\n",
       "          [ 0.1610971 , -0.02602446,  0.02867712, ...,  0.0140357 ,\n",
       "           -0.11231384,  0.084485  ],\n",
       "          ...,\n",
       "          [ 0.1089185 , -0.07678517, -0.13264106, ..., -0.16486214,\n",
       "           -0.11622676,  0.03011318],\n",
       "          [-0.0641083 , -0.15794158,  0.13428071, ...,  0.02477163,\n",
       "            0.1301876 ,  0.06515104],\n",
       "          [ 0.06427466, -0.0339039 , -0.08168947, ..., -0.05647794,\n",
       "           -0.00102344, -0.06947979]],\n",
       " \n",
       "         [[ 0.12244774, -0.05560545, -0.14641477, ..., -0.1662723 ,\n",
       "            0.07359066,  0.06849797],\n",
       "          [-0.0022579 ,  0.0863688 , -0.10856482, ...,  0.00220563,\n",
       "           -0.01350209, -0.00222528],\n",
       "          [-0.08246894,  0.03205479, -0.03510608, ...,  0.0899416 ,\n",
       "           -0.06579664,  0.1294488 ],\n",
       "          ...,\n",
       "          [-0.09190913, -0.06618208, -0.20289604, ..., -0.1215592 ,\n",
       "            0.02927408, -0.03973305],\n",
       "          [-0.15749408, -0.01803858,  0.11656243, ..., -0.13407786,\n",
       "            0.01747663,  0.10586936],\n",
       "          [ 0.24379088,  0.0833822 , -0.07627257, ..., -0.01810347,\n",
       "           -0.07601157, -0.03751169]],\n",
       " \n",
       "         [[-0.05675107,  0.02926915, -0.04664547, ..., -0.04086412,\n",
       "           -0.01690658,  0.13673045],\n",
       "          [-0.20307247,  0.0592289 , -0.03534654, ..., -0.08147457,\n",
       "            0.0633618 , -0.02763775],\n",
       "          [ 0.00129725,  0.00529532,  0.10903876, ..., -0.06712183,\n",
       "            0.00972697,  0.02072153],\n",
       "          ...,\n",
       "          [ 0.01021101,  0.01541339, -0.12702285, ...,  0.03184868,\n",
       "            0.01747477,  0.02083836],\n",
       "          [-0.20726408,  0.12801   ,  0.07659512, ...,  0.1151504 ,\n",
       "           -0.0159482 , -0.02401199],\n",
       "          [ 0.01184418,  0.01618207,  0.03084679, ..., -0.14065911,\n",
       "           -0.07054283,  0.00946315]]],\n",
       " \n",
       " \n",
       "        [[[-0.14863214, -0.03584143,  0.10797153, ...,  0.10652465,\n",
       "           -0.17994136, -0.09006242],\n",
       "          [ 0.17544223,  0.13633944,  0.02586574, ..., -0.2147086 ,\n",
       "            0.00799971,  0.00814461],\n",
       "          [-0.23523098, -0.06623461,  0.12736872, ...,  0.1414561 ,\n",
       "            0.19374542, -0.14996862],\n",
       "          ...,\n",
       "          [ 0.20713848, -0.04926138, -0.10575206, ...,  0.0042523 ,\n",
       "           -0.00088611,  0.00997931],\n",
       "          [-0.1392053 , -0.08042527, -0.07371823, ...,  0.15338539,\n",
       "            0.03251723, -0.27454007],\n",
       "          [-0.19521204,  0.04830429, -0.02113415, ...,  0.15403011,\n",
       "           -0.07595079, -0.05756621]],\n",
       " \n",
       "         [[-0.03064744,  0.10971519,  0.00599282, ..., -0.04057145,\n",
       "           -0.12631807, -0.0794918 ],\n",
       "          [ 0.2459854 ,  0.04537009, -0.03210955, ..., -0.10321484,\n",
       "           -0.11815304,  0.12017673],\n",
       "          [-0.30880073, -0.11054676, -0.0735443 , ..., -0.20020142,\n",
       "           -0.04246123, -0.22874328],\n",
       "          ...,\n",
       "          [-0.0603645 ,  0.03346709, -0.26072383, ...,  0.0899156 ,\n",
       "            0.04142951, -0.10951304],\n",
       "          [-0.09262303,  0.02610753,  0.08604696, ..., -0.28615522,\n",
       "           -0.04147312, -0.10591331],\n",
       "          [ 0.07429226, -0.1078189 , -0.02868268, ..., -0.14341566,\n",
       "            0.07443497, -0.05850049]],\n",
       " \n",
       "         [[-0.02509359, -0.11649409,  0.04245038, ..., -0.12631454,\n",
       "            0.01703254, -0.29400405],\n",
       "          [-0.12423512, -0.16224101, -0.00624433, ...,  0.02883054,\n",
       "            0.05111376,  0.07218461],\n",
       "          [-0.14482237, -0.02356882, -0.15975983, ..., -0.07896259,\n",
       "           -0.09065895, -0.28407142],\n",
       "          ...,\n",
       "          [-0.08798933,  0.12007461, -0.13112934, ..., -0.04425716,\n",
       "           -0.00069894, -0.1556503 ],\n",
       "          [ 0.05009994,  0.1354756 , -0.10860725, ...,  0.022998  ,\n",
       "           -0.06361414, -0.03308641],\n",
       "          [-0.07036486, -0.00846054,  0.00860726, ..., -0.02637712,\n",
       "            0.01980924, -0.10679138]]]], dtype=float32),\n",
       " array([ 0.01925298,  0.02402277,  0.03501058, -0.01985068, -0.04101755,\n",
       "        -0.0434468 , -0.01847188,  0.02336119, -0.01876949,  0.06536531,\n",
       "         0.06570226, -0.06916445,  0.01299286, -0.0417275 , -0.05451317,\n",
       "        -0.0782212 , -0.06921427,  0.02444252, -0.01726377,  0.01665036,\n",
       "         0.00479702, -0.01823899,  0.02636178,  0.00035798, -0.03301939,\n",
       "         0.00645583, -0.07064069, -0.09478707, -0.02905945, -0.00088909,\n",
       "        -0.06085704, -0.06004774,  0.08045274, -0.03491589,  0.0443772 ,\n",
       "        -0.06867448,  0.04861344, -0.07863913, -0.01992965, -0.00402377,\n",
       "        -0.02684539,  0.04094693, -0.02586483, -0.05424359, -0.02879715,\n",
       "        -0.00869159, -0.04784834,  0.06481569,  0.01939198, -0.03176703,\n",
       "        -0.01325944,  0.0980712 , -0.01273893, -0.00345938,  0.01467399,\n",
       "         0.01431608, -0.031599  , -0.05474754, -0.06882641, -0.08628146,\n",
       "        -0.01862662,  0.04082699,  0.02469061,  0.0008432 ], dtype=float32),\n",
       " array([[[[ 3.07376757e-02, -8.93259197e-02, -9.13002118e-02, ...,\n",
       "           -1.57154322e-01, -1.55975014e-01, -1.59916312e-01],\n",
       "          [ 2.09542864e-04,  1.47597007e-02, -6.28410950e-02, ...,\n",
       "           -6.26024902e-02, -3.58988270e-02,  1.28042608e-01],\n",
       "          [-2.42888242e-01, -6.47211596e-02,  1.33282200e-01, ...,\n",
       "           -1.02446496e-01,  5.95282717e-03,  8.92745927e-02],\n",
       "          ...,\n",
       "          [ 1.82340816e-02,  3.11215036e-03,  1.12763673e-01, ...,\n",
       "           -6.76134974e-02, -1.13955535e-01, -6.22454770e-02],\n",
       "          [-6.07550740e-02, -7.33033344e-02, -3.54207866e-02, ...,\n",
       "            3.92378308e-02,  1.36043325e-01, -2.84611583e-02],\n",
       "          [ 1.38038039e-01,  1.37222573e-01, -5.37503846e-02, ...,\n",
       "           -1.48752499e-02, -7.58644252e-04,  2.56935190e-02]],\n",
       " \n",
       "         [[ 1.57313243e-01,  2.62418594e-02,  1.95964426e-01, ...,\n",
       "           -1.06526976e-02, -9.37433243e-02,  5.19319884e-02],\n",
       "          [-5.41911973e-03,  1.22483131e-02, -7.04465136e-02, ...,\n",
       "           -1.20555468e-01, -5.56948371e-02, -1.84335038e-02],\n",
       "          [ 4.47898209e-02,  7.03249723e-02, -9.81011316e-02, ...,\n",
       "            1.92287713e-02, -1.55096985e-02, -1.17311753e-01],\n",
       "          ...,\n",
       "          [-1.15415446e-01,  2.34952550e-02,  2.51131523e-02, ...,\n",
       "            1.15067199e-01,  8.29275250e-02,  4.07340042e-02],\n",
       "          [-8.82617384e-02, -1.59392506e-01, -1.44217789e-01, ...,\n",
       "            8.26059580e-02, -1.03455968e-02, -4.71957773e-02],\n",
       "          [-1.85957015e-01,  1.14160366e-01,  8.57811868e-02, ...,\n",
       "            1.67628869e-01, -5.69726564e-02,  1.88954011e-01]],\n",
       " \n",
       "         [[-6.48908839e-02,  1.87336385e-01,  3.90957706e-02, ...,\n",
       "            1.71885550e-01, -7.95859918e-02,  6.33834451e-02],\n",
       "          [-6.82608932e-02, -2.99693178e-02,  1.95757300e-02, ...,\n",
       "           -1.43537596e-01, -6.75099567e-02, -1.68887768e-02],\n",
       "          [-1.08863994e-01, -3.68114188e-02, -4.30696004e-04, ...,\n",
       "            3.93225364e-02,  1.53512293e-02, -5.34826964e-02],\n",
       "          ...,\n",
       "          [-5.24846576e-02,  1.53261468e-01, -6.13483824e-02, ...,\n",
       "            1.24975689e-01,  1.25180930e-01, -1.90578997e-01],\n",
       "          [-1.22997381e-01, -5.40375523e-02, -9.25853774e-02, ...,\n",
       "            3.50588709e-02,  9.08745304e-02,  4.67393808e-02],\n",
       "          [-2.94311851e-01,  6.54384168e-03, -1.62849590e-01, ...,\n",
       "            8.18632022e-02, -4.49504480e-02,  9.24158320e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.19164249e-02,  4.91217412e-02, -9.92138982e-02, ...,\n",
       "           -1.97935514e-02,  1.83085017e-02,  3.41424197e-02],\n",
       "          [-1.06100693e-01, -1.48956150e-01, -5.66584319e-02, ...,\n",
       "           -1.50356516e-01,  9.20102838e-03,  1.37780681e-02],\n",
       "          [ 9.68283117e-02, -1.79202124e-01,  8.02438185e-02, ...,\n",
       "           -7.36843348e-02,  1.48655800e-02,  7.14064464e-02],\n",
       "          ...,\n",
       "          [ 1.42359272e-01,  2.17116363e-02,  4.62254472e-02, ...,\n",
       "            9.28677246e-02, -5.86159639e-02,  5.65729551e-02],\n",
       "          [-2.07132241e-03, -2.81894580e-02,  2.43069828e-02, ...,\n",
       "           -7.53914863e-02,  4.52851551e-03, -7.44212233e-03],\n",
       "          [ 3.14940922e-02,  4.57242280e-02, -2.17557147e-01, ...,\n",
       "            5.34533989e-03, -4.42017689e-02, -1.76341623e-01]],\n",
       " \n",
       "         [[-1.52747892e-02, -6.46082163e-02,  1.32424124e-02, ...,\n",
       "            1.27445102e-01, -1.26711261e-02,  9.66353118e-02],\n",
       "          [ 4.25204486e-02,  5.53363338e-02, -6.18228056e-02, ...,\n",
       "            6.76199868e-02, -2.95518264e-02, -6.15833560e-04],\n",
       "          [ 1.53338686e-01, -1.98566746e-02, -7.12193623e-02, ...,\n",
       "            4.56458842e-03, -4.90911640e-02,  1.52469277e-01],\n",
       "          ...,\n",
       "          [ 3.40885073e-02, -9.68842134e-02,  1.32823195e-02, ...,\n",
       "            8.54051784e-02, -1.55393407e-01,  1.95237532e-01],\n",
       "          [ 4.32340242e-02,  1.31969750e-02,  8.41848776e-02, ...,\n",
       "            5.42506799e-02, -1.09494455e-01,  1.08452858e-02],\n",
       "          [-3.49107720e-02, -1.41530573e-01,  3.08147296e-02, ...,\n",
       "           -2.03287695e-02, -7.97316339e-03, -1.11977890e-01]],\n",
       " \n",
       "         [[-4.66147363e-02, -5.33521585e-02,  1.84644982e-02, ...,\n",
       "            3.30467038e-02,  1.12951152e-01,  6.61059916e-02],\n",
       "          [-4.89927530e-02, -2.55017821e-02,  1.18395850e-01, ...,\n",
       "            3.65353115e-02,  4.39757667e-02, -1.35162368e-01],\n",
       "          [ 9.85282362e-02, -4.36811633e-02,  1.33361146e-02, ...,\n",
       "           -3.33548244e-03, -1.59671083e-01,  7.24749453e-03],\n",
       "          ...,\n",
       "          [ 7.55040348e-02,  3.18753836e-03, -1.34688243e-01, ...,\n",
       "            1.86188772e-01, -1.69629902e-01, -2.95565780e-02],\n",
       "          [ 1.22495145e-01, -3.55891511e-02, -8.55321065e-02, ...,\n",
       "           -1.65961329e-02,  4.52923439e-02, -2.24062074e-02],\n",
       "          [-1.26958832e-01,  8.53000209e-02,  1.26715619e-02, ...,\n",
       "            1.97646171e-02, -2.96844870e-01,  7.33179897e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.08059272e-01,  2.29272190e-02,  6.06113374e-02, ...,\n",
       "           -1.95133723e-02, -6.87417835e-02,  1.91032533e-02],\n",
       "          [-1.28564283e-01,  3.37348282e-02, -1.12042248e-01, ...,\n",
       "            1.21657655e-01,  1.32925197e-01, -1.12938918e-01],\n",
       "          [ 1.53309375e-01, -4.27940255e-03, -6.63349554e-02, ...,\n",
       "            2.63734348e-02, -7.41096288e-02,  1.01730220e-01],\n",
       "          ...,\n",
       "          [-9.69644114e-02, -1.36621535e-01,  3.00108567e-02, ...,\n",
       "            4.20766398e-02, -8.52784887e-02,  1.58039406e-02],\n",
       "          [-2.11806521e-02,  2.86419578e-02,  3.10323928e-02, ...,\n",
       "           -7.60800913e-02, -7.34725222e-02,  4.55829268e-03],\n",
       "          [-1.30716980e-01,  2.07840409e-02, -2.14693978e-01, ...,\n",
       "           -3.29882987e-02,  1.30880326e-01,  5.26149338e-03]],\n",
       " \n",
       "         [[ 1.00376695e-01, -8.38385224e-02,  1.24581382e-01, ...,\n",
       "           -2.74950508e-02,  1.35384515e-01, -1.58748645e-02],\n",
       "          [ 1.24597447e-02,  1.03994822e-02,  1.25526130e-01, ...,\n",
       "            1.64111435e-01,  7.08116442e-02, -5.47492951e-02],\n",
       "          [ 6.77518034e-03,  2.26604883e-02, -2.14189023e-01, ...,\n",
       "           -8.55717957e-02,  2.00041924e-02,  7.76232034e-02],\n",
       "          ...,\n",
       "          [ 3.76661564e-03,  2.58516401e-01,  4.11914885e-02, ...,\n",
       "            1.27946492e-02, -3.06912810e-02,  6.52179644e-02],\n",
       "          [ 1.20375827e-01, -5.39044738e-02, -3.64809819e-02, ...,\n",
       "            8.76671374e-02, -5.51014096e-02,  7.84277618e-02],\n",
       "          [-8.22667927e-02, -2.52401650e-01,  7.54678994e-02, ...,\n",
       "            1.17159083e-01,  1.65785387e-01, -1.03329167e-01]],\n",
       " \n",
       "         [[ 6.69237152e-02,  3.13501172e-02,  1.27039686e-01, ...,\n",
       "           -1.23788558e-01,  4.65179496e-02, -1.04997016e-01],\n",
       "          [-1.20622709e-01,  1.81384459e-01,  5.92189878e-02, ...,\n",
       "           -1.34452537e-01,  9.80787575e-02,  2.21752897e-02],\n",
       "          [-9.27823037e-02, -1.65402338e-01, -9.95945334e-02, ...,\n",
       "           -4.39178050e-02, -5.37907891e-02, -8.02375227e-02],\n",
       "          ...,\n",
       "          [ 1.33274347e-01,  1.95204213e-01, -1.02361038e-01, ...,\n",
       "            4.37158123e-02, -6.80128410e-02, -8.33389983e-02],\n",
       "          [-9.38085094e-02, -1.31227553e-01,  1.04904184e-02, ...,\n",
       "           -4.33301032e-02, -5.56164309e-02, -2.71393992e-02],\n",
       "          [-2.55309083e-02,  5.90749308e-02,  2.26631500e-02, ...,\n",
       "           -3.34835099e-03,  6.72693476e-02, -8.61058012e-02]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.06844036,  0.12202128,  0.13318741, -0.00111559,  0.10475322,\n",
       "         0.07616493, -0.05754535, -0.01820884,  0.12065089,  0.05862167,\n",
       "        -0.02793129, -0.04001398,  0.06942196,  0.0823991 ,  0.01241798,\n",
       "        -0.09080388,  0.09340974, -0.02433182,  0.07116289,  0.01995107,\n",
       "         0.06059568,  0.0799984 , -0.01303832,  0.06859729,  0.10744353,\n",
       "         0.0593851 ,  0.04613956,  0.0651754 ,  0.1145788 , -0.08530176,\n",
       "        -0.09342452,  0.10873015,  0.07596638,  0.06082336, -0.0421233 ,\n",
       "         0.04544921, -0.01086284,  0.00833722,  0.08717231, -0.04331323,\n",
       "         0.02818115, -0.07025676, -0.07385813,  0.14463803,  0.11868074,\n",
       "         0.00511398,  0.02949248, -0.08917712, -0.03781312, -0.05281513,\n",
       "         0.01861289,  0.10263848,  0.13380411,  0.10047051,  0.08131928,\n",
       "        -0.00178301, -0.00390034,  0.08560655, -0.02326689,  0.12126663,\n",
       "         0.04606064, -0.02516359,  0.06230117,  0.09268276], dtype=float32),\n",
       " array([[[[ 8.39991271e-02,  3.10012214e-02,  1.44256065e-02, ...,\n",
       "           -1.05192490e-01,  3.30535211e-02, -7.43487552e-02],\n",
       "          [-7.91806728e-02, -1.71584949e-01, -1.61964446e-01, ...,\n",
       "            6.00751601e-02,  7.39303157e-02, -2.44090706e-02],\n",
       "          [ 1.48496509e-01,  6.97362646e-02, -6.03377037e-02, ...,\n",
       "            2.94151027e-02, -6.88809082e-02, -6.62952363e-02],\n",
       "          ...,\n",
       "          [ 1.32083431e-01,  3.18644717e-02, -2.30912596e-01, ...,\n",
       "            5.64001463e-02,  4.22069207e-02, -1.12714339e-02],\n",
       "          [-3.82519066e-02,  6.17365018e-02, -9.67571512e-02, ...,\n",
       "           -3.94765362e-02, -4.50250600e-03,  6.17964640e-02],\n",
       "          [ 9.49449316e-02, -1.41169429e-01,  3.49056423e-02, ...,\n",
       "           -8.92701373e-02,  5.74437939e-02, -2.58490015e-02]],\n",
       " \n",
       "         [[ 1.38165057e-01, -2.58127297e-03, -7.36329518e-03, ...,\n",
       "           -6.20724410e-02,  2.48615677e-03,  2.21602693e-02],\n",
       "          [-6.00043535e-02,  2.62503102e-02, -9.41443369e-02, ...,\n",
       "           -7.69993896e-03, -3.41474041e-02, -1.02331705e-01],\n",
       "          [-6.41775876e-02,  3.67624275e-02, -4.64749150e-02, ...,\n",
       "            3.29811722e-02,  2.08149664e-02, -7.24878535e-02],\n",
       "          ...,\n",
       "          [-6.40846044e-02, -8.49263296e-02,  1.17369115e-01, ...,\n",
       "            6.79646730e-02, -1.35549918e-01, -5.33748306e-02],\n",
       "          [-8.51998925e-02,  1.26078531e-01, -1.81000009e-01, ...,\n",
       "            2.69210269e-03, -1.86355191e-03, -4.68660891e-02],\n",
       "          [ 1.36831462e-01,  2.65264176e-02, -9.33714435e-02, ...,\n",
       "           -9.34270024e-03, -2.56818738e-02, -8.41027051e-02]],\n",
       " \n",
       "         [[ 1.32656887e-01,  7.62952166e-03, -1.12332441e-01, ...,\n",
       "           -6.53155297e-02,  1.51689807e-02, -7.89234787e-02],\n",
       "          [-1.48801371e-01, -7.38176033e-02, -1.74497161e-02, ...,\n",
       "           -6.48431405e-02, -3.62357274e-02, -4.59308214e-02],\n",
       "          [-5.17070666e-02,  3.13462550e-03, -6.34741411e-02, ...,\n",
       "           -2.91296635e-02, -1.18379809e-01,  1.03411637e-03],\n",
       "          ...,\n",
       "          [ 7.29439929e-02, -8.11560601e-02, -1.67168915e-01, ...,\n",
       "           -2.28588544e-02,  4.65023844e-03, -4.60522395e-04],\n",
       "          [ 1.85762227e-01,  2.84732673e-02, -1.75318241e-01, ...,\n",
       "           -1.53886741e-02,  2.64092088e-02,  2.47238204e-02],\n",
       "          [ 7.29165748e-02,  1.07622854e-01,  1.63831692e-02, ...,\n",
       "           -4.35891598e-02,  3.33312973e-02,  5.17024379e-03]]],\n",
       " \n",
       " \n",
       "        [[[-7.19659925e-02, -1.48354098e-01,  1.08226098e-01, ...,\n",
       "           -4.07324992e-02, -5.49764819e-02, -6.44392148e-02],\n",
       "          [-3.37837380e-03, -8.24589282e-02,  1.84373781e-02, ...,\n",
       "           -3.54190916e-02,  2.70625502e-01,  4.05098274e-02],\n",
       "          [ 2.43703891e-02,  3.21572609e-02, -6.34710565e-02, ...,\n",
       "            8.62615407e-02,  4.17802297e-02,  2.06266996e-02],\n",
       "          ...,\n",
       "          [ 1.97550744e-01, -7.17860684e-02,  8.85106064e-03, ...,\n",
       "           -8.20083246e-02,  1.52231967e-02, -4.15319689e-02],\n",
       "          [-2.02958763e-01, -1.29473165e-01,  2.21404247e-02, ...,\n",
       "           -1.63401246e-01, -9.03101265e-02,  2.31231973e-02],\n",
       "          [-2.75619968e-04, -1.10510103e-02, -8.22041258e-02, ...,\n",
       "           -1.15598701e-01,  2.17722468e-02, -7.67439678e-02]],\n",
       " \n",
       "         [[ 2.31513325e-02, -3.40078175e-02,  3.16919237e-02, ...,\n",
       "           -2.57928520e-02, -6.47306293e-02, -6.92619756e-02],\n",
       "          [-2.12084427e-01,  8.46041664e-02,  1.17535912e-01, ...,\n",
       "            1.82039264e-04, -8.15721750e-02,  4.39710915e-03],\n",
       "          [ 9.26523358e-02,  5.18659689e-02,  8.55068266e-02, ...,\n",
       "            6.52475283e-02,  3.34932655e-02,  5.69623895e-03],\n",
       "          ...,\n",
       "          [-4.26297300e-02, -1.18491210e-01, -4.20704708e-02, ...,\n",
       "           -1.05184868e-01,  6.39015734e-02, -6.72445148e-02],\n",
       "          [-1.50559515e-01, -1.32668346e-01, -2.26792708e-01, ...,\n",
       "           -8.40608254e-02,  2.16540269e-04, -6.41680509e-02],\n",
       "          [ 8.25062394e-02, -1.03637785e-01, -1.63554296e-01, ...,\n",
       "           -1.06375985e-01,  4.71113548e-02,  1.61744282e-02]],\n",
       " \n",
       "         [[-2.77798381e-02, -1.26363918e-01, -1.09038884e-02, ...,\n",
       "           -2.75967214e-02,  2.55118273e-02,  2.17171814e-02],\n",
       "          [-1.89861327e-01,  1.05527654e-01, -7.87533587e-04, ...,\n",
       "           -1.69205088e-02, -1.14562318e-01, -9.80085060e-02],\n",
       "          [-4.53458950e-02, -2.88191419e-02, -9.26554129e-02, ...,\n",
       "            1.55861964e-02, -1.74510460e-02, -1.53170126e-02],\n",
       "          ...,\n",
       "          [-1.20901957e-01, -3.65074277e-02, -3.65285352e-02, ...,\n",
       "           -9.16436873e-03, -7.37318024e-02, -5.79523705e-02],\n",
       "          [-1.77108020e-01, -2.32480660e-01, -1.44343629e-01, ...,\n",
       "           -6.12378493e-02, -1.13585830e-01, -9.30101126e-02],\n",
       "          [-1.73632041e-01,  2.33576894e-02,  7.42809251e-02, ...,\n",
       "           -8.71827006e-02,  7.49493539e-02,  8.85337219e-03]]],\n",
       " \n",
       " \n",
       "        [[[-2.22317576e-01, -1.68324307e-01, -1.13304429e-01, ...,\n",
       "           -2.47307997e-02, -1.70622617e-02, -7.30349943e-02],\n",
       "          [-4.44993265e-02,  7.68276528e-02, -2.02886507e-01, ...,\n",
       "            5.64438291e-02,  8.97755846e-02, -2.78156158e-02],\n",
       "          [-1.21675961e-01, -1.13843001e-01, -4.91994992e-02, ...,\n",
       "           -6.40421659e-02,  1.09538874e-02, -1.70361772e-02],\n",
       "          ...,\n",
       "          [-1.59294814e-01,  3.80266905e-02,  1.20632984e-01, ...,\n",
       "            8.54775533e-02, -6.25158474e-02,  4.25175466e-02],\n",
       "          [-2.10948303e-01, -1.55440792e-01, -2.38493606e-02, ...,\n",
       "            2.44833268e-02, -1.73441738e-01, -2.12180968e-02],\n",
       "          [-2.18372285e-01, -2.21375227e-01, -1.00021273e-01, ...,\n",
       "           -2.45020892e-02, -2.05014616e-01, -7.22799152e-02]],\n",
       " \n",
       "         [[ 4.53936234e-02, -2.84880191e-01, -2.01937973e-01, ...,\n",
       "           -5.12169115e-02, -7.08845481e-02, -7.67267197e-02],\n",
       "          [ 7.11079687e-02, -4.01570983e-02,  3.21567478e-03, ...,\n",
       "            2.77464334e-02,  1.96964238e-02, -8.55331719e-02],\n",
       "          [-1.39143944e-01, -2.58304831e-02, -5.79896010e-02, ...,\n",
       "            7.60760810e-03, -3.37593816e-02, -8.90062377e-02],\n",
       "          ...,\n",
       "          [-1.01984084e-01, -6.77002519e-02,  1.10177159e-01, ...,\n",
       "            3.34659591e-02,  1.54414937e-01, -4.11182083e-02],\n",
       "          [ 5.21991961e-02, -1.87577441e-01,  5.32305799e-02, ...,\n",
       "           -1.74855534e-02, -1.92653731e-01,  1.77302007e-02],\n",
       "          [-1.01496570e-01, -2.16890380e-01, -1.27430484e-02, ...,\n",
       "           -1.08730510e-01,  4.91689406e-02,  2.01158095e-02]],\n",
       " \n",
       "         [[ 1.44522861e-01, -1.93107873e-01, -5.46528064e-02, ...,\n",
       "            2.34603342e-02, -7.05544800e-02,  2.58395523e-02],\n",
       "          [-3.86651941e-02, -8.51281658e-02,  1.00581512e-01, ...,\n",
       "           -1.53530939e-02, -1.75054789e-01,  4.30093296e-02],\n",
       "          [-7.71082565e-02, -1.27908766e-01, -1.00926764e-01, ...,\n",
       "            5.21198809e-02, -1.75738316e-02,  3.13514508e-02],\n",
       "          ...,\n",
       "          [-7.51990676e-02,  1.48483217e-01,  2.54833568e-02, ...,\n",
       "           -3.83650102e-02,  4.70336229e-02, -4.89060655e-02],\n",
       "          [-2.50075758e-01, -2.42279351e-01, -2.01936424e-01, ...,\n",
       "           -6.31616563e-02, -6.67587817e-02,  1.78037472e-02],\n",
       "          [-2.89124977e-02, -1.73570529e-01, -5.52048162e-02, ...,\n",
       "           -2.83180941e-02,  6.03405163e-02,  6.13432145e-03]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.04833563,  0.01902541, -0.0097178 , -0.03660289,  0.05484023,\n",
       "         0.00303739,  0.03159845,  0.00031865,  0.05374857,  0.04234314,\n",
       "        -0.0452147 ,  0.00908362, -0.06667175, -0.01875144, -0.06520968,\n",
       "        -0.08009973, -0.07152793,  0.04260813, -0.06330973,  0.03229103,\n",
       "         0.03485864, -0.04166678,  0.0260757 ,  0.03421411,  0.0609133 ,\n",
       "         0.00624754, -0.05040986,  0.02398911, -0.00312695, -0.0484894 ,\n",
       "        -0.06347378,  0.02247854, -0.01271731,  0.02557621,  0.05186862,\n",
       "         0.01571165,  0.00600997,  0.03307549, -0.03303062,  0.01419235,\n",
       "         0.05634086,  0.04262258,  0.02668958,  0.01031903,  0.01546801,\n",
       "        -0.01114003, -0.06432333,  0.03233202,  0.02199768, -0.04504181,\n",
       "         0.01319461, -0.01340768, -0.01069657,  0.0690535 ,  0.01461165,\n",
       "         0.04250736, -0.01831801,  0.02066918, -0.08688655,  0.06075685,\n",
       "        -0.04194111, -0.10286658,  0.01283712, -0.04524435], dtype=float32),\n",
       " array([[ 0.07069214,  0.10279189,  0.09561177, ..., -0.20955719,\n",
       "         -0.089341  , -0.05268101],\n",
       "        [ 0.03662322, -0.04316482, -0.09057292, ..., -0.05271154,\n",
       "         -0.16849107, -0.12724733],\n",
       "        [-0.09201699, -0.0503003 , -0.09098876, ..., -0.07729741,\n",
       "         -0.03973654,  0.0456062 ],\n",
       "        ...,\n",
       "        [ 0.06404644,  0.07151382, -0.08971206, ..., -0.09432997,\n",
       "         -0.01119044, -0.04004662],\n",
       "        [-0.03782225,  0.05746596, -0.0436299 , ..., -0.1858974 ,\n",
       "          0.01911189,  0.02742956],\n",
       "        [ 0.06593856,  0.06231039, -0.09669171, ..., -0.07956153,\n",
       "         -0.01782283,  0.06409889]], dtype=float32),\n",
       " array([ 8.28788206e-02,  8.68825689e-02,  8.03254824e-03, -4.89517003e-02,\n",
       "        -1.19751878e-02, -4.86080833e-02, -5.18541336e-02, -3.14495377e-02,\n",
       "        -8.26664982e-05,  6.81923926e-02,  6.17469288e-02,  1.27412528e-02,\n",
       "         3.01273037e-02, -4.74238172e-02, -2.84945462e-02, -5.36975004e-02,\n",
       "         5.73479012e-02,  6.50558472e-02, -6.20304234e-02, -1.30186871e-01,\n",
       "         7.30341896e-02,  1.11576542e-01,  1.57636348e-02,  6.02369122e-02,\n",
       "        -3.04432623e-02, -4.25039511e-03, -2.32656859e-02, -2.08977591e-02,\n",
       "         6.21723235e-02, -5.73647150e-04,  1.09422199e-01, -1.94707457e-02,\n",
       "         4.53715175e-02,  3.42170484e-02,  5.55128045e-02, -3.81619856e-02,\n",
       "         5.25551438e-02, -3.19155604e-02, -4.91578579e-02, -4.13039364e-02,\n",
       "        -6.16163425e-02,  2.13157274e-02, -3.37658003e-02,  5.97953275e-02,\n",
       "        -7.36826658e-02, -7.15949759e-02, -1.39848948e-01, -3.78892086e-02,\n",
       "        -6.05852567e-02, -5.13969697e-02,  5.07991724e-02,  2.28858665e-02,\n",
       "         3.04313395e-02, -3.41023207e-02,  2.28330493e-02,  1.30477007e-02,\n",
       "         7.01798201e-02,  1.03298970e-01, -2.11831518e-02, -4.87955660e-02,\n",
       "         5.62269017e-02,  7.47195408e-02,  5.40600047e-02, -7.90041909e-02,\n",
       "        -5.08743897e-02, -3.06777209e-02,  1.25545546e-01, -1.56208463e-02,\n",
       "        -6.33292943e-02, -6.61090808e-03, -1.72771439e-02, -6.41588569e-02,\n",
       "         9.21586994e-03, -2.85474863e-02, -3.77743505e-02, -5.69215678e-02,\n",
       "        -4.89737503e-02, -2.30919737e-02, -9.05867293e-02, -3.74921076e-02,\n",
       "        -1.07867785e-01, -8.80079716e-03, -5.30735180e-02,  2.64696144e-02,\n",
       "         9.86593068e-02,  1.16259255e-01, -4.18830924e-02,  4.44772430e-02,\n",
       "        -3.09051741e-02, -5.39080985e-02, -3.21398638e-02,  6.85338005e-02,\n",
       "        -8.19350928e-02, -3.34181264e-02,  4.39880714e-02, -9.12349224e-02,\n",
       "         2.21665446e-02, -4.25140485e-02, -4.60537300e-02, -4.82524745e-02,\n",
       "        -8.92774900e-04, -4.19195332e-02, -6.18722849e-02, -2.52575707e-02,\n",
       "         4.08078730e-02,  1.01482600e-01,  1.33627117e-01,  1.18942680e-02,\n",
       "        -3.37257273e-02, -2.63506621e-02, -8.98676217e-02, -2.97052786e-02,\n",
       "         9.12608877e-02,  7.71801323e-02,  8.15187544e-02,  2.37460174e-02,\n",
       "        -5.44336624e-02, -3.55170742e-02, -3.29313762e-02, -4.63554822e-02,\n",
       "         4.91191149e-02,  9.37661305e-02, -1.70669276e-02,  2.98136771e-02,\n",
       "         1.32438242e-01,  7.98913017e-02, -8.29685032e-02,  4.71997261e-02,\n",
       "         4.55740839e-02,  3.02619077e-02,  2.70454194e-02, -4.08059508e-02,\n",
       "        -1.19861672e-02, -4.24104966e-02,  1.80598143e-02, -1.08373217e-01,\n",
       "         3.96656655e-02, -4.12442833e-02,  4.26145084e-02,  5.23680039e-02,\n",
       "         4.64029051e-02,  1.17920123e-01, -1.15144312e-01,  1.03111016e-02,\n",
       "        -2.58280188e-02, -2.03191284e-02,  1.35770246e-01, -2.39842981e-02,\n",
       "        -3.25263739e-02, -3.38866785e-02, -6.69279695e-02,  1.38910145e-01,\n",
       "         3.88169177e-02, -1.98014118e-02,  5.74708544e-02, -4.16466855e-02,\n",
       "        -6.91621155e-02, -8.37940723e-02,  1.14797540e-01,  1.06983937e-01,\n",
       "         6.49279281e-02,  1.49762938e-02,  2.73000225e-02, -5.63606583e-02,\n",
       "         4.29445133e-02,  3.16811614e-02, -7.02366084e-02, -3.00191361e-02,\n",
       "         2.02484410e-02, -4.69609722e-02, -5.69404811e-02,  2.54076533e-02,\n",
       "        -1.59531846e-04, -1.41074928e-02, -3.66887823e-02, -1.25354854e-02,\n",
       "         7.08744396e-03,  1.41335413e-01,  3.89159657e-02,  4.69227694e-02,\n",
       "         5.54393083e-02,  4.09530737e-02,  1.58318281e-01,  1.46181276e-02,\n",
       "         3.97590324e-02, -8.96509886e-02, -6.23888373e-02, -4.43029925e-02,\n",
       "        -5.96750751e-02,  1.89486053e-02, -9.25589204e-02,  8.46555755e-02,\n",
       "         9.34286937e-02,  1.35126188e-01,  5.79821952e-02, -3.46713178e-02,\n",
       "        -2.93823127e-02,  1.05855703e-01,  3.84701416e-02, -7.96554983e-03,\n",
       "        -2.82826312e-02,  9.81320441e-02,  5.77444136e-02,  6.68668076e-02,\n",
       "         5.18939309e-02,  8.55158735e-03,  1.24181986e-01, -5.45365661e-02,\n",
       "         7.51226544e-02,  8.35649893e-02, -1.83871150e-01, -5.35906926e-02,\n",
       "         3.49910855e-02, -4.28136587e-02, -3.11886538e-02,  7.46186227e-02,\n",
       "        -3.52538340e-02,  5.16950563e-02, -5.85346967e-02,  2.73838118e-02,\n",
       "        -5.59526868e-02, -5.35999276e-02, -4.98938300e-02, -5.17245084e-02,\n",
       "        -5.25094680e-02, -3.33259478e-02,  8.33795294e-02, -6.06743544e-02,\n",
       "        -5.20509891e-02,  3.48460190e-02, -7.02642500e-02,  1.14231303e-01,\n",
       "         4.62383367e-02, -2.87875459e-02, -6.22074455e-02,  6.35108724e-02,\n",
       "        -3.52543481e-02, -2.92655658e-02, -7.65061155e-02,  3.54033429e-03,\n",
       "         2.60988194e-02, -6.94250315e-02, -4.81047556e-02, -5.52064665e-02,\n",
       "        -4.04285006e-02,  3.58995236e-02,  4.96880896e-02,  4.93527763e-02,\n",
       "        -2.94653028e-02, -4.85821217e-02, -3.85394022e-02, -6.23168498e-02,\n",
       "        -1.56424399e-02,  3.50955874e-02, -6.63819313e-02, -4.49335165e-02],\n",
       "       dtype=float32),\n",
       " array([[ 0.01931372, -0.00984167, -0.00342725, ..., -0.00748804,\n",
       "         -0.01443158, -0.1111849 ],\n",
       "        [-0.05038111,  0.01310566, -0.08826889, ..., -0.03452643,\n",
       "         -0.00698121, -0.06134051],\n",
       "        [-0.16235949,  0.04704235, -0.0027264 , ..., -0.08385526,\n",
       "         -0.09677488, -0.07505317],\n",
       "        ...,\n",
       "        [ 0.03565689, -0.07427441, -0.06738909, ..., -0.02224106,\n",
       "          0.03840739, -0.02093414],\n",
       "        [-0.06548831, -0.09826227, -0.06895165, ...,  0.0823295 ,\n",
       "         -0.10130813, -0.0016003 ],\n",
       "        [-0.10333154, -0.10501353, -0.0580978 , ..., -0.05458231,\n",
       "         -0.08966853, -0.09266719]], dtype=float32),\n",
       " array([ 0.05895913, -0.02779339, -0.01976886, -0.04724228,  0.01305084,\n",
       "         0.0305156 , -0.00929467,  0.04311436,  0.03116013, -0.00573233,\n",
       "        -0.04181575, -0.02143247, -0.0188504 , -0.02111404,  0.03879433,\n",
       "        -0.01229763, -0.03099583, -0.02715852,  0.0486594 ,  0.0808512 ,\n",
       "         0.00896692, -0.04213478, -0.00781301, -0.00254161,  0.1463907 ,\n",
       "        -0.03565858,  0.05981351, -0.02584966, -0.0007228 , -0.05831547,\n",
       "        -0.02941498, -0.02824197,  0.11983524,  0.02664062, -0.04009929,\n",
       "        -0.00783476,  0.04963645, -0.01528842,  0.0478326 , -0.0134953 ,\n",
       "         0.12888706, -0.01811727, -0.01709266, -0.01457136, -0.03752155,\n",
       "        -0.06021181, -0.02502908, -0.03957277, -0.02365658,  0.10591578,\n",
       "         0.09498352, -0.05792508, -0.01256776, -0.04191877, -0.04614708,\n",
       "         0.13564359,  0.0870855 ,  0.03078983,  0.03812273,  0.00964855,\n",
       "        -0.04900805, -0.0245539 ,  0.08076884, -0.0487802 , -0.03378835,\n",
       "         0.06525247,  0.07249358, -0.01967487,  0.07027103, -0.05241357,\n",
       "         0.04781248,  0.04252461, -0.0557255 , -0.04870406,  0.06491909,\n",
       "         0.06311972, -0.07672671,  0.04771721,  0.03570491, -0.05779532,\n",
       "         0.01779498, -0.04618111, -0.0061896 , -0.03827334, -0.05871305,\n",
       "         0.10090016, -0.03118853,  0.13209644, -0.06275792, -0.03564685,\n",
       "        -0.06127625,  0.0792326 ,  0.01973343,  0.04607489, -0.0346159 ,\n",
       "        -0.03149668, -0.04396724, -0.02894499, -0.02934294,  0.03917453,\n",
       "         0.07325225,  0.08029121,  0.14649123, -0.02507075,  0.01988731,\n",
       "        -0.04349117, -0.03164277, -0.0379166 , -0.01703916, -0.04174495,\n",
       "         0.06718785,  0.03171106,  0.03701721, -0.01876126, -0.05116683,\n",
       "        -0.04765109, -0.03994196, -0.03183614, -0.01976189, -0.00754251,\n",
       "        -0.0057243 , -0.04484007, -0.03240825, -0.06147313,  0.03750576,\n",
       "        -0.00273983, -0.01949545, -0.03422199,  0.02895256,  0.08637679,\n",
       "         0.092658  ,  0.0748957 , -0.02705671, -0.00669392,  0.01820881,\n",
       "         0.10879094, -0.01620062, -0.00770599,  0.06195331,  0.04331865,\n",
       "        -0.02893431, -0.03321552, -0.01629892, -0.0398862 , -0.01332173,\n",
       "        -0.02335157, -0.02546032, -0.01695747, -0.02423359,  0.05680048,\n",
       "        -0.02204605,  0.05301993,  0.00518257, -0.01786379, -0.04807246,\n",
       "        -0.02657273,  0.0723579 , -0.04518852, -0.02510531, -0.03427509,\n",
       "        -0.02349798, -0.02944295,  0.01015837, -0.02661697,  0.06874099,\n",
       "         0.0636068 , -0.0402974 ,  0.06203619, -0.04130769,  0.13119328,\n",
       "        -0.02939007, -0.0315669 ,  0.10578115, -0.07342147, -0.02915514,\n",
       "        -0.03584109, -0.02417808,  0.10243616,  0.06256082, -0.05776143,\n",
       "        -0.04313724,  0.11821137, -0.08396898, -0.05209503, -0.02891733,\n",
       "         0.08459407,  0.08793247, -0.00776747, -0.01862298, -0.01190144,\n",
       "        -0.03942637,  0.03683021, -0.02037082, -0.04343601,  0.02099871,\n",
       "        -0.03130366, -0.04120322, -0.02384573,  0.0790379 ,  0.09389867,\n",
       "         0.06142478,  0.09201937, -0.07402811, -0.02233331, -0.03702921,\n",
       "        -0.05913922,  0.02982509,  0.04150581, -0.04834164, -0.07597917,\n",
       "         0.1269958 , -0.01002469, -0.03013436, -0.06340396,  0.03795933,\n",
       "        -0.05347465,  0.03334184, -0.04871894, -0.03508401,  0.1288556 ,\n",
       "        -0.0200703 , -0.01935642,  0.01715864, -0.00067777,  0.0652084 ,\n",
       "        -0.05053017, -0.02452551,  0.06316845, -0.0281817 , -0.01952763,\n",
       "        -0.06267615, -0.01852955, -0.00998187,  0.12475549,  0.02305214,\n",
       "         0.14180917, -0.01218488, -0.02215174,  0.05774098,  0.09790841,\n",
       "        -0.03840141, -0.01416123, -0.03349404,  0.03781391, -0.02783345,\n",
       "         0.13128853, -0.16100703, -0.03407029,  0.07011657, -0.04538962,\n",
       "        -0.04568501,  0.059204  ,  0.04098789, -0.02890509, -0.05293374,\n",
       "        -0.02005436], dtype=float32),\n",
       " array([[ 0.04097796, -0.12156884,  0.02969803, ..., -0.07329755,\n",
       "          0.13681483,  0.06495682],\n",
       "        [ 0.06610833,  0.0423157 ,  0.06134136, ..., -0.09601277,\n",
       "          0.06980705,  0.05206184],\n",
       "        [-0.04949695,  0.03633466, -0.12520432, ..., -0.08874312,\n",
       "         -0.07905282, -0.04846567],\n",
       "        ...,\n",
       "        [-0.09958678,  0.0911008 ,  0.04792735, ..., -0.12614946,\n",
       "         -0.12562017, -0.14912626],\n",
       "        [-0.03261121,  0.08479261,  0.03733829, ...,  0.13276637,\n",
       "         -0.01969464,  0.02617289],\n",
       "        [-0.02396405,  0.07165615,  0.05038653, ..., -0.00266008,\n",
       "         -0.01457234, -0.01165967]], dtype=float32),\n",
       " array([ 0.0205108 , -0.10808344,  0.06517626,  0.02937478,  0.00707945,\n",
       "        -0.06593815, -0.00293964], dtype=float32)]"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3458774,
     "status": "ok",
     "timestamp": 1583368440008,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "c3ealsZ99dZ1",
    "outputId": "0499eaf6-21d0-4f4d-ecf3-bd129520465b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'block1_conv1_5/kernel:0' shape=(3, 3, 3, 8) dtype=float32, numpy=\n",
       " array([[[[ 0.00603382,  0.02733675, -0.0172347 ,  0.09976361,\n",
       "            0.03591269,  0.06154356, -0.27886167,  0.1747594 ],\n",
       "          [ 0.00335163, -0.21710117,  0.22996181,  0.1251715 ,\n",
       "           -0.10697839,  0.04452933,  0.0711987 ,  0.24787195],\n",
       "          [-0.07506111, -0.25114205,  0.15309526, -0.13634756,\n",
       "           -0.23240252, -0.12852968, -0.19172572,  0.19764704]],\n",
       " \n",
       "         [[-0.13800357, -0.18231395,  0.20344728, -0.17242506,\n",
       "            0.11104856,  0.23513095,  0.2379421 ,  0.11059583],\n",
       "          [-0.01358065, -0.20922793, -0.12049043, -0.09114791,\n",
       "            0.10302974,  0.17773746,  0.13409042, -0.02881867],\n",
       "          [ 0.09041117,  0.12680635, -0.14835255,  0.17584477,\n",
       "           -0.04743635, -0.10408151,  0.18776798, -0.00561239]],\n",
       " \n",
       "         [[ 0.3224108 ,  0.17165905,  0.19499454,  0.1848479 ,\n",
       "           -0.1850659 ,  0.09877757,  0.12642926,  0.09629154],\n",
       "          [-0.08099049, -0.19010457, -0.24314374,  0.13739224,\n",
       "           -0.23073164, -0.15595315, -0.10505022,  0.23872627],\n",
       "          [ 0.2949158 ,  0.18146883, -0.11703736,  0.02088875,\n",
       "            0.12034092,  0.06131832, -0.13638397,  0.20617306]]],\n",
       " \n",
       " \n",
       "        [[[ 0.14390136,  0.02255549,  0.15099195, -0.15663514,\n",
       "           -0.20148638,  0.13729177,  0.14790572, -0.05563233],\n",
       "          [-0.23266317,  0.20376082,  0.17019546,  0.02213419,\n",
       "           -0.14938834,  0.129486  ,  0.26194936, -0.2612618 ],\n",
       "          [-0.17847311,  0.05046068, -0.09711666,  0.22367404,\n",
       "            0.15154496, -0.2226492 ,  0.15439132,  0.1874107 ]],\n",
       " \n",
       "         [[-0.12999332, -0.27157617, -0.0746493 ,  0.28626436,\n",
       "            0.00802611,  0.18102853,  0.08650177, -0.25682238],\n",
       "          [ 0.00236887, -0.25989476,  0.11261756,  0.15957089,\n",
       "           -0.15067421,  0.19178282,  0.07425978, -0.05045439],\n",
       "          [-0.32724887,  0.09075861, -0.07879164, -0.0406656 ,\n",
       "           -0.05084138,  0.08268551,  0.06491712,  0.16362567]],\n",
       " \n",
       "         [[ 0.22760785, -0.1606229 ,  0.00182603, -0.09692313,\n",
       "            0.17681736,  0.13392045, -0.12996991, -0.16853431],\n",
       "          [ 0.15501958, -0.06931265, -0.18702918, -0.05046604,\n",
       "           -0.02657708, -0.10703979, -0.20348774,  0.2452514 ],\n",
       "          [-0.14294216, -0.26179785, -0.1247303 ,  0.2152401 ,\n",
       "           -0.1999745 , -0.11956681,  0.1580587 , -0.05183174]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0463778 ,  0.15794536,  0.08718105, -0.18647462,\n",
       "            0.01997402, -0.1044628 ,  0.26774874,  0.07900577],\n",
       "          [ 0.18544467,  0.2029835 ,  0.2410161 , -0.33955285,\n",
       "           -0.1696537 , -0.14821795, -0.17839555, -0.17431775],\n",
       "          [ 0.3510389 ,  0.08707972,  0.14933644, -0.29324698,\n",
       "            0.07587474, -0.01801753, -0.18301743, -0.16747463]],\n",
       " \n",
       "         [[-0.03232954, -0.09872362, -0.28128403, -0.29610914,\n",
       "           -0.10361303, -0.08023351,  0.18639196,  0.12318122],\n",
       "          [-0.18624018,  0.1465452 , -0.24335548, -0.31235218,\n",
       "            0.04614091, -0.07980105, -0.02252934, -0.19698575],\n",
       "          [-0.1639724 , -0.23319146, -0.28928515, -0.04402482,\n",
       "           -0.1956669 ,  0.24395432,  0.04115193, -0.06133353]],\n",
       " \n",
       "         [[-0.11495397, -0.07915482,  0.19376482, -0.3448626 ,\n",
       "           -0.18085499,  0.10769568, -0.25932384, -0.26828653],\n",
       "          [-0.02276716,  0.03116356,  0.07748909, -0.17826904,\n",
       "            0.15718913,  0.05887273, -0.29387018, -0.30037868],\n",
       "          [-0.02176248,  0.15595059,  0.0601938 , -0.37433693,\n",
       "           -0.04333544, -0.17437622, -0.20748682, -0.08367284]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block1_conv1_5/bias:0' shape=(8,) dtype=float32, numpy=\n",
       " array([ 0.02399732,  0.11352762,  0.02819213, -0.04454377, -0.04555851,\n",
       "        -0.10611806,  0.01442339,  0.07321067], dtype=float32)>,\n",
       " <tf.Variable 'block2_conv1_5/kernel:0' shape=(3, 3, 8, 16) dtype=float32, numpy=\n",
       " array([[[[ 2.06540346e-01, -1.18424661e-01,  1.08434081e-01, ...,\n",
       "           -3.83783877e-01,  1.00764044e-01,  8.29290152e-02],\n",
       "          [ 2.58913226e-02, -1.60666630e-01, -1.26505387e-03, ...,\n",
       "           -5.07018343e-02, -9.10111964e-02,  7.25806050e-04],\n",
       "          [ 4.47452329e-02, -2.06653342e-01, -1.39011264e-01, ...,\n",
       "           -1.94398537e-01, -1.37901038e-01, -1.60178453e-01],\n",
       "          ...,\n",
       "          [ 1.24931885e-02,  1.29274903e-02,  3.83977741e-02, ...,\n",
       "           -2.44372878e-02,  1.37937337e-01,  1.52112171e-01],\n",
       "          [ 6.18398637e-02, -8.12761635e-02, -8.02649185e-02, ...,\n",
       "            1.17274456e-01,  9.32490751e-02,  7.20130503e-02],\n",
       "          [ 1.68992519e-01,  1.57976389e-01,  1.19262256e-01, ...,\n",
       "           -6.33500144e-02,  1.42351985e-01,  1.59025431e-01]],\n",
       " \n",
       "         [[ 3.61674249e-01, -2.93896478e-02, -4.10937667e-02, ...,\n",
       "            2.50360399e-01,  7.87253454e-02,  1.49435356e-01],\n",
       "          [-8.50377455e-02,  7.36844689e-02, -1.90407008e-01, ...,\n",
       "           -8.34347308e-02, -1.43581524e-01,  4.63960245e-02],\n",
       "          [ 4.72939834e-02,  5.07887602e-02, -8.77184421e-02, ...,\n",
       "            1.40916646e-01, -3.61017823e-01, -6.77586421e-02],\n",
       "          ...,\n",
       "          [-2.12533951e-01,  3.16351131e-02,  3.18807364e-02, ...,\n",
       "           -1.18869692e-01,  2.04549238e-01,  3.97095084e-02],\n",
       "          [ 6.39308169e-02, -1.92798860e-02, -7.73901716e-02, ...,\n",
       "            1.23222984e-01, -1.90017253e-01,  7.27005079e-02],\n",
       "          [ 1.50187850e-01,  2.15586238e-02,  1.76882949e-02, ...,\n",
       "            1.46519661e-01,  1.08710811e-01,  1.67550415e-01]],\n",
       " \n",
       "         [[-5.97396977e-02, -7.26968572e-02, -1.15285031e-01, ...,\n",
       "            1.47696272e-01, -1.88449785e-01, -1.82645217e-01],\n",
       "          [-8.62514079e-02,  2.49854222e-01, -7.38166645e-02, ...,\n",
       "           -2.67714374e-02, -3.66780683e-02, -1.04297757e-01],\n",
       "          [-1.76367108e-02, -1.81888163e-01, -7.82052726e-02, ...,\n",
       "           -1.91755593e-01, -3.58185291e-01,  1.65636446e-02],\n",
       "          ...,\n",
       "          [-5.80308251e-02,  1.86771415e-02,  1.96203113e-01, ...,\n",
       "            1.66332528e-01,  7.09093586e-02, -1.03012174e-01],\n",
       "          [-9.03179962e-03, -2.04380304e-01, -3.81354094e-02, ...,\n",
       "           -3.02880615e-01, -1.28867269e-01,  6.09541647e-02],\n",
       "          [ 1.37092173e-01,  8.56672898e-02, -2.92938538e-02, ...,\n",
       "           -1.41246796e-01,  3.84981893e-02,  1.88461691e-01]]],\n",
       " \n",
       " \n",
       "        [[[-1.48166507e-01, -2.32947856e-01,  9.19488668e-02, ...,\n",
       "           -2.43239310e-02, -2.67441794e-02, -7.31982440e-02],\n",
       "          [ 1.71585992e-01, -1.64472610e-01,  1.19473889e-01, ...,\n",
       "           -1.32472470e-01,  2.55152881e-02, -3.56808528e-02],\n",
       "          [-8.02106112e-02,  1.54103329e-02,  2.07292035e-01, ...,\n",
       "           -3.11164781e-02, -6.65329248e-02,  1.26231745e-01],\n",
       "          ...,\n",
       "          [ 1.34003401e-01,  1.11013956e-01,  9.22526196e-02, ...,\n",
       "            4.45513353e-02, -2.82073207e-02, -8.44719261e-02],\n",
       "          [-1.48118958e-01,  2.14017227e-01,  2.97302473e-02, ...,\n",
       "            4.56601568e-02,  3.04279663e-02,  1.43430680e-02],\n",
       "          [-2.43759036e-01,  1.25119001e-01, -1.17644127e-02, ...,\n",
       "           -7.56949559e-02,  1.77595541e-02,  1.52695417e-01]],\n",
       " \n",
       "         [[-4.42650206e-02, -1.73595265e-01,  2.13067368e-01, ...,\n",
       "            3.12038381e-02,  4.71478514e-02, -3.60295594e-01],\n",
       "          [ 2.42227823e-01, -1.73412681e-01,  1.70129105e-01, ...,\n",
       "            6.11637533e-02, -2.28411362e-01,  1.16427923e-02],\n",
       "          [-7.93063566e-02, -1.19299799e-01, -2.03592218e-02, ...,\n",
       "            3.49199593e-01, -6.96261004e-02,  3.83692533e-02],\n",
       "          ...,\n",
       "          [ 5.28779998e-02,  5.14093935e-02, -9.32108760e-02, ...,\n",
       "           -6.64626881e-02,  9.75931287e-02, -7.96833411e-02],\n",
       "          [-6.55213417e-03, -7.68246576e-02,  1.02623723e-01, ...,\n",
       "           -3.25715020e-02,  6.54411502e-03, -1.75132066e-01],\n",
       "          [-1.19670577e-01, -1.75645247e-01,  2.21322462e-01, ...,\n",
       "            3.43742333e-02,  1.39532104e-01,  5.56434505e-02]],\n",
       " \n",
       "         [[ 3.93675178e-01, -2.66155750e-01,  2.52021939e-01, ...,\n",
       "            3.57565522e-01,  1.12786748e-01, -7.50721022e-02],\n",
       "          [ 5.28132804e-02,  2.43274458e-02,  3.10964882e-02, ...,\n",
       "            9.24569592e-02, -1.47924749e-02, -3.38339098e-02],\n",
       "          [-6.04897179e-02, -5.32875769e-02, -7.86412954e-02, ...,\n",
       "           -1.08052805e-01, -3.87131989e-01, -1.62856042e-01],\n",
       "          ...,\n",
       "          [-1.77524060e-01,  3.50688919e-02, -1.70593247e-01, ...,\n",
       "            6.91021001e-03, -3.54190730e-02,  1.42596997e-02],\n",
       "          [-3.89849767e-02,  1.21587783e-01,  1.31809415e-04, ...,\n",
       "           -1.61117807e-01, -2.37209082e-01, -1.13220438e-01],\n",
       "          [-1.18532171e-02, -5.85566051e-02,  3.61773580e-01, ...,\n",
       "           -4.21188362e-02, -1.09387919e-01, -1.43556818e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 1.14404358e-01, -2.06373245e-01, -2.05144798e-03, ...,\n",
       "           -9.54879972e-04, -1.09918170e-01, -1.26407713e-01],\n",
       "          [ 1.02297753e-01, -1.92841202e-01,  1.81002825e-01, ...,\n",
       "           -5.62217459e-02, -4.50758711e-02, -1.36766881e-01],\n",
       "          [-1.87779382e-01,  3.69631827e-01, -9.97374430e-02, ...,\n",
       "            1.28995940e-01,  1.28756359e-01, -1.46616012e-01],\n",
       "          ...,\n",
       "          [-1.06222369e-02, -1.37573481e-01,  2.02611852e-02, ...,\n",
       "            1.06145449e-01, -1.78802744e-01, -5.86445481e-02],\n",
       "          [ 1.43400118e-01,  1.74940810e-01, -8.61760229e-02, ...,\n",
       "           -5.00135757e-02,  3.74950841e-02, -1.31937250e-01],\n",
       "          [ 1.16220951e-01, -7.21186250e-02, -1.23047672e-01, ...,\n",
       "            3.51483412e-02,  7.23087490e-02, -2.07084313e-01]],\n",
       " \n",
       "         [[-5.16066663e-02, -1.36299124e-02, -7.74968117e-02, ...,\n",
       "            1.44212127e-01, -6.60840247e-04, -2.63840295e-02],\n",
       "          [-4.19109538e-02,  2.59528030e-02,  4.88506034e-02, ...,\n",
       "           -5.35576791e-02, -1.09948190e-02, -2.86448598e-01],\n",
       "          [ 2.00326778e-02, -1.85233355e-01, -2.26302017e-02, ...,\n",
       "            2.76258171e-01,  2.07795218e-01, -1.37298450e-01],\n",
       "          ...,\n",
       "          [ 2.29789004e-01,  3.08641768e-03, -9.51521248e-02, ...,\n",
       "            7.04694837e-02, -1.73488483e-02, -3.12889032e-02],\n",
       "          [-1.21090129e-01,  1.37573481e-01, -1.40957311e-01, ...,\n",
       "           -1.40346408e-01,  1.31845772e-01,  1.04456797e-01],\n",
       "          [-1.71392620e-01, -3.14140469e-02, -1.54812708e-01, ...,\n",
       "            2.32169665e-02,  4.50073704e-02,  3.16943265e-02]],\n",
       " \n",
       "         [[-4.02186751e-01, -2.08079159e-01, -1.11051477e-01, ...,\n",
       "            1.90282524e-01,  2.28467479e-01, -1.71678178e-02],\n",
       "          [-1.44725502e-03, -1.60784319e-01,  6.99788183e-02, ...,\n",
       "            1.22079030e-01, -5.83543517e-02, -8.20426941e-02],\n",
       "          [ 1.96054548e-01,  4.07485217e-01, -2.73529161e-02, ...,\n",
       "            3.75546776e-02, -1.03775449e-01,  1.02188915e-01],\n",
       "          ...,\n",
       "          [-1.18326517e-02,  4.72393818e-02, -4.30666879e-02, ...,\n",
       "           -1.04629107e-01, -2.80541390e-01,  3.33029814e-02],\n",
       "          [ 8.33922550e-02,  5.38190231e-02, -6.27427176e-02, ...,\n",
       "            1.76683396e-01, -8.74961615e-02,  6.41657487e-02],\n",
       "          [-2.58210033e-01, -1.49141073e-01, -4.46995907e-02, ...,\n",
       "           -7.24463463e-02,  1.03477299e-01,  5.13813198e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block2_conv1_5/bias:0' shape=(16,) dtype=float32, numpy=\n",
       " array([ 0.01833524, -0.01445881, -0.01649386,  0.06888404,  0.00547507,\n",
       "        -0.01283514, -0.07502608,  0.00405113,  0.04417066,  0.03485512,\n",
       "         0.00379645,  0.03810407, -0.0514663 , -0.03813543,  0.00283697,\n",
       "         0.03908774], dtype=float32)>,\n",
       " <tf.Variable 'block3_conv1_5/kernel:0' shape=(3, 3, 16, 32) dtype=float32, numpy=\n",
       " array([[[[ 0.0725465 ,  0.08346659,  0.1389515 , ..., -0.01214667,\n",
       "            0.15775391,  0.09101051],\n",
       "          [ 0.18733516, -0.05447257,  0.01843798, ..., -0.00181525,\n",
       "            0.1695754 , -0.04312797],\n",
       "          [ 0.04524791, -0.11170965, -0.04869152, ...,  0.01752904,\n",
       "           -0.23016542,  0.02141981],\n",
       "          ...,\n",
       "          [-0.12539057, -0.07321429, -0.10357224, ...,  0.01031399,\n",
       "           -0.0792853 , -0.02706369],\n",
       "          [ 0.10155221, -0.02860574,  0.02134464, ..., -0.06815719,\n",
       "           -0.11782052, -0.06182927],\n",
       "          [ 0.2790902 ,  0.097188  ,  0.11980236, ...,  0.1796938 ,\n",
       "            0.01548037, -0.06085362]],\n",
       " \n",
       "         [[ 0.14141394, -0.23664719, -0.1452798 , ..., -0.08162767,\n",
       "            0.12927076, -0.04609618],\n",
       "          [-0.0027603 , -0.01965904,  0.17695042, ...,  0.06130121,\n",
       "            0.09080233, -0.00725866],\n",
       "          [ 0.15145548, -0.17468289, -0.12750238, ...,  0.03896593,\n",
       "           -0.3796673 , -0.10276213],\n",
       "          ...,\n",
       "          [ 0.03984097, -0.02368789, -0.0764083 , ..., -0.04939689,\n",
       "           -0.14129318, -0.17490387],\n",
       "          [-0.05300451,  0.02882075,  0.10067081, ..., -0.1561241 ,\n",
       "           -0.07744673, -0.01456369],\n",
       "          [-0.07092842,  0.02296062,  0.14223471, ...,  0.20469129,\n",
       "           -0.21451312, -0.06175361]],\n",
       " \n",
       "         [[ 0.11034079, -0.01429263,  0.03016585, ..., -0.09992111,\n",
       "           -0.13093872, -0.00183891],\n",
       "          [-0.14373559,  0.14267461,  0.1435725 , ..., -0.04657228,\n",
       "            0.11852447, -0.03284363],\n",
       "          [ 0.07516598, -0.15797916,  0.13618124, ..., -0.13771307,\n",
       "           -0.08281846,  0.23807132],\n",
       "          ...,\n",
       "          [ 0.1476031 ,  0.00670265,  0.11003633, ..., -0.05102078,\n",
       "           -0.08171322,  0.11524157],\n",
       "          [ 0.13401476,  0.02644526,  0.10297979, ...,  0.01810102,\n",
       "           -0.0196732 ,  0.13199851],\n",
       "          [-0.06743717, -0.07542243,  0.09759843, ...,  0.11849485,\n",
       "           -0.16701226,  0.02170074]]],\n",
       " \n",
       " \n",
       "        [[[ 0.12536737, -0.18763302, -0.24850433, ...,  0.03411254,\n",
       "            0.01809458,  0.10241981],\n",
       "          [ 0.07838625, -0.02279037,  0.01871604, ..., -0.02748411,\n",
       "           -0.0117006 , -0.15489015],\n",
       "          [ 0.13642211, -0.16218936, -0.2645016 , ...,  0.01152935,\n",
       "            0.26941317,  0.00588287],\n",
       "          ...,\n",
       "          [-0.08709716,  0.03240003,  0.0823167 , ...,  0.02005941,\n",
       "           -0.09870876,  0.11012278],\n",
       "          [ 0.01985045, -0.1108795 ,  0.09100088, ..., -0.00538041,\n",
       "            0.07278319,  0.1436455 ],\n",
       "          [ 0.06420154,  0.03654482, -0.06337821, ...,  0.01601561,\n",
       "            0.05893555, -0.21531303]],\n",
       " \n",
       "         [[-0.00512927, -0.09871963, -0.23759525, ...,  0.09008355,\n",
       "           -0.1215563 , -0.1358222 ],\n",
       "          [ 0.13645588, -0.04438855, -0.02934168, ..., -0.01616454,\n",
       "            0.12782298, -0.09733514],\n",
       "          [-0.05264794, -0.03380599, -0.29884148, ...,  0.05665144,\n",
       "           -0.17088892,  0.01005459],\n",
       "          ...,\n",
       "          [-0.08062832,  0.14236327, -0.07733118, ...,  0.0624993 ,\n",
       "           -0.23749536,  0.0293261 ],\n",
       "          [-0.09548747,  0.10205629,  0.02664781, ..., -0.15963565,\n",
       "            0.05649604,  0.16880585],\n",
       "          [-0.06896815,  0.08576199, -0.12778777, ..., -0.02374643,\n",
       "           -0.17995593, -0.14280228]],\n",
       " \n",
       "         [[-0.03026338, -0.14359896, -0.03800713, ...,  0.01401201,\n",
       "           -0.04464285, -0.14622603],\n",
       "          [-0.18965739,  0.13143049,  0.0445314 , ...,  0.13520154,\n",
       "            0.01203876,  0.20170054],\n",
       "          [-0.10061578,  0.01230982,  0.12942198, ...,  0.01728374,\n",
       "           -0.3653313 , -0.00575524],\n",
       "          ...,\n",
       "          [ 0.05889606,  0.03306264,  0.08648226, ..., -0.00666181,\n",
       "            0.01740932,  0.1098759 ],\n",
       "          [-0.04999932, -0.00686395,  0.24440934, ..., -0.2542327 ,\n",
       "           -0.22737868,  0.1623936 ],\n",
       "          [-0.03351363, -0.02043667,  0.06345484, ...,  0.09237426,\n",
       "           -0.21036708, -0.09741583]]],\n",
       " \n",
       " \n",
       "        [[[-0.25201285, -0.10944207,  0.05728775, ...,  0.10335352,\n",
       "            0.24092032,  0.09935754],\n",
       "          [ 0.10276414,  0.06082936,  0.08536608, ..., -0.08097107,\n",
       "            0.05513493,  0.00404322],\n",
       "          [-0.00355542,  0.02407267, -0.18154319, ...,  0.04782899,\n",
       "            0.05123577, -0.0184078 ],\n",
       "          ...,\n",
       "          [-0.26197383, -0.00948343,  0.20430624, ...,  0.00369381,\n",
       "           -0.12119769,  0.00373289],\n",
       "          [-0.03948703,  0.08687253,  0.06226939, ...,  0.19372338,\n",
       "            0.06284981,  0.07318896],\n",
       "          [-0.13832377,  0.11389042, -0.0457679 , ..., -0.02817739,\n",
       "           -0.00317499, -0.03204745]],\n",
       " \n",
       "         [[ 0.04359232,  0.09559507, -0.28630206, ...,  0.02161167,\n",
       "            0.00734612,  0.14280854],\n",
       "          [ 0.06883519,  0.04349172,  0.05548784, ...,  0.06604509,\n",
       "           -0.09117954,  0.03638939],\n",
       "          [-0.0708422 ,  0.05530958, -0.26090693, ..., -0.01067341,\n",
       "           -0.2421372 ,  0.02866258],\n",
       "          ...,\n",
       "          [ 0.02184799,  0.19306177,  0.04778832, ..., -0.26380542,\n",
       "           -0.49257365,  0.01472627],\n",
       "          [-0.04714994, -0.01014166, -0.16919681, ..., -0.02999623,\n",
       "           -0.06808145,  0.02027502],\n",
       "          [-0.09161057, -0.1287028 , -0.42182365, ..., -0.00314977,\n",
       "           -0.17185952,  0.03758449]],\n",
       " \n",
       "         [[ 0.04070688,  0.0048851 ,  0.06693037, ..., -0.05684924,\n",
       "            0.00880093, -0.06885187],\n",
       "          [-0.04704131,  0.17214188, -0.19990253, ...,  0.13474819,\n",
       "           -0.03551356,  0.093321  ],\n",
       "          [ 0.005892  ,  0.13668196,  0.18486951, ..., -0.13254152,\n",
       "           -0.14159082, -0.13848177],\n",
       "          ...,\n",
       "          [ 0.02104789,  0.14570566,  0.11722764, ..., -0.3351071 ,\n",
       "           -0.20488709, -0.02724919],\n",
       "          [-0.13517886,  0.18321304,  0.07094335, ..., -0.10675164,\n",
       "            0.00539574, -0.17623624],\n",
       "          [-0.04589065, -0.02996734, -0.14256087, ...,  0.12115508,\n",
       "           -0.12921064,  0.13437091]]]], dtype=float32)>,\n",
       " <tf.Variable 'block3_conv1_5/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([-0.15484741, -0.06252424,  0.0766439 ,  0.05978486,  0.03480628,\n",
       "         0.08197206,  0.09707367, -0.03904669,  0.0285302 , -0.04642882,\n",
       "         0.13650316,  0.02215963,  0.066216  ,  0.01946565, -0.02507489,\n",
       "         0.10085054, -0.01085287,  0.06533812,  0.01362276,  0.03919302,\n",
       "         0.03922914,  0.09382238,  0.08097375,  0.01496687,  0.07309191,\n",
       "         0.04143219,  0.00123729,  0.05446931,  0.11656909,  0.06771113,\n",
       "         0.06133033,  0.02251646], dtype=float32)>,\n",
       " <tf.Variable 'block3_conv2_5/kernel:0' shape=(3, 3, 32, 32) dtype=float32, numpy=\n",
       " array([[[[-0.01513063, -0.04862227,  0.13865836, ...,  0.02455333,\n",
       "            0.10692064, -0.09880172],\n",
       "          [ 0.03122072, -0.10170542,  0.12052013, ..., -0.05108332,\n",
       "           -0.06783529, -0.07429724],\n",
       "          [-0.16957957,  0.05338782,  0.1412804 , ..., -0.04467365,\n",
       "            0.25199756,  0.03631617],\n",
       "          ...,\n",
       "          [ 0.01458191, -0.20451654,  0.17212316, ..., -0.06337702,\n",
       "           -0.09165251, -0.00933322],\n",
       "          [ 0.00083731,  0.13760191, -0.17598912, ...,  0.03119347,\n",
       "            0.12490631, -0.1412599 ],\n",
       "          [-0.13440719, -0.09249908, -0.09546541, ...,  0.09152023,\n",
       "           -0.01785727, -0.14997894]],\n",
       " \n",
       "         [[ 0.20015457,  0.04984206,  0.07891876, ...,  0.06265697,\n",
       "           -0.02792909, -0.15315756],\n",
       "          [ 0.07146785,  0.02465041,  0.12238267, ..., -0.10004909,\n",
       "            0.0473012 , -0.08857654],\n",
       "          [-0.13044158, -0.14520028,  0.00562192, ..., -0.24333446,\n",
       "            0.21263817, -0.03228731],\n",
       "          ...,\n",
       "          [ 0.1590245 , -0.2043857 ,  0.00105339, ..., -0.05389934,\n",
       "           -0.13255909, -0.0659525 ],\n",
       "          [-0.023637  ,  0.02622456, -0.16019928, ...,  0.17444445,\n",
       "           -0.0215502 ,  0.09973491],\n",
       "          [-0.04638829, -0.03357984,  0.03969058, ...,  0.18728991,\n",
       "           -0.06695957, -0.02610408]],\n",
       " \n",
       "         [[-0.12610972,  0.09890357,  0.07563017, ...,  0.12320165,\n",
       "           -0.04378276, -0.02902511],\n",
       "          [ 0.03187706, -0.10497668, -0.04646737, ...,  0.0493187 ,\n",
       "            0.04522759,  0.04901936],\n",
       "          [-0.05959829, -0.06199139, -0.04421965, ..., -0.03828646,\n",
       "            0.08683793, -0.14493378],\n",
       "          ...,\n",
       "          [ 0.05214632, -0.18696532,  0.12063458, ..., -0.05430499,\n",
       "           -0.06897146, -0.12915336],\n",
       "          [ 0.08983935, -0.06368084,  0.03413767, ..., -0.05010463,\n",
       "           -0.00287913,  0.16710274],\n",
       "          [-0.04046388,  0.05793923, -0.06252434, ..., -0.04248429,\n",
       "           -0.10894772,  0.07931216]]],\n",
       " \n",
       " \n",
       "        [[[ 0.07747605, -0.04100625, -0.08554148, ...,  0.08802913,\n",
       "            0.02294118, -0.1521742 ],\n",
       "          [-0.03928396, -0.08845329, -0.12712602, ..., -0.15738629,\n",
       "           -0.05423476, -0.0918092 ],\n",
       "          [-0.06056822,  0.13019499,  0.10682499, ..., -0.21935463,\n",
       "            0.17862934,  0.09632214],\n",
       "          ...,\n",
       "          [ 0.09495218,  0.01553531, -0.00284604, ...,  0.12797496,\n",
       "            0.00138074, -0.02415473],\n",
       "          [-0.05182264, -0.03932034, -0.12945138, ..., -0.02335605,\n",
       "            0.39308354, -0.20065016],\n",
       "          [-0.21563835,  0.05759921, -0.25829476, ...,  0.00995958,\n",
       "           -0.03368217, -0.21426651]],\n",
       " \n",
       "         [[ 0.02737994,  0.06032746, -0.04974093, ...,  0.05779359,\n",
       "           -0.05900361,  0.09244609],\n",
       "          [-0.04199873, -0.07504296, -0.2333641 , ..., -0.14492543,\n",
       "           -0.06587053, -0.32257673],\n",
       "          [-0.06276832,  0.01351512,  0.10116667, ..., -0.06218731,\n",
       "           -0.05907742, -0.17392914],\n",
       "          ...,\n",
       "          [ 0.15606807,  0.0654626 ,  0.19540629, ..., -0.02629406,\n",
       "           -0.1634767 ,  0.02308211],\n",
       "          [-0.06432243, -0.11512457, -0.10743095, ...,  0.03623068,\n",
       "            0.18999761, -0.16550118],\n",
       "          [-0.06554364,  0.12951188, -0.4056509 , ...,  0.09873155,\n",
       "           -0.00843794, -0.07525419]],\n",
       " \n",
       "         [[-0.1962517 ,  0.07187799,  0.04974776, ...,  0.08682942,\n",
       "            0.11748827, -0.08191408],\n",
       "          [ 0.12642619, -0.02716351, -0.24070126, ...,  0.1399176 ,\n",
       "           -0.02359308, -0.03616526],\n",
       "          [ 0.03226882,  0.10212188, -0.04335919, ...,  0.09196645,\n",
       "           -0.07789373, -0.05742345],\n",
       "          ...,\n",
       "          [ 0.10989371, -0.03522003,  0.07579759, ..., -0.04310738,\n",
       "           -0.13511465,  0.03194493],\n",
       "          [ 0.15667287,  0.08304536,  0.0248075 , ..., -0.0028005 ,\n",
       "            0.10632947,  0.02789945],\n",
       "          [-0.02519399, -0.02757921, -0.28079116, ..., -0.17570159,\n",
       "           -0.22881405,  0.13410324]]],\n",
       " \n",
       " \n",
       "        [[[-0.00067574,  0.04037515, -0.00873634, ...,  0.17088707,\n",
       "            0.01977108, -0.03226915],\n",
       "          [ 0.00254923,  0.04281643,  0.00904447, ..., -0.16183276,\n",
       "           -0.04426852, -0.06851221],\n",
       "          [ 0.00657754,  0.0692651 , -0.15493985, ..., -0.07220098,\n",
       "           -0.14714086, -0.02413881],\n",
       "          ...,\n",
       "          [-0.07531752,  0.15006137, -0.234193  , ...,  0.19047022,\n",
       "           -0.04636411,  0.10451167],\n",
       "          [ 0.13585271, -0.1342312 , -0.12448166, ..., -0.12016331,\n",
       "           -0.08911368,  0.1325007 ],\n",
       "          [ 0.01359652, -0.13252595,  0.13986766, ..., -0.1764996 ,\n",
       "            0.11956269, -0.0125646 ]],\n",
       " \n",
       "         [[-0.1616466 , -0.1819952 ,  0.01725365, ..., -0.20428592,\n",
       "           -0.1709551 ,  0.06150475],\n",
       "          [ 0.1473588 , -0.00925221, -0.0290093 , ..., -0.00320259,\n",
       "           -0.12884441,  0.02692149],\n",
       "          [ 0.03173043,  0.19909337, -0.04486019, ...,  0.02669746,\n",
       "           -0.28829753, -0.28209132],\n",
       "          ...,\n",
       "          [ 0.02205753,  0.06915452, -0.13900582, ..., -0.11355002,\n",
       "           -0.05551716,  0.09450689],\n",
       "          [ 0.17454085, -0.17232637, -0.1583292 , ..., -0.02961154,\n",
       "           -0.09480074,  0.1553686 ],\n",
       "          [-0.02209046, -0.18213733,  0.12683609, ..., -0.04002179,\n",
       "            0.03499347,  0.02010596]],\n",
       " \n",
       "         [[-0.22708547, -0.1632408 ,  0.13831335, ..., -0.17160232,\n",
       "           -0.16925019, -0.09345769],\n",
       "          [ 0.17057191, -0.07002714,  0.08143594, ...,  0.07670254,\n",
       "            0.0528126 , -0.06977096],\n",
       "          [-0.12771468,  0.10692632, -0.16512956, ...,  0.19480824,\n",
       "           -0.20975572, -0.01236591],\n",
       "          ...,\n",
       "          [ 0.00900698, -0.07017161, -0.19146205, ..., -0.15621626,\n",
       "            0.09944035,  0.05963947],\n",
       "          [ 0.18536177, -0.1095983 , -0.26176906, ...,  0.09028251,\n",
       "           -0.10708776, -0.14553809],\n",
       "          [ 0.17170186, -0.08118528,  0.14571083, ..., -0.11659718,\n",
       "           -0.14848457,  0.03128488]]]], dtype=float32)>,\n",
       " <tf.Variable 'block3_conv2_5/bias:0' shape=(32,) dtype=float32, numpy=\n",
       " array([ 0.06717017,  0.08732106, -0.02496137, -0.06616404,  0.03496521,\n",
       "         0.00995503,  0.03494661, -0.04670615, -0.01390091,  0.01316897,\n",
       "         0.03426657,  0.02123792, -0.03652127, -0.0571823 , -0.00736364,\n",
       "        -0.03720619, -0.02925509,  0.09610537, -0.10303104,  0.10256828,\n",
       "         0.04494863,  0.00425685, -0.10346117,  0.04127326,  0.04959923,\n",
       "        -0.00407151,  0.00815153,  0.02602067, -0.07866612, -0.03125947,\n",
       "         0.02634396,  0.06384747], dtype=float32)>,\n",
       " <tf.Variable 'block4_conv1_5/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\n",
       " array([[[[-2.85969004e-02, -1.07216779e-02,  5.21045271e-03, ...,\n",
       "           -1.41374364e-01,  5.61290942e-02,  2.54200753e-02],\n",
       "          [-3.47477533e-02,  9.60312933e-02, -1.31017063e-02, ...,\n",
       "           -6.17263913e-02, -5.56175299e-02, -1.29811555e-01],\n",
       "          [-1.51880398e-01,  1.90692365e-01,  1.31672826e-02, ...,\n",
       "           -3.14794451e-01, -1.20081626e-01,  2.94405990e-03],\n",
       "          ...,\n",
       "          [-1.09443121e-01,  1.01847149e-01, -1.47430733e-01, ...,\n",
       "           -3.30685288e-01, -4.51211929e-02, -1.38276979e-01],\n",
       "          [-1.30816743e-01, -8.69368240e-02,  1.40282333e-01, ...,\n",
       "           -9.11826938e-02,  3.53392251e-02, -8.26159194e-02],\n",
       "          [-4.63965572e-02, -7.38564730e-02,  4.87823710e-02, ...,\n",
       "            1.26591459e-01, -1.35180354e-01, -1.64516538e-01]],\n",
       " \n",
       "         [[ 3.89708355e-02, -8.12037587e-02, -1.21906004e-03, ...,\n",
       "            1.70201790e-02,  4.88948002e-02, -4.33160588e-02],\n",
       "          [-6.62467070e-03,  4.82112877e-02, -1.40505031e-01, ...,\n",
       "            2.40753125e-02, -1.59849212e-01, -1.42701808e-02],\n",
       "          [ 2.51776376e-03,  1.22252911e-01, -1.15869686e-01, ...,\n",
       "           -1.17270663e-01, -6.85491189e-02, -1.93125047e-02],\n",
       "          ...,\n",
       "          [-5.48589379e-02,  5.58731444e-02, -2.66651046e-02, ...,\n",
       "           -1.84607327e-01, -1.06464177e-01, -3.59825343e-02],\n",
       "          [ 2.13687465e-01, -2.50034809e-01, -1.05503644e-03, ...,\n",
       "            5.38570508e-02, -1.24177136e-01, -1.80101514e-01],\n",
       "          [-9.90788862e-02, -1.65274423e-02,  1.58967108e-01, ...,\n",
       "            2.85869837e-02,  1.30285889e-01, -2.38372665e-02]],\n",
       " \n",
       "         [[-1.74239520e-02, -9.53062698e-02,  1.16328411e-01, ...,\n",
       "           -8.14004019e-02, -3.08357142e-02, -5.26834801e-02],\n",
       "          [ 8.44304413e-02,  5.19085117e-02, -3.61732207e-02, ...,\n",
       "           -8.92907605e-02, -2.90260594e-02, -1.34926870e-01],\n",
       "          [ 5.64690270e-02,  1.11723974e-01, -2.22821251e-01, ...,\n",
       "            8.12877435e-03,  2.46416591e-02, -9.71030071e-02],\n",
       "          ...,\n",
       "          [ 6.50730133e-02, -1.29864216e-02, -8.28818530e-02, ...,\n",
       "           -6.10503070e-02,  1.27063310e-02, -6.74089268e-02],\n",
       "          [ 2.34335244e-01, -1.03668593e-01, -1.19255580e-01, ...,\n",
       "            1.55621111e-01,  1.59882195e-02, -1.19877778e-01],\n",
       "          [ 2.10859954e-01,  5.01967482e-02,  1.99088338e-03, ...,\n",
       "            5.47726266e-02,  2.78715249e-02, -5.10161854e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 5.51686846e-02, -1.76377017e-02, -4.86796023e-03, ...,\n",
       "           -3.53047997e-02,  1.24763567e-02,  6.40233932e-03],\n",
       "          [ 1.63479783e-02, -4.02480774e-02,  2.21602008e-01, ...,\n",
       "           -1.92862302e-02,  2.22779304e-01, -1.22252367e-01],\n",
       "          [ 2.21250746e-02,  4.18869779e-02, -1.21289253e-01, ...,\n",
       "           -5.45574799e-02, -2.61950254e-01, -6.36507524e-03],\n",
       "          ...,\n",
       "          [-2.29679868e-01, -3.46059352e-02, -1.95179299e-01, ...,\n",
       "            8.68200660e-02,  4.13194112e-02, -6.69589862e-02],\n",
       "          [-1.10340446e-01, -2.17693239e-01, -6.97236881e-02, ...,\n",
       "           -1.03149369e-01, -2.21647695e-02, -5.55002363e-03],\n",
       "          [ 3.25768776e-02, -2.15336278e-01, -4.04945463e-02, ...,\n",
       "            8.30711573e-02, -6.53926879e-02,  9.62547883e-02]],\n",
       " \n",
       "         [[ 8.11495930e-02,  1.95540160e-01, -1.27213240e-01, ...,\n",
       "           -2.70065963e-02,  2.78577432e-02,  1.31813779e-01],\n",
       "          [-6.17225654e-02, -4.59690504e-02,  2.32850716e-01, ...,\n",
       "            9.36890170e-02, -9.73901972e-02, -8.70541558e-02],\n",
       "          [-5.85592464e-02,  1.13327324e-01,  6.35203905e-03, ...,\n",
       "            1.58126764e-02, -1.38221115e-01, -3.84555832e-02],\n",
       "          ...,\n",
       "          [-1.90689620e-02, -8.90405942e-03, -4.86934707e-02, ...,\n",
       "           -7.94674158e-02, -4.02867086e-02, -2.34811619e-01],\n",
       "          [ 9.90656242e-02, -6.09520823e-02, -7.65060559e-02, ...,\n",
       "           -1.41233712e-01, -1.00688830e-01, -2.12159753e-01],\n",
       "          [ 2.02225591e-03,  1.01002276e-01,  1.22842036e-01, ...,\n",
       "            1.03150330e-01, -2.72645596e-02, -4.21293005e-02]],\n",
       " \n",
       "         [[-1.10193416e-01, -1.44263521e-01,  8.51422995e-02, ...,\n",
       "            1.62879433e-02,  1.28599986e-01, -2.50947922e-02],\n",
       "          [ 2.48838402e-02,  2.70658731e-01,  3.58441286e-03, ...,\n",
       "           -1.09513365e-01, -3.72496396e-01,  3.53210643e-02],\n",
       "          [ 6.76845387e-02,  5.70219681e-02, -1.30889550e-01, ...,\n",
       "           -1.21004447e-01, -1.65227205e-01, -1.03574365e-01],\n",
       "          ...,\n",
       "          [ 1.02472141e-01,  5.14683835e-02, -9.53472685e-03, ...,\n",
       "           -7.07501620e-02, -1.36984751e-01, -2.47807428e-02],\n",
       "          [ 4.94699329e-02, -8.79250988e-02,  7.42610693e-02, ...,\n",
       "           -3.12322795e-01,  7.52000213e-02, -1.84042320e-01],\n",
       "          [ 1.75117597e-01,  1.77100272e-04,  7.25610852e-02, ...,\n",
       "            4.50482480e-02, -1.11472398e-01, -1.36519343e-01]]],\n",
       " \n",
       " \n",
       "        [[[ 1.63766176e-01, -1.83037698e-01,  3.06089539e-02, ...,\n",
       "           -1.44092068e-01,  4.07979861e-02, -4.57205474e-02],\n",
       "          [-6.26345947e-02, -9.90209579e-02, -4.88584638e-02, ...,\n",
       "            2.87830699e-02,  1.44177720e-01, -1.45336732e-01],\n",
       "          [ 6.30883649e-02, -1.46248147e-01,  1.09623345e-02, ...,\n",
       "            1.20007388e-01, -9.72094312e-02, -7.40410611e-02],\n",
       "          ...,\n",
       "          [ 8.08315799e-02,  2.69716624e-02,  4.49733576e-03, ...,\n",
       "            1.40347689e-01,  1.85604066e-01, -5.83582632e-02],\n",
       "          [-7.54465302e-03, -3.14734015e-03, -6.01421949e-03, ...,\n",
       "            1.08072516e-02,  1.26273602e-01, -1.60248369e-01],\n",
       "          [ 1.24172159e-01, -1.37659028e-01, -2.01820582e-01, ...,\n",
       "            5.29635847e-02,  9.50931907e-02, -6.68565854e-02]],\n",
       " \n",
       "         [[ 8.54842961e-02,  2.36158207e-01, -1.39706582e-01, ...,\n",
       "           -4.24024928e-03, -1.67078063e-01,  6.21402711e-02],\n",
       "          [ 4.38682325e-02, -1.15302004e-01,  9.07342136e-02, ...,\n",
       "           -7.95204341e-02,  1.14430385e-02, -4.82070027e-03],\n",
       "          [-1.23805396e-04,  7.91520551e-02,  1.96515396e-01, ...,\n",
       "           -6.45926297e-02, -4.98119555e-02, -4.01551500e-02],\n",
       "          ...,\n",
       "          [-3.03754620e-02, -6.50579557e-02, -7.03768060e-02, ...,\n",
       "           -9.36303884e-02, -4.23746556e-03, -3.15795213e-01],\n",
       "          [-1.84830844e-01, -1.21593848e-01,  1.04578212e-01, ...,\n",
       "           -2.69633392e-03, -5.58978170e-02, -1.48219585e-01],\n",
       "          [-6.90598786e-02,  1.05996460e-01,  3.66605818e-02, ...,\n",
       "           -8.11663829e-03, -2.54985765e-02, -1.54000893e-01]],\n",
       " \n",
       "         [[-1.85066998e-01, -1.13235034e-01, -1.83945358e-01, ...,\n",
       "            3.64733525e-02,  6.29345849e-02, -1.90564498e-01],\n",
       "          [ 1.93506747e-01,  1.23072453e-01, -2.44010910e-02, ...,\n",
       "            1.11675449e-01, -2.42512926e-01, -2.13113353e-01],\n",
       "          [ 1.98679253e-01, -1.33707784e-02, -8.63543823e-02, ...,\n",
       "            1.69502765e-01, -1.30187139e-01, -7.10118860e-02],\n",
       "          ...,\n",
       "          [ 8.48091915e-02, -2.48277448e-02, -6.80771917e-02, ...,\n",
       "            1.07793495e-01, -7.35159591e-02, -1.20320998e-01],\n",
       "          [-8.05981010e-02, -1.47565886e-01, -2.23606993e-02, ...,\n",
       "           -1.41163260e-01, -8.73482078e-02, -1.94796070e-01],\n",
       "          [ 2.33709011e-02, -1.10983372e-01,  7.98931122e-02, ...,\n",
       "            2.68037207e-02, -7.31863678e-02, -4.03082445e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block4_conv1_5/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([-0.02061274, -0.02360253, -0.05459574,  0.03130476,  0.03517974,\n",
       "        -0.06966298,  0.05116604, -0.0086432 ,  0.04415346, -0.01630963,\n",
       "        -0.05479279,  0.09635   , -0.0417104 ,  0.06772787, -0.07089088,\n",
       "         0.03087839,  0.12115099,  0.00168544,  0.02962834, -0.07386225,\n",
       "         0.05120674,  0.01593411,  0.02122129,  0.07978033, -0.03693098,\n",
       "        -0.04572721, -0.00650184,  0.00686211,  0.07961646,  0.03133691,\n",
       "         0.01704139,  0.02725413, -0.0328    ,  0.11205161,  0.05875481,\n",
       "        -0.01275448, -0.02219463,  0.03146242, -0.11532915,  0.04128096,\n",
       "        -0.05021863,  0.01688473, -0.06306124,  0.07697988,  0.09902595,\n",
       "        -0.02155839,  0.01287565, -0.08260431,  0.00519016,  0.03265589,\n",
       "         0.02387811,  0.02417001,  0.00429774,  0.02401014, -0.020933  ,\n",
       "        -0.06063441,  0.08039304, -0.06076749,  0.09786135,  0.06192409,\n",
       "         0.06262877,  0.0906016 ,  0.13076206, -0.06415122], dtype=float32)>,\n",
       " <tf.Variable 'block4_conv2_5/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
       " array([[[[ 0.15517583, -0.12411087, -0.02711235, ...,  0.04628432,\n",
       "           -0.07760491,  0.04823203],\n",
       "          [ 0.15427113,  0.00554184,  0.12442375, ...,  0.03618246,\n",
       "           -0.13827252, -0.03428236],\n",
       "          [ 0.1899301 , -0.2850972 , -0.21835689, ...,  0.01603995,\n",
       "           -0.15831155,  0.2135666 ],\n",
       "          ...,\n",
       "          [ 0.13901669,  0.02922038, -0.07263207, ..., -0.09258412,\n",
       "            0.04297095,  0.12013708],\n",
       "          [-0.11757725, -0.12031741,  0.10133862, ..., -0.13535483,\n",
       "            0.03513   ,  0.08599398],\n",
       "          [ 0.10043123,  0.00115581,  0.10821374, ..., -0.04685861,\n",
       "           -0.02736132, -0.09223089]],\n",
       " \n",
       "         [[ 0.13138208, -0.2088721 ,  0.11312982, ..., -0.10680146,\n",
       "           -0.01560453,  0.06226289],\n",
       "          [ 0.11461202,  0.09658216,  0.01408696, ...,  0.01183313,\n",
       "            0.10835605,  0.0486048 ],\n",
       "          [ 0.15747093, -0.17442875, -0.05498003, ..., -0.0274874 ,\n",
       "           -0.12696439,  0.00546248],\n",
       "          ...,\n",
       "          [-0.02654479,  0.00309927, -0.11106626, ...,  0.21548788,\n",
       "           -0.09714489,  0.09297863],\n",
       "          [-0.10840186,  0.05517175, -0.05997511, ...,  0.05826068,\n",
       "            0.02509197,  0.11640014],\n",
       "          [-0.01878252, -0.02497624, -0.01333266, ...,  0.00850125,\n",
       "           -0.02637762, -0.07404487]],\n",
       " \n",
       "         [[ 0.04106837,  0.04243252, -0.1222437 , ..., -0.09072214,\n",
       "           -0.03637537, -0.00432907],\n",
       "          [ 0.08094874, -0.03623834, -0.01853321, ...,  0.0743726 ,\n",
       "           -0.13299328,  0.14105868],\n",
       "          [ 0.20019397, -0.10472691,  0.14440417, ...,  0.01482759,\n",
       "           -0.13134949, -0.05095596],\n",
       "          ...,\n",
       "          [-0.01517695, -0.11878387, -0.02569292, ...,  0.30704227,\n",
       "            0.09548267, -0.15179408],\n",
       "          [-0.06879283,  0.13133305, -0.03880754, ..., -0.0277403 ,\n",
       "            0.04955456, -0.20638342],\n",
       "          [ 0.10450422, -0.11504131, -0.02280677, ...,  0.15774699,\n",
       "            0.00316907, -0.1266084 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0487374 , -0.05568007, -0.10565618, ...,  0.15422812,\n",
       "            0.00034919,  0.02900046],\n",
       "          [ 0.00403841,  0.01310872,  0.02166575, ..., -0.08982203,\n",
       "           -0.01033458, -0.12480845],\n",
       "          [ 0.1610971 , -0.02602446,  0.02867712, ...,  0.0140357 ,\n",
       "           -0.11231384,  0.084485  ],\n",
       "          ...,\n",
       "          [ 0.1089185 , -0.07678517, -0.13264106, ..., -0.16486214,\n",
       "           -0.11622676,  0.03011318],\n",
       "          [-0.0641083 , -0.15794158,  0.13428071, ...,  0.02477163,\n",
       "            0.1301876 ,  0.06515104],\n",
       "          [ 0.06427466, -0.0339039 , -0.08168947, ..., -0.05647794,\n",
       "           -0.00102344, -0.06947979]],\n",
       " \n",
       "         [[ 0.12244774, -0.05560545, -0.14641477, ..., -0.1662723 ,\n",
       "            0.07359066,  0.06849797],\n",
       "          [-0.0022579 ,  0.0863688 , -0.10856482, ...,  0.00220563,\n",
       "           -0.01350209, -0.00222528],\n",
       "          [-0.08246894,  0.03205479, -0.03510608, ...,  0.0899416 ,\n",
       "           -0.06579664,  0.1294488 ],\n",
       "          ...,\n",
       "          [-0.09190913, -0.06618208, -0.20289604, ..., -0.1215592 ,\n",
       "            0.02927408, -0.03973305],\n",
       "          [-0.15749408, -0.01803858,  0.11656243, ..., -0.13407786,\n",
       "            0.01747663,  0.10586936],\n",
       "          [ 0.24379088,  0.0833822 , -0.07627257, ..., -0.01810347,\n",
       "           -0.07601157, -0.03751169]],\n",
       " \n",
       "         [[-0.05675107,  0.02926915, -0.04664547, ..., -0.04086412,\n",
       "           -0.01690658,  0.13673045],\n",
       "          [-0.20307247,  0.0592289 , -0.03534654, ..., -0.08147457,\n",
       "            0.0633618 , -0.02763775],\n",
       "          [ 0.00129725,  0.00529532,  0.10903876, ..., -0.06712183,\n",
       "            0.00972697,  0.02072153],\n",
       "          ...,\n",
       "          [ 0.01021101,  0.01541339, -0.12702285, ...,  0.03184868,\n",
       "            0.01747477,  0.02083836],\n",
       "          [-0.20726408,  0.12801   ,  0.07659512, ...,  0.1151504 ,\n",
       "           -0.0159482 , -0.02401199],\n",
       "          [ 0.01184418,  0.01618207,  0.03084679, ..., -0.14065911,\n",
       "           -0.07054283,  0.00946315]]],\n",
       " \n",
       " \n",
       "        [[[-0.14863214, -0.03584143,  0.10797153, ...,  0.10652465,\n",
       "           -0.17994136, -0.09006242],\n",
       "          [ 0.17544223,  0.13633944,  0.02586574, ..., -0.2147086 ,\n",
       "            0.00799971,  0.00814461],\n",
       "          [-0.23523098, -0.06623461,  0.12736872, ...,  0.1414561 ,\n",
       "            0.19374542, -0.14996862],\n",
       "          ...,\n",
       "          [ 0.20713848, -0.04926138, -0.10575206, ...,  0.0042523 ,\n",
       "           -0.00088611,  0.00997931],\n",
       "          [-0.1392053 , -0.08042527, -0.07371823, ...,  0.15338539,\n",
       "            0.03251723, -0.27454007],\n",
       "          [-0.19521204,  0.04830429, -0.02113415, ...,  0.15403011,\n",
       "           -0.07595079, -0.05756621]],\n",
       " \n",
       "         [[-0.03064744,  0.10971519,  0.00599282, ..., -0.04057145,\n",
       "           -0.12631807, -0.0794918 ],\n",
       "          [ 0.2459854 ,  0.04537009, -0.03210955, ..., -0.10321484,\n",
       "           -0.11815304,  0.12017673],\n",
       "          [-0.30880073, -0.11054676, -0.0735443 , ..., -0.20020142,\n",
       "           -0.04246123, -0.22874328],\n",
       "          ...,\n",
       "          [-0.0603645 ,  0.03346709, -0.26072383, ...,  0.0899156 ,\n",
       "            0.04142951, -0.10951304],\n",
       "          [-0.09262303,  0.02610753,  0.08604696, ..., -0.28615522,\n",
       "           -0.04147312, -0.10591331],\n",
       "          [ 0.07429226, -0.1078189 , -0.02868268, ..., -0.14341566,\n",
       "            0.07443497, -0.05850049]],\n",
       " \n",
       "         [[-0.02509359, -0.11649409,  0.04245038, ..., -0.12631454,\n",
       "            0.01703254, -0.29400405],\n",
       "          [-0.12423512, -0.16224101, -0.00624433, ...,  0.02883054,\n",
       "            0.05111376,  0.07218461],\n",
       "          [-0.14482237, -0.02356882, -0.15975983, ..., -0.07896259,\n",
       "           -0.09065895, -0.28407142],\n",
       "          ...,\n",
       "          [-0.08798933,  0.12007461, -0.13112934, ..., -0.04425716,\n",
       "           -0.00069894, -0.1556503 ],\n",
       "          [ 0.05009994,  0.1354756 , -0.10860725, ...,  0.022998  ,\n",
       "           -0.06361414, -0.03308641],\n",
       "          [-0.07036486, -0.00846054,  0.00860726, ..., -0.02637712,\n",
       "            0.01980924, -0.10679138]]]], dtype=float32)>,\n",
       " <tf.Variable 'block4_conv2_5/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.01925298,  0.02402277,  0.03501058, -0.01985068, -0.04101755,\n",
       "        -0.0434468 , -0.01847188,  0.02336119, -0.01876949,  0.06536531,\n",
       "         0.06570226, -0.06916445,  0.01299286, -0.0417275 , -0.05451317,\n",
       "        -0.0782212 , -0.06921427,  0.02444252, -0.01726377,  0.01665036,\n",
       "         0.00479702, -0.01823899,  0.02636178,  0.00035798, -0.03301939,\n",
       "         0.00645583, -0.07064069, -0.09478707, -0.02905945, -0.00088909,\n",
       "        -0.06085704, -0.06004774,  0.08045274, -0.03491589,  0.0443772 ,\n",
       "        -0.06867448,  0.04861344, -0.07863913, -0.01992965, -0.00402377,\n",
       "        -0.02684539,  0.04094693, -0.02586483, -0.05424359, -0.02879715,\n",
       "        -0.00869159, -0.04784834,  0.06481569,  0.01939198, -0.03176703,\n",
       "        -0.01325944,  0.0980712 , -0.01273893, -0.00345938,  0.01467399,\n",
       "         0.01431608, -0.031599  , -0.05474754, -0.06882641, -0.08628146,\n",
       "        -0.01862662,  0.04082699,  0.02469061,  0.0008432 ], dtype=float32)>,\n",
       " <tf.Variable 'block5_conv1_5/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
       " array([[[[ 3.07376757e-02, -8.93259197e-02, -9.13002118e-02, ...,\n",
       "           -1.57154322e-01, -1.55975014e-01, -1.59916312e-01],\n",
       "          [ 2.09542864e-04,  1.47597007e-02, -6.28410950e-02, ...,\n",
       "           -6.26024902e-02, -3.58988270e-02,  1.28042608e-01],\n",
       "          [-2.42888242e-01, -6.47211596e-02,  1.33282200e-01, ...,\n",
       "           -1.02446496e-01,  5.95282717e-03,  8.92745927e-02],\n",
       "          ...,\n",
       "          [ 1.82340816e-02,  3.11215036e-03,  1.12763673e-01, ...,\n",
       "           -6.76134974e-02, -1.13955535e-01, -6.22454770e-02],\n",
       "          [-6.07550740e-02, -7.33033344e-02, -3.54207866e-02, ...,\n",
       "            3.92378308e-02,  1.36043325e-01, -2.84611583e-02],\n",
       "          [ 1.38038039e-01,  1.37222573e-01, -5.37503846e-02, ...,\n",
       "           -1.48752499e-02, -7.58644252e-04,  2.56935190e-02]],\n",
       " \n",
       "         [[ 1.57313243e-01,  2.62418594e-02,  1.95964426e-01, ...,\n",
       "           -1.06526976e-02, -9.37433243e-02,  5.19319884e-02],\n",
       "          [-5.41911973e-03,  1.22483131e-02, -7.04465136e-02, ...,\n",
       "           -1.20555468e-01, -5.56948371e-02, -1.84335038e-02],\n",
       "          [ 4.47898209e-02,  7.03249723e-02, -9.81011316e-02, ...,\n",
       "            1.92287713e-02, -1.55096985e-02, -1.17311753e-01],\n",
       "          ...,\n",
       "          [-1.15415446e-01,  2.34952550e-02,  2.51131523e-02, ...,\n",
       "            1.15067199e-01,  8.29275250e-02,  4.07340042e-02],\n",
       "          [-8.82617384e-02, -1.59392506e-01, -1.44217789e-01, ...,\n",
       "            8.26059580e-02, -1.03455968e-02, -4.71957773e-02],\n",
       "          [-1.85957015e-01,  1.14160366e-01,  8.57811868e-02, ...,\n",
       "            1.67628869e-01, -5.69726564e-02,  1.88954011e-01]],\n",
       " \n",
       "         [[-6.48908839e-02,  1.87336385e-01,  3.90957706e-02, ...,\n",
       "            1.71885550e-01, -7.95859918e-02,  6.33834451e-02],\n",
       "          [-6.82608932e-02, -2.99693178e-02,  1.95757300e-02, ...,\n",
       "           -1.43537596e-01, -6.75099567e-02, -1.68887768e-02],\n",
       "          [-1.08863994e-01, -3.68114188e-02, -4.30696004e-04, ...,\n",
       "            3.93225364e-02,  1.53512293e-02, -5.34826964e-02],\n",
       "          ...,\n",
       "          [-5.24846576e-02,  1.53261468e-01, -6.13483824e-02, ...,\n",
       "            1.24975689e-01,  1.25180930e-01, -1.90578997e-01],\n",
       "          [-1.22997381e-01, -5.40375523e-02, -9.25853774e-02, ...,\n",
       "            3.50588709e-02,  9.08745304e-02,  4.67393808e-02],\n",
       "          [-2.94311851e-01,  6.54384168e-03, -1.62849590e-01, ...,\n",
       "            8.18632022e-02, -4.49504480e-02,  9.24158320e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 2.19164249e-02,  4.91217412e-02, -9.92138982e-02, ...,\n",
       "           -1.97935514e-02,  1.83085017e-02,  3.41424197e-02],\n",
       "          [-1.06100693e-01, -1.48956150e-01, -5.66584319e-02, ...,\n",
       "           -1.50356516e-01,  9.20102838e-03,  1.37780681e-02],\n",
       "          [ 9.68283117e-02, -1.79202124e-01,  8.02438185e-02, ...,\n",
       "           -7.36843348e-02,  1.48655800e-02,  7.14064464e-02],\n",
       "          ...,\n",
       "          [ 1.42359272e-01,  2.17116363e-02,  4.62254472e-02, ...,\n",
       "            9.28677246e-02, -5.86159639e-02,  5.65729551e-02],\n",
       "          [-2.07132241e-03, -2.81894580e-02,  2.43069828e-02, ...,\n",
       "           -7.53914863e-02,  4.52851551e-03, -7.44212233e-03],\n",
       "          [ 3.14940922e-02,  4.57242280e-02, -2.17557147e-01, ...,\n",
       "            5.34533989e-03, -4.42017689e-02, -1.76341623e-01]],\n",
       " \n",
       "         [[-1.52747892e-02, -6.46082163e-02,  1.32424124e-02, ...,\n",
       "            1.27445102e-01, -1.26711261e-02,  9.66353118e-02],\n",
       "          [ 4.25204486e-02,  5.53363338e-02, -6.18228056e-02, ...,\n",
       "            6.76199868e-02, -2.95518264e-02, -6.15833560e-04],\n",
       "          [ 1.53338686e-01, -1.98566746e-02, -7.12193623e-02, ...,\n",
       "            4.56458842e-03, -4.90911640e-02,  1.52469277e-01],\n",
       "          ...,\n",
       "          [ 3.40885073e-02, -9.68842134e-02,  1.32823195e-02, ...,\n",
       "            8.54051784e-02, -1.55393407e-01,  1.95237532e-01],\n",
       "          [ 4.32340242e-02,  1.31969750e-02,  8.41848776e-02, ...,\n",
       "            5.42506799e-02, -1.09494455e-01,  1.08452858e-02],\n",
       "          [-3.49107720e-02, -1.41530573e-01,  3.08147296e-02, ...,\n",
       "           -2.03287695e-02, -7.97316339e-03, -1.11977890e-01]],\n",
       " \n",
       "         [[-4.66147363e-02, -5.33521585e-02,  1.84644982e-02, ...,\n",
       "            3.30467038e-02,  1.12951152e-01,  6.61059916e-02],\n",
       "          [-4.89927530e-02, -2.55017821e-02,  1.18395850e-01, ...,\n",
       "            3.65353115e-02,  4.39757667e-02, -1.35162368e-01],\n",
       "          [ 9.85282362e-02, -4.36811633e-02,  1.33361146e-02, ...,\n",
       "           -3.33548244e-03, -1.59671083e-01,  7.24749453e-03],\n",
       "          ...,\n",
       "          [ 7.55040348e-02,  3.18753836e-03, -1.34688243e-01, ...,\n",
       "            1.86188772e-01, -1.69629902e-01, -2.95565780e-02],\n",
       "          [ 1.22495145e-01, -3.55891511e-02, -8.55321065e-02, ...,\n",
       "           -1.65961329e-02,  4.52923439e-02, -2.24062074e-02],\n",
       "          [-1.26958832e-01,  8.53000209e-02,  1.26715619e-02, ...,\n",
       "            1.97646171e-02, -2.96844870e-01,  7.33179897e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 1.08059272e-01,  2.29272190e-02,  6.06113374e-02, ...,\n",
       "           -1.95133723e-02, -6.87417835e-02,  1.91032533e-02],\n",
       "          [-1.28564283e-01,  3.37348282e-02, -1.12042248e-01, ...,\n",
       "            1.21657655e-01,  1.32925197e-01, -1.12938918e-01],\n",
       "          [ 1.53309375e-01, -4.27940255e-03, -6.63349554e-02, ...,\n",
       "            2.63734348e-02, -7.41096288e-02,  1.01730220e-01],\n",
       "          ...,\n",
       "          [-9.69644114e-02, -1.36621535e-01,  3.00108567e-02, ...,\n",
       "            4.20766398e-02, -8.52784887e-02,  1.58039406e-02],\n",
       "          [-2.11806521e-02,  2.86419578e-02,  3.10323928e-02, ...,\n",
       "           -7.60800913e-02, -7.34725222e-02,  4.55829268e-03],\n",
       "          [-1.30716980e-01,  2.07840409e-02, -2.14693978e-01, ...,\n",
       "           -3.29882987e-02,  1.30880326e-01,  5.26149338e-03]],\n",
       " \n",
       "         [[ 1.00376695e-01, -8.38385224e-02,  1.24581382e-01, ...,\n",
       "           -2.74950508e-02,  1.35384515e-01, -1.58748645e-02],\n",
       "          [ 1.24597447e-02,  1.03994822e-02,  1.25526130e-01, ...,\n",
       "            1.64111435e-01,  7.08116442e-02, -5.47492951e-02],\n",
       "          [ 6.77518034e-03,  2.26604883e-02, -2.14189023e-01, ...,\n",
       "           -8.55717957e-02,  2.00041924e-02,  7.76232034e-02],\n",
       "          ...,\n",
       "          [ 3.76661564e-03,  2.58516401e-01,  4.11914885e-02, ...,\n",
       "            1.27946492e-02, -3.06912810e-02,  6.52179644e-02],\n",
       "          [ 1.20375827e-01, -5.39044738e-02, -3.64809819e-02, ...,\n",
       "            8.76671374e-02, -5.51014096e-02,  7.84277618e-02],\n",
       "          [-8.22667927e-02, -2.52401650e-01,  7.54678994e-02, ...,\n",
       "            1.17159083e-01,  1.65785387e-01, -1.03329167e-01]],\n",
       " \n",
       "         [[ 6.69237152e-02,  3.13501172e-02,  1.27039686e-01, ...,\n",
       "           -1.23788558e-01,  4.65179496e-02, -1.04997016e-01],\n",
       "          [-1.20622709e-01,  1.81384459e-01,  5.92189878e-02, ...,\n",
       "           -1.34452537e-01,  9.80787575e-02,  2.21752897e-02],\n",
       "          [-9.27823037e-02, -1.65402338e-01, -9.95945334e-02, ...,\n",
       "           -4.39178050e-02, -5.37907891e-02, -8.02375227e-02],\n",
       "          ...,\n",
       "          [ 1.33274347e-01,  1.95204213e-01, -1.02361038e-01, ...,\n",
       "            4.37158123e-02, -6.80128410e-02, -8.33389983e-02],\n",
       "          [-9.38085094e-02, -1.31227553e-01,  1.04904184e-02, ...,\n",
       "           -4.33301032e-02, -5.56164309e-02, -2.71393992e-02],\n",
       "          [-2.55309083e-02,  5.90749308e-02,  2.26631500e-02, ...,\n",
       "           -3.34835099e-03,  6.72693476e-02, -8.61058012e-02]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block5_conv1_5/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.06844036,  0.12202128,  0.13318741, -0.00111559,  0.10475322,\n",
       "         0.07616493, -0.05754535, -0.01820884,  0.12065089,  0.05862167,\n",
       "        -0.02793129, -0.04001398,  0.06942196,  0.0823991 ,  0.01241798,\n",
       "        -0.09080388,  0.09340974, -0.02433182,  0.07116289,  0.01995107,\n",
       "         0.06059568,  0.0799984 , -0.01303832,  0.06859729,  0.10744353,\n",
       "         0.0593851 ,  0.04613956,  0.0651754 ,  0.1145788 , -0.08530176,\n",
       "        -0.09342452,  0.10873015,  0.07596638,  0.06082336, -0.0421233 ,\n",
       "         0.04544921, -0.01086284,  0.00833722,  0.08717231, -0.04331323,\n",
       "         0.02818115, -0.07025676, -0.07385813,  0.14463803,  0.11868074,\n",
       "         0.00511398,  0.02949248, -0.08917712, -0.03781312, -0.05281513,\n",
       "         0.01861289,  0.10263848,  0.13380411,  0.10047051,  0.08131928,\n",
       "        -0.00178301, -0.00390034,  0.08560655, -0.02326689,  0.12126663,\n",
       "         0.04606064, -0.02516359,  0.06230117,  0.09268276], dtype=float32)>,\n",
       " <tf.Variable 'block5_conv2_5/kernel:0' shape=(3, 3, 64, 64) dtype=float32, numpy=\n",
       " array([[[[ 8.39991271e-02,  3.10012214e-02,  1.44256065e-02, ...,\n",
       "           -1.05192490e-01,  3.30535211e-02, -7.43487552e-02],\n",
       "          [-7.91806728e-02, -1.71584949e-01, -1.61964446e-01, ...,\n",
       "            6.00751601e-02,  7.39303157e-02, -2.44090706e-02],\n",
       "          [ 1.48496509e-01,  6.97362646e-02, -6.03377037e-02, ...,\n",
       "            2.94151027e-02, -6.88809082e-02, -6.62952363e-02],\n",
       "          ...,\n",
       "          [ 1.32083431e-01,  3.18644717e-02, -2.30912596e-01, ...,\n",
       "            5.64001463e-02,  4.22069207e-02, -1.12714339e-02],\n",
       "          [-3.82519066e-02,  6.17365018e-02, -9.67571512e-02, ...,\n",
       "           -3.94765362e-02, -4.50250600e-03,  6.17964640e-02],\n",
       "          [ 9.49449316e-02, -1.41169429e-01,  3.49056423e-02, ...,\n",
       "           -8.92701373e-02,  5.74437939e-02, -2.58490015e-02]],\n",
       " \n",
       "         [[ 1.38165057e-01, -2.58127297e-03, -7.36329518e-03, ...,\n",
       "           -6.20724410e-02,  2.48615677e-03,  2.21602693e-02],\n",
       "          [-6.00043535e-02,  2.62503102e-02, -9.41443369e-02, ...,\n",
       "           -7.69993896e-03, -3.41474041e-02, -1.02331705e-01],\n",
       "          [-6.41775876e-02,  3.67624275e-02, -4.64749150e-02, ...,\n",
       "            3.29811722e-02,  2.08149664e-02, -7.24878535e-02],\n",
       "          ...,\n",
       "          [-6.40846044e-02, -8.49263296e-02,  1.17369115e-01, ...,\n",
       "            6.79646730e-02, -1.35549918e-01, -5.33748306e-02],\n",
       "          [-8.51998925e-02,  1.26078531e-01, -1.81000009e-01, ...,\n",
       "            2.69210269e-03, -1.86355191e-03, -4.68660891e-02],\n",
       "          [ 1.36831462e-01,  2.65264176e-02, -9.33714435e-02, ...,\n",
       "           -9.34270024e-03, -2.56818738e-02, -8.41027051e-02]],\n",
       " \n",
       "         [[ 1.32656887e-01,  7.62952166e-03, -1.12332441e-01, ...,\n",
       "           -6.53155297e-02,  1.51689807e-02, -7.89234787e-02],\n",
       "          [-1.48801371e-01, -7.38176033e-02, -1.74497161e-02, ...,\n",
       "           -6.48431405e-02, -3.62357274e-02, -4.59308214e-02],\n",
       "          [-5.17070666e-02,  3.13462550e-03, -6.34741411e-02, ...,\n",
       "           -2.91296635e-02, -1.18379809e-01,  1.03411637e-03],\n",
       "          ...,\n",
       "          [ 7.29439929e-02, -8.11560601e-02, -1.67168915e-01, ...,\n",
       "           -2.28588544e-02,  4.65023844e-03, -4.60522395e-04],\n",
       "          [ 1.85762227e-01,  2.84732673e-02, -1.75318241e-01, ...,\n",
       "           -1.53886741e-02,  2.64092088e-02,  2.47238204e-02],\n",
       "          [ 7.29165748e-02,  1.07622854e-01,  1.63831692e-02, ...,\n",
       "           -4.35891598e-02,  3.33312973e-02,  5.17024379e-03]]],\n",
       " \n",
       " \n",
       "        [[[-7.19659925e-02, -1.48354098e-01,  1.08226098e-01, ...,\n",
       "           -4.07324992e-02, -5.49764819e-02, -6.44392148e-02],\n",
       "          [-3.37837380e-03, -8.24589282e-02,  1.84373781e-02, ...,\n",
       "           -3.54190916e-02,  2.70625502e-01,  4.05098274e-02],\n",
       "          [ 2.43703891e-02,  3.21572609e-02, -6.34710565e-02, ...,\n",
       "            8.62615407e-02,  4.17802297e-02,  2.06266996e-02],\n",
       "          ...,\n",
       "          [ 1.97550744e-01, -7.17860684e-02,  8.85106064e-03, ...,\n",
       "           -8.20083246e-02,  1.52231967e-02, -4.15319689e-02],\n",
       "          [-2.02958763e-01, -1.29473165e-01,  2.21404247e-02, ...,\n",
       "           -1.63401246e-01, -9.03101265e-02,  2.31231973e-02],\n",
       "          [-2.75619968e-04, -1.10510103e-02, -8.22041258e-02, ...,\n",
       "           -1.15598701e-01,  2.17722468e-02, -7.67439678e-02]],\n",
       " \n",
       "         [[ 2.31513325e-02, -3.40078175e-02,  3.16919237e-02, ...,\n",
       "           -2.57928520e-02, -6.47306293e-02, -6.92619756e-02],\n",
       "          [-2.12084427e-01,  8.46041664e-02,  1.17535912e-01, ...,\n",
       "            1.82039264e-04, -8.15721750e-02,  4.39710915e-03],\n",
       "          [ 9.26523358e-02,  5.18659689e-02,  8.55068266e-02, ...,\n",
       "            6.52475283e-02,  3.34932655e-02,  5.69623895e-03],\n",
       "          ...,\n",
       "          [-4.26297300e-02, -1.18491210e-01, -4.20704708e-02, ...,\n",
       "           -1.05184868e-01,  6.39015734e-02, -6.72445148e-02],\n",
       "          [-1.50559515e-01, -1.32668346e-01, -2.26792708e-01, ...,\n",
       "           -8.40608254e-02,  2.16540269e-04, -6.41680509e-02],\n",
       "          [ 8.25062394e-02, -1.03637785e-01, -1.63554296e-01, ...,\n",
       "           -1.06375985e-01,  4.71113548e-02,  1.61744282e-02]],\n",
       " \n",
       "         [[-2.77798381e-02, -1.26363918e-01, -1.09038884e-02, ...,\n",
       "           -2.75967214e-02,  2.55118273e-02,  2.17171814e-02],\n",
       "          [-1.89861327e-01,  1.05527654e-01, -7.87533587e-04, ...,\n",
       "           -1.69205088e-02, -1.14562318e-01, -9.80085060e-02],\n",
       "          [-4.53458950e-02, -2.88191419e-02, -9.26554129e-02, ...,\n",
       "            1.55861964e-02, -1.74510460e-02, -1.53170126e-02],\n",
       "          ...,\n",
       "          [-1.20901957e-01, -3.65074277e-02, -3.65285352e-02, ...,\n",
       "           -9.16436873e-03, -7.37318024e-02, -5.79523705e-02],\n",
       "          [-1.77108020e-01, -2.32480660e-01, -1.44343629e-01, ...,\n",
       "           -6.12378493e-02, -1.13585830e-01, -9.30101126e-02],\n",
       "          [-1.73632041e-01,  2.33576894e-02,  7.42809251e-02, ...,\n",
       "           -8.71827006e-02,  7.49493539e-02,  8.85337219e-03]]],\n",
       " \n",
       " \n",
       "        [[[-2.22317576e-01, -1.68324307e-01, -1.13304429e-01, ...,\n",
       "           -2.47307997e-02, -1.70622617e-02, -7.30349943e-02],\n",
       "          [-4.44993265e-02,  7.68276528e-02, -2.02886507e-01, ...,\n",
       "            5.64438291e-02,  8.97755846e-02, -2.78156158e-02],\n",
       "          [-1.21675961e-01, -1.13843001e-01, -4.91994992e-02, ...,\n",
       "           -6.40421659e-02,  1.09538874e-02, -1.70361772e-02],\n",
       "          ...,\n",
       "          [-1.59294814e-01,  3.80266905e-02,  1.20632984e-01, ...,\n",
       "            8.54775533e-02, -6.25158474e-02,  4.25175466e-02],\n",
       "          [-2.10948303e-01, -1.55440792e-01, -2.38493606e-02, ...,\n",
       "            2.44833268e-02, -1.73441738e-01, -2.12180968e-02],\n",
       "          [-2.18372285e-01, -2.21375227e-01, -1.00021273e-01, ...,\n",
       "           -2.45020892e-02, -2.05014616e-01, -7.22799152e-02]],\n",
       " \n",
       "         [[ 4.53936234e-02, -2.84880191e-01, -2.01937973e-01, ...,\n",
       "           -5.12169115e-02, -7.08845481e-02, -7.67267197e-02],\n",
       "          [ 7.11079687e-02, -4.01570983e-02,  3.21567478e-03, ...,\n",
       "            2.77464334e-02,  1.96964238e-02, -8.55331719e-02],\n",
       "          [-1.39143944e-01, -2.58304831e-02, -5.79896010e-02, ...,\n",
       "            7.60760810e-03, -3.37593816e-02, -8.90062377e-02],\n",
       "          ...,\n",
       "          [-1.01984084e-01, -6.77002519e-02,  1.10177159e-01, ...,\n",
       "            3.34659591e-02,  1.54414937e-01, -4.11182083e-02],\n",
       "          [ 5.21991961e-02, -1.87577441e-01,  5.32305799e-02, ...,\n",
       "           -1.74855534e-02, -1.92653731e-01,  1.77302007e-02],\n",
       "          [-1.01496570e-01, -2.16890380e-01, -1.27430484e-02, ...,\n",
       "           -1.08730510e-01,  4.91689406e-02,  2.01158095e-02]],\n",
       " \n",
       "         [[ 1.44522861e-01, -1.93107873e-01, -5.46528064e-02, ...,\n",
       "            2.34603342e-02, -7.05544800e-02,  2.58395523e-02],\n",
       "          [-3.86651941e-02, -8.51281658e-02,  1.00581512e-01, ...,\n",
       "           -1.53530939e-02, -1.75054789e-01,  4.30093296e-02],\n",
       "          [-7.71082565e-02, -1.27908766e-01, -1.00926764e-01, ...,\n",
       "            5.21198809e-02, -1.75738316e-02,  3.13514508e-02],\n",
       "          ...,\n",
       "          [-7.51990676e-02,  1.48483217e-01,  2.54833568e-02, ...,\n",
       "           -3.83650102e-02,  4.70336229e-02, -4.89060655e-02],\n",
       "          [-2.50075758e-01, -2.42279351e-01, -2.01936424e-01, ...,\n",
       "           -6.31616563e-02, -6.67587817e-02,  1.78037472e-02],\n",
       "          [-2.89124977e-02, -1.73570529e-01, -5.52048162e-02, ...,\n",
       "           -2.83180941e-02,  6.03405163e-02,  6.13432145e-03]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'block5_conv2_5/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([ 0.04833563,  0.01902541, -0.0097178 , -0.03660289,  0.05484023,\n",
       "         0.00303739,  0.03159845,  0.00031865,  0.05374857,  0.04234314,\n",
       "        -0.0452147 ,  0.00908362, -0.06667175, -0.01875144, -0.06520968,\n",
       "        -0.08009973, -0.07152793,  0.04260813, -0.06330973,  0.03229103,\n",
       "         0.03485864, -0.04166678,  0.0260757 ,  0.03421411,  0.0609133 ,\n",
       "         0.00624754, -0.05040986,  0.02398911, -0.00312695, -0.0484894 ,\n",
       "        -0.06347378,  0.02247854, -0.01271731,  0.02557621,  0.05186862,\n",
       "         0.01571165,  0.00600997,  0.03307549, -0.03303062,  0.01419235,\n",
       "         0.05634086,  0.04262258,  0.02668958,  0.01031903,  0.01546801,\n",
       "        -0.01114003, -0.06432333,  0.03233202,  0.02199768, -0.04504181,\n",
       "         0.01319461, -0.01340768, -0.01069657,  0.0690535 ,  0.01461165,\n",
       "         0.04250736, -0.01831801,  0.02066918, -0.08688655,  0.06075685,\n",
       "        -0.04194111, -0.10286658,  0.01283712, -0.04524435], dtype=float32)>,\n",
       " <tf.Variable 'fc1_5/kernel:0' shape=(64, 256) dtype=float32, numpy=\n",
       " array([[ 0.07069214,  0.10279189,  0.09561177, ..., -0.20955719,\n",
       "         -0.089341  , -0.05268101],\n",
       "        [ 0.03662322, -0.04316482, -0.09057292, ..., -0.05271154,\n",
       "         -0.16849107, -0.12724733],\n",
       "        [-0.09201699, -0.0503003 , -0.09098876, ..., -0.07729741,\n",
       "         -0.03973654,  0.0456062 ],\n",
       "        ...,\n",
       "        [ 0.06404644,  0.07151382, -0.08971206, ..., -0.09432997,\n",
       "         -0.01119044, -0.04004662],\n",
       "        [-0.03782225,  0.05746596, -0.0436299 , ..., -0.1858974 ,\n",
       "          0.01911189,  0.02742956],\n",
       "        [ 0.06593856,  0.06231039, -0.09669171, ..., -0.07956153,\n",
       "         -0.01782283,  0.06409889]], dtype=float32)>,\n",
       " <tf.Variable 'fc1_5/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([ 8.28788206e-02,  8.68825689e-02,  8.03254824e-03, -4.89517003e-02,\n",
       "        -1.19751878e-02, -4.86080833e-02, -5.18541336e-02, -3.14495377e-02,\n",
       "        -8.26664982e-05,  6.81923926e-02,  6.17469288e-02,  1.27412528e-02,\n",
       "         3.01273037e-02, -4.74238172e-02, -2.84945462e-02, -5.36975004e-02,\n",
       "         5.73479012e-02,  6.50558472e-02, -6.20304234e-02, -1.30186871e-01,\n",
       "         7.30341896e-02,  1.11576542e-01,  1.57636348e-02,  6.02369122e-02,\n",
       "        -3.04432623e-02, -4.25039511e-03, -2.32656859e-02, -2.08977591e-02,\n",
       "         6.21723235e-02, -5.73647150e-04,  1.09422199e-01, -1.94707457e-02,\n",
       "         4.53715175e-02,  3.42170484e-02,  5.55128045e-02, -3.81619856e-02,\n",
       "         5.25551438e-02, -3.19155604e-02, -4.91578579e-02, -4.13039364e-02,\n",
       "        -6.16163425e-02,  2.13157274e-02, -3.37658003e-02,  5.97953275e-02,\n",
       "        -7.36826658e-02, -7.15949759e-02, -1.39848948e-01, -3.78892086e-02,\n",
       "        -6.05852567e-02, -5.13969697e-02,  5.07991724e-02,  2.28858665e-02,\n",
       "         3.04313395e-02, -3.41023207e-02,  2.28330493e-02,  1.30477007e-02,\n",
       "         7.01798201e-02,  1.03298970e-01, -2.11831518e-02, -4.87955660e-02,\n",
       "         5.62269017e-02,  7.47195408e-02,  5.40600047e-02, -7.90041909e-02,\n",
       "        -5.08743897e-02, -3.06777209e-02,  1.25545546e-01, -1.56208463e-02,\n",
       "        -6.33292943e-02, -6.61090808e-03, -1.72771439e-02, -6.41588569e-02,\n",
       "         9.21586994e-03, -2.85474863e-02, -3.77743505e-02, -5.69215678e-02,\n",
       "        -4.89737503e-02, -2.30919737e-02, -9.05867293e-02, -3.74921076e-02,\n",
       "        -1.07867785e-01, -8.80079716e-03, -5.30735180e-02,  2.64696144e-02,\n",
       "         9.86593068e-02,  1.16259255e-01, -4.18830924e-02,  4.44772430e-02,\n",
       "        -3.09051741e-02, -5.39080985e-02, -3.21398638e-02,  6.85338005e-02,\n",
       "        -8.19350928e-02, -3.34181264e-02,  4.39880714e-02, -9.12349224e-02,\n",
       "         2.21665446e-02, -4.25140485e-02, -4.60537300e-02, -4.82524745e-02,\n",
       "        -8.92774900e-04, -4.19195332e-02, -6.18722849e-02, -2.52575707e-02,\n",
       "         4.08078730e-02,  1.01482600e-01,  1.33627117e-01,  1.18942680e-02,\n",
       "        -3.37257273e-02, -2.63506621e-02, -8.98676217e-02, -2.97052786e-02,\n",
       "         9.12608877e-02,  7.71801323e-02,  8.15187544e-02,  2.37460174e-02,\n",
       "        -5.44336624e-02, -3.55170742e-02, -3.29313762e-02, -4.63554822e-02,\n",
       "         4.91191149e-02,  9.37661305e-02, -1.70669276e-02,  2.98136771e-02,\n",
       "         1.32438242e-01,  7.98913017e-02, -8.29685032e-02,  4.71997261e-02,\n",
       "         4.55740839e-02,  3.02619077e-02,  2.70454194e-02, -4.08059508e-02,\n",
       "        -1.19861672e-02, -4.24104966e-02,  1.80598143e-02, -1.08373217e-01,\n",
       "         3.96656655e-02, -4.12442833e-02,  4.26145084e-02,  5.23680039e-02,\n",
       "         4.64029051e-02,  1.17920123e-01, -1.15144312e-01,  1.03111016e-02,\n",
       "        -2.58280188e-02, -2.03191284e-02,  1.35770246e-01, -2.39842981e-02,\n",
       "        -3.25263739e-02, -3.38866785e-02, -6.69279695e-02,  1.38910145e-01,\n",
       "         3.88169177e-02, -1.98014118e-02,  5.74708544e-02, -4.16466855e-02,\n",
       "        -6.91621155e-02, -8.37940723e-02,  1.14797540e-01,  1.06983937e-01,\n",
       "         6.49279281e-02,  1.49762938e-02,  2.73000225e-02, -5.63606583e-02,\n",
       "         4.29445133e-02,  3.16811614e-02, -7.02366084e-02, -3.00191361e-02,\n",
       "         2.02484410e-02, -4.69609722e-02, -5.69404811e-02,  2.54076533e-02,\n",
       "        -1.59531846e-04, -1.41074928e-02, -3.66887823e-02, -1.25354854e-02,\n",
       "         7.08744396e-03,  1.41335413e-01,  3.89159657e-02,  4.69227694e-02,\n",
       "         5.54393083e-02,  4.09530737e-02,  1.58318281e-01,  1.46181276e-02,\n",
       "         3.97590324e-02, -8.96509886e-02, -6.23888373e-02, -4.43029925e-02,\n",
       "        -5.96750751e-02,  1.89486053e-02, -9.25589204e-02,  8.46555755e-02,\n",
       "         9.34286937e-02,  1.35126188e-01,  5.79821952e-02, -3.46713178e-02,\n",
       "        -2.93823127e-02,  1.05855703e-01,  3.84701416e-02, -7.96554983e-03,\n",
       "        -2.82826312e-02,  9.81320441e-02,  5.77444136e-02,  6.68668076e-02,\n",
       "         5.18939309e-02,  8.55158735e-03,  1.24181986e-01, -5.45365661e-02,\n",
       "         7.51226544e-02,  8.35649893e-02, -1.83871150e-01, -5.35906926e-02,\n",
       "         3.49910855e-02, -4.28136587e-02, -3.11886538e-02,  7.46186227e-02,\n",
       "        -3.52538340e-02,  5.16950563e-02, -5.85346967e-02,  2.73838118e-02,\n",
       "        -5.59526868e-02, -5.35999276e-02, -4.98938300e-02, -5.17245084e-02,\n",
       "        -5.25094680e-02, -3.33259478e-02,  8.33795294e-02, -6.06743544e-02,\n",
       "        -5.20509891e-02,  3.48460190e-02, -7.02642500e-02,  1.14231303e-01,\n",
       "         4.62383367e-02, -2.87875459e-02, -6.22074455e-02,  6.35108724e-02,\n",
       "        -3.52543481e-02, -2.92655658e-02, -7.65061155e-02,  3.54033429e-03,\n",
       "         2.60988194e-02, -6.94250315e-02, -4.81047556e-02, -5.52064665e-02,\n",
       "        -4.04285006e-02,  3.58995236e-02,  4.96880896e-02,  4.93527763e-02,\n",
       "        -2.94653028e-02, -4.85821217e-02, -3.85394022e-02, -6.23168498e-02,\n",
       "        -1.56424399e-02,  3.50955874e-02, -6.63819313e-02, -4.49335165e-02],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'fc2_5/kernel:0' shape=(256, 256) dtype=float32, numpy=\n",
       " array([[ 0.01931372, -0.00984167, -0.00342725, ..., -0.00748804,\n",
       "         -0.01443158, -0.1111849 ],\n",
       "        [-0.05038111,  0.01310566, -0.08826889, ..., -0.03452643,\n",
       "         -0.00698121, -0.06134051],\n",
       "        [-0.16235949,  0.04704235, -0.0027264 , ..., -0.08385526,\n",
       "         -0.09677488, -0.07505317],\n",
       "        ...,\n",
       "        [ 0.03565689, -0.07427441, -0.06738909, ..., -0.02224106,\n",
       "          0.03840739, -0.02093414],\n",
       "        [-0.06548831, -0.09826227, -0.06895165, ...,  0.0823295 ,\n",
       "         -0.10130813, -0.0016003 ],\n",
       "        [-0.10333154, -0.10501353, -0.0580978 , ..., -0.05458231,\n",
       "         -0.08966853, -0.09266719]], dtype=float32)>,\n",
       " <tf.Variable 'fc2_5/bias:0' shape=(256,) dtype=float32, numpy=\n",
       " array([ 0.05895913, -0.02779339, -0.01976886, -0.04724228,  0.01305084,\n",
       "         0.0305156 , -0.00929467,  0.04311436,  0.03116013, -0.00573233,\n",
       "        -0.04181575, -0.02143247, -0.0188504 , -0.02111404,  0.03879433,\n",
       "        -0.01229763, -0.03099583, -0.02715852,  0.0486594 ,  0.0808512 ,\n",
       "         0.00896692, -0.04213478, -0.00781301, -0.00254161,  0.1463907 ,\n",
       "        -0.03565858,  0.05981351, -0.02584966, -0.0007228 , -0.05831547,\n",
       "        -0.02941498, -0.02824197,  0.11983524,  0.02664062, -0.04009929,\n",
       "        -0.00783476,  0.04963645, -0.01528842,  0.0478326 , -0.0134953 ,\n",
       "         0.12888706, -0.01811727, -0.01709266, -0.01457136, -0.03752155,\n",
       "        -0.06021181, -0.02502908, -0.03957277, -0.02365658,  0.10591578,\n",
       "         0.09498352, -0.05792508, -0.01256776, -0.04191877, -0.04614708,\n",
       "         0.13564359,  0.0870855 ,  0.03078983,  0.03812273,  0.00964855,\n",
       "        -0.04900805, -0.0245539 ,  0.08076884, -0.0487802 , -0.03378835,\n",
       "         0.06525247,  0.07249358, -0.01967487,  0.07027103, -0.05241357,\n",
       "         0.04781248,  0.04252461, -0.0557255 , -0.04870406,  0.06491909,\n",
       "         0.06311972, -0.07672671,  0.04771721,  0.03570491, -0.05779532,\n",
       "         0.01779498, -0.04618111, -0.0061896 , -0.03827334, -0.05871305,\n",
       "         0.10090016, -0.03118853,  0.13209644, -0.06275792, -0.03564685,\n",
       "        -0.06127625,  0.0792326 ,  0.01973343,  0.04607489, -0.0346159 ,\n",
       "        -0.03149668, -0.04396724, -0.02894499, -0.02934294,  0.03917453,\n",
       "         0.07325225,  0.08029121,  0.14649123, -0.02507075,  0.01988731,\n",
       "        -0.04349117, -0.03164277, -0.0379166 , -0.01703916, -0.04174495,\n",
       "         0.06718785,  0.03171106,  0.03701721, -0.01876126, -0.05116683,\n",
       "        -0.04765109, -0.03994196, -0.03183614, -0.01976189, -0.00754251,\n",
       "        -0.0057243 , -0.04484007, -0.03240825, -0.06147313,  0.03750576,\n",
       "        -0.00273983, -0.01949545, -0.03422199,  0.02895256,  0.08637679,\n",
       "         0.092658  ,  0.0748957 , -0.02705671, -0.00669392,  0.01820881,\n",
       "         0.10879094, -0.01620062, -0.00770599,  0.06195331,  0.04331865,\n",
       "        -0.02893431, -0.03321552, -0.01629892, -0.0398862 , -0.01332173,\n",
       "        -0.02335157, -0.02546032, -0.01695747, -0.02423359,  0.05680048,\n",
       "        -0.02204605,  0.05301993,  0.00518257, -0.01786379, -0.04807246,\n",
       "        -0.02657273,  0.0723579 , -0.04518852, -0.02510531, -0.03427509,\n",
       "        -0.02349798, -0.02944295,  0.01015837, -0.02661697,  0.06874099,\n",
       "         0.0636068 , -0.0402974 ,  0.06203619, -0.04130769,  0.13119328,\n",
       "        -0.02939007, -0.0315669 ,  0.10578115, -0.07342147, -0.02915514,\n",
       "        -0.03584109, -0.02417808,  0.10243616,  0.06256082, -0.05776143,\n",
       "        -0.04313724,  0.11821137, -0.08396898, -0.05209503, -0.02891733,\n",
       "         0.08459407,  0.08793247, -0.00776747, -0.01862298, -0.01190144,\n",
       "        -0.03942637,  0.03683021, -0.02037082, -0.04343601,  0.02099871,\n",
       "        -0.03130366, -0.04120322, -0.02384573,  0.0790379 ,  0.09389867,\n",
       "         0.06142478,  0.09201937, -0.07402811, -0.02233331, -0.03702921,\n",
       "        -0.05913922,  0.02982509,  0.04150581, -0.04834164, -0.07597917,\n",
       "         0.1269958 , -0.01002469, -0.03013436, -0.06340396,  0.03795933,\n",
       "        -0.05347465,  0.03334184, -0.04871894, -0.03508401,  0.1288556 ,\n",
       "        -0.0200703 , -0.01935642,  0.01715864, -0.00067777,  0.0652084 ,\n",
       "        -0.05053017, -0.02452551,  0.06316845, -0.0281817 , -0.01952763,\n",
       "        -0.06267615, -0.01852955, -0.00998187,  0.12475549,  0.02305214,\n",
       "         0.14180917, -0.01218488, -0.02215174,  0.05774098,  0.09790841,\n",
       "        -0.03840141, -0.01416123, -0.03349404,  0.03781391, -0.02783345,\n",
       "         0.13128853, -0.16100703, -0.03407029,  0.07011657, -0.04538962,\n",
       "        -0.04568501,  0.059204  ,  0.04098789, -0.02890509, -0.05293374,\n",
       "        -0.02005436], dtype=float32)>,\n",
       " <tf.Variable 'predictions_5/kernel:0' shape=(256, 7) dtype=float32, numpy=\n",
       " array([[ 0.04097796, -0.12156884,  0.02969803, ..., -0.07329755,\n",
       "          0.13681483,  0.06495682],\n",
       "        [ 0.06610833,  0.0423157 ,  0.06134136, ..., -0.09601277,\n",
       "          0.06980705,  0.05206184],\n",
       "        [-0.04949695,  0.03633466, -0.12520432, ..., -0.08874312,\n",
       "         -0.07905282, -0.04846567],\n",
       "        ...,\n",
       "        [-0.09958678,  0.0911008 ,  0.04792735, ..., -0.12614946,\n",
       "         -0.12562017, -0.14912626],\n",
       "        [-0.03261121,  0.08479261,  0.03733829, ...,  0.13276637,\n",
       "         -0.01969464,  0.02617289],\n",
       "        [-0.02396405,  0.07165615,  0.05038653, ..., -0.00266008,\n",
       "         -0.01457234, -0.01165967]], dtype=float32)>,\n",
       " <tf.Variable 'predictions_5/bias:0' shape=(7,) dtype=float32, numpy=\n",
       " array([ 0.0205108 , -0.10808344,  0.06517626,  0.02937478,  0.00707945,\n",
       "        -0.06593815, -0.00293964], dtype=float32)>]"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights # 참고. get_weights()와 weights는 다른 매서드임을 알자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3458772,
     "status": "ok",
     "timestamp": 1583368440009,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "GkesY8Rs9dZ4",
    "outputId": "d8f8a3c5-6b73-43c7-cf85-aea0f524ccb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형태는 이렇게 생김\n",
    "np.array(W).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsRCepsp9daJ"
   },
   "source": [
    "### 2) My VGG16 (Pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IN4KG4tE9daK"
   },
   "outputs": [],
   "source": [
    "def VGG16(input_shape=(48,48,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    # 데이터 size = 48로 하므로써, 전체를 maxpooling 하는 것으로 바꿈.\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n",
    "        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='vgg19')\n",
    "\n",
    "    # Load weights.\n",
    "    # 내 모형에서는 쓸모없다. 다만, 나중의 혹시모를 참고를 위해 코드는 남겨놓는다.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,cache_subdir='models',file_hash='cbe5617147190e668d6c5d5026f83318')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,cache_subdir='models',file_hash='253f8cb515780f3b799900260a226db6')\n",
    "\n",
    "        model.load_weights(weights_path) #경로에 있는 초기치 weights가져오기\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JNNWkMu9daM"
   },
   "outputs": [],
   "source": [
    "model = VGG16(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 840,
     "status": "ok",
     "timestamp": 1583368758709,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "zpjWzJHC9daN",
    "outputId": "43f28b1a-f27d-4a24-bfd4-0894fafc7b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 8)         584       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 314,799\n",
      "Trainable params: 314,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rr6H7kKq9daQ"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 484756,
     "status": "ok",
     "timestamp": 1583369245086,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "747u68c59daT",
    "outputId": "9086179b-e15d-4592-99b6-e672b0d049af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8073 - accuracy: 0.2494 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8556 - val_accuracy: 0.2602 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.7501 - accuracy: 0.2808 - macro_f1score: 0.0255 - weighted_f1score: 0.0035 - val_loss: 1.7189 - val_accuracy: 0.3433 - val_macro_f1score: 0.0719 - val_weighted_f1score: 0.0123\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.6152 - accuracy: 0.3518 - macro_f1score: 0.1143 - weighted_f1score: 0.0219 - val_loss: 1.5940 - val_accuracy: 0.3764 - val_macro_f1score: 0.1508 - val_weighted_f1score: 0.0284\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.5425 - accuracy: 0.3840 - macro_f1score: 0.1423 - weighted_f1score: 0.0271 - val_loss: 1.6018 - val_accuracy: 0.3990 - val_macro_f1score: 0.1717 - val_weighted_f1score: 0.0317\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.4969 - accuracy: 0.4029 - macro_f1score: 0.1569 - weighted_f1score: 0.0301 - val_loss: 1.5108 - val_accuracy: 0.4191 - val_macro_f1score: 0.1761 - val_weighted_f1score: 0.0328\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.4552 - accuracy: 0.4234 - macro_f1score: 0.1676 - weighted_f1score: 0.0318 - val_loss: 1.4587 - val_accuracy: 0.4508 - val_macro_f1score: 0.1920 - val_weighted_f1score: 0.0357\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.4163 - accuracy: 0.4416 - macro_f1score: 0.1827 - weighted_f1score: 0.0345 - val_loss: 1.4585 - val_accuracy: 0.4567 - val_macro_f1score: 0.1720 - val_weighted_f1score: 0.0336\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.3765 - accuracy: 0.4632 - macro_f1score: 0.2004 - weighted_f1score: 0.0379 - val_loss: 1.4372 - val_accuracy: 0.4427 - val_macro_f1score: 0.2012 - val_weighted_f1score: 0.0384\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.3351 - accuracy: 0.4811 - macro_f1score: 0.2269 - weighted_f1score: 0.0421 - val_loss: 1.3550 - val_accuracy: 0.5013 - val_macro_f1score: 0.2825 - val_weighted_f1score: 0.0517\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.3032 - accuracy: 0.4957 - macro_f1score: 0.2479 - weighted_f1score: 0.0454 - val_loss: 1.3312 - val_accuracy: 0.5110 - val_macro_f1score: 0.2530 - val_weighted_f1score: 0.0461\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.2872 - accuracy: 0.5045 - macro_f1score: 0.2565 - weighted_f1score: 0.0466 - val_loss: 1.3234 - val_accuracy: 0.5068 - val_macro_f1score: 0.2843 - val_weighted_f1score: 0.0505\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.2533 - accuracy: 0.5177 - macro_f1score: 0.2792 - weighted_f1score: 0.0505 - val_loss: 1.2810 - val_accuracy: 0.5219 - val_macro_f1score: 0.2974 - val_weighted_f1score: 0.0534\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.2477 - accuracy: 0.5253 - macro_f1score: 0.2880 - weighted_f1score: 0.0518 - val_loss: 1.2474 - val_accuracy: 0.5400 - val_macro_f1score: 0.3052 - val_weighted_f1score: 0.0552\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.2201 - accuracy: 0.5326 - macro_f1score: 0.3003 - weighted_f1score: 0.0540 - val_loss: 1.2749 - val_accuracy: 0.5358 - val_macro_f1score: 0.3503 - val_weighted_f1score: 0.0625\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.2138 - accuracy: 0.5357 - macro_f1score: 0.3115 - weighted_f1score: 0.0557 - val_loss: 1.2461 - val_accuracy: 0.5456 - val_macro_f1score: 0.3427 - val_weighted_f1score: 0.0617\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 28s 123ms/step - loss: 1.1917 - accuracy: 0.5422 - macro_f1score: 0.3194 - weighted_f1score: 0.0571 - val_loss: 1.2627 - val_accuracy: 0.5364 - val_macro_f1score: 0.3177 - val_weighted_f1score: 0.0573\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 28s 123ms/step - loss: 1.1840 - accuracy: 0.5451 - macro_f1score: 0.3242 - weighted_f1score: 0.0578 - val_loss: 1.2162 - val_accuracy: 0.5520 - val_macro_f1score: 0.3403 - val_weighted_f1score: 0.0609\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a5823bcc0>"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1324,
     "status": "ok",
     "timestamp": 1583369268372,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "6APhKqEc9daW",
    "outputId": "31756d6a-64a4-458f-c1d9-74a74410a4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 0s 130us/sample - loss: 1.1879 - accuracy: 0.5365 - macro_f1score: 0.3312 - weighted_f1score: 0.0585\n",
      "\n",
      "Accuracy: 0.5365, Macro F1 Score: 0.3312, Weighted F1 Score: 0.0585\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYDROEyk9dZ6"
   },
   "source": [
    "### 3) My VGG19 (Pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4MJXIS29dZ8"
   },
   "outputs": [],
   "source": [
    "def VGG19(input_shape=(48,48,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(3, 3), name='block5_pool')(x) \n",
    "    # 데이터 size = 48로 하므로써, 전체를 maxpooling 하는 것으로 바꿈.   \n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n",
    "        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='vgg19')\n",
    "\n",
    "    # Load weights.\n",
    "    # 내 모형에서는 쓸모없다. 다만, 나중의 혹시모를 참고를 위해 코드는 남겨놓는다.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,cache_subdir='models',file_hash='cbe5617147190e668d6c5d5026f83318')\n",
    "        else:\n",
    "            weights_path = get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,cache_subdir='models',file_hash='253f8cb515780f3b799900260a226db6')\n",
    "\n",
    "        model.load_weights(weights_path) #경로에 있는 초기치 weights가져오기\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rs7ILtE89dZ-"
   },
   "outputs": [],
   "source": [
    "#내 데이터 맞춤형 모형\n",
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "\n",
    "model = VGG19(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1583369299653,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "Dw5az0eE9daA",
    "outputId": "8afea280-34b9-47a2-fd01-23ef1936706d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 8)         584       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 16)        2320      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 397,903\n",
      "Trainable params: 397,903\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CIKZ3fOD9daC"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 296030,
     "status": "ok",
     "timestamp": 1583369757417,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "UNKIKOav9daD",
    "outputId": "07576500-8a1d-46b1-a86b-5dd75cf9cba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.6886 - accuracy: 0.3150 - macro_f1score: 0.0560 - weighted_f1score: 0.0086 - val_loss: 1.7725 - val_accuracy: 0.3112 - val_macro_f1score: 0.0905 - val_weighted_f1score: 0.0132\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.6353 - accuracy: 0.3437 - macro_f1score: 0.1049 - weighted_f1score: 0.0195 - val_loss: 1.6559 - val_accuracy: 0.3642 - val_macro_f1score: 0.1391 - val_weighted_f1score: 0.0258\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.5815 - accuracy: 0.3705 - macro_f1score: 0.1291 - weighted_f1score: 0.0245 - val_loss: 1.6197 - val_accuracy: 0.3823 - val_macro_f1score: 0.1340 - val_weighted_f1score: 0.0235\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.5352 - accuracy: 0.3977 - macro_f1score: 0.1446 - weighted_f1score: 0.0274 - val_loss: 1.5653 - val_accuracy: 0.4129 - val_macro_f1score: 0.1656 - val_weighted_f1score: 0.0294\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.5043 - accuracy: 0.4139 - macro_f1score: 0.1554 - weighted_f1score: 0.0292 - val_loss: 1.5654 - val_accuracy: 0.4157 - val_macro_f1score: 0.1917 - val_weighted_f1score: 0.0332\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.4720 - accuracy: 0.4321 - macro_f1score: 0.1728 - weighted_f1score: 0.0321 - val_loss: 1.5215 - val_accuracy: 0.4316 - val_macro_f1score: 0.1715 - val_weighted_f1score: 0.0305\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.4513 - accuracy: 0.4404 - macro_f1score: 0.1844 - weighted_f1score: 0.0344 - val_loss: 1.4845 - val_accuracy: 0.4553 - val_macro_f1score: 0.2237 - val_weighted_f1score: 0.0399\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.4233 - accuracy: 0.4554 - macro_f1score: 0.1995 - weighted_f1score: 0.0369 - val_loss: 1.4807 - val_accuracy: 0.4628 - val_macro_f1score: 0.1951 - val_weighted_f1score: 0.0356\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.4060 - accuracy: 0.4613 - macro_f1score: 0.2102 - weighted_f1score: 0.0387 - val_loss: 1.4238 - val_accuracy: 0.4773 - val_macro_f1score: 0.2027 - val_weighted_f1score: 0.0370\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.3938 - accuracy: 0.4681 - macro_f1score: 0.2197 - weighted_f1score: 0.0404 - val_loss: 1.4124 - val_accuracy: 0.4909 - val_macro_f1score: 0.2222 - val_weighted_f1score: 0.0407\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a0e55c358>"
      ]
     },
     "execution_count": 100,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1430,
     "status": "ok",
     "timestamp": 1583369758884,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "JTSsbR589daF",
    "outputId": "0062b6cc-fd32-42b5-f1b4-d9f8949c9251",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 1s 141us/sample - loss: 1.3594 - accuracy: 0.4746 - macro_f1score: 0.2274 - weighted_f1score: 0.0419\n",
      "\n",
      "Accuracy: 0.4746, Macro F1 Score: 0.2274, Weighted F1 Score: 0.0419\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cm8zjN7R9daY"
   },
   "source": [
    "### 4) My VGG11 (Convergence Speed Comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CnrhqbNJ9daY"
   },
   "outputs": [],
   "source": [
    "# Vgg11에서, pretraining 된 fc층을 가지고 VGG 11을 재학습 시킬때, 얼마나 적은 epoch만에 수렴하는지를 보기 위해 만들었다.\n",
    "\n",
    "def VGG11_init(input_shape=(48,48,3), classes=7,include_top=True,pooling=None, weights = None):\n",
    "\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # Block 1\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "    # 데이터 size = 48로 하므로써, 전체를 maxpooling 하는 것으로 바꿈.\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-6]), bias_initializer= tf.constant_initializer(W[-5]) , name='fc1')(x) # 초기값은     tf.constant_initializer     로 한다!!\n",
    "        x = Dense(256, activation='relu', kernel_initializer= tf.constant_initializer(W[-4]), bias_initializer= tf.constant_initializer(W[-3]) , name='fc2')(x)\n",
    "        output = Dense(classes, kernel_initializer=tf.constant_initializer(W[-2]) , bias_initializer= tf.constant_initializer(W[-1]) , activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            output = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            output = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(img_input, output, name='Vgg11_Pretrained')\n",
    "\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DeEmMW3B9daa"
   },
   "outputs": [],
   "source": [
    "model = VGG11_init(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1751,
     "status": "ok",
     "timestamp": 1583369759248,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "StXQvzKw9dae",
    "outputId": "f7dd2b22-b910-4d9b-cdf3-b65e45c0e955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Vgg11_Pretrained\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 8)         224       \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 8)         0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 16)        1168      \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 228,791\n",
      "Trainable params: 228,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1tP60Sp9daf"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_macro_f1score',patience = 3 , verbose=1,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 656832,
     "status": "ok",
     "timestamp": 1583370414354,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "iQgecNQi9dah",
    "outputId": "4ecbf0b7-87d9-458a-d9ad-1966256a4efe",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.7723 - accuracy: 0.2641 - macro_f1score: 0.0057 - weighted_f1score: 6.8730e-04 - val_loss: 1.7416 - val_accuracy: 0.3263 - val_macro_f1score: 0.0240 - val_weighted_f1score: 0.0030\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.6160 - accuracy: 0.3587 - macro_f1score: 0.1034 - weighted_f1score: 0.0198 - val_loss: 1.6015 - val_accuracy: 0.3948 - val_macro_f1score: 0.1127 - val_weighted_f1score: 0.0215\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.5221 - accuracy: 0.4020 - macro_f1score: 0.1432 - weighted_f1score: 0.0279 - val_loss: 1.4894 - val_accuracy: 0.4352 - val_macro_f1score: 0.1604 - val_weighted_f1score: 0.0310\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.4647 - accuracy: 0.4312 - macro_f1score: 0.1679 - weighted_f1score: 0.0321 - val_loss: 1.4822 - val_accuracy: 0.4355 - val_macro_f1score: 0.1791 - val_weighted_f1score: 0.0341\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.4223 - accuracy: 0.4479 - macro_f1score: 0.1891 - weighted_f1score: 0.0358 - val_loss: 1.4065 - val_accuracy: 0.4742 - val_macro_f1score: 0.2122 - val_weighted_f1score: 0.0398\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.3826 - accuracy: 0.4680 - macro_f1score: 0.2079 - weighted_f1score: 0.0387 - val_loss: 1.4008 - val_accuracy: 0.4840 - val_macro_f1score: 0.2662 - val_weighted_f1score: 0.0488\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.3550 - accuracy: 0.4775 - macro_f1score: 0.2249 - weighted_f1score: 0.0416 - val_loss: 1.3792 - val_accuracy: 0.4778 - val_macro_f1score: 0.2365 - val_weighted_f1score: 0.0433\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.3200 - accuracy: 0.4879 - macro_f1score: 0.2469 - weighted_f1score: 0.0452 - val_loss: 1.3529 - val_accuracy: 0.4843 - val_macro_f1score: 0.2432 - val_weighted_f1score: 0.0436\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.3008 - accuracy: 0.4996 - macro_f1score: 0.2565 - weighted_f1score: 0.0466 - val_loss: 1.3422 - val_accuracy: 0.4921 - val_macro_f1score: 0.2797 - val_weighted_f1score: 0.0503\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.2830 - accuracy: 0.5102 - macro_f1score: 0.2728 - weighted_f1score: 0.0493 - val_loss: 1.3120 - val_accuracy: 0.5116 - val_macro_f1score: 0.2959 - val_weighted_f1score: 0.0546\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.2596 - accuracy: 0.5136 - macro_f1score: 0.2836 - weighted_f1score: 0.0511 - val_loss: 1.3331 - val_accuracy: 0.5029 - val_macro_f1score: 0.2829 - val_weighted_f1score: 0.0515\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.2450 - accuracy: 0.5188 - macro_f1score: 0.2971 - weighted_f1score: 0.0532 - val_loss: 1.2684 - val_accuracy: 0.5261 - val_macro_f1score: 0.3216 - val_weighted_f1score: 0.0581\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.2248 - accuracy: 0.5287 - macro_f1score: 0.3089 - weighted_f1score: 0.0551 - val_loss: 1.2567 - val_accuracy: 0.5213 - val_macro_f1score: 0.3158 - val_weighted_f1score: 0.0564\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.2147 - accuracy: 0.5356 - macro_f1score: 0.3182 - weighted_f1score: 0.0564 - val_loss: 1.2406 - val_accuracy: 0.5414 - val_macro_f1score: 0.3238 - val_weighted_f1score: 0.0577\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.1959 - accuracy: 0.5438 - macro_f1score: 0.3357 - weighted_f1score: 0.0592 - val_loss: 1.2331 - val_accuracy: 0.5433 - val_macro_f1score: 0.3411 - val_weighted_f1score: 0.0602\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.1851 - accuracy: 0.5454 - macro_f1score: 0.3403 - weighted_f1score: 0.0599 - val_loss: 1.2377 - val_accuracy: 0.5478 - val_macro_f1score: 0.3505 - val_weighted_f1score: 0.0628\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.1783 - accuracy: 0.5507 - macro_f1score: 0.3445 - weighted_f1score: 0.0608 - val_loss: 1.2429 - val_accuracy: 0.5456 - val_macro_f1score: 0.3349 - val_weighted_f1score: 0.0593\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.1675 - accuracy: 0.5526 - macro_f1score: 0.3513 - weighted_f1score: 0.0615 - val_loss: 1.1995 - val_accuracy: 0.5589 - val_macro_f1score: 0.3611 - val_weighted_f1score: 0.0640\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.1646 - accuracy: 0.5536 - macro_f1score: 0.3544 - weighted_f1score: 0.0620 - val_loss: 1.2193 - val_accuracy: 0.5525 - val_macro_f1score: 0.3518 - val_weighted_f1score: 0.0615\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.1531 - accuracy: 0.5589 - macro_f1score: 0.3634 - weighted_f1score: 0.0634 - val_loss: 1.1959 - val_accuracy: 0.5531 - val_macro_f1score: 0.3882 - val_weighted_f1score: 0.0665\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.1495 - accuracy: 0.5619 - macro_f1score: 0.3663 - weighted_f1score: 0.0638 - val_loss: 1.2222 - val_accuracy: 0.5517 - val_macro_f1score: 0.3447 - val_weighted_f1score: 0.0616\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.1337 - accuracy: 0.5683 - macro_f1score: 0.3745 - weighted_f1score: 0.0651 - val_loss: 1.1959 - val_accuracy: 0.5595 - val_macro_f1score: 0.3428 - val_weighted_f1score: 0.0604\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.1223 - accuracy: 0.5688 - macro_f1score: 0.3850 - weighted_f1score: 0.0662 - val_loss: 1.1798 - val_accuracy: 0.5690 - val_macro_f1score: 0.3839 - val_weighted_f1score: 0.0667\n",
      "Epoch 00023: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a40719eb8>"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=100, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 657372,
     "status": "ok",
     "timestamp": 1583370414914,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "6WQ2xRya9dai",
    "outputId": "2ef660e0-f135-4bcc-d0b2-2ea912e2a679",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 0s 124us/sample - loss: 1.1556 - accuracy: 0.5641 - macro_f1score: 0.3822 - weighted_f1score: 0.0652\n",
      "\n",
      "Accuracy: 0.5641, Macro F1 Score: 0.3822, Weighted F1 Score: 0.0652\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vj3Miwl5AlIr"
   },
   "source": [
    "## 4. For Size = 48, No Early Stopping\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w6q4HsR4AlIt"
   },
   "source": [
    "### 1) Epoch = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1HxFpteAlIu"
   },
   "source": [
    "#### (1) My VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f88pcY-ZPQF4"
   },
   "outputs": [],
   "source": [
    "############# 이 아래는 early stopping 없이 진행 #######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mi5rUPHuPP3m"
   },
   "outputs": [],
   "source": [
    "# VGG 11 - pretraining\n",
    "model = VGG11(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jiNbdhBPP2P"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2085284,
     "status": "ok",
     "timestamp": 1583371842867,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "f9FQD_KpPPz5",
    "outputId": "9ab47493-a975-466e-94f4-1310a7899df9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8179 - accuracy: 0.2487 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8694 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.7497 - accuracy: 0.2820 - macro_f1score: 0.0292 - weighted_f1score: 0.0058 - val_loss: 1.6380 - val_accuracy: 0.3831 - val_macro_f1score: 0.1331 - val_weighted_f1score: 0.0248\n",
      "Epoch 3/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.5519 - accuracy: 0.3819 - macro_f1score: 0.1420 - weighted_f1score: 0.0275 - val_loss: 1.5473 - val_accuracy: 0.4107 - val_macro_f1score: 0.1544 - val_weighted_f1score: 0.0303\n",
      "Epoch 4/50\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.4762 - accuracy: 0.4204 - macro_f1score: 0.1672 - weighted_f1score: 0.0320 - val_loss: 1.4923 - val_accuracy: 0.4191 - val_macro_f1score: 0.1716 - val_weighted_f1score: 0.0327\n",
      "Epoch 5/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.4305 - accuracy: 0.4369 - macro_f1score: 0.1828 - weighted_f1score: 0.0348 - val_loss: 1.4321 - val_accuracy: 0.4572 - val_macro_f1score: 0.2245 - val_weighted_f1score: 0.0413\n",
      "Epoch 6/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.3894 - accuracy: 0.4579 - macro_f1score: 0.2040 - weighted_f1score: 0.0382 - val_loss: 1.3810 - val_accuracy: 0.4854 - val_macro_f1score: 0.2163 - val_weighted_f1score: 0.0402\n",
      "Epoch 7/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.3505 - accuracy: 0.4744 - macro_f1score: 0.2220 - weighted_f1score: 0.0412 - val_loss: 1.3612 - val_accuracy: 0.4932 - val_macro_f1score: 0.2637 - val_weighted_f1score: 0.0482\n",
      "Epoch 8/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.3083 - accuracy: 0.4916 - macro_f1score: 0.2458 - weighted_f1score: 0.0451 - val_loss: 1.3911 - val_accuracy: 0.4781 - val_macro_f1score: 0.2184 - val_weighted_f1score: 0.0411\n",
      "Epoch 9/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.2811 - accuracy: 0.5043 - macro_f1score: 0.2667 - weighted_f1score: 0.0485 - val_loss: 1.2973 - val_accuracy: 0.5174 - val_macro_f1score: 0.2722 - val_weighted_f1score: 0.0491\n",
      "Epoch 10/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.2644 - accuracy: 0.5099 - macro_f1score: 0.2738 - weighted_f1score: 0.0496 - val_loss: 1.2673 - val_accuracy: 0.5258 - val_macro_f1score: 0.2967 - val_weighted_f1score: 0.0530\n",
      "Epoch 11/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.2398 - accuracy: 0.5248 - macro_f1score: 0.2979 - weighted_f1score: 0.0533 - val_loss: 1.2736 - val_accuracy: 0.5311 - val_macro_f1score: 0.3118 - val_weighted_f1score: 0.0555\n",
      "Epoch 12/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.2180 - accuracy: 0.5320 - macro_f1score: 0.3114 - weighted_f1score: 0.0558 - val_loss: 1.2752 - val_accuracy: 0.5244 - val_macro_f1score: 0.3182 - val_weighted_f1score: 0.0563\n",
      "Epoch 13/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.2057 - accuracy: 0.5405 - macro_f1score: 0.3220 - weighted_f1score: 0.0574 - val_loss: 1.2063 - val_accuracy: 0.5481 - val_macro_f1score: 0.3336 - val_weighted_f1score: 0.0601\n",
      "Epoch 14/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.1920 - accuracy: 0.5445 - macro_f1score: 0.3294 - weighted_f1score: 0.0585 - val_loss: 1.2206 - val_accuracy: 0.5414 - val_macro_f1score: 0.3548 - val_weighted_f1score: 0.0626\n",
      "Epoch 15/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.1798 - accuracy: 0.5489 - macro_f1score: 0.3409 - weighted_f1score: 0.0602 - val_loss: 1.2056 - val_accuracy: 0.5383 - val_macro_f1score: 0.3466 - val_weighted_f1score: 0.0622\n",
      "Epoch 16/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.1658 - accuracy: 0.5538 - macro_f1score: 0.3471 - weighted_f1score: 0.0612 - val_loss: 1.2086 - val_accuracy: 0.5531 - val_macro_f1score: 0.3817 - val_weighted_f1score: 0.0660\n",
      "Epoch 17/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.1600 - accuracy: 0.5581 - macro_f1score: 0.3572 - weighted_f1score: 0.0627 - val_loss: 1.1918 - val_accuracy: 0.5626 - val_macro_f1score: 0.3766 - val_weighted_f1score: 0.0656\n",
      "Epoch 18/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.1433 - accuracy: 0.5648 - macro_f1score: 0.3696 - weighted_f1score: 0.0644 - val_loss: 1.1932 - val_accuracy: 0.5645 - val_macro_f1score: 0.3951 - val_weighted_f1score: 0.0675\n",
      "Epoch 19/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.1432 - accuracy: 0.5637 - macro_f1score: 0.3697 - weighted_f1score: 0.0643 - val_loss: 1.2170 - val_accuracy: 0.5483 - val_macro_f1score: 0.3579 - val_weighted_f1score: 0.0628\n",
      "Epoch 20/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.1359 - accuracy: 0.5660 - macro_f1score: 0.3720 - weighted_f1score: 0.0648 - val_loss: 1.1736 - val_accuracy: 0.5678 - val_macro_f1score: 0.3824 - val_weighted_f1score: 0.0679\n",
      "Epoch 21/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.1264 - accuracy: 0.5704 - macro_f1score: 0.3806 - weighted_f1score: 0.0663 - val_loss: 1.1892 - val_accuracy: 0.5673 - val_macro_f1score: 0.3704 - val_weighted_f1score: 0.0646\n",
      "Epoch 22/50\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 1.1138 - accuracy: 0.5775 - macro_f1score: 0.3856 - weighted_f1score: 0.0665 - val_loss: 1.1722 - val_accuracy: 0.5770 - val_macro_f1score: 0.3854 - val_weighted_f1score: 0.0674\n",
      "Epoch 23/50\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.1102 - accuracy: 0.5759 - macro_f1score: 0.3912 - weighted_f1score: 0.0674 - val_loss: 1.2066 - val_accuracy: 0.5628 - val_macro_f1score: 0.3933 - val_weighted_f1score: 0.0689\n",
      "Epoch 24/50\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.1083 - accuracy: 0.5809 - macro_f1score: 0.3981 - weighted_f1score: 0.0680 - val_loss: 1.1707 - val_accuracy: 0.5706 - val_macro_f1score: 0.3932 - val_weighted_f1score: 0.0683\n",
      "Epoch 25/50\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.1031 - accuracy: 0.5815 - macro_f1score: 0.3982 - weighted_f1score: 0.0681 - val_loss: 1.1724 - val_accuracy: 0.5670 - val_macro_f1score: 0.4007 - val_weighted_f1score: 0.0670\n",
      "Epoch 26/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.1017 - accuracy: 0.5852 - macro_f1score: 0.4017 - weighted_f1score: 0.0686 - val_loss: 1.1701 - val_accuracy: 0.5795 - val_macro_f1score: 0.3904 - val_weighted_f1score: 0.0680\n",
      "Epoch 27/50\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.0895 - accuracy: 0.5850 - macro_f1score: 0.4042 - weighted_f1score: 0.0694 - val_loss: 1.1700 - val_accuracy: 0.5743 - val_macro_f1score: 0.4022 - val_weighted_f1score: 0.0703\n",
      "Epoch 28/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.0878 - accuracy: 0.5867 - macro_f1score: 0.4127 - weighted_f1score: 0.0697 - val_loss: 1.1476 - val_accuracy: 0.5759 - val_macro_f1score: 0.4027 - val_weighted_f1score: 0.0681\n",
      "Epoch 29/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.0733 - accuracy: 0.5912 - macro_f1score: 0.4178 - weighted_f1score: 0.0710 - val_loss: 1.1507 - val_accuracy: 0.5673 - val_macro_f1score: 0.4207 - val_weighted_f1score: 0.0715\n",
      "Epoch 30/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.0737 - accuracy: 0.5885 - macro_f1score: 0.4154 - weighted_f1score: 0.0710 - val_loss: 1.1541 - val_accuracy: 0.5807 - val_macro_f1score: 0.4183 - val_weighted_f1score: 0.0708\n",
      "Epoch 31/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.0700 - accuracy: 0.5942 - macro_f1score: 0.4272 - weighted_f1score: 0.0718 - val_loss: 1.1510 - val_accuracy: 0.5756 - val_macro_f1score: 0.4333 - val_weighted_f1score: 0.0721\n",
      "Epoch 32/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.0624 - accuracy: 0.5966 - macro_f1score: 0.4332 - weighted_f1score: 0.0727 - val_loss: 1.1507 - val_accuracy: 0.5795 - val_macro_f1score: 0.4263 - val_weighted_f1score: 0.0736\n",
      "Epoch 33/50\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 1.0573 - accuracy: 0.5991 - macro_f1score: 0.4364 - weighted_f1score: 0.0731 - val_loss: 1.1371 - val_accuracy: 0.5913 - val_macro_f1score: 0.4364 - val_weighted_f1score: 0.0737\n",
      "Epoch 34/50\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 1.0592 - accuracy: 0.5973 - macro_f1score: 0.4410 - weighted_f1score: 0.0733 - val_loss: 1.1131 - val_accuracy: 0.5929 - val_macro_f1score: 0.4348 - val_weighted_f1score: 0.0723\n",
      "Epoch 35/50\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.0594 - accuracy: 0.5958 - macro_f1score: 0.4353 - weighted_f1score: 0.0727 - val_loss: 1.1308 - val_accuracy: 0.5843 - val_macro_f1score: 0.4357 - val_weighted_f1score: 0.0753\n",
      "Epoch 36/50\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.0497 - accuracy: 0.6007 - macro_f1score: 0.4414 - weighted_f1score: 0.0735 - val_loss: 1.1568 - val_accuracy: 0.5706 - val_macro_f1score: 0.4104 - val_weighted_f1score: 0.0717\n",
      "Epoch 37/50\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.0438 - accuracy: 0.6007 - macro_f1score: 0.4464 - weighted_f1score: 0.0738 - val_loss: 1.1372 - val_accuracy: 0.5848 - val_macro_f1score: 0.4468 - val_weighted_f1score: 0.0747\n",
      "Epoch 38/50\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.0413 - accuracy: 0.6032 - macro_f1score: 0.4460 - weighted_f1score: 0.0739 - val_loss: 1.1111 - val_accuracy: 0.5904 - val_macro_f1score: 0.4130 - val_weighted_f1score: 0.0717\n",
      "Epoch 39/50\n",
      "225/224 [==============================] - 28s 122ms/step - loss: 1.0409 - accuracy: 0.6022 - macro_f1score: 0.4463 - weighted_f1score: 0.0738 - val_loss: 1.1151 - val_accuracy: 0.5862 - val_macro_f1score: 0.4413 - val_weighted_f1score: 0.0735\n",
      "Epoch 40/50\n",
      "225/224 [==============================] - 28s 123ms/step - loss: 1.0326 - accuracy: 0.6070 - macro_f1score: 0.4483 - weighted_f1score: 0.0746 - val_loss: 1.1230 - val_accuracy: 0.5868 - val_macro_f1score: 0.4511 - val_weighted_f1score: 0.0759\n",
      "Epoch 41/50\n",
      "225/224 [==============================] - 27s 122ms/step - loss: 1.0263 - accuracy: 0.6078 - macro_f1score: 0.4573 - weighted_f1score: 0.0756 - val_loss: 1.1267 - val_accuracy: 0.5846 - val_macro_f1score: 0.4478 - val_weighted_f1score: 0.0732\n",
      "Epoch 42/50\n",
      "225/224 [==============================] - 28s 123ms/step - loss: 1.0241 - accuracy: 0.6084 - macro_f1score: 0.4577 - weighted_f1score: 0.0759 - val_loss: 1.1106 - val_accuracy: 0.5929 - val_macro_f1score: 0.4396 - val_weighted_f1score: 0.0741\n",
      "Epoch 43/50\n",
      "225/224 [==============================] - 28s 122ms/step - loss: 1.0261 - accuracy: 0.6102 - macro_f1score: 0.4562 - weighted_f1score: 0.0753 - val_loss: 1.1181 - val_accuracy: 0.5846 - val_macro_f1score: 0.4306 - val_weighted_f1score: 0.0728\n",
      "Epoch 44/50\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.0226 - accuracy: 0.6123 - macro_f1score: 0.4623 - weighted_f1score: 0.0757 - val_loss: 1.1240 - val_accuracy: 0.5954 - val_macro_f1score: 0.4607 - val_weighted_f1score: 0.0764\n",
      "Epoch 45/50\n",
      "225/224 [==============================] - 28s 123ms/step - loss: 1.0162 - accuracy: 0.6137 - macro_f1score: 0.4680 - weighted_f1score: 0.0766 - val_loss: 1.1106 - val_accuracy: 0.5890 - val_macro_f1score: 0.4515 - val_weighted_f1score: 0.0739\n",
      "Epoch 46/50\n",
      "225/224 [==============================] - 28s 123ms/step - loss: 1.0227 - accuracy: 0.6120 - macro_f1score: 0.4615 - weighted_f1score: 0.0761 - val_loss: 1.0833 - val_accuracy: 0.5982 - val_macro_f1score: 0.4568 - val_weighted_f1score: 0.0756\n",
      "Epoch 47/50\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.0114 - accuracy: 0.6159 - macro_f1score: 0.4712 - weighted_f1score: 0.0770 - val_loss: 1.1080 - val_accuracy: 0.5949 - val_macro_f1score: 0.4700 - val_weighted_f1score: 0.0773\n",
      "Epoch 48/50\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.0160 - accuracy: 0.6126 - macro_f1score: 0.4730 - weighted_f1score: 0.0768 - val_loss: 1.1313 - val_accuracy: 0.5832 - val_macro_f1score: 0.4296 - val_weighted_f1score: 0.0740\n",
      "Epoch 49/50\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 1.0119 - accuracy: 0.6173 - macro_f1score: 0.4712 - weighted_f1score: 0.0772 - val_loss: 1.0912 - val_accuracy: 0.5999 - val_macro_f1score: 0.4664 - val_weighted_f1score: 0.0754\n",
      "Epoch 50/50\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 1.0066 - accuracy: 0.6170 - macro_f1score: 0.4683 - weighted_f1score: 0.0771 - val_loss: 1.0973 - val_accuracy: 0.5921 - val_macro_f1score: 0.4471 - val_weighted_f1score: 0.0745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3a40371940>"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2085832,
     "status": "ok",
     "timestamp": 1583371843426,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "aK3qCrYTPPxc",
    "outputId": "40bde7f8-7ffe-4964-8f59-ed442520de9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 0s 117us/sample - loss: 1.1078 - accuracy: 0.5856 - macro_f1score: 0.4504 - weighted_f1score: 0.0723\n",
      "\n",
      "Accuracy: 0.5856, Macro F1 Score: 0.4504, Weighted F1 Score: 0.0723\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNS7IeCJPPvo"
   },
   "outputs": [],
   "source": [
    "# 한층당 W 와 b , 2개씩 있으므로 11개층이라면 22개의 모수 벡터 및 행렬이 출력된다.\n",
    "W = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-D539YqnAlI1"
   },
   "source": [
    "#### (2) My VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVBGw5RmP17c"
   },
   "outputs": [],
   "source": [
    "# VGG 16 - pretrained\n",
    "\n",
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "\n",
    "model = VGG16(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02ilMM8ZQAwX"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3556809,
     "status": "ok",
     "timestamp": 1583373314446,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "HPKzJ7vKQAuy",
    "outputId": "7da633e1-85b5-48da-d99c-2ce326e93eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/50\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8002 - accuracy: 0.2494 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8273 - val_accuracy: 0.2666 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.7181 - accuracy: 0.2959 - macro_f1score: 0.0302 - weighted_f1score: 0.0040 - val_loss: 1.6887 - val_accuracy: 0.3566 - val_macro_f1score: 0.0798 - val_weighted_f1score: 0.0144\n",
      "Epoch 3/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.5853 - accuracy: 0.3725 - macro_f1score: 0.1236 - weighted_f1score: 0.0235 - val_loss: 1.5754 - val_accuracy: 0.4107 - val_macro_f1score: 0.1649 - val_weighted_f1score: 0.0307\n",
      "Epoch 4/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.4993 - accuracy: 0.4146 - macro_f1score: 0.1545 - weighted_f1score: 0.0296 - val_loss: 1.5202 - val_accuracy: 0.4394 - val_macro_f1score: 0.1881 - val_weighted_f1score: 0.0355\n",
      "Epoch 5/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.4455 - accuracy: 0.4346 - macro_f1score: 0.1722 - weighted_f1score: 0.0327 - val_loss: 1.4505 - val_accuracy: 0.4539 - val_macro_f1score: 0.1939 - val_weighted_f1score: 0.0358\n",
      "Epoch 6/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.4023 - accuracy: 0.4502 - macro_f1score: 0.1910 - weighted_f1score: 0.0360 - val_loss: 1.4661 - val_accuracy: 0.4416 - val_macro_f1score: 0.2069 - val_weighted_f1score: 0.0389\n",
      "Epoch 7/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.3685 - accuracy: 0.4641 - macro_f1score: 0.2088 - weighted_f1score: 0.0391 - val_loss: 1.3974 - val_accuracy: 0.4751 - val_macro_f1score: 0.2236 - val_weighted_f1score: 0.0407\n",
      "Epoch 8/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.3336 - accuracy: 0.4813 - macro_f1score: 0.2229 - weighted_f1score: 0.0414 - val_loss: 1.3747 - val_accuracy: 0.4862 - val_macro_f1score: 0.2594 - val_weighted_f1score: 0.0473\n",
      "Epoch 9/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.3111 - accuracy: 0.4957 - macro_f1score: 0.2454 - weighted_f1score: 0.0452 - val_loss: 1.3464 - val_accuracy: 0.4987 - val_macro_f1score: 0.2644 - val_weighted_f1score: 0.0475\n",
      "Epoch 10/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.2846 - accuracy: 0.5032 - macro_f1score: 0.2578 - weighted_f1score: 0.0473 - val_loss: 1.3079 - val_accuracy: 0.5188 - val_macro_f1score: 0.2741 - val_weighted_f1score: 0.0495\n",
      "Epoch 11/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.2615 - accuracy: 0.5152 - macro_f1score: 0.2742 - weighted_f1score: 0.0498 - val_loss: 1.3135 - val_accuracy: 0.5063 - val_macro_f1score: 0.2502 - val_weighted_f1score: 0.0459\n",
      "Epoch 12/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.2440 - accuracy: 0.5208 - macro_f1score: 0.2831 - weighted_f1score: 0.0515 - val_loss: 1.2759 - val_accuracy: 0.5219 - val_macro_f1score: 0.3175 - val_weighted_f1score: 0.0561\n",
      "Epoch 13/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.2284 - accuracy: 0.5272 - macro_f1score: 0.2911 - weighted_f1score: 0.0528 - val_loss: 1.2880 - val_accuracy: 0.5238 - val_macro_f1score: 0.2913 - val_weighted_f1score: 0.0523\n",
      "Epoch 14/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.2072 - accuracy: 0.5395 - macro_f1score: 0.3127 - weighted_f1score: 0.0559 - val_loss: 1.2342 - val_accuracy: 0.5439 - val_macro_f1score: 0.3122 - val_weighted_f1score: 0.0551\n",
      "Epoch 15/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.1923 - accuracy: 0.5443 - macro_f1score: 0.3248 - weighted_f1score: 0.0579 - val_loss: 1.2369 - val_accuracy: 0.5425 - val_macro_f1score: 0.3612 - val_weighted_f1score: 0.0612\n",
      "Epoch 16/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.1848 - accuracy: 0.5462 - macro_f1score: 0.3296 - weighted_f1score: 0.0586 - val_loss: 1.2136 - val_accuracy: 0.5469 - val_macro_f1score: 0.3323 - val_weighted_f1score: 0.0592\n",
      "Epoch 17/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.1683 - accuracy: 0.5525 - macro_f1score: 0.3431 - weighted_f1score: 0.0605 - val_loss: 1.2286 - val_accuracy: 0.5439 - val_macro_f1score: 0.3249 - val_weighted_f1score: 0.0581\n",
      "Epoch 18/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.1592 - accuracy: 0.5568 - macro_f1score: 0.3510 - weighted_f1score: 0.0617 - val_loss: 1.1876 - val_accuracy: 0.5553 - val_macro_f1score: 0.3612 - val_weighted_f1score: 0.0633\n",
      "Epoch 19/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1532 - accuracy: 0.5598 - macro_f1score: 0.3533 - weighted_f1score: 0.0617 - val_loss: 1.2038 - val_accuracy: 0.5587 - val_macro_f1score: 0.3549 - val_weighted_f1score: 0.0632\n",
      "Epoch 20/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1404 - accuracy: 0.5653 - macro_f1score: 0.3698 - weighted_f1score: 0.0641 - val_loss: 1.2162 - val_accuracy: 0.5456 - val_macro_f1score: 0.3672 - val_weighted_f1score: 0.0646\n",
      "Epoch 21/50\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.1324 - accuracy: 0.5674 - macro_f1score: 0.3680 - weighted_f1score: 0.0641 - val_loss: 1.1732 - val_accuracy: 0.5637 - val_macro_f1score: 0.3868 - val_weighted_f1score: 0.0680\n",
      "Epoch 22/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.1264 - accuracy: 0.5709 - macro_f1score: 0.3720 - weighted_f1score: 0.0650 - val_loss: 1.2027 - val_accuracy: 0.5559 - val_macro_f1score: 0.3607 - val_weighted_f1score: 0.0634\n",
      "Epoch 23/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.1231 - accuracy: 0.5737 - macro_f1score: 0.3769 - weighted_f1score: 0.0657 - val_loss: 1.1660 - val_accuracy: 0.5656 - val_macro_f1score: 0.3934 - val_weighted_f1score: 0.0686\n",
      "Epoch 24/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1066 - accuracy: 0.5759 - macro_f1score: 0.3919 - weighted_f1score: 0.0676 - val_loss: 1.1763 - val_accuracy: 0.5606 - val_macro_f1score: 0.3866 - val_weighted_f1score: 0.0674\n",
      "Epoch 25/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1087 - accuracy: 0.5783 - macro_f1score: 0.3861 - weighted_f1score: 0.0667 - val_loss: 1.1466 - val_accuracy: 0.5743 - val_macro_f1score: 0.3849 - val_weighted_f1score: 0.0676\n",
      "Epoch 26/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0997 - accuracy: 0.5810 - macro_f1score: 0.3950 - weighted_f1score: 0.0678 - val_loss: 1.2129 - val_accuracy: 0.5550 - val_macro_f1score: 0.3693 - val_weighted_f1score: 0.0643\n",
      "Epoch 27/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0943 - accuracy: 0.5842 - macro_f1score: 0.4027 - weighted_f1score: 0.0685 - val_loss: 1.1813 - val_accuracy: 0.5704 - val_macro_f1score: 0.4050 - val_weighted_f1score: 0.0709\n",
      "Epoch 28/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0888 - accuracy: 0.5850 - macro_f1score: 0.4090 - weighted_f1score: 0.0698 - val_loss: 1.1746 - val_accuracy: 0.5665 - val_macro_f1score: 0.4016 - val_weighted_f1score: 0.0697\n",
      "Epoch 29/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0784 - accuracy: 0.5894 - macro_f1score: 0.4154 - weighted_f1score: 0.0702 - val_loss: 1.1458 - val_accuracy: 0.5765 - val_macro_f1score: 0.4084 - val_weighted_f1score: 0.0704\n",
      "Epoch 30/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.0786 - accuracy: 0.5912 - macro_f1score: 0.4118 - weighted_f1score: 0.0702 - val_loss: 1.1389 - val_accuracy: 0.5765 - val_macro_f1score: 0.3992 - val_weighted_f1score: 0.0685\n",
      "Epoch 31/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0717 - accuracy: 0.5907 - macro_f1score: 0.4190 - weighted_f1score: 0.0712 - val_loss: 1.1426 - val_accuracy: 0.5843 - val_macro_f1score: 0.4323 - val_weighted_f1score: 0.0746\n",
      "Epoch 32/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.0700 - accuracy: 0.5931 - macro_f1score: 0.4229 - weighted_f1score: 0.0713 - val_loss: 1.1300 - val_accuracy: 0.5846 - val_macro_f1score: 0.4139 - val_weighted_f1score: 0.0702\n",
      "Epoch 33/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.0621 - accuracy: 0.5960 - macro_f1score: 0.4266 - weighted_f1score: 0.0720 - val_loss: 1.1740 - val_accuracy: 0.5673 - val_macro_f1score: 0.3927 - val_weighted_f1score: 0.0679\n",
      "Epoch 34/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0593 - accuracy: 0.6002 - macro_f1score: 0.4275 - weighted_f1score: 0.0720 - val_loss: 1.1123 - val_accuracy: 0.6002 - val_macro_f1score: 0.4384 - val_weighted_f1score: 0.0730\n",
      "Epoch 35/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0435 - accuracy: 0.6046 - macro_f1score: 0.4390 - weighted_f1score: 0.0735 - val_loss: 1.1561 - val_accuracy: 0.5807 - val_macro_f1score: 0.4092 - val_weighted_f1score: 0.0702\n",
      "Epoch 36/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0533 - accuracy: 0.6001 - macro_f1score: 0.4342 - weighted_f1score: 0.0728 - val_loss: 1.1420 - val_accuracy: 0.5876 - val_macro_f1score: 0.4337 - val_weighted_f1score: 0.0744\n",
      "Epoch 37/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0466 - accuracy: 0.6010 - macro_f1score: 0.4421 - weighted_f1score: 0.0735 - val_loss: 1.1124 - val_accuracy: 0.5935 - val_macro_f1score: 0.4409 - val_weighted_f1score: 0.0749\n",
      "Epoch 38/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0463 - accuracy: 0.6023 - macro_f1score: 0.4415 - weighted_f1score: 0.0742 - val_loss: 1.1462 - val_accuracy: 0.5801 - val_macro_f1score: 0.4303 - val_weighted_f1score: 0.0711\n",
      "Epoch 39/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0372 - accuracy: 0.6028 - macro_f1score: 0.4450 - weighted_f1score: 0.0744 - val_loss: 1.1409 - val_accuracy: 0.5759 - val_macro_f1score: 0.4194 - val_weighted_f1score: 0.0702\n",
      "Epoch 40/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0316 - accuracy: 0.6097 - macro_f1score: 0.4490 - weighted_f1score: 0.0745 - val_loss: 1.1459 - val_accuracy: 0.5899 - val_macro_f1score: 0.4539 - val_weighted_f1score: 0.0763\n",
      "Epoch 41/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0252 - accuracy: 0.6108 - macro_f1score: 0.4550 - weighted_f1score: 0.0754 - val_loss: 1.1427 - val_accuracy: 0.5751 - val_macro_f1score: 0.4176 - val_weighted_f1score: 0.0712\n",
      "Epoch 42/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0330 - accuracy: 0.6059 - macro_f1score: 0.4440 - weighted_f1score: 0.0744 - val_loss: 1.1331 - val_accuracy: 0.5915 - val_macro_f1score: 0.4274 - val_weighted_f1score: 0.0739\n",
      "Epoch 43/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0221 - accuracy: 0.6088 - macro_f1score: 0.4574 - weighted_f1score: 0.0759 - val_loss: 1.1481 - val_accuracy: 0.5818 - val_macro_f1score: 0.4165 - val_weighted_f1score: 0.0721\n",
      "Epoch 44/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0238 - accuracy: 0.6107 - macro_f1score: 0.4529 - weighted_f1score: 0.0752 - val_loss: 1.1222 - val_accuracy: 0.5874 - val_macro_f1score: 0.4252 - val_weighted_f1score: 0.0723\n",
      "Epoch 45/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0160 - accuracy: 0.6125 - macro_f1score: 0.4593 - weighted_f1score: 0.0761 - val_loss: 1.1135 - val_accuracy: 0.5988 - val_macro_f1score: 0.4411 - val_weighted_f1score: 0.0750\n",
      "Epoch 46/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0099 - accuracy: 0.6152 - macro_f1score: 0.4584 - weighted_f1score: 0.0764 - val_loss: 1.1434 - val_accuracy: 0.5812 - val_macro_f1score: 0.4325 - val_weighted_f1score: 0.0744\n",
      "Epoch 47/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0187 - accuracy: 0.6142 - macro_f1score: 0.4623 - weighted_f1score: 0.0765 - val_loss: 1.1348 - val_accuracy: 0.5854 - val_macro_f1score: 0.4301 - val_weighted_f1score: 0.0741\n",
      "Epoch 48/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0044 - accuracy: 0.6197 - macro_f1score: 0.4699 - weighted_f1score: 0.0775 - val_loss: 1.1141 - val_accuracy: 0.5993 - val_macro_f1score: 0.4672 - val_weighted_f1score: 0.0763\n",
      "Epoch 49/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.0048 - accuracy: 0.6164 - macro_f1score: 0.4672 - weighted_f1score: 0.0772 - val_loss: 1.1034 - val_accuracy: 0.6063 - val_macro_f1score: 0.4698 - val_weighted_f1score: 0.0775\n",
      "Epoch 50/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.0056 - accuracy: 0.6189 - macro_f1score: 0.4706 - weighted_f1score: 0.0775 - val_loss: 1.1126 - val_accuracy: 0.5979 - val_macro_f1score: 0.4384 - val_weighted_f1score: 0.0755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3957082c88>"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3557389,
     "status": "ok",
     "timestamp": 1583373315036,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "m-39j9WgQAtK",
    "outputId": "46338b3a-0d87-4112-f100-44128324bbaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 0s 138us/sample - loss: 1.0883 - accuracy: 0.6042 - macro_f1score: 0.4372 - weighted_f1score: 0.0734\n",
      "\n",
      "Accuracy: 0.6042, Macro F1 Score: 0.4372, Weighted F1 Score: 0.0734\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9h1G9LaQAlI6"
   },
   "source": [
    "#### (3) My VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSAPVOvZP1Kp"
   },
   "outputs": [],
   "source": [
    "# VGG 19 - pretrained\n",
    "\n",
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "\n",
    "model = VGG19(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "74j03AhyP2Fw"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1469509,
     "status": "ok",
     "timestamp": 1583375589522,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "iq_wS0l0P2D6",
    "outputId": "a0d463dd-31c7-4819-a2a3-55ff1a2fb222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/50\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8134 - accuracy: 0.2499 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8832 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/50\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8125 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8817 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 3/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8110 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8795 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 4/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8114 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8814 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 5/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8109 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 6/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8109 - accuracy: 0.2517 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 7/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8111 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 8/50\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8111 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8798 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 9/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8819 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 10/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8110 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8803 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 11/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 12/50\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8799 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 13/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8109 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 14/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8782 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 15/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 16/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8808 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 17/50\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8106 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8783 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 18/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8805 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 19/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8804 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 20/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 21/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 22/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8801 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 23/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8106 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 24/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 25/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8106 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 26/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 27/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 28/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8106 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8796 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 29/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 30/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 31/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 32/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8800 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 33/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.8106 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8795 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 34/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8794 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 35/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 36/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 37/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8794 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 38/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 39/50\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 40/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 41/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.8101 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8784 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 42/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 43/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 44/50\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 45/50\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 46/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8783 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 47/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8784 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 48/50\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 49/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8795 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 50/50\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36ff401630>"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1306,
     "status": "ok",
     "timestamp": 1583375590858,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "TmM4JmyoP2Cd",
    "outputId": "0254387d-c88d-4369-bb77-fccecef54d1e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 1s 145us/sample - loss: 1.8111 - accuracy: 0.2494 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00\n",
      "\n",
      "Accuracy: 0.2494, Macro F1 Score: 0.0000, Weighted F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DYHQ4DGsAlI_"
   },
   "source": [
    "### 2) Epoch = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erI-HfAAAlI_"
   },
   "source": [
    "#### (1) My VGG11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vkr_ttBaAlI_"
   },
   "outputs": [],
   "source": [
    "# VGG 11 - pretraining\n",
    "model = VGG11(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xb78xWL5AlJA"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8962,
     "status": "ok",
     "timestamp": 1583378827205,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "23XoOo_IAlJB",
    "outputId": "181b9b28-79ae-4e6e-9b8b-5d1f68c2b001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8193 - accuracy: 0.2494 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8814 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.7859 - accuracy: 0.2629 - macro_f1score: 0.0043 - weighted_f1score: 4.8646e-04 - val_loss: 1.8012 - val_accuracy: 0.2781 - val_macro_f1score: 0.0401 - val_weighted_f1score: 0.0047\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.6905 - accuracy: 0.3067 - macro_f1score: 0.0617 - weighted_f1score: 0.0086 - val_loss: 1.6502 - val_accuracy: 0.3692 - val_macro_f1score: 0.1262 - val_weighted_f1score: 0.0227\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.5707 - accuracy: 0.3756 - macro_f1score: 0.1369 - weighted_f1score: 0.0255 - val_loss: 1.5988 - val_accuracy: 0.3982 - val_macro_f1score: 0.1274 - val_weighted_f1score: 0.0267\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.4976 - accuracy: 0.4064 - macro_f1score: 0.1586 - weighted_f1score: 0.0299 - val_loss: 1.5324 - val_accuracy: 0.4241 - val_macro_f1score: 0.1592 - val_weighted_f1score: 0.0310\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.4337 - accuracy: 0.4369 - macro_f1score: 0.1815 - weighted_f1score: 0.0341 - val_loss: 1.4585 - val_accuracy: 0.4439 - val_macro_f1score: 0.1772 - val_weighted_f1score: 0.0329\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.3927 - accuracy: 0.4519 - macro_f1score: 0.2018 - weighted_f1score: 0.0378 - val_loss: 1.4332 - val_accuracy: 0.4572 - val_macro_f1score: 0.1860 - val_weighted_f1score: 0.0347\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.3572 - accuracy: 0.4678 - macro_f1score: 0.2175 - weighted_f1score: 0.0403 - val_loss: 1.3611 - val_accuracy: 0.4962 - val_macro_f1score: 0.2705 - val_weighted_f1score: 0.0487\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.3242 - accuracy: 0.4833 - macro_f1score: 0.2400 - weighted_f1score: 0.0439 - val_loss: 1.3490 - val_accuracy: 0.4937 - val_macro_f1score: 0.2733 - val_weighted_f1score: 0.0488\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.2911 - accuracy: 0.5016 - macro_f1score: 0.2566 - weighted_f1score: 0.0466 - val_loss: 1.2998 - val_accuracy: 0.5169 - val_macro_f1score: 0.2735 - val_weighted_f1score: 0.0491\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.2689 - accuracy: 0.5091 - macro_f1score: 0.2690 - weighted_f1score: 0.0487 - val_loss: 1.2797 - val_accuracy: 0.5283 - val_macro_f1score: 0.2726 - val_weighted_f1score: 0.0487\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.2394 - accuracy: 0.5239 - macro_f1score: 0.2923 - weighted_f1score: 0.0524 - val_loss: 1.2564 - val_accuracy: 0.5394 - val_macro_f1score: 0.3158 - val_weighted_f1score: 0.0570\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.2232 - accuracy: 0.5314 - macro_f1score: 0.3071 - weighted_f1score: 0.0547 - val_loss: 1.2621 - val_accuracy: 0.5339 - val_macro_f1score: 0.3279 - val_weighted_f1score: 0.0580\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.2144 - accuracy: 0.5362 - macro_f1score: 0.3180 - weighted_f1score: 0.0562 - val_loss: 1.2197 - val_accuracy: 0.5414 - val_macro_f1score: 0.3258 - val_weighted_f1score: 0.0576\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.1963 - accuracy: 0.5395 - macro_f1score: 0.3278 - weighted_f1score: 0.0580 - val_loss: 1.2313 - val_accuracy: 0.5386 - val_macro_f1score: 0.3113 - val_weighted_f1score: 0.0556\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1815 - accuracy: 0.5488 - macro_f1score: 0.3414 - weighted_f1score: 0.0598 - val_loss: 1.2517 - val_accuracy: 0.5456 - val_macro_f1score: 0.3491 - val_weighted_f1score: 0.0585\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1736 - accuracy: 0.5485 - macro_f1score: 0.3474 - weighted_f1score: 0.0608 - val_loss: 1.2186 - val_accuracy: 0.5531 - val_macro_f1score: 0.3892 - val_weighted_f1score: 0.0657\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1626 - accuracy: 0.5550 - macro_f1score: 0.3603 - weighted_f1score: 0.0624 - val_loss: 1.1878 - val_accuracy: 0.5639 - val_macro_f1score: 0.3629 - val_weighted_f1score: 0.0641\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.1467 - accuracy: 0.5635 - macro_f1score: 0.3700 - weighted_f1score: 0.0641 - val_loss: 1.1962 - val_accuracy: 0.5536 - val_macro_f1score: 0.3622 - val_weighted_f1score: 0.0636\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.1436 - accuracy: 0.5617 - macro_f1score: 0.3731 - weighted_f1score: 0.0641 - val_loss: 1.1848 - val_accuracy: 0.5656 - val_macro_f1score: 0.3741 - val_weighted_f1score: 0.0645\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.1324 - accuracy: 0.5674 - macro_f1score: 0.3716 - weighted_f1score: 0.0645 - val_loss: 1.1770 - val_accuracy: 0.5754 - val_macro_f1score: 0.4008 - val_weighted_f1score: 0.0697\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.1297 - accuracy: 0.5641 - macro_f1score: 0.3805 - weighted_f1score: 0.0656 - val_loss: 1.1756 - val_accuracy: 0.5692 - val_macro_f1score: 0.3963 - val_weighted_f1score: 0.0690\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1184 - accuracy: 0.5738 - macro_f1score: 0.3926 - weighted_f1score: 0.0667 - val_loss: 1.1680 - val_accuracy: 0.5639 - val_macro_f1score: 0.3771 - val_weighted_f1score: 0.0651\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1129 - accuracy: 0.5750 - macro_f1score: 0.3986 - weighted_f1score: 0.0675 - val_loss: 1.1607 - val_accuracy: 0.5784 - val_macro_f1score: 0.3983 - val_weighted_f1score: 0.0687\n",
      "Epoch 25/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1131 - accuracy: 0.5765 - macro_f1score: 0.3952 - weighted_f1score: 0.0672 - val_loss: 1.1746 - val_accuracy: 0.5740 - val_macro_f1score: 0.4090 - val_weighted_f1score: 0.0697\n",
      "Epoch 26/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.1046 - accuracy: 0.5794 - macro_f1score: 0.4019 - weighted_f1score: 0.0683 - val_loss: 1.1785 - val_accuracy: 0.5759 - val_macro_f1score: 0.4087 - val_weighted_f1score: 0.0716\n",
      "Epoch 27/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0985 - accuracy: 0.5782 - macro_f1score: 0.4100 - weighted_f1score: 0.0690 - val_loss: 1.1638 - val_accuracy: 0.5712 - val_macro_f1score: 0.3969 - val_weighted_f1score: 0.0682\n",
      "Epoch 28/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0912 - accuracy: 0.5805 - macro_f1score: 0.4144 - weighted_f1score: 0.0695 - val_loss: 1.1879 - val_accuracy: 0.5812 - val_macro_f1score: 0.4203 - val_weighted_f1score: 0.0719\n",
      "Epoch 29/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.0879 - accuracy: 0.5869 - macro_f1score: 0.4201 - weighted_f1score: 0.0701 - val_loss: 1.1818 - val_accuracy: 0.5770 - val_macro_f1score: 0.3980 - val_weighted_f1score: 0.0676\n",
      "Epoch 30/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.0866 - accuracy: 0.5851 - macro_f1score: 0.4226 - weighted_f1score: 0.0702 - val_loss: 1.1920 - val_accuracy: 0.5531 - val_macro_f1score: 0.3809 - val_weighted_f1score: 0.0662\n",
      "Epoch 31/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0785 - accuracy: 0.5889 - macro_f1score: 0.4317 - weighted_f1score: 0.0711 - val_loss: 1.1977 - val_accuracy: 0.5729 - val_macro_f1score: 0.4290 - val_weighted_f1score: 0.0732\n",
      "Epoch 32/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0762 - accuracy: 0.5910 - macro_f1score: 0.4317 - weighted_f1score: 0.0715 - val_loss: 1.1741 - val_accuracy: 0.5670 - val_macro_f1score: 0.4151 - val_weighted_f1score: 0.0712\n",
      "Epoch 33/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0717 - accuracy: 0.5975 - macro_f1score: 0.4360 - weighted_f1score: 0.0716 - val_loss: 1.1717 - val_accuracy: 0.5681 - val_macro_f1score: 0.4242 - val_weighted_f1score: 0.0717\n",
      "Epoch 34/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0607 - accuracy: 0.5924 - macro_f1score: 0.4377 - weighted_f1score: 0.0724 - val_loss: 1.1478 - val_accuracy: 0.5840 - val_macro_f1score: 0.4266 - val_weighted_f1score: 0.0727\n",
      "Epoch 35/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0651 - accuracy: 0.5970 - macro_f1score: 0.4408 - weighted_f1score: 0.0727 - val_loss: 1.1701 - val_accuracy: 0.5756 - val_macro_f1score: 0.4209 - val_weighted_f1score: 0.0719\n",
      "Epoch 36/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0540 - accuracy: 0.5989 - macro_f1score: 0.4466 - weighted_f1score: 0.0732 - val_loss: 1.1558 - val_accuracy: 0.5901 - val_macro_f1score: 0.4327 - val_weighted_f1score: 0.0736\n",
      "Epoch 37/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0499 - accuracy: 0.6015 - macro_f1score: 0.4493 - weighted_f1score: 0.0736 - val_loss: 1.1623 - val_accuracy: 0.5823 - val_macro_f1score: 0.4211 - val_weighted_f1score: 0.0714\n",
      "Epoch 38/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0448 - accuracy: 0.6014 - macro_f1score: 0.4471 - weighted_f1score: 0.0739 - val_loss: 1.1521 - val_accuracy: 0.5821 - val_macro_f1score: 0.4321 - val_weighted_f1score: 0.0735\n",
      "Epoch 39/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0521 - accuracy: 0.5974 - macro_f1score: 0.4509 - weighted_f1score: 0.0735 - val_loss: 1.1469 - val_accuracy: 0.5807 - val_macro_f1score: 0.4181 - val_weighted_f1score: 0.0711\n",
      "Epoch 40/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0442 - accuracy: 0.6000 - macro_f1score: 0.4512 - weighted_f1score: 0.0737 - val_loss: 1.1208 - val_accuracy: 0.5985 - val_macro_f1score: 0.4279 - val_weighted_f1score: 0.0721\n",
      "Epoch 41/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0442 - accuracy: 0.6038 - macro_f1score: 0.4532 - weighted_f1score: 0.0739 - val_loss: 1.1201 - val_accuracy: 0.5954 - val_macro_f1score: 0.4436 - val_weighted_f1score: 0.0741\n",
      "Epoch 42/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0319 - accuracy: 0.6088 - macro_f1score: 0.4664 - weighted_f1score: 0.0756 - val_loss: 1.1409 - val_accuracy: 0.5840 - val_macro_f1score: 0.4238 - val_weighted_f1score: 0.0726\n",
      "Epoch 43/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0312 - accuracy: 0.6086 - macro_f1score: 0.4657 - weighted_f1score: 0.0754 - val_loss: 1.1376 - val_accuracy: 0.5798 - val_macro_f1score: 0.4235 - val_weighted_f1score: 0.0721\n",
      "Epoch 44/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0310 - accuracy: 0.6079 - macro_f1score: 0.4634 - weighted_f1score: 0.0755 - val_loss: 1.1387 - val_accuracy: 0.5868 - val_macro_f1score: 0.4277 - val_weighted_f1score: 0.0722\n",
      "Epoch 45/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0281 - accuracy: 0.6082 - macro_f1score: 0.4692 - weighted_f1score: 0.0760 - val_loss: 1.1249 - val_accuracy: 0.5952 - val_macro_f1score: 0.4420 - val_weighted_f1score: 0.0749\n",
      "Epoch 46/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.0258 - accuracy: 0.6096 - macro_f1score: 0.4710 - weighted_f1score: 0.0757 - val_loss: 1.0995 - val_accuracy: 0.6013 - val_macro_f1score: 0.4612 - val_weighted_f1score: 0.0760\n",
      "Epoch 47/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0210 - accuracy: 0.6127 - macro_f1score: 0.4671 - weighted_f1score: 0.0758 - val_loss: 1.1411 - val_accuracy: 0.6002 - val_macro_f1score: 0.4470 - val_weighted_f1score: 0.0748\n",
      "Epoch 48/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0221 - accuracy: 0.6109 - macro_f1score: 0.4684 - weighted_f1score: 0.0760 - val_loss: 1.1126 - val_accuracy: 0.6066 - val_macro_f1score: 0.4640 - val_weighted_f1score: 0.0777\n",
      "Epoch 49/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.0161 - accuracy: 0.6109 - macro_f1score: 0.4744 - weighted_f1score: 0.0764 - val_loss: 1.1527 - val_accuracy: 0.5868 - val_macro_f1score: 0.4429 - val_weighted_f1score: 0.0749\n",
      "Epoch 50/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 1.0101 - accuracy: 0.6135 - macro_f1score: 0.4744 - weighted_f1score: 0.0767 - val_loss: 1.1284 - val_accuracy: 0.5935 - val_macro_f1score: 0.4574 - val_weighted_f1score: 0.0757\n",
      "Epoch 51/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0092 - accuracy: 0.6144 - macro_f1score: 0.4837 - weighted_f1score: 0.0773 - val_loss: 1.1256 - val_accuracy: 0.5896 - val_macro_f1score: 0.4496 - val_weighted_f1score: 0.0738\n",
      "Epoch 52/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0024 - accuracy: 0.6180 - macro_f1score: 0.4818 - weighted_f1score: 0.0776 - val_loss: 1.1136 - val_accuracy: 0.5999 - val_macro_f1score: 0.4504 - val_weighted_f1score: 0.0748\n",
      "Epoch 53/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0056 - accuracy: 0.6168 - macro_f1score: 0.4792 - weighted_f1score: 0.0772 - val_loss: 1.1092 - val_accuracy: 0.5985 - val_macro_f1score: 0.4523 - val_weighted_f1score: 0.0765\n",
      "Epoch 54/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 1.0008 - accuracy: 0.6183 - macro_f1score: 0.4839 - weighted_f1score: 0.0784 - val_loss: 1.1120 - val_accuracy: 0.5949 - val_macro_f1score: 0.4674 - val_weighted_f1score: 0.0773\n",
      "Epoch 55/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9967 - accuracy: 0.6186 - macro_f1score: 0.4863 - weighted_f1score: 0.0782 - val_loss: 1.1210 - val_accuracy: 0.5943 - val_macro_f1score: 0.4694 - val_weighted_f1score: 0.0775\n",
      "Epoch 56/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9998 - accuracy: 0.6204 - macro_f1score: 0.4895 - weighted_f1score: 0.0780 - val_loss: 1.0982 - val_accuracy: 0.5954 - val_macro_f1score: 0.4507 - val_weighted_f1score: 0.0739\n",
      "Epoch 57/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.0026 - accuracy: 0.6167 - macro_f1score: 0.4826 - weighted_f1score: 0.0773 - val_loss: 1.0906 - val_accuracy: 0.6027 - val_macro_f1score: 0.4614 - val_weighted_f1score: 0.0773\n",
      "Epoch 58/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9925 - accuracy: 0.6209 - macro_f1score: 0.4900 - weighted_f1score: 0.0785 - val_loss: 1.1092 - val_accuracy: 0.6046 - val_macro_f1score: 0.4583 - val_weighted_f1score: 0.0757\n",
      "Epoch 59/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9950 - accuracy: 0.6200 - macro_f1score: 0.4947 - weighted_f1score: 0.0784 - val_loss: 1.1029 - val_accuracy: 0.5957 - val_macro_f1score: 0.4476 - val_weighted_f1score: 0.0752\n",
      "Epoch 60/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9948 - accuracy: 0.6179 - macro_f1score: 0.4863 - weighted_f1score: 0.0777 - val_loss: 1.0906 - val_accuracy: 0.6060 - val_macro_f1score: 0.4633 - val_weighted_f1score: 0.0781\n",
      "Epoch 61/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9917 - accuracy: 0.6229 - macro_f1score: 0.4887 - weighted_f1score: 0.0782 - val_loss: 1.1370 - val_accuracy: 0.5887 - val_macro_f1score: 0.4579 - val_weighted_f1score: 0.0756\n",
      "Epoch 62/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9845 - accuracy: 0.6240 - macro_f1score: 0.4923 - weighted_f1score: 0.0791 - val_loss: 1.0962 - val_accuracy: 0.6038 - val_macro_f1score: 0.4599 - val_weighted_f1score: 0.0745\n",
      "Epoch 63/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9793 - accuracy: 0.6260 - macro_f1score: 0.4984 - weighted_f1score: 0.0795 - val_loss: 1.1041 - val_accuracy: 0.6085 - val_macro_f1score: 0.4788 - val_weighted_f1score: 0.0776\n",
      "Epoch 64/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9814 - accuracy: 0.6304 - macro_f1score: 0.4989 - weighted_f1score: 0.0798 - val_loss: 1.1174 - val_accuracy: 0.6002 - val_macro_f1score: 0.4704 - val_weighted_f1score: 0.0765\n",
      "Epoch 65/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9822 - accuracy: 0.6259 - macro_f1score: 0.5009 - weighted_f1score: 0.0795 - val_loss: 1.1531 - val_accuracy: 0.5854 - val_macro_f1score: 0.4474 - val_weighted_f1score: 0.0756\n",
      "Epoch 66/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 0.9769 - accuracy: 0.6284 - macro_f1score: 0.5063 - weighted_f1score: 0.0800 - val_loss: 1.0932 - val_accuracy: 0.5977 - val_macro_f1score: 0.4501 - val_weighted_f1score: 0.0750\n",
      "Epoch 67/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9755 - accuracy: 0.6278 - macro_f1score: 0.5103 - weighted_f1score: 0.0804 - val_loss: 1.1197 - val_accuracy: 0.5907 - val_macro_f1score: 0.4387 - val_weighted_f1score: 0.0745\n",
      "Epoch 68/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9717 - accuracy: 0.6314 - macro_f1score: 0.5107 - weighted_f1score: 0.0807 - val_loss: 1.1226 - val_accuracy: 0.5921 - val_macro_f1score: 0.4463 - val_weighted_f1score: 0.0749\n",
      "Epoch 69/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9711 - accuracy: 0.6309 - macro_f1score: 0.5124 - weighted_f1score: 0.0808 - val_loss: 1.0982 - val_accuracy: 0.6002 - val_macro_f1score: 0.4743 - val_weighted_f1score: 0.0780\n",
      "Epoch 70/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9712 - accuracy: 0.6308 - macro_f1score: 0.5087 - weighted_f1score: 0.0809 - val_loss: 1.0966 - val_accuracy: 0.6055 - val_macro_f1score: 0.4938 - val_weighted_f1score: 0.0781\n",
      "Epoch 71/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 0.9618 - accuracy: 0.6323 - macro_f1score: 0.5181 - weighted_f1score: 0.0814 - val_loss: 1.1037 - val_accuracy: 0.6041 - val_macro_f1score: 0.4606 - val_weighted_f1score: 0.0773\n",
      "Epoch 72/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9638 - accuracy: 0.6351 - macro_f1score: 0.5074 - weighted_f1score: 0.0810 - val_loss: 1.1136 - val_accuracy: 0.6069 - val_macro_f1score: 0.4830 - val_weighted_f1score: 0.0784\n",
      "Epoch 73/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9661 - accuracy: 0.6290 - macro_f1score: 0.5155 - weighted_f1score: 0.0810 - val_loss: 1.1022 - val_accuracy: 0.6080 - val_macro_f1score: 0.4649 - val_weighted_f1score: 0.0754\n",
      "Epoch 74/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9638 - accuracy: 0.6322 - macro_f1score: 0.5191 - weighted_f1score: 0.0813 - val_loss: 1.1071 - val_accuracy: 0.6074 - val_macro_f1score: 0.4828 - val_weighted_f1score: 0.0781\n",
      "Epoch 75/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 0.9629 - accuracy: 0.6353 - macro_f1score: 0.5178 - weighted_f1score: 0.0812 - val_loss: 1.1163 - val_accuracy: 0.6041 - val_macro_f1score: 0.4721 - val_weighted_f1score: 0.0769\n",
      "Epoch 76/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9577 - accuracy: 0.6346 - macro_f1score: 0.5146 - weighted_f1score: 0.0815 - val_loss: 1.1044 - val_accuracy: 0.6074 - val_macro_f1score: 0.5017 - val_weighted_f1score: 0.0790\n",
      "Epoch 77/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9552 - accuracy: 0.6345 - macro_f1score: 0.5171 - weighted_f1score: 0.0817 - val_loss: 1.1238 - val_accuracy: 0.6032 - val_macro_f1score: 0.4865 - val_weighted_f1score: 0.0779\n",
      "Epoch 78/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9559 - accuracy: 0.6357 - macro_f1score: 0.5233 - weighted_f1score: 0.0819 - val_loss: 1.0925 - val_accuracy: 0.6144 - val_macro_f1score: 0.4841 - val_weighted_f1score: 0.0801\n",
      "Epoch 79/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 0.9491 - accuracy: 0.6375 - macro_f1score: 0.5195 - weighted_f1score: 0.0820 - val_loss: 1.1135 - val_accuracy: 0.6110 - val_macro_f1score: 0.5003 - val_weighted_f1score: 0.0789\n",
      "Epoch 80/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9473 - accuracy: 0.6393 - macro_f1score: 0.5239 - weighted_f1score: 0.0823 - val_loss: 1.0946 - val_accuracy: 0.6116 - val_macro_f1score: 0.4924 - val_weighted_f1score: 0.0777\n",
      "Epoch 81/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 0.9408 - accuracy: 0.6403 - macro_f1score: 0.5313 - weighted_f1score: 0.0829 - val_loss: 1.0931 - val_accuracy: 0.6147 - val_macro_f1score: 0.5023 - val_weighted_f1score: 0.0796\n",
      "Epoch 82/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9505 - accuracy: 0.6362 - macro_f1score: 0.5221 - weighted_f1score: 0.0822 - val_loss: 1.0986 - val_accuracy: 0.6105 - val_macro_f1score: 0.5048 - val_weighted_f1score: 0.0795\n",
      "Epoch 83/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9530 - accuracy: 0.6341 - macro_f1score: 0.5159 - weighted_f1score: 0.0814 - val_loss: 1.1275 - val_accuracy: 0.6002 - val_macro_f1score: 0.4775 - val_weighted_f1score: 0.0775\n",
      "Epoch 84/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9455 - accuracy: 0.6401 - macro_f1score: 0.5290 - weighted_f1score: 0.0828 - val_loss: 1.0997 - val_accuracy: 0.6138 - val_macro_f1score: 0.4777 - val_weighted_f1score: 0.0774\n",
      "Epoch 85/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 0.9391 - accuracy: 0.6404 - macro_f1score: 0.5276 - weighted_f1score: 0.0829 - val_loss: 1.0985 - val_accuracy: 0.6119 - val_macro_f1score: 0.4831 - val_weighted_f1score: 0.0787\n",
      "Epoch 86/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9417 - accuracy: 0.6405 - macro_f1score: 0.5292 - weighted_f1score: 0.0828 - val_loss: 1.1450 - val_accuracy: 0.5946 - val_macro_f1score: 0.4834 - val_weighted_f1score: 0.0777\n",
      "Epoch 87/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9441 - accuracy: 0.6376 - macro_f1score: 0.5320 - weighted_f1score: 0.0828 - val_loss: 1.1115 - val_accuracy: 0.6055 - val_macro_f1score: 0.4695 - val_weighted_f1score: 0.0736\n",
      "Epoch 88/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9332 - accuracy: 0.6436 - macro_f1score: 0.5360 - weighted_f1score: 0.0837 - val_loss: 1.0920 - val_accuracy: 0.6052 - val_macro_f1score: 0.4650 - val_weighted_f1score: 0.0767\n",
      "Epoch 89/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9412 - accuracy: 0.6399 - macro_f1score: 0.5235 - weighted_f1score: 0.0826 - val_loss: 1.1427 - val_accuracy: 0.6038 - val_macro_f1score: 0.4789 - val_weighted_f1score: 0.0753\n",
      "Epoch 90/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9368 - accuracy: 0.6422 - macro_f1score: 0.5324 - weighted_f1score: 0.0837 - val_loss: 1.0921 - val_accuracy: 0.6016 - val_macro_f1score: 0.4783 - val_weighted_f1score: 0.0786\n",
      "Epoch 91/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9302 - accuracy: 0.6425 - macro_f1score: 0.5364 - weighted_f1score: 0.0839 - val_loss: 1.0894 - val_accuracy: 0.6133 - val_macro_f1score: 0.5044 - val_weighted_f1score: 0.0788\n",
      "Epoch 92/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9291 - accuracy: 0.6458 - macro_f1score: 0.5394 - weighted_f1score: 0.0841 - val_loss: 1.1021 - val_accuracy: 0.6113 - val_macro_f1score: 0.4928 - val_weighted_f1score: 0.0787\n",
      "Epoch 93/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9259 - accuracy: 0.6462 - macro_f1score: 0.5356 - weighted_f1score: 0.0838 - val_loss: 1.1044 - val_accuracy: 0.6091 - val_macro_f1score: 0.4936 - val_weighted_f1score: 0.0799\n",
      "Epoch 94/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9351 - accuracy: 0.6436 - macro_f1score: 0.5380 - weighted_f1score: 0.0837 - val_loss: 1.1156 - val_accuracy: 0.6055 - val_macro_f1score: 0.4893 - val_weighted_f1score: 0.0770\n",
      "Epoch 95/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9304 - accuracy: 0.6446 - macro_f1score: 0.5352 - weighted_f1score: 0.0836 - val_loss: 1.0815 - val_accuracy: 0.6172 - val_macro_f1score: 0.4969 - val_weighted_f1score: 0.0808\n",
      "Epoch 96/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9254 - accuracy: 0.6449 - macro_f1score: 0.5331 - weighted_f1score: 0.0838 - val_loss: 1.0771 - val_accuracy: 0.6094 - val_macro_f1score: 0.4810 - val_weighted_f1score: 0.0789\n",
      "Epoch 97/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9247 - accuracy: 0.6476 - macro_f1score: 0.5476 - weighted_f1score: 0.0846 - val_loss: 1.1274 - val_accuracy: 0.6085 - val_macro_f1score: 0.4728 - val_weighted_f1score: 0.0798\n",
      "Epoch 98/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 0.9157 - accuracy: 0.6515 - macro_f1score: 0.5513 - weighted_f1score: 0.0855 - val_loss: 1.0928 - val_accuracy: 0.6177 - val_macro_f1score: 0.4983 - val_weighted_f1score: 0.0815\n",
      "Epoch 99/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9255 - accuracy: 0.6473 - macro_f1score: 0.5387 - weighted_f1score: 0.0839 - val_loss: 1.1587 - val_accuracy: 0.6060 - val_macro_f1score: 0.4836 - val_weighted_f1score: 0.0791\n",
      "Epoch 100/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9203 - accuracy: 0.6504 - macro_f1score: 0.5436 - weighted_f1score: 0.0848 - val_loss: 1.0976 - val_accuracy: 0.6096 - val_macro_f1score: 0.4862 - val_weighted_f1score: 0.0789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36fe03b358>"
      ]
     },
     "execution_count": 137,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1583378827210,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "VKKGtybLQQIb",
    "outputId": "a9cbd9de-49c5-44a4-d026-a0a423dd21a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 0s 115us/sample - loss: 1.0850 - accuracy: 0.6056 - macro_f1score: 0.4916 - weighted_f1score: 0.0793\n",
      "\n",
      "Accuracy: 0.6056, Macro F1 Score: 0.4916, Weighted F1 Score: 0.0793\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dTSsHkw_BZeV"
   },
   "outputs": [],
   "source": [
    "# 한층당 W 와 b , 2개씩 있으므로 11개층이라면 22개의 모수 벡터 및 행렬이 출력된다.\n",
    "W = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XuYn810CAlJE"
   },
   "source": [
    "#### (2) My VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WS6Jx2JbAlJE"
   },
   "outputs": [],
   "source": [
    "# VGG 16 - pretrained\n",
    "\n",
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "\n",
    "model = VGG16(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58DHBkAYAlJF"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2659065,
     "status": "ok",
     "timestamp": 1583381486187,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "Rw8lLM9rAlJG",
    "outputId": "67aca27c-972a-4c69-96c3-101692c35d4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 1.8034 - accuracy: 0.2496 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8576 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.7867 - accuracy: 0.2525 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8414 - val_accuracy: 0.2625 - val_macro_f1score: 0.0249 - val_weighted_f1score: 0.0029\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.7312 - accuracy: 0.2858 - macro_f1score: 0.0210 - weighted_f1score: 0.0023 - val_loss: 1.7283 - val_accuracy: 0.3232 - val_macro_f1score: 0.0884 - val_weighted_f1score: 0.0132\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.6153 - accuracy: 0.3585 - macro_f1score: 0.1098 - weighted_f1score: 0.0206 - val_loss: 1.6157 - val_accuracy: 0.3873 - val_macro_f1score: 0.1326 - val_weighted_f1score: 0.0262\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.5302 - accuracy: 0.4014 - macro_f1score: 0.1430 - weighted_f1score: 0.0275 - val_loss: 1.5410 - val_accuracy: 0.4280 - val_macro_f1score: 0.1674 - val_weighted_f1score: 0.0315\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.4818 - accuracy: 0.4183 - macro_f1score: 0.1596 - weighted_f1score: 0.0304 - val_loss: 1.4835 - val_accuracy: 0.4408 - val_macro_f1score: 0.1768 - val_weighted_f1score: 0.0337\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.4352 - accuracy: 0.4396 - macro_f1score: 0.1780 - weighted_f1score: 0.0336 - val_loss: 1.4531 - val_accuracy: 0.4609 - val_macro_f1score: 0.2164 - val_weighted_f1score: 0.0389\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 1.4103 - accuracy: 0.4472 - macro_f1score: 0.1912 - weighted_f1score: 0.0358 - val_loss: 1.4042 - val_accuracy: 0.4689 - val_macro_f1score: 0.2073 - val_weighted_f1score: 0.0386\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 1.3766 - accuracy: 0.4658 - macro_f1score: 0.2107 - weighted_f1score: 0.0392 - val_loss: 1.4482 - val_accuracy: 0.4650 - val_macro_f1score: 0.2492 - val_weighted_f1score: 0.0457\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.3471 - accuracy: 0.4790 - macro_f1score: 0.2283 - weighted_f1score: 0.0421 - val_loss: 1.3569 - val_accuracy: 0.4940 - val_macro_f1score: 0.2368 - val_weighted_f1score: 0.0438\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 1.3187 - accuracy: 0.4898 - macro_f1score: 0.2397 - weighted_f1score: 0.0440 - val_loss: 1.3373 - val_accuracy: 0.5007 - val_macro_f1score: 0.2588 - val_weighted_f1score: 0.0477\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.2905 - accuracy: 0.5018 - macro_f1score: 0.2585 - weighted_f1score: 0.0471 - val_loss: 1.3333 - val_accuracy: 0.4993 - val_macro_f1score: 0.2821 - val_weighted_f1score: 0.0507\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.2750 - accuracy: 0.5116 - macro_f1score: 0.2713 - weighted_f1score: 0.0493 - val_loss: 1.2979 - val_accuracy: 0.5183 - val_macro_f1score: 0.3124 - val_weighted_f1score: 0.0556\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.2491 - accuracy: 0.5198 - macro_f1score: 0.2921 - weighted_f1score: 0.0526 - val_loss: 1.2821 - val_accuracy: 0.5339 - val_macro_f1score: 0.3131 - val_weighted_f1score: 0.0560\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.2294 - accuracy: 0.5305 - macro_f1score: 0.3038 - weighted_f1score: 0.0543 - val_loss: 1.2779 - val_accuracy: 0.5308 - val_macro_f1score: 0.3077 - val_weighted_f1score: 0.0556\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.2181 - accuracy: 0.5332 - macro_f1score: 0.3074 - weighted_f1score: 0.0549 - val_loss: 1.2587 - val_accuracy: 0.5347 - val_macro_f1score: 0.3306 - val_weighted_f1score: 0.0585\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.2049 - accuracy: 0.5387 - macro_f1score: 0.3157 - weighted_f1score: 0.0564 - val_loss: 1.2382 - val_accuracy: 0.5442 - val_macro_f1score: 0.3247 - val_weighted_f1score: 0.0577\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1912 - accuracy: 0.5448 - macro_f1score: 0.3281 - weighted_f1score: 0.0583 - val_loss: 1.2329 - val_accuracy: 0.5528 - val_macro_f1score: 0.3264 - val_weighted_f1score: 0.0581\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.1834 - accuracy: 0.5495 - macro_f1score: 0.3364 - weighted_f1score: 0.0596 - val_loss: 1.2100 - val_accuracy: 0.5520 - val_macro_f1score: 0.3556 - val_weighted_f1score: 0.0627\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1679 - accuracy: 0.5532 - macro_f1score: 0.3456 - weighted_f1score: 0.0609 - val_loss: 1.2143 - val_accuracy: 0.5561 - val_macro_f1score: 0.3396 - val_weighted_f1score: 0.0610\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1614 - accuracy: 0.5593 - macro_f1score: 0.3522 - weighted_f1score: 0.0617 - val_loss: 1.2101 - val_accuracy: 0.5656 - val_macro_f1score: 0.3608 - val_weighted_f1score: 0.0635\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1582 - accuracy: 0.5589 - macro_f1score: 0.3521 - weighted_f1score: 0.0618 - val_loss: 1.2240 - val_accuracy: 0.5567 - val_macro_f1score: 0.3764 - val_weighted_f1score: 0.0652\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.1456 - accuracy: 0.5659 - macro_f1score: 0.3609 - weighted_f1score: 0.0631 - val_loss: 1.1933 - val_accuracy: 0.5612 - val_macro_f1score: 0.3565 - val_weighted_f1score: 0.0636\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.1334 - accuracy: 0.5687 - macro_f1score: 0.3728 - weighted_f1score: 0.0647 - val_loss: 1.1883 - val_accuracy: 0.5570 - val_macro_f1score: 0.3601 - val_weighted_f1score: 0.0634\n",
      "Epoch 25/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.1280 - accuracy: 0.5715 - macro_f1score: 0.3755 - weighted_f1score: 0.0653 - val_loss: 1.1649 - val_accuracy: 0.5709 - val_macro_f1score: 0.3710 - val_weighted_f1score: 0.0659\n",
      "Epoch 26/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1151 - accuracy: 0.5766 - macro_f1score: 0.3871 - weighted_f1score: 0.0667 - val_loss: 1.1541 - val_accuracy: 0.5737 - val_macro_f1score: 0.4095 - val_weighted_f1score: 0.0719\n",
      "Epoch 27/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1080 - accuracy: 0.5778 - macro_f1score: 0.3892 - weighted_f1score: 0.0674 - val_loss: 1.1568 - val_accuracy: 0.5690 - val_macro_f1score: 0.3800 - val_weighted_f1score: 0.0659\n",
      "Epoch 28/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.1030 - accuracy: 0.5796 - macro_f1score: 0.3914 - weighted_f1score: 0.0673 - val_loss: 1.1523 - val_accuracy: 0.5812 - val_macro_f1score: 0.3895 - val_weighted_f1score: 0.0681\n",
      "Epoch 29/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.0988 - accuracy: 0.5812 - macro_f1score: 0.3951 - weighted_f1score: 0.0678 - val_loss: 1.1488 - val_accuracy: 0.5737 - val_macro_f1score: 0.3911 - val_weighted_f1score: 0.0683\n",
      "Epoch 30/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.0867 - accuracy: 0.5877 - macro_f1score: 0.4076 - weighted_f1score: 0.0694 - val_loss: 1.1537 - val_accuracy: 0.5768 - val_macro_f1score: 0.3932 - val_weighted_f1score: 0.0689\n",
      "Epoch 31/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.0873 - accuracy: 0.5877 - macro_f1score: 0.4127 - weighted_f1score: 0.0699 - val_loss: 1.1394 - val_accuracy: 0.5798 - val_macro_f1score: 0.4110 - val_weighted_f1score: 0.0717\n",
      "Epoch 32/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.0824 - accuracy: 0.5891 - macro_f1score: 0.4129 - weighted_f1score: 0.0699 - val_loss: 1.1583 - val_accuracy: 0.5690 - val_macro_f1score: 0.3694 - val_weighted_f1score: 0.0648\n",
      "Epoch 33/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.0773 - accuracy: 0.5924 - macro_f1score: 0.4173 - weighted_f1score: 0.0709 - val_loss: 1.1043 - val_accuracy: 0.5885 - val_macro_f1score: 0.4200 - val_weighted_f1score: 0.0730\n",
      "Epoch 34/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.0749 - accuracy: 0.5889 - macro_f1score: 0.4133 - weighted_f1score: 0.0707 - val_loss: 1.1225 - val_accuracy: 0.5854 - val_macro_f1score: 0.4161 - val_weighted_f1score: 0.0724\n",
      "Epoch 35/100\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 1.0718 - accuracy: 0.5921 - macro_f1score: 0.4183 - weighted_f1score: 0.0710 - val_loss: 1.1464 - val_accuracy: 0.5740 - val_macro_f1score: 0.4156 - val_weighted_f1score: 0.0715\n",
      "Epoch 36/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.0584 - accuracy: 0.5971 - macro_f1score: 0.4289 - weighted_f1score: 0.0723 - val_loss: 1.1323 - val_accuracy: 0.5818 - val_macro_f1score: 0.4077 - val_weighted_f1score: 0.0711\n",
      "Epoch 37/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.0640 - accuracy: 0.5945 - macro_f1score: 0.4218 - weighted_f1score: 0.0712 - val_loss: 1.1298 - val_accuracy: 0.5851 - val_macro_f1score: 0.4155 - val_weighted_f1score: 0.0707\n",
      "Epoch 38/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.0548 - accuracy: 0.6012 - macro_f1score: 0.4341 - weighted_f1score: 0.0729 - val_loss: 1.1101 - val_accuracy: 0.5913 - val_macro_f1score: 0.4052 - val_weighted_f1score: 0.0707\n",
      "Epoch 39/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0545 - accuracy: 0.5987 - macro_f1score: 0.4328 - weighted_f1score: 0.0725 - val_loss: 1.1281 - val_accuracy: 0.5904 - val_macro_f1score: 0.4112 - val_weighted_f1score: 0.0721\n",
      "Epoch 40/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0520 - accuracy: 0.5970 - macro_f1score: 0.4357 - weighted_f1score: 0.0730 - val_loss: 1.1130 - val_accuracy: 0.5924 - val_macro_f1score: 0.4203 - val_weighted_f1score: 0.0723\n",
      "Epoch 41/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0408 - accuracy: 0.6032 - macro_f1score: 0.4392 - weighted_f1score: 0.0735 - val_loss: 1.1296 - val_accuracy: 0.5907 - val_macro_f1score: 0.4263 - val_weighted_f1score: 0.0731\n",
      "Epoch 42/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0427 - accuracy: 0.6037 - macro_f1score: 0.4428 - weighted_f1score: 0.0741 - val_loss: 1.1515 - val_accuracy: 0.5837 - val_macro_f1score: 0.4151 - val_weighted_f1score: 0.0715\n",
      "Epoch 43/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.0336 - accuracy: 0.6051 - macro_f1score: 0.4445 - weighted_f1score: 0.0743 - val_loss: 1.1399 - val_accuracy: 0.5712 - val_macro_f1score: 0.3881 - val_weighted_f1score: 0.0675\n",
      "Epoch 44/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0316 - accuracy: 0.6090 - macro_f1score: 0.4423 - weighted_f1score: 0.0744 - val_loss: 1.1396 - val_accuracy: 0.5793 - val_macro_f1score: 0.4123 - val_weighted_f1score: 0.0716\n",
      "Epoch 45/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0365 - accuracy: 0.6074 - macro_f1score: 0.4496 - weighted_f1score: 0.0748 - val_loss: 1.1153 - val_accuracy: 0.5985 - val_macro_f1score: 0.4079 - val_weighted_f1score: 0.0710\n",
      "Epoch 46/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0262 - accuracy: 0.6097 - macro_f1score: 0.4525 - weighted_f1score: 0.0747 - val_loss: 1.1182 - val_accuracy: 0.5963 - val_macro_f1score: 0.4355 - val_weighted_f1score: 0.0741\n",
      "Epoch 47/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.0207 - accuracy: 0.6138 - macro_f1score: 0.4558 - weighted_f1score: 0.0754 - val_loss: 1.1382 - val_accuracy: 0.5874 - val_macro_f1score: 0.4230 - val_weighted_f1score: 0.0731\n",
      "Epoch 48/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.0173 - accuracy: 0.6114 - macro_f1score: 0.4608 - weighted_f1score: 0.0761 - val_loss: 1.1202 - val_accuracy: 0.5946 - val_macro_f1score: 0.4413 - val_weighted_f1score: 0.0745\n",
      "Epoch 49/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.0163 - accuracy: 0.6131 - macro_f1score: 0.4610 - weighted_f1score: 0.0765 - val_loss: 1.1384 - val_accuracy: 0.5837 - val_macro_f1score: 0.4380 - val_weighted_f1score: 0.0741\n",
      "Epoch 50/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.0112 - accuracy: 0.6184 - macro_f1score: 0.4654 - weighted_f1score: 0.0770 - val_loss: 1.1189 - val_accuracy: 0.5885 - val_macro_f1score: 0.4311 - val_weighted_f1score: 0.0739\n",
      "Epoch 51/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.0056 - accuracy: 0.6185 - macro_f1score: 0.4635 - weighted_f1score: 0.0772 - val_loss: 1.0965 - val_accuracy: 0.6032 - val_macro_f1score: 0.4450 - val_weighted_f1score: 0.0769\n",
      "Epoch 52/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 1.0146 - accuracy: 0.6129 - macro_f1score: 0.4581 - weighted_f1score: 0.0762 - val_loss: 1.1065 - val_accuracy: 0.5932 - val_macro_f1score: 0.4617 - val_weighted_f1score: 0.0772\n",
      "Epoch 53/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0096 - accuracy: 0.6162 - macro_f1score: 0.4648 - weighted_f1score: 0.0765 - val_loss: 1.0994 - val_accuracy: 0.5979 - val_macro_f1score: 0.4427 - val_weighted_f1score: 0.0758\n",
      "Epoch 54/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0045 - accuracy: 0.6190 - macro_f1score: 0.4731 - weighted_f1score: 0.0775 - val_loss: 1.1176 - val_accuracy: 0.5971 - val_macro_f1score: 0.4362 - val_weighted_f1score: 0.0758\n",
      "Epoch 55/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9983 - accuracy: 0.6208 - macro_f1score: 0.4754 - weighted_f1score: 0.0774 - val_loss: 1.1147 - val_accuracy: 0.5979 - val_macro_f1score: 0.4402 - val_weighted_f1score: 0.0756\n",
      "Epoch 56/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9966 - accuracy: 0.6227 - macro_f1score: 0.4772 - weighted_f1score: 0.0780 - val_loss: 1.1148 - val_accuracy: 0.5932 - val_macro_f1score: 0.4338 - val_weighted_f1score: 0.0750\n",
      "Epoch 57/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.0033 - accuracy: 0.6229 - macro_f1score: 0.4722 - weighted_f1score: 0.0778 - val_loss: 1.0805 - val_accuracy: 0.6127 - val_macro_f1score: 0.4388 - val_weighted_f1score: 0.0754\n",
      "Epoch 58/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 0.9938 - accuracy: 0.6237 - macro_f1score: 0.4780 - weighted_f1score: 0.0779 - val_loss: 1.0866 - val_accuracy: 0.6035 - val_macro_f1score: 0.4588 - val_weighted_f1score: 0.0759\n",
      "Epoch 59/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9899 - accuracy: 0.6245 - macro_f1score: 0.4880 - weighted_f1score: 0.0791 - val_loss: 1.0819 - val_accuracy: 0.6077 - val_macro_f1score: 0.4518 - val_weighted_f1score: 0.0763\n",
      "Epoch 60/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9868 - accuracy: 0.6246 - macro_f1score: 0.4802 - weighted_f1score: 0.0783 - val_loss: 1.0940 - val_accuracy: 0.6102 - val_macro_f1score: 0.4652 - val_weighted_f1score: 0.0771\n",
      "Epoch 61/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 0.9907 - accuracy: 0.6268 - macro_f1score: 0.4835 - weighted_f1score: 0.0790 - val_loss: 1.1137 - val_accuracy: 0.5974 - val_macro_f1score: 0.4476 - val_weighted_f1score: 0.0753\n",
      "Epoch 62/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 0.9927 - accuracy: 0.6223 - macro_f1score: 0.4747 - weighted_f1score: 0.0782 - val_loss: 1.0986 - val_accuracy: 0.5991 - val_macro_f1score: 0.4417 - val_weighted_f1score: 0.0739\n",
      "Epoch 63/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 0.9783 - accuracy: 0.6289 - macro_f1score: 0.4910 - weighted_f1score: 0.0795 - val_loss: 1.1330 - val_accuracy: 0.5979 - val_macro_f1score: 0.4573 - val_weighted_f1score: 0.0759\n",
      "Epoch 64/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 0.9840 - accuracy: 0.6251 - macro_f1score: 0.4859 - weighted_f1score: 0.0789 - val_loss: 1.1018 - val_accuracy: 0.5974 - val_macro_f1score: 0.4421 - val_weighted_f1score: 0.0755\n",
      "Epoch 65/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9829 - accuracy: 0.6268 - macro_f1score: 0.4816 - weighted_f1score: 0.0790 - val_loss: 1.1150 - val_accuracy: 0.6018 - val_macro_f1score: 0.4667 - val_weighted_f1score: 0.0758\n",
      "Epoch 66/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9757 - accuracy: 0.6297 - macro_f1score: 0.4960 - weighted_f1score: 0.0801 - val_loss: 1.0875 - val_accuracy: 0.6004 - val_macro_f1score: 0.4592 - val_weighted_f1score: 0.0782\n",
      "Epoch 67/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 0.9765 - accuracy: 0.6295 - macro_f1score: 0.4918 - weighted_f1score: 0.0795 - val_loss: 1.1138 - val_accuracy: 0.5974 - val_macro_f1score: 0.4597 - val_weighted_f1score: 0.0785\n",
      "Epoch 68/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9745 - accuracy: 0.6269 - macro_f1score: 0.4855 - weighted_f1score: 0.0796 - val_loss: 1.1024 - val_accuracy: 0.5946 - val_macro_f1score: 0.4508 - val_weighted_f1score: 0.0755\n",
      "Epoch 69/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9700 - accuracy: 0.6292 - macro_f1score: 0.4976 - weighted_f1score: 0.0802 - val_loss: 1.1043 - val_accuracy: 0.6046 - val_macro_f1score: 0.4583 - val_weighted_f1score: 0.0770\n",
      "Epoch 70/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 0.9756 - accuracy: 0.6304 - macro_f1score: 0.4951 - weighted_f1score: 0.0800 - val_loss: 1.1042 - val_accuracy: 0.6010 - val_macro_f1score: 0.4792 - val_weighted_f1score: 0.0774\n",
      "Epoch 71/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 0.9670 - accuracy: 0.6340 - macro_f1score: 0.4937 - weighted_f1score: 0.0802 - val_loss: 1.0850 - val_accuracy: 0.6096 - val_macro_f1score: 0.4531 - val_weighted_f1score: 0.0778\n",
      "Epoch 72/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 0.9747 - accuracy: 0.6305 - macro_f1score: 0.4944 - weighted_f1score: 0.0796 - val_loss: 1.0995 - val_accuracy: 0.5996 - val_macro_f1score: 0.4481 - val_weighted_f1score: 0.0759\n",
      "Epoch 73/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9643 - accuracy: 0.6327 - macro_f1score: 0.5027 - weighted_f1score: 0.0808 - val_loss: 1.0937 - val_accuracy: 0.6016 - val_macro_f1score: 0.4516 - val_weighted_f1score: 0.0753\n",
      "Epoch 74/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 0.9602 - accuracy: 0.6376 - macro_f1score: 0.5024 - weighted_f1score: 0.0811 - val_loss: 1.0879 - val_accuracy: 0.6046 - val_macro_f1score: 0.4859 - val_weighted_f1score: 0.0782\n",
      "Epoch 75/100\n",
      "225/224 [==============================] - 30s 131ms/step - loss: 0.9619 - accuracy: 0.6335 - macro_f1score: 0.4989 - weighted_f1score: 0.0807 - val_loss: 1.1011 - val_accuracy: 0.6099 - val_macro_f1score: 0.4560 - val_weighted_f1score: 0.0768\n",
      "Epoch 76/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9559 - accuracy: 0.6351 - macro_f1score: 0.5037 - weighted_f1score: 0.0816 - val_loss: 1.0774 - val_accuracy: 0.6094 - val_macro_f1score: 0.4729 - val_weighted_f1score: 0.0784\n",
      "Epoch 77/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 0.9567 - accuracy: 0.6355 - macro_f1score: 0.5096 - weighted_f1score: 0.0814 - val_loss: 1.0731 - val_accuracy: 0.6096 - val_macro_f1score: 0.4743 - val_weighted_f1score: 0.0803\n",
      "Epoch 78/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9530 - accuracy: 0.6379 - macro_f1score: 0.5065 - weighted_f1score: 0.0820 - val_loss: 1.0993 - val_accuracy: 0.6124 - val_macro_f1score: 0.4784 - val_weighted_f1score: 0.0778\n",
      "Epoch 79/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9518 - accuracy: 0.6401 - macro_f1score: 0.5125 - weighted_f1score: 0.0819 - val_loss: 1.0814 - val_accuracy: 0.6077 - val_macro_f1score: 0.4763 - val_weighted_f1score: 0.0781\n",
      "Epoch 80/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9519 - accuracy: 0.6381 - macro_f1score: 0.5090 - weighted_f1score: 0.0821 - val_loss: 1.0862 - val_accuracy: 0.6099 - val_macro_f1score: 0.4798 - val_weighted_f1score: 0.0809\n",
      "Epoch 81/100\n",
      "225/224 [==============================] - 29s 131ms/step - loss: 0.9450 - accuracy: 0.6411 - macro_f1score: 0.5167 - weighted_f1score: 0.0830 - val_loss: 1.1148 - val_accuracy: 0.6030 - val_macro_f1score: 0.4434 - val_weighted_f1score: 0.0742\n",
      "Epoch 82/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9526 - accuracy: 0.6365 - macro_f1score: 0.5034 - weighted_f1score: 0.0815 - val_loss: 1.1145 - val_accuracy: 0.5910 - val_macro_f1score: 0.4640 - val_weighted_f1score: 0.0757\n",
      "Epoch 83/100\n",
      "225/224 [==============================] - 29s 130ms/step - loss: 0.9456 - accuracy: 0.6392 - macro_f1score: 0.5108 - weighted_f1score: 0.0823 - val_loss: 1.1015 - val_accuracy: 0.6035 - val_macro_f1score: 0.4731 - val_weighted_f1score: 0.0781\n",
      "Epoch 84/100\n",
      "225/224 [==============================] - 29s 127ms/step - loss: 0.9469 - accuracy: 0.6418 - macro_f1score: 0.5102 - weighted_f1score: 0.0822 - val_loss: 1.0832 - val_accuracy: 0.6041 - val_macro_f1score: 0.4467 - val_weighted_f1score: 0.0765\n",
      "Epoch 85/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 0.9395 - accuracy: 0.6456 - macro_f1score: 0.5220 - weighted_f1score: 0.0836 - val_loss: 1.1044 - val_accuracy: 0.6007 - val_macro_f1score: 0.4680 - val_weighted_f1score: 0.0771\n",
      "Epoch 86/100\n",
      "225/224 [==============================] - 28s 127ms/step - loss: 0.9413 - accuracy: 0.6443 - macro_f1score: 0.5222 - weighted_f1score: 0.0830 - val_loss: 1.0948 - val_accuracy: 0.6043 - val_macro_f1score: 0.4625 - val_weighted_f1score: 0.0775\n",
      "Epoch 87/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 0.9447 - accuracy: 0.6423 - macro_f1score: 0.5167 - weighted_f1score: 0.0826 - val_loss: 1.0815 - val_accuracy: 0.6082 - val_macro_f1score: 0.4809 - val_weighted_f1score: 0.0788\n",
      "Epoch 88/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 0.9486 - accuracy: 0.6384 - macro_f1score: 0.5143 - weighted_f1score: 0.0820 - val_loss: 1.0879 - val_accuracy: 0.6091 - val_macro_f1score: 0.4609 - val_weighted_f1score: 0.0759\n",
      "Epoch 89/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 0.9382 - accuracy: 0.6447 - macro_f1score: 0.5206 - weighted_f1score: 0.0833 - val_loss: 1.0646 - val_accuracy: 0.6160 - val_macro_f1score: 0.4966 - val_weighted_f1score: 0.0817\n",
      "Epoch 90/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 0.9349 - accuracy: 0.6444 - macro_f1score: 0.5226 - weighted_f1score: 0.0835 - val_loss: 1.0851 - val_accuracy: 0.6099 - val_macro_f1score: 0.4840 - val_weighted_f1score: 0.0776\n",
      "Epoch 91/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 0.9336 - accuracy: 0.6445 - macro_f1score: 0.5307 - weighted_f1score: 0.0839 - val_loss: 1.0846 - val_accuracy: 0.6096 - val_macro_f1score: 0.4613 - val_weighted_f1score: 0.0779\n",
      "Epoch 92/100\n",
      "225/224 [==============================] - 28s 124ms/step - loss: 0.9349 - accuracy: 0.6475 - macro_f1score: 0.5282 - weighted_f1score: 0.0837 - val_loss: 1.0766 - val_accuracy: 0.6002 - val_macro_f1score: 0.4846 - val_weighted_f1score: 0.0794\n",
      "Epoch 93/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 0.9245 - accuracy: 0.6487 - macro_f1score: 0.5278 - weighted_f1score: 0.0844 - val_loss: 1.0767 - val_accuracy: 0.6035 - val_macro_f1score: 0.4800 - val_weighted_f1score: 0.0796\n",
      "Epoch 94/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 0.9288 - accuracy: 0.6444 - macro_f1score: 0.5260 - weighted_f1score: 0.0842 - val_loss: 1.0880 - val_accuracy: 0.6032 - val_macro_f1score: 0.4900 - val_weighted_f1score: 0.0797\n",
      "Epoch 95/100\n",
      "225/224 [==============================] - 28s 125ms/step - loss: 0.9282 - accuracy: 0.6473 - macro_f1score: 0.5257 - weighted_f1score: 0.0834 - val_loss: 1.0804 - val_accuracy: 0.6205 - val_macro_f1score: 0.4893 - val_weighted_f1score: 0.0803\n",
      "Epoch 96/100\n",
      "225/224 [==============================] - 28s 126ms/step - loss: 0.9331 - accuracy: 0.6452 - macro_f1score: 0.5241 - weighted_f1score: 0.0834 - val_loss: 1.0897 - val_accuracy: 0.6091 - val_macro_f1score: 0.4691 - val_weighted_f1score: 0.0787\n",
      "Epoch 97/100\n",
      "225/224 [==============================] - 29s 128ms/step - loss: 0.9308 - accuracy: 0.6476 - macro_f1score: 0.5233 - weighted_f1score: 0.0841 - val_loss: 1.0921 - val_accuracy: 0.6130 - val_macro_f1score: 0.5176 - val_weighted_f1score: 0.0818\n",
      "Epoch 98/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9222 - accuracy: 0.6477 - macro_f1score: 0.5303 - weighted_f1score: 0.0842 - val_loss: 1.0996 - val_accuracy: 0.6113 - val_macro_f1score: 0.4725 - val_weighted_f1score: 0.0802\n",
      "Epoch 99/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9230 - accuracy: 0.6503 - macro_f1score: 0.5344 - weighted_f1score: 0.0847 - val_loss: 1.0767 - val_accuracy: 0.6163 - val_macro_f1score: 0.5090 - val_weighted_f1score: 0.0798\n",
      "Epoch 100/100\n",
      "225/224 [==============================] - 29s 129ms/step - loss: 0.9226 - accuracy: 0.6488 - macro_f1score: 0.5306 - weighted_f1score: 0.0846 - val_loss: 1.0991 - val_accuracy: 0.6077 - val_macro_f1score: 0.4710 - val_weighted_f1score: 0.0769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36fdca3da0>"
      ]
     },
     "execution_count": 142,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1583381486942,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "2LhCUel6QQGm",
    "outputId": "7c30ac58-b31c-4836-cfb7-b8eec850f998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 1s 141us/sample - loss: 1.0926 - accuracy: 0.6081 - macro_f1score: 0.4688 - weighted_f1score: 0.0759\n",
      "\n",
      "Accuracy: 0.6081, Macro F1 Score: 0.4688, Weighted F1 Score: 0.0759\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cBL6RgNqAlJI"
   },
   "source": [
    "#### (3) My VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Sc_Y5eMAlJI"
   },
   "outputs": [],
   "source": [
    "# VGG 19 - pretrained\n",
    "\n",
    "# 모수가 데이터에 비해 굉장히 많기 때문에 모수의 수를 좀 줄여서 확인해보자.\n",
    "# 기본은 모형을 조절하는 것이 아닌, 데이터를 뻥튀기 하는 것임을 늘 잊지말기!!\n",
    "\n",
    "model = VGG19(input_shape=(48, 48, 3), classes=7, include_top=True,pooling=None, weights = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3VwPxaHvAlJJ"
   },
   "outputs": [],
   "source": [
    "# 여기는 학습의 효율을 위해. Adam으로 넘어간다.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=['accuracy',macro_f1score,weighted_f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1215386,
     "status": "ok",
     "timestamp": 1583384538193,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "6z4eh3WPAlJL",
    "outputId": "dc3cd117-b44c-4557-9e5a-dd15bd349ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224.203125 steps, validate for 28.0390625 steps\n",
      "Epoch 1/100\n",
      "225/224 [==============================] - 32s 144ms/step - loss: 1.8127 - accuracy: 0.2494 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8784 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 2/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8111 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 3/100\n",
      "225/224 [==============================] - 31s 139ms/step - loss: 1.8112 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8808 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 4/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8110 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 5/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8113 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8794 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 6/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8109 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 7/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8783 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 8/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8801 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 9/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 10/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 11/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 12/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 13/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 14/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8794 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 15/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 16/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8817 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 17/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 18/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8108 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 19/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 20/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8106 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 21/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 22/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 23/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 24/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 25/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 26/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8107 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8783 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 27/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 28/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 29/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8109 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 30/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 31/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 32/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 33/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 34/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8782 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 35/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 36/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 37/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 38/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 39/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 40/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 41/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 42/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 43/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 44/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 45/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8784 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 46/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8105 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 47/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 48/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 49/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 50/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8794 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 51/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 52/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 53/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 54/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 55/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 56/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 57/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 58/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 59/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 60/100\n",
      "225/224 [==============================] - 31s 138ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8783 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 61/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 62/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 63/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 64/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 65/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 66/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 67/100\n",
      "225/224 [==============================] - 31s 137ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 68/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 69/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 70/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 71/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 72/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 73/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8104 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 74/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8794 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 75/100\n",
      "225/224 [==============================] - 31s 136ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 76/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 77/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 78/100\n",
      "225/224 [==============================] - 30s 132ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8797 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 79/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 80/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8791 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 81/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 82/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 83/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8795 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 84/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 85/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8787 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 86/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 87/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 88/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8789 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 89/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 90/100\n",
      "225/224 [==============================] - 30s 133ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 91/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8790 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 92/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8785 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 93/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 94/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8786 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 95/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 96/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 97/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 98/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8793 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 99/100\n",
      "225/224 [==============================] - 30s 134ms/step - loss: 1.8102 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8788 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n",
      "Epoch 100/100\n",
      "225/224 [==============================] - 30s 135ms/step - loss: 1.8103 - accuracy: 0.2514 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00 - val_loss: 1.8792 - val_accuracy: 0.2449 - val_macro_f1score: 0.0000e+00 - val_weighted_f1score: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36fd7f9f98>"
      ]
     },
     "execution_count": 146,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(datagen.flow(x_train,y_train,batch_size=128), steps_per_epoch=len(x_train)/128, validation_data= xy_valid_gen, validation_steps=len(x_valid)/128, epochs=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1583384539062,
     "user": {
      "displayName": "‍이동규[ 대학원석사과정재학 / 통계학과 ]",
      "photoUrl": "",
      "userId": "08134145419451519269"
     },
     "user_tz": -540
    },
    "id": "A5ddCE4uQQEf",
    "outputId": "1b3f277c-2918-45c1-9df9-733037351fee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3588/3588 [==============================] - 1s 152us/sample - loss: 1.8110 - accuracy: 0.2494 - macro_f1score: 0.0000e+00 - weighted_f1score: 0.0000e+00\n",
      "\n",
      "Accuracy: 0.2494, Macro F1 Score: 0.0000, Weighted F1 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "_, acc, mac_f1, wei_f1 = model.evaluate(x_test,y_test,batch_size=128)\n",
    "print(\"\\nAccuracy: {:.4f}, Macro F1 Score: {:.4f}, Weighted F1 Score: {:.4f}\".format(acc,mac_f1,wei_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqXrsxtaFGAa"
   },
   "source": [
    "## 5. Model Save & Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zYN3sg0FGAb"
   },
   "outputs": [],
   "source": [
    "#참고.\n",
    "model.save('CNN model/VGG19.h5') # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5gnyByvFGAf"
   },
   "outputs": [],
   "source": [
    "model.save_weights('CNN model/VGG19_weights.h5') # 가중치 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FzCWcJ1MFGAk"
   },
   "outputs": [],
   "source": [
    "model2 = load_model('CNN model/VGG19.h5',custom_objects={\"macro_f1score\": macro_f1score,\"weighted_f1score\":weighted_f1score}) # 모델 불러오기  custom_objects={\"\":} 로 정의했던 측도들 불러온다."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "10. FER_Aug_Basic_Models(VGG) - 2020.02.26(WED).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Basic Models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "아래 코드는 f1-score를 정의한 함수. \n",
    "tensorflow2.0 버전 이후로 f1-score 지원이 metrics애서 사라졌다.\n",
    "'''\n",
    "\n",
    "def recall(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))  # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))  # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn)\n",
    "    # (True Positive + False Negative) = 실제 값이 1(Positive) 전체\n",
    "    count_true_positive_false_negative = K.sum(y_target_yn)\n",
    "    # Recall =  (True Positive) / (True Positive + False Negative)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    recall = count_true_positive / (count_true_positive_false_negative + K.epsilon())\n",
    "    # return a single tensor value\n",
    "    return recall\n",
    "\n",
    "def precision(y_target, y_pred):\n",
    "    # clip(t, clip_value_min, clip_value_max) : clip_value_min~clip_value_max 이외 가장자리를 깎아 낸다\n",
    "    # round : 반올림한다\n",
    "    y_pred_yn = K.round(K.clip(y_pred, 0, 1))  # 예측값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    y_target_yn = K.round(K.clip(y_target, 0, 1))  # 실제값을 0(Negative) 또는 1(Positive)로 설정한다\n",
    "    # True Positive는 실제 값과 예측 값이 모두 1(Positive)인 경우이다\n",
    "    count_true_positive = K.sum(y_target_yn * y_pred_yn)\n",
    "    # (True Positive + False Positive) = 예측 값이 1(Positive) 전체\n",
    "    count_true_positive_false_positive = K.sum(y_pred_yn)\n",
    "    # Precision = (True Positive) / (True Positive + False Positive)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    precision = count_true_positive / (count_true_positive_false_positive + K.epsilon())\n",
    "    # return a single tensor value\n",
    "    return precision\n",
    "\n",
    "def f1score(y_target, y_pred):\n",
    "    _recall = recall(y_target, y_pred)\n",
    "    _precision = precision(y_target, y_pred)\n",
    "    # K.epsilon()는 'divide by zero error' 예방차원에서 작은 수를 더한다\n",
    "    _f1score = (2 * _recall * _precision) / (_recall + _precision + K.epsilon())\n",
    "    # return a single tensor value\n",
    "    return _f1score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MLP\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### 1. model - MLP ######################\n",
    "\n",
    "#data import\n",
    "x_train = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\X_train.csv\",\n",
    "                      header=0,index_col=0)\n",
    "x_valid = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\X_private_test.csv\",\n",
    "                      header=0,index_col=0)\n",
    "x_test = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\X_public_test.csv\",\n",
    "                      header=0,index_col=0)\n",
    "y_train = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\y_train.csv\",\n",
    "                      header=0,index_col=0)\n",
    "y_valid = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\y_private_test.csv\",\n",
    "                      header=0,index_col=0)\n",
    "y_test = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\y_public_test.csv\",\n",
    "                      header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data handling\n",
    "x_train = np.array(x_train).reshape([-1,48,48]) / 255\n",
    "x_valid = np.array(x_valid).reshape([-1,48,48]) / 255\n",
    "x_test = np.array(x_test).reshape([-1,48,48]) / 255\n",
    "y_train = np.array(y_train).reshape([-1,])\n",
    "y_valid = np.array(y_valid).reshape([-1,])\n",
    "y_test = np.array(y_test).reshape([-1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "classes = len(np.unique(y_test))\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model\n",
    "inputs = tf.keras.Input(shape=(48,48))\n",
    "x=tf.keras.layers.Flatten()(inputs)\n",
    "x=tf.keras.layers.Dense(units=128,activation = 'relu',name='d1')(x)\n",
    "x=tf.keras.layers.Dropout(0.3)(x)\n",
    "x=tf.keras.layers.Dense(units=512,activation = 'relu',name='d2')(x)\n",
    "x=tf.keras.layers.Dropout(0.3)(x)\n",
    "outputs = tf.keras.layers.Dense(units=classes,activation = tf.nn.softmax,name='d3')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs,outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 48, 48)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "d1 (Dense)                   (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "d2 (Dense)                   (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "d3 (Dense)                   (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 364,679\n",
      "Trainable params: 364,679\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss='sparse_categorical_crossentropy',metrics=['accuracy',f1score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28698 samples, validate on 3589 samples\n",
      "Epoch 1/15\n",
      "28698/28698 [==============================] - 4s 128us/sample - loss: 1.8227 - accuracy: 0.2439 - f1score: 0.0149 - val_loss: 1.8042 - val_accuracy: 0.2449 - val_f1score: 0.0000e+00\n",
      "Epoch 2/15\n",
      "28698/28698 [==============================] - 3s 97us/sample - loss: 1.7862 - accuracy: 0.2509 - f1score: 0.0585 - val_loss: 1.7906 - val_accuracy: 0.2449 - val_f1score: 0.0056\n",
      "Epoch 3/15\n",
      "28698/28698 [==============================] - 3s 97us/sample - loss: 1.7893 - accuracy: 0.2466 - f1score: 0.0678 - val_loss: 1.7689 - val_accuracy: 0.2449 - val_f1score: 0.0174\n",
      "Epoch 4/15\n",
      "28698/28698 [==============================] - 3s 89us/sample - loss: 1.7754 - accuracy: 0.2497 - f1score: 0.1006 - val_loss: 1.7569 - val_accuracy: 0.2792 - val_f1score: 0.0318\n",
      "Epoch 5/15\n",
      "28698/28698 [==============================] - 3s 92us/sample - loss: 1.7716 - accuracy: 0.2522 - f1score: 0.1160 - val_loss: 1.7476 - val_accuracy: 0.2792 - val_f1score: 0.0336\n",
      "Epoch 6/15\n",
      "28698/28698 [==============================] - 3s 90us/sample - loss: 1.7728 - accuracy: 0.2484 - f1score: 0.1093 - val_loss: 1.7925 - val_accuracy: 0.2343 - val_f1score: 6.2696e-04\n",
      "Epoch 7/15\n",
      "28698/28698 [==============================] - 3s 91us/sample - loss: 1.7688 - accuracy: 0.2555 - f1score: 0.1170 - val_loss: 1.7576 - val_accuracy: 0.2449 - val_f1score: 0.0336\n",
      "Epoch 8/15\n",
      "28698/28698 [==============================] - 3s 92us/sample - loss: 1.7687 - accuracy: 0.2534 - f1score: 0.1226 - val_loss: 1.7568 - val_accuracy: 0.2527 - val_f1score: 0.0289\n",
      "Epoch 9/15\n",
      "28698/28698 [==============================] - 3s 90us/sample - loss: 1.7727 - accuracy: 0.2525 - f1score: 0.1139 - val_loss: 1.7606 - val_accuracy: 0.2455 - val_f1score: 0.0246\n",
      "Epoch 10/15\n",
      "28698/28698 [==============================] - 3s 93us/sample - loss: 1.7674 - accuracy: 0.2545 - f1score: 0.1210 - val_loss: 1.7578 - val_accuracy: 0.2491 - val_f1score: 0.0349\n",
      "Epoch 11/15\n",
      "28698/28698 [==============================] - 3s 93us/sample - loss: 1.7649 - accuracy: 0.2534 - f1score: 0.1380 - val_loss: 1.7469 - val_accuracy: 0.3012 - val_f1score: 0.0325\n",
      "Epoch 12/15\n",
      "28698/28698 [==============================] - 3s 93us/sample - loss: 1.7657 - accuracy: 0.2503 - f1score: 0.1313 - val_loss: 1.7667 - val_accuracy: 0.2744 - val_f1score: 0.0246\n",
      "Epoch 13/15\n",
      "28698/28698 [==============================] - 3s 91us/sample - loss: 1.7656 - accuracy: 0.2519 - f1score: 0.1307 - val_loss: 1.7497 - val_accuracy: 0.2839 - val_f1score: 0.0616\n",
      "Epoch 14/15\n",
      "28698/28698 [==============================] - 3s 93us/sample - loss: 1.7716 - accuracy: 0.2493 - f1score: 0.1194 - val_loss: 1.7768 - val_accuracy: 0.2279 - val_f1score: 0.0227\n",
      "Epoch 15/15\n",
      "28698/28698 [==============================] - 3s 91us/sample - loss: 1.7710 - accuracy: 0.2508 - f1score: 0.1162 - val_loss: 1.7429 - val_accuracy: 0.3012 - val_f1score: 0.0467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8ac39a4e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=128, validation_data=(x_valid,y_valid) , epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP <br>\n",
    "In Epoch 8/15\n",
    "<br> \n",
    "Train // $\\quad$ Accuracy : 0.2534 $\\quad$ F1 Score : 0.1226  <br>\n",
    "Valid //  $\\quad$ Accuracy : 0.2527 $\\quad$  F1 Score : 0.0289 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#_, acc, f1 = model.evaluate(x_test,y_test, batch_size=batch_size) # early stopping으로 training에서  epoch 8번후 적용해야함.\n",
    "#print(\"\\nAccuracy: {:.4f}, F1 Score: {:.4f}\".format(acc,f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic CNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### 2. model - CNN Basic ######################\n",
    "\n",
    "#data import\n",
    "x_train = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\X_train.csv\",\n",
    "                      header=0,index_col=0)\n",
    "x_valid = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\X_private_test.csv\",\n",
    "                      header=0,index_col=0)\n",
    "x_test = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\X_public_test.csv\",\n",
    "                      header=0,index_col=0)\n",
    "y_train = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\y_train.csv\",\n",
    "                      header=0,index_col=0)\n",
    "y_valid = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\y_private_test.csv\",\n",
    "                      header=0,index_col=0)\n",
    "y_test = pd.read_csv(\"C:\\\\Users\\\\82104\\\\Desktop\\\\fer2013\\\\mydata\\\\y_public_test.csv\",\n",
    "                      header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data handling\n",
    "x_train = np.array(x_train).reshape([-1,48,48,1]) / 255\n",
    "x_valid = np.array(x_valid).reshape([-1,48,48,1]) / 255\n",
    "x_test = np.array(x_test).reshape([-1,48,48,1]) / 255\n",
    "y_train = np.array(y_train).reshape([-1,])\n",
    "y_valid = np.array(y_valid).reshape([-1,])\n",
    "y_test = np.array(y_test).reshape([-1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "image_size=48\n",
    "classes = len(np.unique(y_test))\n",
    "\n",
    "input_shape = (image_size,image_size,1)\n",
    "batch_size = 128\n",
    "kernel_size = (3,3) \n",
    "filters = 64 \n",
    "dropout = 0.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model\n",
    "cnn_model = tf.keras.models.Sequential()\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                                     activation='relu', input_shape=input_shape, strides = (1,1) , name='Conv2D_layer1'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D((2, 2), name='Maxpooling1_2D'))\n",
    "cnn_model.add(tf.keras.layers.Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "                                     activation='relu', input_shape=input_shape, strides = (1,1) , name='Conv2D_layer2'))\n",
    "cnn_model.add(tf.keras.layers.MaxPooling2D((2, 2), name='Maxpooling2_2D'))\n",
    "cnn_model.add(tf.keras.layers.Flatten(name='Flatten'))\n",
    "cnn_model.add(tf.keras.layers.Dropout(dropout))\n",
    "cnn_model.add(tf.keras.layers.Dense(64, activation='relu', name='Hidden_layer'))\n",
    "cnn_model.add(tf.keras.layers.Dense(classes, activation='softmax', name='Output_layer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv2D_layer1 (Conv2D)       (None, 46, 46, 64)        640       \n",
      "_________________________________________________________________\n",
      "Maxpooling1_2D (MaxPooling2D (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv2D_layer2 (Conv2D)       (None, 21, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "Maxpooling2_2D (MaxPooling2D (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "Flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "Hidden_layer (Dense)         (None, 64)                409664    \n",
      "_________________________________________________________________\n",
      "Output_layer (Dense)         (None, 7)                 455       \n",
      "=================================================================\n",
      "Total params: 447,687\n",
      "Trainable params: 447,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy',f1score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28698 samples, validate on 3589 samples\n",
      "Epoch 1/15\n",
      "28698/28698 [==============================] - 118s 4ms/sample - loss: 1.7035 - accuracy: 0.3190 - f1score: 0.0947 - val_loss: 1.5898 - val_accuracy: 0.3906 - val_f1score: 0.1948\n",
      "Epoch 2/15\n",
      "28698/28698 [==============================] - 113s 4ms/sample - loss: 1.5358 - accuracy: 0.4096 - f1score: 0.3287 - val_loss: 1.4740 - val_accuracy: 0.4291 - val_f1score: 0.4406\n",
      "Epoch 3/15\n",
      "28698/28698 [==============================] - 115s 4ms/sample - loss: 1.4441 - accuracy: 0.4491 - f1score: 0.4093 - val_loss: 1.4419 - val_accuracy: 0.4508 - val_f1score: 0.4819\n",
      "Epoch 4/15\n",
      "28698/28698 [==============================] - 116s 4ms/sample - loss: 1.3824 - accuracy: 0.4731 - f1score: 0.4677 - val_loss: 1.3511 - val_accuracy: 0.4781 - val_f1score: 0.4560\n",
      "Epoch 5/15\n",
      "28698/28698 [==============================] - 113s 4ms/sample - loss: 1.3374 - accuracy: 0.4925 - f1score: 0.5087 - val_loss: 1.3466 - val_accuracy: 0.4778 - val_f1score: 0.5495\n",
      "Epoch 6/15\n",
      "28698/28698 [==============================] - 118s 4ms/sample - loss: 1.2974 - accuracy: 0.5098 - f1score: 0.5382 - val_loss: 1.2973 - val_accuracy: 0.5038 - val_f1score: 0.5375\n",
      "Epoch 7/15\n",
      "28698/28698 [==============================] - 116s 4ms/sample - loss: 1.2570 - accuracy: 0.5235 - f1score: 0.5694 - val_loss: 1.2882 - val_accuracy: 0.5132 - val_f1score: 0.5713\n",
      "Epoch 8/15\n",
      "28698/28698 [==============================] - 122s 4ms/sample - loss: 1.2341 - accuracy: 0.5346 - f1score: 0.5863 - val_loss: 1.2745 - val_accuracy: 0.5130 - val_f1score: 0.5852\n",
      "Epoch 9/15\n",
      "28698/28698 [==============================] - 124s 4ms/sample - loss: 1.2050 - accuracy: 0.5455 - f1score: 0.6008 - val_loss: 1.2537 - val_accuracy: 0.5263 - val_f1score: 0.5900\n",
      "Epoch 10/15\n",
      "28698/28698 [==============================] - 122s 4ms/sample - loss: 1.1828 - accuracy: 0.5546 - f1score: 0.6231 - val_loss: 1.2411 - val_accuracy: 0.5235 - val_f1score: 0.5891\n",
      "Epoch 11/15\n",
      "28698/28698 [==============================] - 122s 4ms/sample - loss: 1.1567 - accuracy: 0.5642 - f1score: 0.6367 - val_loss: 1.2402 - val_accuracy: 0.5171 - val_f1score: 0.5794\n",
      "Epoch 12/15\n",
      "28698/28698 [==============================] - 124s 4ms/sample - loss: 1.1337 - accuracy: 0.5732 - f1score: 0.6538 - val_loss: 1.2293 - val_accuracy: 0.5336 - val_f1score: 0.6153\n",
      "Epoch 13/15\n",
      "28698/28698 [==============================] - 122s 4ms/sample - loss: 1.1098 - accuracy: 0.5822 - f1score: 0.6628 - val_loss: 1.2284 - val_accuracy: 0.5308 - val_f1score: 0.6639\n",
      "Epoch 14/15\n",
      "28698/28698 [==============================] - 125s 4ms/sample - loss: 1.0935 - accuracy: 0.5904 - f1score: 0.6752 - val_loss: 1.2291 - val_accuracy: 0.5333 - val_f1score: 0.6864\n",
      "Epoch 15/15\n",
      "28698/28698 [==============================] - 127s 4ms/sample - loss: 1.0762 - accuracy: 0.5956 - f1score: 0.6902 - val_loss: 1.2132 - val_accuracy: 0.5325 - val_f1score: 0.6545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f8aca0d5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(x_train,y_train, validation_data=(x_valid,y_valid) ,batch_size=batch_size,epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic CNN <br>\n",
    "In Epoch 6/15\n",
    "<br> \n",
    "Train // $\\quad$ Accuracy : 0.5098 $\\quad$ F1 Score : 0.5382  <br>\n",
    "Valid //  $\\quad$ Accuracy : 0.5038 $\\quad$  F1 Score : 0.5375 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, acc, f1 = cnn_model.evaluate(x_test,y_test,batch_size=batch_size) # early stopping으로 training에서 epoch 6번후 적용해야함.\n",
    "#print(\"\\nAccuracy: {:.4f}, F1 Score: {:.4f}\".format(acc,f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

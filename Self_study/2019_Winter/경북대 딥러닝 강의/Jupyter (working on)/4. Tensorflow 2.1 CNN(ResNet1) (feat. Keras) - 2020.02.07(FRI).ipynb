{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2-2 CNN(ResNet)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was used during the workshop at Kyungpook National University. <br>\n",
    "Also, the content of this material is what I learned while moving Pycham to Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : TensorFlow 2.1 Quick Start Guide (by Holdroyd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ResNet v1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "참고교재: Advanced Deep Learning with Keras\n",
    "\n",
    "예제 2-1-3. ResNet classification on the CIFAR10 dataset  \n",
    "  \n",
    "ResNet v1\n",
    "[a] Deep Residual Learning for Image Recognition\n",
    "https://arxiv.org/pdf/1512.03385.pdf\n",
    "\n",
    "ResNet v2\n",
    "[b] Identity Mappings in Deep Residual Networks\n",
    "https://arxiv.org/pdf/1603.05027.pdf\n",
    "\"\"\"\n",
    "\n",
    "# training parameters\n",
    "batch_size = 32 # orig paper trained all networks with batch_size=128\n",
    "epochs = 2 # 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3 #영역의 수. 한 영역은 6개의 층으로 구성되어있다. 그리고 2개의 층이 1개의 residual block으로 구성됨.\n",
    "\n",
    "# model version\n",
    "# orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "\n",
    "version = 1\n",
    "depth = n * 6 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ResNet20v1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# if subtract pixel mean is enabled  (데이터를 중심화 하기 위해서 뺀다 - stddev로 나눠주면 z정규화임.)\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0) # 데이터들에 대한 각 픽셀별 평균\n",
    "    x_train -= x_train_mean #중심화\n",
    "    x_test -= x_train_mean #중심화\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape) #2차원 텐서임을 확인하자.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices.\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Learning Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate는 적당한 epoch를 돌리고나면, 급격히 줄임으로써 좀더 세밀한 지역의 최적화를 이어나간다.\n",
    "# 고차원 loss function의 모습은 fractal처럼 맞물려있기 때문.\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Resnet Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우리가 쓸 resnet함수 정의.\n",
    "# 옵션으로 여러개 설정해준다.\n",
    "# 이 옵션들은 결국 tf.keras안에 있는 함수들로 연결될 것이다.\n",
    "# 편의상 아래와 같은 층의 구성이름을 resnet_layer이라 하자.\n",
    "# !!!! conv-bn-activation     or    bn-activation-conv  에 대한 함수를 만드는거임 !!!!\n",
    "# 당연하게, bn은 activation function 앞에 있어야함. 이에따라 위의 두가지 경우가 생김.\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16, #필터 개수\n",
    "                 kernel_size=3, #필터사이즈\n",
    "                 strides=1, #필터 strdie\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or   # <----------- 이런 옵션이 있음을 확인하자.\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4)) #정규화는 이렇게 사용함을 확인.\n",
    "    # tf.tensorflow.keras.regularizers.l2 임. l1, l2, l1_l2 세종류가 있음. 그밖에는 사용자정의로 만들어야함.\n",
    "    # 이 필터들(conv 층)에서 적용할 규제의 타입을 결정짓는다.\n",
    "    # tf.tensorflow.keras.activity_regularizer 도 있으며, activation function 의 모수 규제화를 진행한다. (ex. maxout)\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first: # conv_first가 맞으면, 첫번째 conv는 규제화 진행. (위에서 옵션 정의한걸 보자.)\n",
    "        x = conv(x)\n",
    "        if batch_normalization: #batch normailzation이 있으면(True), 그걸 받아 사용한다.\n",
    "            x = BatchNormalization()(x) # tf.keras.layers.BatchNormalization\n",
    "        if activation is not None: # activation이 있으면(not None), 그걸 받아 사용한다.\n",
    "            x = Activation(activation)(x) # tf.keras.layers.Activation\n",
    "                                          # conv-bn-activatio\n",
    "    else: #나머지 conv층이라면 아래를 진행.\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x) #bn-activation-conv\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Resnet v1 Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## resnet version1 에 대해 알아보자.\n",
    "# Identity Mappings in Deep Residual Networks 논문의 conv shortcut 버전임을 잊지말자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "    \n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    \n",
    "    for stack in range(3): \n",
    "\n",
    "        for res_block in range(num_res_blocks):\n",
    "\n",
    "            strides = 1\n",
    "\n",
    "            if stack > 0 and res_block == 0:  \n",
    "                strides = 2  \n",
    "\n",
    "            y = resnet_layer(inputs=x, \n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "\n",
    "\n",
    "            if stack > 0 and res_block == 0: \n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None, \n",
    "                                 batch_normalization=False)\n",
    "            x = add([x, y]) \n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "        num_filters *= 2 \n",
    "\n",
    "    x = AveragePooling2D(pool_size=8)(x) \n",
    "\n",
    "\n",
    "    y = Flatten()(x) \n",
    "    outputs = Dense(num_classes, \n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs) \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an explanation code.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "\n",
    "    ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    ex) ResNet20 0.27M\n",
    "    # 초기층 + 1영역 + 2영역 + 3영역 + 마지막층 = 20층\n",
    "    # 가장 안쪽 괄호 덧셈구조는 XW + b\n",
    "    {\n",
    "      { 3*3*3*16  + 1*1*16 } + # 초기층\n",
    "      { { 3*3*16*16 + 1*1*16 } *2 } *3 + # 1영역\n",
    "      { { 3*3*16*32 + 1*1*32 } + { 3*3*32*32 + 1*1*32}* 1  + { 3*3*32*32 + 1*1*32}* 4 } + # 2영역\n",
    "      { { 3*3*32*64 + 1*1*64 } + { 3*3*64*64 + 1*1*64}* 1  + { 3*3*64*64 + 1*1*64}* 4 } + # 3영역\n",
    "      { 64*10 + 10 } # 마지막층\n",
    "    } +\n",
    "    # 여기에 , batch normalization에 필요한 모수의 수 4개씩\n",
    "    {\n",
    "      { 16 * 4 } * 1 + # 초기층\n",
    "      { 16 * 4 } * 6 + # 1영역\n",
    "      { 32 * 4 } * 6 + # 2영역\n",
    "      { 64 * 4 } * 6 + # 3영역\n",
    "      0 # 마지막층\n",
    "    } +\n",
    "    # 마지막으로 2번째, 3번째 영역에서 x 관련 모수가 한번씩 발생.\n",
    "    {\n",
    "      { 1*1*16*32 + 32} + #2번째 영역 XW + b\n",
    "      { 1*1*32*64 + 64}  #3번째 영역 XW + b\n",
    "    }\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "\n",
    "    \n",
    "    \n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "    # resnet block은 여기선 2개의 conv층으로 구성되어있는 하나의 구조물을 의미한다.\n",
    "    # 만약 depth가 20이라면, block의 수는 3이다. 그리고 한 block에는 2개의 층이 있음.\n",
    "    # 즉 한 stack([a]논문의 색깔영역) 당 6개의 층이 있게 되는것.\n",
    "    # 또한, conv shortcut 모형에서 x의 conv층은 deep 숫자에 넣지 않는다. (resnet20의 20은 사실 x에 대한 conv연산 2개를 합쳐 22층임.)\n",
    "\n",
    "    # 우린 depth를 입력받을 것이기에, 위의 규칙을 상기하고 입력하면 된다.\n",
    "    # 2를 뺴는 이유는, 모형의 시작과 끝에 1층씩 연산을 진행하기 때문.\n",
    "\n",
    "    # 바로 아래가 1층\n",
    "    inputs = Input(shape=input_shape) #tf.keras.layers.Input\n",
    "    x = resnet_layer(inputs=inputs) # 위에서 정의한 함수 사용. conv_first = True 가 default이다.\n",
    "    #즉, conv-bn-activation.\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "\n",
    "    for stack in range(3): #서로다른 색깔영역을 3번 쌓음. 0,1,2 // (이는 논문 Deep Residual Learning for Image Recognition 모형의 색깔구분영역이다.)\n",
    "        # 0은 첫번째 영역, 1은 두번째영역, 2는 마지막영역 // 각 영역당 3개의 residual block(블럭)이 있음.\n",
    "\n",
    "        for res_block in range(num_res_blocks): # 20층 기준 각 영역(블럭)은 3개.\n",
    "            # 마찬가지로, res_block은 0,1,2 가 올 수 있다.\n",
    "\n",
    "            # 참고로 위의 for문의 조합으로는 9개의 가지가 나온다.\n",
    "            # (stack,res_block) = (0,0),(0,1),(0,2),(1,0),(1,1),(1,2),(2,0),(2,1),(2,2)\n",
    "\n",
    "            # stack=0 은 첫번째 영역이다.\n",
    "            # (0,0),(0,1),(0,2) : 첫번째 if문 pass / y를 통해 2개층씩 쌓고 / 바로 x랑 합침. (output의 차원이 같기 때문) -> 2 + 2 + 2 = 6층 (한영역에서)\n",
    "            # (1,0) : 첫번째 if문 downsample / y를 통해 2개층 쌓음 / x도 downsampling. -> 2층 (둘째 영역 첫번째 블럭에대해 진행)\n",
    "            # (1,1),(1,2) : 다시 strides = 1로 둠./ y를 통해 2개층 쌓음 / 바로 합침.  -> 2 + 2 = 4층\n",
    "            # (2,0) : 첫번째 if문 downsample / y를 통해 2개층 쌓음 / x도 downsampling. -> 2층 (마지막영역 첫번째 블럭에 대해 진행)\n",
    "            # (2,1),(2,2) :  (1,1),(1,2) 과 동일.\n",
    "            # 맨 앞과 뒤 2층 더해서 ->> 총 20층.\n",
    "\n",
    "            strides = 1\n",
    "            # 2,3 영역의 첫번째 블럭에 대해서만 downsample // 다음 영역으로 넘어갈때 feature map 1/2\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "\n",
    "            #잘보기. 아래는 if문에 안걸려있음.\n",
    "            # resnet_layer의 conv_first 옵션이 True(default) 이므로, conv-BN-activation의 순서이다.\n",
    "            y = resnet_layer(inputs=x, #두번째부터 down sample , kernel_size = 3 , strides = 2\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "\n",
    "            # 2,3 영역의 첫번째 블럭에 대해서만 downsample // 다음 영역으로 넘어갈때 feature map 1/2\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                # resnet_layer의 conv_first 옵션이 True(default) 이므로, conv-BN-activation의 순서이다.\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1, #filter size를 1로하고, strides=2로주면 feature map이 절반으로 줄어듦.\n",
    "                                 strides=strides,\n",
    "                                 activation=None, #첫번째 영역에서는 x를 아무것도 안씀.\n",
    "                                 batch_normalization=False)\n",
    "            x = add([x, y]) # tf.keras.layers.add\n",
    "            # 이 코드의 존재로 resnet이 완성됨. 그냥 결과를 더함.\n",
    "            x = Activation('relu')(x)\n",
    "\n",
    "        num_filters *= 2 #필터수는 영역당 2배씩 증가.\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x) #tf.keras.layers.AveragePooling2D\n",
    "    # 8x8 짜리 feature map을 pool_size =8로, 즉 global average pooling 한다는 소리.\n",
    "\n",
    "    # 마지막 1층\n",
    "    y = Flatten()(x) #tf.keras.layers.Flatten\n",
    "    outputs = Dense(num_classes, #tf.keras.layers.Dense\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs) #tf.keras.models.Model\n",
    "    return model\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "print(\"This is an explanation code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 32)   4640        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 32)   544         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 16, 16, 32)   0           conv2d_9[0][0]                   \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 32)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 16, 16, 32)   0           activation_8[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 32)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 16, 16, 32)   0           activation_10[0][0]              \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 8, 64)     18496       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 8, 64)     2112        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 64)     0           conv2d_16[0][0]                  \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           activation_14[0][0]              \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 64)     0           activation_16[0][0]              \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_v1(input_shape=input_shape, depth=20).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_v1(input_shape=input_shape, depth=depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)), # lr_schedule은 우리가 만든 함수로, argument로 epoch를 받음.\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Path Setting for Data and Resnet v1 Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare model model saving directory.\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type #모델의 이름을 출력\n",
    "\n",
    "if not os.path.isdir(save_dir): # save_dir경로가 없으면,\n",
    "    os.makedirs(save_dir) #폴더를 추가 시켜라.\n",
    "    \n",
    "filepath = os.path.join(save_dir, model_name) #경로에 모형을 저장할거임."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare callbacks for model saving and for learning rate adjustment.\n",
    "# 모형이 epoch를 도는 순간에는, model.save를 사용할수가 없다.\n",
    "# 이를 위해, callback이라는 기능을 제공한다. (자세한건, https://hwiyong.tistory.com/108 참고)\n",
    "# 정한 epoch, 혹은 1 epoch가 끝날때마다 함수를 저장하고, 그 저장한 함수를 다시 불러서 사용하는 방식을 취하게 된다.\n",
    "# 아래는 모델 저장하는 코드.### 4) Path Setting for Data and Resnet v1 Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=filepath, # tensorflow.keras.callback.ModelCheckpoint\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#함수를 argument로 사용한다. (우리가 만든 lr_schedule)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule) # tensorflow.keras.callback.LearningRateScheduler\n",
    "\n",
    "# learning rate(lr) decay을 행하되, 위는 '정적'에 관련된 사항이라면\n",
    "# 아래는 '동적'에 관련된 사항이다. validation loss가 더 이상 감소하지 않을 때 lr을 감소시켜주는 경우가 이에 해당하며,\n",
    "# 이 경우에도 역시 callback을 통해 더욱 진행할수 있다고 한다.\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), # tensorflow.keras.callback.ReduceLROnPlateau\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "# callbacks 에 대한 내용을 아래 세개로 하자.\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate on 10000 samples\n",
      "Learning rate:  0.001\n",
      "Epoch 1/2\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.0998 - accuracy: 0.3056WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "10/10 [==============================] - 33s 3s/step - loss: 2.0965 - accuracy: 0.2969 - val_loss: 2.2869 - val_accuracy: 0.2030\n",
      "Learning rate:  0.001\n",
      "Epoch 2/2\n",
      " 9/10 [==========================>...] - ETA: 0s - loss: 2.1160 - accuracy: 0.2882WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "10/10 [==============================] - 35s 4s/step - loss: 2.0906 - accuracy: 0.2906 - val_loss: 2.3231 - val_accuracy: 0.1871\n"
     ]
    }
   ],
   "source": [
    "# run training, with or without data augmentation.\n",
    "# 데이터 augmentation이 적용이 된경우와 아닌경우에 모델을 적합시키는데,\n",
    "# 결국 같은 모형을 쓰는 것이다.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # this will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator( #tensorflow.keras.preprocessing.image.ImageDataGenerator 함수로 flipping, cropping을 한다.\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow().\n",
    "    \n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        steps_per_epoch=10, # 주의! 돌아가는지만 확인하기 위해, 임의로 숫자를 바꿈. 원래 코드는 아래와 같다.\n",
    "                        callbacks=callbacks)\n",
    "    \n",
    "    #아래 코드를 원래 사용해야한다!\n",
    "    \"\"\"\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        steps_per_epoch=len(x_train)//batch_size,\n",
    "                        callbacks=callbacks)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 51s 5ms/sample - loss: 2.3231 - accuracy: 0.1871\n",
      "Test loss: 2.323065531158447\n",
      "Test accuracy: 0.1871\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "#결과는 당연하다... 10개이기때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Resnet1](https://arxiv.org/pdf/1512.03385.pdf)\n",
    "- [Resnet2](https://arxiv.org/pdf/1603.05027.pdf)\n",
    "- [Callback](https://hwiyong.tistory.com/108)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

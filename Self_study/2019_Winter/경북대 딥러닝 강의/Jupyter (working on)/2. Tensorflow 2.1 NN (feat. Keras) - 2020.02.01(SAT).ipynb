{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1-2 NN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*KU LeeDongGyu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was used during the workshop at Kyungpook National University. <br>\n",
    "Also, the content of this material is what I learned while moving Pycham to Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference : TensorFlow 2.1 Quick Start Guide (by Holdroyd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Example 1-2\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "참고교재: 텐서플로로 배우는 딥러닝 (박혜정, 석경하, 심주용, 황창하 공저)\n",
    "\n",
    "예제 1-2. UCI 기계학습 저장소에 있는 Wine 데이터를 이용하여 은닉층이 1개인 \n",
    "MLP 분류 알고리즘을 작성하시오. 이때 종속변수는 첫 번째 열에 있는 Wiine의 \n",
    "품종을 나타내는 class 변수이다\n",
    "(자료 위치: http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data).\n",
    "\"\"\"\n",
    "\n",
    "col_name = [\"Class\", \"Alcohol\", \"Malic_acid\",\"Ash\", \"Alcalinity_of_ash\", \n",
    "\"Magnesium\",\"Total_phenols\", \"Flavanoids\",\"Nonflavanoid_phenols\",\n",
    "\"Proanthocyanins\",\"Color_intensity\",\"Hue\",\"Diluted wines\",\"Proline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\",header=None,\n",
    "                 names=col_name,na_values=[\"NA\", \"null\", \"\"],sep=\",\")\n",
    "# \"\"도 NA취급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      "Class                   178 non-null int64\n",
      "Alcohol                 178 non-null float64\n",
      "Malic_acid              178 non-null float64\n",
      "Ash                     178 non-null float64\n",
      "Alcalinity_of_ash       178 non-null float64\n",
      "Magnesium               178 non-null int64\n",
      "Total_phenols           178 non-null float64\n",
      "Flavanoids              178 non-null float64\n",
      "Nonflavanoid_phenols    178 non-null float64\n",
      "Proanthocyanins         178 non-null float64\n",
      "Color_intensity         178 non-null float64\n",
      "Hue                     178 non-null float64\n",
      "Diluted wines           178 non-null float64\n",
      "Proline                 178 non-null int64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class     Alcohol  Malic_acid         Ash  Alcalinity_of_ash  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
       "mean     1.938202   13.000618    2.336348    2.366517          19.494944   \n",
       "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
       "min      1.000000   11.030000    0.740000    1.360000          10.600000   \n",
       "25%      1.000000   12.362500    1.602500    2.210000          17.200000   \n",
       "50%      2.000000   13.050000    1.865000    2.360000          19.500000   \n",
       "75%      3.000000   13.677500    3.082500    2.557500          21.500000   \n",
       "max      3.000000   14.830000    5.800000    3.230000          30.000000   \n",
       "\n",
       "        Magnesium  Total_phenols  Flavanoids  Nonflavanoid_phenols  \\\n",
       "count  178.000000     178.000000  178.000000            178.000000   \n",
       "mean    99.741573       2.295112    2.029270              0.361854   \n",
       "std     14.282484       0.625851    0.998859              0.124453   \n",
       "min     70.000000       0.980000    0.340000              0.130000   \n",
       "25%     88.000000       1.742500    1.205000              0.270000   \n",
       "50%     98.000000       2.355000    2.135000              0.340000   \n",
       "75%    107.000000       2.800000    2.875000              0.437500   \n",
       "max    162.000000       3.880000    5.080000              0.660000   \n",
       "\n",
       "       Proanthocyanins  Color_intensity         Hue  Diluted wines  \\\n",
       "count       178.000000       178.000000  178.000000     178.000000   \n",
       "mean          1.590899         5.058090    0.957449       2.611685   \n",
       "std           0.572359         2.318286    0.228572       0.709990   \n",
       "min           0.410000         1.280000    0.480000       1.270000   \n",
       "25%           1.250000         3.220000    0.782500       1.937500   \n",
       "50%           1.555000         4.690000    0.965000       2.780000   \n",
       "75%           1.950000         6.200000    1.120000       3.170000   \n",
       "max           3.580000        13.000000    1.710000       4.000000   \n",
       "\n",
       "           Proline  \n",
       "count   178.000000  \n",
       "mean    746.893258  \n",
       "std     314.907474  \n",
       "min     278.000000  \n",
       "25%     500.500000  \n",
       "50%     673.500000  \n",
       "75%     985.000000  \n",
       "max    1680.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                   0\n",
       "Alcohol                 0\n",
       "Malic_acid              0\n",
       "Ash                     0\n",
       "Alcalinity_of_ash       0\n",
       "Magnesium               0\n",
       "Total_phenols           0\n",
       "Flavanoids              0\n",
       "Nonflavanoid_phenols    0\n",
       "Proanthocyanins         0\n",
       "Color_intensity         0\n",
       "Hue                     0\n",
       "Diluted wines           0\n",
       "Proline                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(wine).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>Diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic_acid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color_intensity   Hue  Diluted wines  Proline  \n",
       "0             5.64  1.04           3.92     1065  \n",
       "1             4.38  1.05           3.40     1050  \n",
       "2             5.68  1.03           3.17     1185  \n",
       "3             7.80  0.86           3.45     1480  \n",
       "4             4.32  1.04           2.93      735  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.Class.value_counts()  # value_counts()함수는 값을 출력하라는 함수."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "173    3\n",
       "174    3\n",
       "175    3\n",
       "176    3\n",
       "177    3\n",
       "Name: Class, Length: 178, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.Class #Class라는 속성변수를 method로 불러옴. wine[\"Class\"] 와 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.Class = wine.Class-1 #0,1,2 로 만듦."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineX = wine[col_name[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 13)\n",
      "(124,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wineX, wine.Class, test_size=0.3, random_state=20200202)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#sklearn.model_selection에 있는 train_test_split 매서드를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax 표준화\n",
    "scaler = MinMaxScaler()\n",
    "# sklearn.preprocessing.MinMaxScaler 임.\n",
    "x_train = scaler.fit_transform(x_train) #Compute the minimum and maximum, then transform it.\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "#fit_transform 이나, fit 후 transform이나 같음. 또한 여기선 transform도 같음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== 1개 은닉층을 갖는 신경망 모형의 은닉노드 개수 결정 (start)  =====#\n",
    "# 즉, 모델 (model) selection을 하고 싶을 때, 아래의 코드를 보면됨. 이 작업은 시간이 굉장히 오래걸림.\n",
    "# 참고: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition\n",
    "\n",
    "def build_model(n_neurons=30):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(n_neurons,activation=\"tanh\",input_shape=[13])) \n",
    "    # 은닉층은 한개 , input 노드개수 13개: (,13) , output 노드개수는 n_neurons\n",
    "    model.add(tf.keras.layers.Dense(3,activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"]) \n",
    "    return model\n",
    "# model 이 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "참고: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition\n",
    "\n",
    "def build_model2(n_hidden=1,n_neurons=30,learning_rate=3e-3,input_shape=[13]):\n",
    "    model=tf.keras.models.Sequential()\n",
    "    options={\"input_shape\":input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons,activation=\"tanh\",**options))\n",
    "        options={}\n",
    "    model.add(tf.keras.layers.Dense(3,activation=\"softmax\"))\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"]) \n",
    "    return model\n",
    "\"\"\"\n",
    "\n",
    "keras_class = tf.keras.wrappers.scikit_learn.KerasClassifier(build_model,epochs=100,verbose=0)\n",
    "# grid_search를 하기 위해서 반드시 해야하는 작업. keras를 scikit_learn에사 사용할 수 있도록 함수를 감싸는 작업."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x20d6712d2b0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_distribs={\n",
    "        \"n_neurons\":np.arange(1,41) # reciprocal 상호 연속적인 랜덤변수 또는 역수 \n",
    "} \n",
    "# neuron의 수를 1부터 40까지 확인 // 사전형으로 정의해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv = RandomizedSearchCV(keras_class,para_distribs,n_iter=10,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 4ms/sample - loss: 1.0607 - accuracy: 0.5000 - val_loss: 1.0554 - val_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 1.0416 - accuracy: 0.5122 - val_loss: 1.0399 - val_accuracy: 0.4630\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 1.0219 - accuracy: 0.5366 - val_loss: 1.0249 - val_accuracy: 0.4815\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 1.0069 - accuracy: 0.5854 - val_loss: 1.0112 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.9906 - accuracy: 0.5732 - val_loss: 0.9974 - val_accuracy: 0.5185\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.9754 - accuracy: 0.5976 - val_loss: 0.9834 - val_accuracy: 0.5556\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.9624 - accuracy: 0.5976 - val_loss: 0.9697 - val_accuracy: 0.5741\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.9483 - accuracy: 0.5976 - val_loss: 0.9564 - val_accuracy: 0.6111\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 269us/sample - loss: 0.9349 - accuracy: 0.5976 - val_loss: 0.9433 - val_accuracy: 0.6481\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.9224 - accuracy: 0.6220 - val_loss: 0.9299 - val_accuracy: 0.6481\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.9094 - accuracy: 0.6341 - val_loss: 0.9171 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.8972 - accuracy: 0.6341 - val_loss: 0.9040 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8846 - accuracy: 0.6341 - val_loss: 0.8905 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.8725 - accuracy: 0.6341 - val_loss: 0.8769 - val_accuracy: 0.6852\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 288us/sample - loss: 0.8599 - accuracy: 0.6829 - val_loss: 0.8632 - val_accuracy: 0.7407\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8479 - accuracy: 0.7317 - val_loss: 0.8492 - val_accuracy: 0.7593\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8353 - accuracy: 0.7439 - val_loss: 0.8358 - val_accuracy: 0.7778\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8235 - accuracy: 0.7439 - val_loss: 0.8225 - val_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8118 - accuracy: 0.7439 - val_loss: 0.8098 - val_accuracy: 0.8519\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7998 - accuracy: 0.7561 - val_loss: 0.7972 - val_accuracy: 0.8519\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7882 - accuracy: 0.7683 - val_loss: 0.7848 - val_accuracy: 0.8519\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 329us/sample - loss: 0.7765 - accuracy: 0.7927 - val_loss: 0.7720 - val_accuracy: 0.8889\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7652 - accuracy: 0.8049 - val_loss: 0.7592 - val_accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 463us/sample - loss: 0.7534 - accuracy: 0.8171 - val_loss: 0.7464 - val_accuracy: 0.9259\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.7420 - accuracy: 0.8293 - val_loss: 0.7335 - val_accuracy: 0.9259\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7304 - accuracy: 0.8415 - val_loss: 0.7207 - val_accuracy: 0.9259\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7191 - accuracy: 0.8537 - val_loss: 0.7080 - val_accuracy: 0.9259\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7078 - accuracy: 0.8659 - val_loss: 0.6956 - val_accuracy: 0.9630\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6972 - accuracy: 0.8780 - val_loss: 0.6832 - val_accuracy: 0.9630\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.93 - 0s 281us/sample - loss: 0.6855 - accuracy: 0.8780 - val_loss: 0.6716 - val_accuracy: 0.9630\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6745 - accuracy: 0.8902 - val_loss: 0.6600 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6639 - accuracy: 0.8902 - val_loss: 0.6484 - val_accuracy: 0.9444\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6529 - accuracy: 0.8902 - val_loss: 0.6367 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6423 - accuracy: 0.8902 - val_loss: 0.6250 - val_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6316 - accuracy: 0.9024 - val_loss: 0.6134 - val_accuracy: 0.9444\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.6218 - accuracy: 0.9146 - val_loss: 0.6017 - val_accuracy: 0.9444\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6112 - accuracy: 0.9146 - val_loss: 0.5907 - val_accuracy: 0.9630\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6009 - accuracy: 0.9146 - val_loss: 0.5800 - val_accuracy: 0.9815\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.5905 - accuracy: 0.9146 - val_loss: 0.5696 - val_accuracy: 0.9815\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5808 - accuracy: 0.9268 - val_loss: 0.5592 - val_accuracy: 0.9815\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5710 - accuracy: 0.9268 - val_loss: 0.5493 - val_accuracy: 0.9815\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 238us/sample - loss: 0.5613 - accuracy: 0.9268 - val_loss: 0.5394 - val_accuracy: 0.9815\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.5519 - accuracy: 0.9268 - val_loss: 0.5294 - val_accuracy: 0.9815\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.90 - 0s 329us/sample - loss: 0.5423 - accuracy: 0.9268 - val_loss: 0.5199 - val_accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5335 - accuracy: 0.9268 - val_loss: 0.5108 - val_accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5244 - accuracy: 0.9390 - val_loss: 0.5018 - val_accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5154 - accuracy: 0.9390 - val_loss: 0.4925 - val_accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5068 - accuracy: 0.9390 - val_loss: 0.4832 - val_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4978 - accuracy: 0.9390 - val_loss: 0.4741 - val_accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4894 - accuracy: 0.9390 - val_loss: 0.4652 - val_accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.4811 - accuracy: 0.9390 - val_loss: 0.4566 - val_accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4730 - accuracy: 0.9390 - val_loss: 0.4482 - val_accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4649 - accuracy: 0.9512 - val_loss: 0.4402 - val_accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4570 - accuracy: 0.9634 - val_loss: 0.4322 - val_accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.4493 - accuracy: 0.9634 - val_loss: 0.4246 - val_accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.4416 - accuracy: 0.9634 - val_loss: 0.4170 - val_accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4341 - accuracy: 0.9634 - val_loss: 0.4095 - val_accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.4268 - accuracy: 0.9634 - val_loss: 0.4023 - val_accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.4194 - accuracy: 0.9634 - val_loss: 0.3952 - val_accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4125 - accuracy: 0.9634 - val_loss: 0.3881 - val_accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4054 - accuracy: 0.9634 - val_loss: 0.3811 - val_accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3987 - accuracy: 0.9634 - val_loss: 0.3743 - val_accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.3921 - accuracy: 0.9634 - val_loss: 0.3678 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3856 - accuracy: 0.9634 - val_loss: 0.3614 - val_accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.3794 - accuracy: 0.9634 - val_loss: 0.3554 - val_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.3730 - accuracy: 0.9634 - val_loss: 0.3497 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3668 - accuracy: 0.9634 - val_loss: 0.3439 - val_accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3609 - accuracy: 0.9634 - val_loss: 0.3385 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3549 - accuracy: 0.9634 - val_loss: 0.3332 - val_accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 248us/sample - loss: 0.3496 - accuracy: 0.9634 - val_loss: 0.3282 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 336us/sample - loss: 0.3437 - accuracy: 0.9634 - val_loss: 0.3231 - val_accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3382 - accuracy: 0.9756 - val_loss: 0.3178 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3329 - accuracy: 0.9756 - val_loss: 0.3127 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.3278 - accuracy: 0.9756 - val_loss: 0.3078 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3227 - accuracy: 0.9756 - val_loss: 0.3029 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 366us/sample - loss: 0.3176 - accuracy: 0.9756 - val_loss: 0.2983 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 328us/sample - loss: 0.3127 - accuracy: 0.9756 - val_loss: 0.2938 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3079 - accuracy: 0.9756 - val_loss: 0.2894 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3033 - accuracy: 0.9756 - val_loss: 0.2850 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.2986 - accuracy: 0.9756 - val_loss: 0.2807 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2945 - accuracy: 0.9756 - val_loss: 0.2765 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2899 - accuracy: 0.9756 - val_loss: 0.2732 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2855 - accuracy: 0.9756 - val_loss: 0.2697 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2814 - accuracy: 0.9756 - val_loss: 0.2662 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2772 - accuracy: 0.9756 - val_loss: 0.2626 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2731 - accuracy: 0.9756 - val_loss: 0.2589 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2696 - accuracy: 0.9756 - val_loss: 0.2548 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.2654 - accuracy: 0.9756 - val_loss: 0.2512 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.2617 - accuracy: 0.9756 - val_loss: 0.2483 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2580 - accuracy: 0.9756 - val_loss: 0.2452 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 206us/sample - loss: 0.2544 - accuracy: 0.9756 - val_loss: 0.2418 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.2509 - accuracy: 0.9756 - val_loss: 0.2388 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2472 - accuracy: 0.9756 - val_loss: 0.2355 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.2444 - accuracy: 0.9756 - val_loss: 0.2321 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.2407 - accuracy: 0.9756 - val_loss: 0.2295 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2374 - accuracy: 0.9756 - val_loss: 0.2268 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2342 - accuracy: 0.9756 - val_loss: 0.2240 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2313 - accuracy: 0.9756 - val_loss: 0.2211 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2281 - accuracy: 0.9878 - val_loss: 0.2185 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 246us/sample - loss: 0.2251 - accuracy: 0.9878 - val_loss: 0.2160 - val_accuracy: 0.9815\n",
      "42/42 [==============================] - 0s 119us/sample - loss: 0.2897 - accuracy: 0.9286\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1023 - accuracy: 0.3735 - val_loss: 1.1238 - val_accuracy: 0.3148\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0603 - accuracy: 0.3855 - val_loss: 1.0724 - val_accuracy: 0.3148\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0208 - accuracy: 0.3855 - val_loss: 1.0265 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9900 - accuracy: 0.3976 - val_loss: 0.9870 - val_accuracy: 0.3704\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9595 - accuracy: 0.4096 - val_loss: 0.9532 - val_accuracy: 0.3704\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9328 - accuracy: 0.4458 - val_loss: 0.9240 - val_accuracy: 0.3704\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9093 - accuracy: 0.4699 - val_loss: 0.8982 - val_accuracy: 0.4630\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8918 - accuracy: 0.4940 - val_loss: 0.8741 - val_accuracy: 0.5556\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8745 - accuracy: 0.5783 - val_loss: 0.8524 - val_accuracy: 0.5926\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.8590 - accuracy: 0.6506 - val_loss: 0.8332 - val_accuracy: 0.6481\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 337us/sample - loss: 0.8458 - accuracy: 0.7108 - val_loss: 0.8152 - val_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.8328 - accuracy: 0.7229 - val_loss: 0.7986 - val_accuracy: 0.7407\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8193 - accuracy: 0.7590 - val_loss: 0.7832 - val_accuracy: 0.8148\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8067 - accuracy: 0.7831 - val_loss: 0.7687 - val_accuracy: 0.8704\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7936 - accuracy: 0.8193 - val_loss: 0.7549 - val_accuracy: 0.9074\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7811 - accuracy: 0.8313 - val_loss: 0.7417 - val_accuracy: 0.9074\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7685 - accuracy: 0.8193 - val_loss: 0.7288 - val_accuracy: 0.9074\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7564 - accuracy: 0.8434 - val_loss: 0.7155 - val_accuracy: 0.9074\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7440 - accuracy: 0.8554 - val_loss: 0.7033 - val_accuracy: 0.9074\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7321 - accuracy: 0.8554 - val_loss: 0.6912 - val_accuracy: 0.9074\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7204 - accuracy: 0.8554 - val_loss: 0.6797 - val_accuracy: 0.9074\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7089 - accuracy: 0.8554 - val_loss: 0.6685 - val_accuracy: 0.9074\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6972 - accuracy: 0.8554 - val_loss: 0.6569 - val_accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.6860 - accuracy: 0.8554 - val_loss: 0.6456 - val_accuracy: 0.9074\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6751 - accuracy: 0.8554 - val_loss: 0.6342 - val_accuracy: 0.9074\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6640 - accuracy: 0.8554 - val_loss: 0.6230 - val_accuracy: 0.9074\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6534 - accuracy: 0.8554 - val_loss: 0.6119 - val_accuracy: 0.9074\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6425 - accuracy: 0.8675 - val_loss: 0.6005 - val_accuracy: 0.9074\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6327 - accuracy: 0.8675 - val_loss: 0.5891 - val_accuracy: 0.9259\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6224 - accuracy: 0.8675 - val_loss: 0.5784 - val_accuracy: 0.9259\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6126 - accuracy: 0.8675 - val_loss: 0.5683 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6026 - accuracy: 0.8675 - val_loss: 0.5588 - val_accuracy: 0.9444\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 236us/sample - loss: 0.5927 - accuracy: 0.8795 - val_loss: 0.5492 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5831 - accuracy: 0.8795 - val_loss: 0.5394 - val_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5738 - accuracy: 0.8795 - val_loss: 0.5300 - val_accuracy: 0.9444\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5646 - accuracy: 0.8916 - val_loss: 0.5210 - val_accuracy: 0.9444\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5555 - accuracy: 0.9036 - val_loss: 0.5119 - val_accuracy: 0.9444\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5467 - accuracy: 0.9036 - val_loss: 0.5031 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5381 - accuracy: 0.9036 - val_loss: 0.4945 - val_accuracy: 0.9444\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.5294 - accuracy: 0.9157 - val_loss: 0.4859 - val_accuracy: 0.9444\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5210 - accuracy: 0.9157 - val_loss: 0.4771 - val_accuracy: 0.9444\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 239us/sample - loss: 0.5132 - accuracy: 0.9157 - val_loss: 0.4680 - val_accuracy: 0.9444\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 251us/sample - loss: 0.5047 - accuracy: 0.9157 - val_loss: 0.4604 - val_accuracy: 0.9444\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4966 - accuracy: 0.9157 - val_loss: 0.4525 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4890 - accuracy: 0.9157 - val_loss: 0.4447 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4813 - accuracy: 0.9157 - val_loss: 0.4377 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4738 - accuracy: 0.9277 - val_loss: 0.4307 - val_accuracy: 0.9630\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 223us/sample - loss: 0.4663 - accuracy: 0.9277 - val_loss: 0.4235 - val_accuracy: 0.9630\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4591 - accuracy: 0.9277 - val_loss: 0.4169 - val_accuracy: 0.9630\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4520 - accuracy: 0.9277 - val_loss: 0.4101 - val_accuracy: 0.9630\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4452 - accuracy: 0.9277 - val_loss: 0.4035 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4385 - accuracy: 0.9277 - val_loss: 0.3974 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4316 - accuracy: 0.9277 - val_loss: 0.3908 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4249 - accuracy: 0.9277 - val_loss: 0.3843 - val_accuracy: 0.9630\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4184 - accuracy: 0.9277 - val_loss: 0.3782 - val_accuracy: 0.9630\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4122 - accuracy: 0.9277 - val_loss: 0.3720 - val_accuracy: 0.9630\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4060 - accuracy: 0.9277 - val_loss: 0.3657 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3999 - accuracy: 0.9277 - val_loss: 0.3600 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3946 - accuracy: 0.9277 - val_loss: 0.3555 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3882 - accuracy: 0.9277 - val_loss: 0.3498 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3825 - accuracy: 0.9277 - val_loss: 0.3447 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 243us/sample - loss: 0.3769 - accuracy: 0.9277 - val_loss: 0.3394 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3714 - accuracy: 0.9277 - val_loss: 0.3337 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3661 - accuracy: 0.9398 - val_loss: 0.3280 - val_accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3608 - accuracy: 0.9398 - val_loss: 0.3235 - val_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3553 - accuracy: 0.9398 - val_loss: 0.3183 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3504 - accuracy: 0.9518 - val_loss: 0.3130 - val_accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3453 - accuracy: 0.9518 - val_loss: 0.3082 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3403 - accuracy: 0.9518 - val_loss: 0.3039 - val_accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3356 - accuracy: 0.9518 - val_loss: 0.2999 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3308 - accuracy: 0.9518 - val_loss: 0.2953 - val_accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3262 - accuracy: 0.9518 - val_loss: 0.2911 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3217 - accuracy: 0.9518 - val_loss: 0.2865 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3171 - accuracy: 0.9639 - val_loss: 0.2824 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 240us/sample - loss: 0.3129 - accuracy: 0.9639 - val_loss: 0.2785 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3084 - accuracy: 0.9639 - val_loss: 0.2747 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3043 - accuracy: 0.9639 - val_loss: 0.2709 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3002 - accuracy: 0.9639 - val_loss: 0.2674 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2963 - accuracy: 0.9639 - val_loss: 0.2638 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2921 - accuracy: 0.9639 - val_loss: 0.2611 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2882 - accuracy: 0.9639 - val_loss: 0.2582 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 554us/sample - loss: 0.2844 - accuracy: 0.9639 - val_loss: 0.2550 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.2808 - accuracy: 0.9639 - val_loss: 0.2518 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2772 - accuracy: 0.9639 - val_loss: 0.2488 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2733 - accuracy: 0.9639 - val_loss: 0.2451 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2699 - accuracy: 0.9639 - val_loss: 0.2416 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2663 - accuracy: 0.9639 - val_loss: 0.2382 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2629 - accuracy: 0.9759 - val_loss: 0.2349 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2595 - accuracy: 0.9759 - val_loss: 0.2321 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2562 - accuracy: 0.9759 - val_loss: 0.2298 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2529 - accuracy: 0.9759 - val_loss: 0.2275 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2497 - accuracy: 0.9759 - val_loss: 0.2256 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2468 - accuracy: 0.9759 - val_loss: 0.2240 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2437 - accuracy: 0.9639 - val_loss: 0.2218 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2407 - accuracy: 0.9639 - val_loss: 0.2196 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2379 - accuracy: 0.9639 - val_loss: 0.2178 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2349 - accuracy: 0.9639 - val_loss: 0.2151 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2321 - accuracy: 0.9759 - val_loss: 0.2121 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2291 - accuracy: 0.9880 - val_loss: 0.2093 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2263 - accuracy: 0.9880 - val_loss: 0.2069 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.2447 - accuracy: 0.9756\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1589 - accuracy: 0.3373 - val_loss: 1.1496 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.1372 - accuracy: 0.3253 - val_loss: 1.1284 - val_accuracy: 0.3519\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.1134 - accuracy: 0.3855 - val_loss: 1.1096 - val_accuracy: 0.3889\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0939 - accuracy: 0.4096 - val_loss: 1.0922 - val_accuracy: 0.4074\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0769 - accuracy: 0.4096 - val_loss: 1.0757 - val_accuracy: 0.4444\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0613 - accuracy: 0.4458 - val_loss: 1.0600 - val_accuracy: 0.4630\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 223us/sample - loss: 1.0459 - accuracy: 0.4337 - val_loss: 1.0452 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0309 - accuracy: 0.4337 - val_loss: 1.0308 - val_accuracy: 0.5370\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0168 - accuracy: 0.4578 - val_loss: 1.0165 - val_accuracy: 0.5556\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0044 - accuracy: 0.5181 - val_loss: 1.0027 - val_accuracy: 0.5741\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9907 - accuracy: 0.5542 - val_loss: 0.9890 - val_accuracy: 0.5926\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9780 - accuracy: 0.5783 - val_loss: 0.9754 - val_accuracy: 0.6111\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9655 - accuracy: 0.5904 - val_loss: 0.9620 - val_accuracy: 0.6296\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9533 - accuracy: 0.6024 - val_loss: 0.9486 - val_accuracy: 0.6667\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9408 - accuracy: 0.6386 - val_loss: 0.9356 - val_accuracy: 0.6852\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9294 - accuracy: 0.6506 - val_loss: 0.9224 - val_accuracy: 0.6852\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9168 - accuracy: 0.6627 - val_loss: 0.9096 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9052 - accuracy: 0.6867 - val_loss: 0.8971 - val_accuracy: 0.6852\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8936 - accuracy: 0.7470 - val_loss: 0.8843 - val_accuracy: 0.7407\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8819 - accuracy: 0.7470 - val_loss: 0.8718 - val_accuracy: 0.7593\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8707 - accuracy: 0.7470 - val_loss: 0.8590 - val_accuracy: 0.7778\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8590 - accuracy: 0.7831 - val_loss: 0.8465 - val_accuracy: 0.7963\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 259us/sample - loss: 0.8474 - accuracy: 0.7952 - val_loss: 0.8343 - val_accuracy: 0.8148\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8360 - accuracy: 0.7952 - val_loss: 0.8221 - val_accuracy: 0.8519\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8250 - accuracy: 0.8193 - val_loss: 0.8098 - val_accuracy: 0.8704\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8136 - accuracy: 0.8313 - val_loss: 0.7977 - val_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8027 - accuracy: 0.8434 - val_loss: 0.7855 - val_accuracy: 0.9074\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7916 - accuracy: 0.8795 - val_loss: 0.7736 - val_accuracy: 0.9074\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7803 - accuracy: 0.8795 - val_loss: 0.7619 - val_accuracy: 0.9074\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7698 - accuracy: 0.9036 - val_loss: 0.7501 - val_accuracy: 0.9259\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7590 - accuracy: 0.9157 - val_loss: 0.7386 - val_accuracy: 0.9259\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7480 - accuracy: 0.9157 - val_loss: 0.7273 - val_accuracy: 0.9259\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7374 - accuracy: 0.9157 - val_loss: 0.7163 - val_accuracy: 0.9259\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7270 - accuracy: 0.9157 - val_loss: 0.7053 - val_accuracy: 0.9259\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7164 - accuracy: 0.9157 - val_loss: 0.6943 - val_accuracy: 0.9259\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7063 - accuracy: 0.9157 - val_loss: 0.6832 - val_accuracy: 0.9259\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6958 - accuracy: 0.9157 - val_loss: 0.6721 - val_accuracy: 0.9259\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6855 - accuracy: 0.9157 - val_loss: 0.6613 - val_accuracy: 0.9259\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6756 - accuracy: 0.9157 - val_loss: 0.6504 - val_accuracy: 0.9259\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6655 - accuracy: 0.9277 - val_loss: 0.6399 - val_accuracy: 0.9259\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6555 - accuracy: 0.9277 - val_loss: 0.6296 - val_accuracy: 0.9259\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6458 - accuracy: 0.9277 - val_loss: 0.6192 - val_accuracy: 0.9259\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6362 - accuracy: 0.9277 - val_loss: 0.6089 - val_accuracy: 0.9444\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6264 - accuracy: 0.9277 - val_loss: 0.5988 - val_accuracy: 0.9444\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6168 - accuracy: 0.9277 - val_loss: 0.5889 - val_accuracy: 0.9444\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6076 - accuracy: 0.9277 - val_loss: 0.5792 - val_accuracy: 0.9444\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5981 - accuracy: 0.9398 - val_loss: 0.5697 - val_accuracy: 0.9444\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5890 - accuracy: 0.9398 - val_loss: 0.5603 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5802 - accuracy: 0.9398 - val_loss: 0.5509 - val_accuracy: 0.9444\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5711 - accuracy: 0.9398 - val_loss: 0.5418 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5624 - accuracy: 0.9398 - val_loss: 0.5327 - val_accuracy: 0.9444\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5535 - accuracy: 0.9398 - val_loss: 0.5238 - val_accuracy: 0.9444\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5450 - accuracy: 0.9398 - val_loss: 0.5149 - val_accuracy: 0.9444\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5367 - accuracy: 0.9398 - val_loss: 0.5062 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5281 - accuracy: 0.9398 - val_loss: 0.4978 - val_accuracy: 0.9444\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5199 - accuracy: 0.9398 - val_loss: 0.4895 - val_accuracy: 0.9444\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5119 - accuracy: 0.9398 - val_loss: 0.4814 - val_accuracy: 0.9444\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5038 - accuracy: 0.9398 - val_loss: 0.4735 - val_accuracy: 0.9444\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 196us/sample - loss: 0.4961 - accuracy: 0.9398 - val_loss: 0.4656 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4884 - accuracy: 0.9398 - val_loss: 0.4578 - val_accuracy: 0.9444\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 224us/sample - loss: 0.4811 - accuracy: 0.9398 - val_loss: 0.4500 - val_accuracy: 0.9444\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4731 - accuracy: 0.9398 - val_loss: 0.4426 - val_accuracy: 0.9444\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4659 - accuracy: 0.9398 - val_loss: 0.4353 - val_accuracy: 0.9444\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4587 - accuracy: 0.9518 - val_loss: 0.4282 - val_accuracy: 0.9444\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4518 - accuracy: 0.9639 - val_loss: 0.4214 - val_accuracy: 0.9444\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.4449 - accuracy: 0.9639 - val_loss: 0.4146 - val_accuracy: 0.9444\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4380 - accuracy: 0.9639 - val_loss: 0.4077 - val_accuracy: 0.9444\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4313 - accuracy: 0.9639 - val_loss: 0.4011 - val_accuracy: 0.9444\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4247 - accuracy: 0.9639 - val_loss: 0.3944 - val_accuracy: 0.9444\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4182 - accuracy: 0.9639 - val_loss: 0.3880 - val_accuracy: 0.9444\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 350us/sample - loss: 0.4118 - accuracy: 0.9639 - val_loss: 0.3817 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4056 - accuracy: 0.9639 - val_loss: 0.3757 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3995 - accuracy: 0.9639 - val_loss: 0.3698 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3935 - accuracy: 0.9639 - val_loss: 0.3640 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3875 - accuracy: 0.9639 - val_loss: 0.3583 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3817 - accuracy: 0.9639 - val_loss: 0.3528 - val_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3760 - accuracy: 0.9639 - val_loss: 0.3474 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3704 - accuracy: 0.9639 - val_loss: 0.3420 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3650 - accuracy: 0.9639 - val_loss: 0.3368 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3595 - accuracy: 0.9639 - val_loss: 0.3316 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3543 - accuracy: 0.9639 - val_loss: 0.3264 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3492 - accuracy: 0.9639 - val_loss: 0.3213 - val_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3439 - accuracy: 0.9639 - val_loss: 0.3164 - val_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3390 - accuracy: 0.9639 - val_loss: 0.3117 - val_accuracy: 0.9444\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3341 - accuracy: 0.9639 - val_loss: 0.3072 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3295 - accuracy: 0.9639 - val_loss: 0.3026 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3246 - accuracy: 0.9639 - val_loss: 0.2984 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3200 - accuracy: 0.9759 - val_loss: 0.2940 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3157 - accuracy: 0.9759 - val_loss: 0.2898 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3109 - accuracy: 0.9759 - val_loss: 0.2860 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3067 - accuracy: 0.9759 - val_loss: 0.2822 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3026 - accuracy: 0.9759 - val_loss: 0.2784 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2983 - accuracy: 0.9759 - val_loss: 0.2745 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2943 - accuracy: 0.9759 - val_loss: 0.2705 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2902 - accuracy: 0.9759 - val_loss: 0.2666 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2863 - accuracy: 0.9759 - val_loss: 0.2630 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2824 - accuracy: 0.9759 - val_loss: 0.2597 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2787 - accuracy: 0.9759 - val_loss: 0.2562 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2750 - accuracy: 0.9759 - val_loss: 0.2530 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2713 - accuracy: 0.9759 - val_loss: 0.2497 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.2639 - accuracy: 0.9756\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 5ms/sample - loss: 1.0784 - accuracy: 0.1951 - val_loss: 1.1096 - val_accuracy: 0.2037\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.0590 - accuracy: 0.1707 - val_loss: 1.0898 - val_accuracy: 0.2037\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 348us/sample - loss: 1.0408 - accuracy: 0.1951 - val_loss: 1.0706 - val_accuracy: 0.2222\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.0226 - accuracy: 0.2317 - val_loss: 1.0522 - val_accuracy: 0.2222\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.0052 - accuracy: 0.2683 - val_loss: 1.0346 - val_accuracy: 0.2963\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9884 - accuracy: 0.3537 - val_loss: 1.0168 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9714 - accuracy: 0.4146 - val_loss: 0.9993 - val_accuracy: 0.3889\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9548 - accuracy: 0.4390 - val_loss: 0.9810 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9383 - accuracy: 0.5122 - val_loss: 0.9629 - val_accuracy: 0.5370\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.9219 - accuracy: 0.5610 - val_loss: 0.9444 - val_accuracy: 0.5556\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9055 - accuracy: 0.6585 - val_loss: 0.9265 - val_accuracy: 0.6296\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8903 - accuracy: 0.7073 - val_loss: 0.9091 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 214us/sample - loss: 0.8738 - accuracy: 0.7561 - val_loss: 0.8916 - val_accuracy: 0.7407\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8591 - accuracy: 0.7683 - val_loss: 0.8745 - val_accuracy: 0.7407\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8434 - accuracy: 0.7927 - val_loss: 0.8585 - val_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.8282 - accuracy: 0.7927 - val_loss: 0.8433 - val_accuracy: 0.7778\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8135 - accuracy: 0.8293 - val_loss: 0.8279 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.7992 - accuracy: 0.8293 - val_loss: 0.8126 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7846 - accuracy: 0.8293 - val_loss: 0.7973 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7702 - accuracy: 0.8537 - val_loss: 0.7822 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.7568 - accuracy: 0.8780 - val_loss: 0.7672 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.7255 - accuracy: 0.90 - 0s 256us/sample - loss: 0.7424 - accuracy: 0.8780 - val_loss: 0.7525 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7292 - accuracy: 0.8780 - val_loss: 0.7379 - val_accuracy: 0.8519\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.7158 - accuracy: 0.8902 - val_loss: 0.7232 - val_accuracy: 0.8519\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.7022 - accuracy: 0.9146 - val_loss: 0.7089 - val_accuracy: 0.8519\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.6887 - accuracy: 0.9390 - val_loss: 0.6953 - val_accuracy: 0.8704\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6763 - accuracy: 0.9390 - val_loss: 0.6818 - val_accuracy: 0.8889\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.6628 - accuracy: 0.9512 - val_loss: 0.6683 - val_accuracy: 0.8889\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6507 - accuracy: 0.9512 - val_loss: 0.6553 - val_accuracy: 0.8889\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6385 - accuracy: 0.9634 - val_loss: 0.6426 - val_accuracy: 0.9074\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6268 - accuracy: 0.9756 - val_loss: 0.6302 - val_accuracy: 0.8889\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6145 - accuracy: 0.9756 - val_loss: 0.6182 - val_accuracy: 0.8889\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6028 - accuracy: 0.9756 - val_loss: 0.6066 - val_accuracy: 0.9074\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5912 - accuracy: 0.9756 - val_loss: 0.5951 - val_accuracy: 0.9259\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5796 - accuracy: 0.9756 - val_loss: 0.5840 - val_accuracy: 0.9259\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5683 - accuracy: 0.9756 - val_loss: 0.5730 - val_accuracy: 0.9259\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5574 - accuracy: 0.9756 - val_loss: 0.5623 - val_accuracy: 0.9259\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5461 - accuracy: 0.9756 - val_loss: 0.5518 - val_accuracy: 0.9259\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5354 - accuracy: 0.9756 - val_loss: 0.5417 - val_accuracy: 0.9259\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.5250 - accuracy: 0.9756 - val_loss: 0.5316 - val_accuracy: 0.9259\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5145 - accuracy: 0.9756 - val_loss: 0.5216 - val_accuracy: 0.9259\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.5047 - accuracy: 0.9756 - val_loss: 0.5118 - val_accuracy: 0.9259\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4949 - accuracy: 0.9756 - val_loss: 0.5022 - val_accuracy: 0.9259\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4853 - accuracy: 0.9756 - val_loss: 0.4933 - val_accuracy: 0.9259\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.4758 - accuracy: 0.9756 - val_loss: 0.4841 - val_accuracy: 0.9259\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4665 - accuracy: 0.9756 - val_loss: 0.4751 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4573 - accuracy: 0.9756 - val_loss: 0.4665 - val_accuracy: 0.9259\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4484 - accuracy: 0.9756 - val_loss: 0.4581 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4395 - accuracy: 0.9756 - val_loss: 0.4502 - val_accuracy: 0.9444\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4312 - accuracy: 0.9756 - val_loss: 0.4422 - val_accuracy: 0.9444\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4227 - accuracy: 0.9756 - val_loss: 0.4341 - val_accuracy: 0.9444\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.4151 - accuracy: 0.9756 - val_loss: 0.4259 - val_accuracy: 0.9444\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 329us/sample - loss: 0.4065 - accuracy: 0.9756 - val_loss: 0.4184 - val_accuracy: 0.9444\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.3986 - accuracy: 0.9756 - val_loss: 0.4112 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3911 - accuracy: 0.9756 - val_loss: 0.4041 - val_accuracy: 0.9630\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.3835 - accuracy: 0.9756 - val_loss: 0.3969 - val_accuracy: 0.9630\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.3761 - accuracy: 0.9756 - val_loss: 0.3899 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3689 - accuracy: 0.9756 - val_loss: 0.3829 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3620 - accuracy: 0.9756 - val_loss: 0.3760 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.3553 - accuracy: 0.9756 - val_loss: 0.3699 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3487 - accuracy: 0.9756 - val_loss: 0.3633 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3420 - accuracy: 0.9756 - val_loss: 0.3575 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3355 - accuracy: 0.9756 - val_loss: 0.3514 - val_accuracy: 0.9630\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3293 - accuracy: 0.9756 - val_loss: 0.3453 - val_accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3233 - accuracy: 0.9756 - val_loss: 0.3398 - val_accuracy: 0.9630\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.3174 - accuracy: 0.9756 - val_loss: 0.3340 - val_accuracy: 0.9630\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3116 - accuracy: 0.9756 - val_loss: 0.3285 - val_accuracy: 0.9630\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3065 - accuracy: 0.9756 - val_loss: 0.3236 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3008 - accuracy: 0.9756 - val_loss: 0.3184 - val_accuracy: 0.9630\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2952 - accuracy: 0.9756 - val_loss: 0.3139 - val_accuracy: 0.9630\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2898 - accuracy: 0.9756 - val_loss: 0.3094 - val_accuracy: 0.9630\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2846 - accuracy: 0.9756 - val_loss: 0.3047 - val_accuracy: 0.9630\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2796 - accuracy: 0.9756 - val_loss: 0.3005 - val_accuracy: 0.9630\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2749 - accuracy: 0.9756 - val_loss: 0.2961 - val_accuracy: 0.9630\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2701 - accuracy: 0.9756 - val_loss: 0.2920 - val_accuracy: 0.9630\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2654 - accuracy: 0.9756 - val_loss: 0.2881 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2608 - accuracy: 0.9756 - val_loss: 0.2838 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2564 - accuracy: 0.9756 - val_loss: 0.2797 - val_accuracy: 0.9630\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.2520 - accuracy: 0.9756 - val_loss: 0.2755 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 247us/sample - loss: 0.2477 - accuracy: 0.9756 - val_loss: 0.2715 - val_accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2438 - accuracy: 0.9756 - val_loss: 0.2676 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2398 - accuracy: 0.9756 - val_loss: 0.2642 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.2359 - accuracy: 0.9756 - val_loss: 0.2610 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2319 - accuracy: 0.9756 - val_loss: 0.2577 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2283 - accuracy: 0.9756 - val_loss: 0.2542 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2246 - accuracy: 0.9756 - val_loss: 0.2510 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2209 - accuracy: 0.9756 - val_loss: 0.2475 - val_accuracy: 0.9630\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2174 - accuracy: 0.9756 - val_loss: 0.2443 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2141 - accuracy: 0.9756 - val_loss: 0.2412 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2107 - accuracy: 0.9756 - val_loss: 0.2383 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2075 - accuracy: 0.9756 - val_loss: 0.2355 - val_accuracy: 0.9630\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 234us/sample - loss: 0.2042 - accuracy: 0.9756 - val_loss: 0.2331 - val_accuracy: 0.9630\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2015 - accuracy: 0.9756 - val_loss: 0.2310 - val_accuracy: 0.9630\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.1981 - accuracy: 0.9756 - val_loss: 0.2282 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.1951 - accuracy: 0.9756 - val_loss: 0.2251 - val_accuracy: 0.9630\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.96 - 0s 232us/sample - loss: 0.1924 - accuracy: 0.9878 - val_loss: 0.2220 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.1896 - accuracy: 0.9878 - val_loss: 0.2197 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.1868 - accuracy: 0.9878 - val_loss: 0.2177 - val_accuracy: 0.9630\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.1841 - accuracy: 0.9878 - val_loss: 0.2159 - val_accuracy: 0.9630\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.1813 - accuracy: 0.9878 - val_loss: 0.2144 - val_accuracy: 0.9630\n",
      "42/42 [==============================] - 0s 119us/sample - loss: 0.2398 - accuracy: 0.9524\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.0483 - accuracy: 0.4217 - val_loss: 1.1091 - val_accuracy: 0.4259\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0185 - accuracy: 0.4458 - val_loss: 1.0707 - val_accuracy: 0.4259\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 232us/sample - loss: 0.9868 - accuracy: 0.4458 - val_loss: 1.0369 - val_accuracy: 0.4815\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9600 - accuracy: 0.4940 - val_loss: 1.0062 - val_accuracy: 0.5185\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9398 - accuracy: 0.5422 - val_loss: 0.9763 - val_accuracy: 0.5556\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9168 - accuracy: 0.5904 - val_loss: 0.9500 - val_accuracy: 0.5926\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8963 - accuracy: 0.6024 - val_loss: 0.9253 - val_accuracy: 0.5926\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8776 - accuracy: 0.6386 - val_loss: 0.9016 - val_accuracy: 0.6111\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8588 - accuracy: 0.6627 - val_loss: 0.8797 - val_accuracy: 0.6852\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8422 - accuracy: 0.6988 - val_loss: 0.8582 - val_accuracy: 0.7407\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8240 - accuracy: 0.7349 - val_loss: 0.8389 - val_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8076 - accuracy: 0.7711 - val_loss: 0.8203 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7904 - accuracy: 0.7711 - val_loss: 0.8028 - val_accuracy: 0.7778\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 255us/sample - loss: 0.7740 - accuracy: 0.8072 - val_loss: 0.7862 - val_accuracy: 0.7778\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7580 - accuracy: 0.8072 - val_loss: 0.7692 - val_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7419 - accuracy: 0.8313 - val_loss: 0.7534 - val_accuracy: 0.7778\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7260 - accuracy: 0.8313 - val_loss: 0.7374 - val_accuracy: 0.8148\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7108 - accuracy: 0.8675 - val_loss: 0.7219 - val_accuracy: 0.8148\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6959 - accuracy: 0.8675 - val_loss: 0.7063 - val_accuracy: 0.8333\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6809 - accuracy: 0.8916 - val_loss: 0.6918 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6665 - accuracy: 0.9036 - val_loss: 0.6783 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6525 - accuracy: 0.9036 - val_loss: 0.6648 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6386 - accuracy: 0.9036 - val_loss: 0.6509 - val_accuracy: 0.8519\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6250 - accuracy: 0.9157 - val_loss: 0.6371 - val_accuracy: 0.8519\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6120 - accuracy: 0.9157 - val_loss: 0.6225 - val_accuracy: 0.8519\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 266us/sample - loss: 0.5986 - accuracy: 0.9157 - val_loss: 0.6090 - val_accuracy: 0.8519\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.5859 - accuracy: 0.9157 - val_loss: 0.5959 - val_accuracy: 0.8704\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.5733 - accuracy: 0.9157 - val_loss: 0.5827 - val_accuracy: 0.8704\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5620 - accuracy: 0.9157 - val_loss: 0.5681 - val_accuracy: 0.8704\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5496 - accuracy: 0.9157 - val_loss: 0.5551 - val_accuracy: 0.8704\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 244us/sample - loss: 0.5379 - accuracy: 0.9277 - val_loss: 0.5433 - val_accuracy: 0.8704\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5264 - accuracy: 0.9277 - val_loss: 0.5325 - val_accuracy: 0.8704\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5155 - accuracy: 0.9277 - val_loss: 0.5215 - val_accuracy: 0.8704\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5047 - accuracy: 0.9277 - val_loss: 0.5121 - val_accuracy: 0.8704\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.4941 - accuracy: 0.9277 - val_loss: 0.5021 - val_accuracy: 0.8704\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4834 - accuracy: 0.9277 - val_loss: 0.4918 - val_accuracy: 0.8704\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4735 - accuracy: 0.9277 - val_loss: 0.4815 - val_accuracy: 0.8704\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4636 - accuracy: 0.9277 - val_loss: 0.4719 - val_accuracy: 0.8704\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4539 - accuracy: 0.9277 - val_loss: 0.4621 - val_accuracy: 0.8889\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4447 - accuracy: 0.9277 - val_loss: 0.4521 - val_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4356 - accuracy: 0.9277 - val_loss: 0.4436 - val_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4264 - accuracy: 0.9277 - val_loss: 0.4340 - val_accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4178 - accuracy: 0.9277 - val_loss: 0.4245 - val_accuracy: 0.8889\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4092 - accuracy: 0.9277 - val_loss: 0.4157 - val_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 222us/sample - loss: 0.4012 - accuracy: 0.9277 - val_loss: 0.4073 - val_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3928 - accuracy: 0.9518 - val_loss: 0.4002 - val_accuracy: 0.8889\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3849 - accuracy: 0.9398 - val_loss: 0.3932 - val_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3771 - accuracy: 0.9639 - val_loss: 0.3858 - val_accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 227us/sample - loss: 0.3701 - accuracy: 0.9639 - val_loss: 0.3779 - val_accuracy: 0.8889\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3624 - accuracy: 0.9639 - val_loss: 0.3716 - val_accuracy: 0.8889\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3552 - accuracy: 0.9639 - val_loss: 0.3655 - val_accuracy: 0.8889\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3483 - accuracy: 0.9639 - val_loss: 0.3599 - val_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3414 - accuracy: 0.9639 - val_loss: 0.3535 - val_accuracy: 0.8889\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3350 - accuracy: 0.9639 - val_loss: 0.3474 - val_accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 255us/sample - loss: 0.3285 - accuracy: 0.9639 - val_loss: 0.3410 - val_accuracy: 0.9074\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3225 - accuracy: 0.9759 - val_loss: 0.3347 - val_accuracy: 0.9074\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3165 - accuracy: 0.9759 - val_loss: 0.3281 - val_accuracy: 0.9259\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.3105 - accuracy: 0.9759 - val_loss: 0.3232 - val_accuracy: 0.9259\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3043 - accuracy: 0.9759 - val_loss: 0.3176 - val_accuracy: 0.9259\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2988 - accuracy: 0.9759 - val_loss: 0.3118 - val_accuracy: 0.9259\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2933 - accuracy: 0.9759 - val_loss: 0.3068 - val_accuracy: 0.9259\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2880 - accuracy: 0.9759 - val_loss: 0.3020 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2828 - accuracy: 0.9759 - val_loss: 0.2967 - val_accuracy: 0.9259\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2776 - accuracy: 0.9759 - val_loss: 0.2928 - val_accuracy: 0.9259\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2727 - accuracy: 0.9759 - val_loss: 0.2889 - val_accuracy: 0.9259\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2679 - accuracy: 0.9759 - val_loss: 0.2844 - val_accuracy: 0.9259\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.2631 - accuracy: 0.9759 - val_loss: 0.2803 - val_accuracy: 0.9259\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2587 - accuracy: 0.9759 - val_loss: 0.2758 - val_accuracy: 0.9259\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2542 - accuracy: 0.9759 - val_loss: 0.2719 - val_accuracy: 0.9259\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2496 - accuracy: 0.9759 - val_loss: 0.2672 - val_accuracy: 0.9259\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2458 - accuracy: 0.9759 - val_loss: 0.2621 - val_accuracy: 0.9259\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2415 - accuracy: 0.9759 - val_loss: 0.2593 - val_accuracy: 0.9259\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2373 - accuracy: 0.9759 - val_loss: 0.2555 - val_accuracy: 0.9259\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2333 - accuracy: 0.9759 - val_loss: 0.2519 - val_accuracy: 0.9259\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 231us/sample - loss: 0.2296 - accuracy: 0.9759 - val_loss: 0.2488 - val_accuracy: 0.9259\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 228us/sample - loss: 0.2256 - accuracy: 0.9759 - val_loss: 0.2462 - val_accuracy: 0.9259\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2220 - accuracy: 0.9759 - val_loss: 0.2438 - val_accuracy: 0.9259\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2185 - accuracy: 0.9759 - val_loss: 0.2413 - val_accuracy: 0.9259\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2151 - accuracy: 0.9759 - val_loss: 0.2383 - val_accuracy: 0.9259\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2116 - accuracy: 0.9759 - val_loss: 0.2341 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2081 - accuracy: 0.9880 - val_loss: 0.2294 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2050 - accuracy: 0.9880 - val_loss: 0.2250 - val_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2020 - accuracy: 0.9880 - val_loss: 0.2212 - val_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 240us/sample - loss: 0.1989 - accuracy: 0.9880 - val_loss: 0.2187 - val_accuracy: 0.9444\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.1960 - accuracy: 0.9880 - val_loss: 0.2172 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.1928 - accuracy: 0.9880 - val_loss: 0.2144 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.1900 - accuracy: 0.9880 - val_loss: 0.2126 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.1871 - accuracy: 0.9880 - val_loss: 0.2098 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.1845 - accuracy: 0.9880 - val_loss: 0.2084 - val_accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.1819 - accuracy: 0.9880 - val_loss: 0.2051 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.1789 - accuracy: 0.9880 - val_loss: 0.2030 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.1763 - accuracy: 0.9880 - val_loss: 0.2016 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.1738 - accuracy: 0.9880 - val_loss: 0.2003 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.1716 - accuracy: 0.9880 - val_loss: 0.1989 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.1691 - accuracy: 0.9880 - val_loss: 0.1963 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 274us/sample - loss: 0.1671 - accuracy: 0.9880 - val_loss: 0.1926 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 284us/sample - loss: 0.1643 - accuracy: 0.9880 - val_loss: 0.1905 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.1621 - accuracy: 0.9880 - val_loss: 0.1889 - val_accuracy: 0.9630\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.1598 - accuracy: 0.9880 - val_loss: 0.1881 - val_accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.1578 - accuracy: 0.9880 - val_loss: 0.1875 - val_accuracy: 0.9444\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.1795 - accuracy: 1.0000\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.0804 - accuracy: 0.4217 - val_loss: 1.0412 - val_accuracy: 0.4074\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 248us/sample - loss: 1.0524 - accuracy: 0.4217 - val_loss: 1.0145 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 219us/sample - loss: 1.0270 - accuracy: 0.4096 - val_loss: 0.9907 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0090 - accuracy: 0.4217 - val_loss: 0.9698 - val_accuracy: 0.5185\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9849 - accuracy: 0.4337 - val_loss: 0.9512 - val_accuracy: 0.5185\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9715 - accuracy: 0.4940 - val_loss: 0.9341 - val_accuracy: 0.5556\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9524 - accuracy: 0.5542 - val_loss: 0.9175 - val_accuracy: 0.6111\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9365 - accuracy: 0.5663 - val_loss: 0.9010 - val_accuracy: 0.6852\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9208 - accuracy: 0.6145 - val_loss: 0.8845 - val_accuracy: 0.7407\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9054 - accuracy: 0.6988 - val_loss: 0.8682 - val_accuracy: 0.7778\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8906 - accuracy: 0.7229 - val_loss: 0.8518 - val_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8755 - accuracy: 0.7590 - val_loss: 0.8358 - val_accuracy: 0.7963\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8605 - accuracy: 0.7590 - val_loss: 0.8199 - val_accuracy: 0.8519\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8460 - accuracy: 0.7952 - val_loss: 0.8043 - val_accuracy: 0.8889\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 292us/sample - loss: 0.8316 - accuracy: 0.8072 - val_loss: 0.7886 - val_accuracy: 0.9074\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.8169 - accuracy: 0.8193 - val_loss: 0.7734 - val_accuracy: 0.9074\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8030 - accuracy: 0.8193 - val_loss: 0.7583 - val_accuracy: 0.9074\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7888 - accuracy: 0.8313 - val_loss: 0.7435 - val_accuracy: 0.9259\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7748 - accuracy: 0.8434 - val_loss: 0.7291 - val_accuracy: 0.9259\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7618 - accuracy: 0.8434 - val_loss: 0.7147 - val_accuracy: 0.9259\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7483 - accuracy: 0.8554 - val_loss: 0.7010 - val_accuracy: 0.9259\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7351 - accuracy: 0.8675 - val_loss: 0.6875 - val_accuracy: 0.9259\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7224 - accuracy: 0.8795 - val_loss: 0.6742 - val_accuracy: 0.9259\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.7102 - accuracy: 0.8795 - val_loss: 0.6615 - val_accuracy: 0.9259\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 320us/sample - loss: 0.6975 - accuracy: 0.8795 - val_loss: 0.6488 - val_accuracy: 0.9259\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.6853 - accuracy: 0.8795 - val_loss: 0.6362 - val_accuracy: 0.9259\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6739 - accuracy: 0.8795 - val_loss: 0.6238 - val_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6621 - accuracy: 0.8795 - val_loss: 0.6119 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6511 - accuracy: 0.8795 - val_loss: 0.6001 - val_accuracy: 0.9630\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6396 - accuracy: 0.8795 - val_loss: 0.5886 - val_accuracy: 0.9630\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6284 - accuracy: 0.8795 - val_loss: 0.5774 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6177 - accuracy: 0.8795 - val_loss: 0.5664 - val_accuracy: 0.9444\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6074 - accuracy: 0.8795 - val_loss: 0.5557 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 506us/sample - loss: 0.5967 - accuracy: 0.8795 - val_loss: 0.5452 - val_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5864 - accuracy: 0.8795 - val_loss: 0.5349 - val_accuracy: 0.9630\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.5764 - accuracy: 0.8795 - val_loss: 0.5249 - val_accuracy: 0.9630\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.5668 - accuracy: 0.8795 - val_loss: 0.5150 - val_accuracy: 0.9630\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.5571 - accuracy: 0.8795 - val_loss: 0.5054 - val_accuracy: 0.9630\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5478 - accuracy: 0.8795 - val_loss: 0.4960 - val_accuracy: 0.9630\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5386 - accuracy: 0.9036 - val_loss: 0.4867 - val_accuracy: 0.9630\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5297 - accuracy: 0.9036 - val_loss: 0.4777 - val_accuracy: 0.9630\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5210 - accuracy: 0.9157 - val_loss: 0.4690 - val_accuracy: 0.9630\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5118 - accuracy: 0.9036 - val_loss: 0.4604 - val_accuracy: 0.9630\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5030 - accuracy: 0.9157 - val_loss: 0.4520 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4947 - accuracy: 0.9277 - val_loss: 0.4437 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4866 - accuracy: 0.9277 - val_loss: 0.4357 - val_accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4787 - accuracy: 0.9277 - val_loss: 0.4277 - val_accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4707 - accuracy: 0.9277 - val_loss: 0.4202 - val_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4629 - accuracy: 0.9398 - val_loss: 0.4126 - val_accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4552 - accuracy: 0.9398 - val_loss: 0.4054 - val_accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4480 - accuracy: 0.9398 - val_loss: 0.3982 - val_accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4404 - accuracy: 0.9518 - val_loss: 0.3912 - val_accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4334 - accuracy: 0.9518 - val_loss: 0.3842 - val_accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4264 - accuracy: 0.9398 - val_loss: 0.3773 - val_accuracy: 0.9815\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4195 - accuracy: 0.9518 - val_loss: 0.3706 - val_accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4129 - accuracy: 0.9398 - val_loss: 0.3641 - val_accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.4061 - accuracy: 0.9398 - val_loss: 0.3578 - val_accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 356us/sample - loss: 0.3997 - accuracy: 0.9398 - val_loss: 0.3516 - val_accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 795us/sample - loss: 0.3932 - accuracy: 0.9518 - val_loss: 0.3458 - val_accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 530us/sample - loss: 0.3878 - accuracy: 0.9518 - val_loss: 0.3402 - val_accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 361us/sample - loss: 0.3812 - accuracy: 0.9518 - val_loss: 0.3344 - val_accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 386us/sample - loss: 0.3749 - accuracy: 0.9518 - val_loss: 0.3288 - val_accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3692 - accuracy: 0.9518 - val_loss: 0.3232 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 566us/sample - loss: 0.3635 - accuracy: 0.9518 - val_loss: 0.3177 - val_accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3578 - accuracy: 0.9518 - val_loss: 0.3125 - val_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3525 - accuracy: 0.9518 - val_loss: 0.3072 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 290us/sample - loss: 0.3470 - accuracy: 0.9518 - val_loss: 0.3023 - val_accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 283us/sample - loss: 0.3417 - accuracy: 0.9518 - val_loss: 0.2971 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 271us/sample - loss: 0.3363 - accuracy: 0.9518 - val_loss: 0.2924 - val_accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3313 - accuracy: 0.9518 - val_loss: 0.2878 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3262 - accuracy: 0.9639 - val_loss: 0.2831 - val_accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3214 - accuracy: 0.9639 - val_loss: 0.2786 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3164 - accuracy: 0.9639 - val_loss: 0.2744 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3119 - accuracy: 0.9759 - val_loss: 0.2702 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3072 - accuracy: 0.9759 - val_loss: 0.2661 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3028 - accuracy: 0.9759 - val_loss: 0.2620 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2983 - accuracy: 0.9759 - val_loss: 0.2577 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2937 - accuracy: 0.9759 - val_loss: 0.2535 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2894 - accuracy: 0.9759 - val_loss: 0.2495 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2855 - accuracy: 0.9639 - val_loss: 0.2455 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2817 - accuracy: 0.9639 - val_loss: 0.2418 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2775 - accuracy: 0.9639 - val_loss: 0.2383 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2734 - accuracy: 0.9639 - val_loss: 0.2348 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2698 - accuracy: 0.9639 - val_loss: 0.2316 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2657 - accuracy: 0.9759 - val_loss: 0.2283 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2618 - accuracy: 0.9759 - val_loss: 0.2249 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2586 - accuracy: 0.9639 - val_loss: 0.2214 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 258us/sample - loss: 0.2546 - accuracy: 0.9759 - val_loss: 0.2186 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2509 - accuracy: 0.9759 - val_loss: 0.2157 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2474 - accuracy: 0.9759 - val_loss: 0.2130 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2441 - accuracy: 0.9759 - val_loss: 0.2102 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2411 - accuracy: 0.9759 - val_loss: 0.2077 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2375 - accuracy: 0.9759 - val_loss: 0.2046 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2344 - accuracy: 0.9759 - val_loss: 0.2016 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2311 - accuracy: 0.9759 - val_loss: 0.1989 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2282 - accuracy: 0.9759 - val_loss: 0.1964 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2250 - accuracy: 0.9759 - val_loss: 0.1939 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2222 - accuracy: 0.9759 - val_loss: 0.1914 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2194 - accuracy: 0.9759 - val_loss: 0.1889 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2164 - accuracy: 0.9759 - val_loss: 0.1858 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 259us/sample - loss: 0.2190 - accuracy: 0.9512\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 4ms/sample - loss: 1.2282 - accuracy: 0.1585 - val_loss: 1.1965 - val_accuracy: 0.2222\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.1827 - accuracy: 0.0976 - val_loss: 1.1628 - val_accuracy: 0.1481\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.1406 - accuracy: 0.1463 - val_loss: 1.1330 - val_accuracy: 0.1667\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.1054 - accuracy: 0.2561 - val_loss: 1.1070 - val_accuracy: 0.4074\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.0787 - accuracy: 0.4512 - val_loss: 1.0836 - val_accuracy: 0.4444\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 1.0496 - accuracy: 0.5366 - val_loss: 1.0628 - val_accuracy: 0.4630\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.0282 - accuracy: 0.5732 - val_loss: 1.0435 - val_accuracy: 0.4815\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 1.0071 - accuracy: 0.6098 - val_loss: 1.0261 - val_accuracy: 0.4815\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9869 - accuracy: 0.6098 - val_loss: 1.0097 - val_accuracy: 0.4815\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9702 - accuracy: 0.6220 - val_loss: 0.9940 - val_accuracy: 0.4815\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9545 - accuracy: 0.6585 - val_loss: 0.9781 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9384 - accuracy: 0.6707 - val_loss: 0.9617 - val_accuracy: 0.5185\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9226 - accuracy: 0.6829 - val_loss: 0.9448 - val_accuracy: 0.5741\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9078 - accuracy: 0.7317 - val_loss: 0.9280 - val_accuracy: 0.5741\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.8924 - accuracy: 0.7439 - val_loss: 0.9115 - val_accuracy: 0.5926\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.8780 - accuracy: 0.7439 - val_loss: 0.8947 - val_accuracy: 0.6111\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.8633 - accuracy: 0.7317 - val_loss: 0.8787 - val_accuracy: 0.6852\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8495 - accuracy: 0.7317 - val_loss: 0.8626 - val_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 250us/sample - loss: 0.8350 - accuracy: 0.7317 - val_loss: 0.8470 - val_accuracy: 0.7407\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.8215 - accuracy: 0.7317 - val_loss: 0.8314 - val_accuracy: 0.7778\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.8074 - accuracy: 0.7439 - val_loss: 0.8162 - val_accuracy: 0.8148\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.7941 - accuracy: 0.7683 - val_loss: 0.8011 - val_accuracy: 0.8519\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7809 - accuracy: 0.7927 - val_loss: 0.7865 - val_accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7672 - accuracy: 0.8171 - val_loss: 0.7717 - val_accuracy: 0.9074\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7538 - accuracy: 0.8415 - val_loss: 0.7573 - val_accuracy: 0.9074\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7410 - accuracy: 0.8537 - val_loss: 0.7432 - val_accuracy: 0.9259\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.7279 - accuracy: 0.8659 - val_loss: 0.7298 - val_accuracy: 0.9259\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.7148 - accuracy: 0.8780 - val_loss: 0.7161 - val_accuracy: 0.9259\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 260us/sample - loss: 0.7021 - accuracy: 0.9024 - val_loss: 0.7022 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 225us/sample - loss: 0.6893 - accuracy: 0.9268 - val_loss: 0.6886 - val_accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6774 - accuracy: 0.9268 - val_loss: 0.6751 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6645 - accuracy: 0.9390 - val_loss: 0.6616 - val_accuracy: 0.9444\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6525 - accuracy: 0.9390 - val_loss: 0.6485 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6402 - accuracy: 0.9390 - val_loss: 0.6352 - val_accuracy: 0.9259\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 257us/sample - loss: 0.6282 - accuracy: 0.9390 - val_loss: 0.6220 - val_accuracy: 0.9259\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 243us/sample - loss: 0.6163 - accuracy: 0.9512 - val_loss: 0.6092 - val_accuracy: 0.9259\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6047 - accuracy: 0.9512 - val_loss: 0.5965 - val_accuracy: 0.9259\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.5931 - accuracy: 0.9512 - val_loss: 0.5842 - val_accuracy: 0.9259\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5820 - accuracy: 0.9634 - val_loss: 0.5724 - val_accuracy: 0.9259\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5704 - accuracy: 0.9756 - val_loss: 0.5607 - val_accuracy: 0.9259\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 330us/sample - loss: 0.5594 - accuracy: 0.9756 - val_loss: 0.5491 - val_accuracy: 0.9259\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.5485 - accuracy: 0.9756 - val_loss: 0.5379 - val_accuracy: 0.9259\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5377 - accuracy: 0.9756 - val_loss: 0.5270 - val_accuracy: 0.9259\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5279 - accuracy: 0.9756 - val_loss: 0.5168 - val_accuracy: 0.9259\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5170 - accuracy: 0.9756 - val_loss: 0.5060 - val_accuracy: 0.9259\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 233us/sample - loss: 0.5066 - accuracy: 0.9756 - val_loss: 0.4954 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4968 - accuracy: 0.9756 - val_loss: 0.4851 - val_accuracy: 0.9259\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4871 - accuracy: 0.9878 - val_loss: 0.4747 - val_accuracy: 0.9444\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4774 - accuracy: 0.9878 - val_loss: 0.4649 - val_accuracy: 0.9444\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.4682 - accuracy: 0.9878 - val_loss: 0.4552 - val_accuracy: 0.9630\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4593 - accuracy: 0.9878 - val_loss: 0.4459 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4502 - accuracy: 0.9878 - val_loss: 0.4370 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4417 - accuracy: 0.9878 - val_loss: 0.4282 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4330 - accuracy: 0.9878 - val_loss: 0.4197 - val_accuracy: 0.9630\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4245 - accuracy: 0.9878 - val_loss: 0.4116 - val_accuracy: 0.9630\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4166 - accuracy: 0.9878 - val_loss: 0.4034 - val_accuracy: 0.9630\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4082 - accuracy: 0.9878 - val_loss: 0.3959 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4004 - accuracy: 0.9878 - val_loss: 0.3888 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3925 - accuracy: 0.9878 - val_loss: 0.3821 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3855 - accuracy: 0.9878 - val_loss: 0.3761 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3786 - accuracy: 0.9756 - val_loss: 0.3699 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3712 - accuracy: 0.9878 - val_loss: 0.3631 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3643 - accuracy: 0.9878 - val_loss: 0.3569 - val_accuracy: 0.9630\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.3577 - accuracy: 0.9878 - val_loss: 0.3505 - val_accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3512 - accuracy: 0.9878 - val_loss: 0.3435 - val_accuracy: 0.9630\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3445 - accuracy: 0.9878 - val_loss: 0.3371 - val_accuracy: 0.9630\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3380 - accuracy: 0.9878 - val_loss: 0.3312 - val_accuracy: 0.9630\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3320 - accuracy: 0.9878 - val_loss: 0.3253 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3259 - accuracy: 0.9878 - val_loss: 0.3197 - val_accuracy: 0.9630\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.3202 - accuracy: 0.9878 - val_loss: 0.3141 - val_accuracy: 0.9630\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.3147 - accuracy: 0.9878 - val_loss: 0.3085 - val_accuracy: 0.9630\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3092 - accuracy: 0.9878 - val_loss: 0.3037 - val_accuracy: 0.9630\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.3035 - accuracy: 0.9878 - val_loss: 0.2984 - val_accuracy: 0.9630\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2983 - accuracy: 0.9878 - val_loss: 0.2933 - val_accuracy: 0.9630\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2931 - accuracy: 0.9878 - val_loss: 0.2886 - val_accuracy: 0.9630\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2883 - accuracy: 0.9878 - val_loss: 0.2838 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 299us/sample - loss: 0.2836 - accuracy: 0.9878 - val_loss: 0.2799 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.2786 - accuracy: 0.9878 - val_loss: 0.2754 - val_accuracy: 0.9630\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.2739 - accuracy: 0.9878 - val_loss: 0.2710 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 378us/sample - loss: 0.2694 - accuracy: 0.9878 - val_loss: 0.2668 - val_accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 295us/sample - loss: 0.2649 - accuracy: 0.9878 - val_loss: 0.2630 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.2607 - accuracy: 0.9878 - val_loss: 0.2593 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2566 - accuracy: 0.9878 - val_loss: 0.2562 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.2524 - accuracy: 0.9878 - val_loss: 0.2528 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2483 - accuracy: 0.9878 - val_loss: 0.2491 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.2446 - accuracy: 0.9878 - val_loss: 0.2460 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2408 - accuracy: 0.9878 - val_loss: 0.2424 - val_accuracy: 0.9630\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.2370 - accuracy: 0.9878 - val_loss: 0.2395 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.2332 - accuracy: 0.9878 - val_loss: 0.2362 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2298 - accuracy: 0.9878 - val_loss: 0.2332 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2264 - accuracy: 0.9878 - val_loss: 0.2300 - val_accuracy: 0.9630\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2229 - accuracy: 0.9878 - val_loss: 0.2271 - val_accuracy: 0.9630\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2198 - accuracy: 0.9878 - val_loss: 0.2246 - val_accuracy: 0.9630\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.2163 - accuracy: 0.9878 - val_loss: 0.2220 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2132 - accuracy: 0.9878 - val_loss: 0.2193 - val_accuracy: 0.9630\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2100 - accuracy: 0.9878 - val_loss: 0.2169 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2071 - accuracy: 0.9878 - val_loss: 0.2148 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 222us/sample - loss: 0.2041 - accuracy: 0.9878 - val_loss: 0.2125 - val_accuracy: 0.9630\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2011 - accuracy: 0.9878 - val_loss: 0.2102 - val_accuracy: 0.9630\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.1983 - accuracy: 0.9878 - val_loss: 0.2074 - val_accuracy: 0.9630\n",
      "42/42 [==============================] - 0s 119us/sample - loss: 0.2581 - accuracy: 0.9524\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 5ms/sample - loss: 1.1213 - accuracy: 0.2892 - val_loss: 1.1378 - val_accuracy: 0.2778\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0861 - accuracy: 0.3133 - val_loss: 1.1054 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0568 - accuracy: 0.4096 - val_loss: 1.0751 - val_accuracy: 0.4630\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0302 - accuracy: 0.5060 - val_loss: 1.0482 - val_accuracy: 0.5370\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0061 - accuracy: 0.6265 - val_loss: 1.0234 - val_accuracy: 0.6111\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9831 - accuracy: 0.6747 - val_loss: 1.0024 - val_accuracy: 0.6111\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9641 - accuracy: 0.6627 - val_loss: 0.9819 - val_accuracy: 0.6296\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 228us/sample - loss: 0.9473 - accuracy: 0.6867 - val_loss: 0.9628 - val_accuracy: 0.6296\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9301 - accuracy: 0.6988 - val_loss: 0.9445 - val_accuracy: 0.6296\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9142 - accuracy: 0.6627 - val_loss: 0.9268 - val_accuracy: 0.6296\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.8994 - accuracy: 0.6747 - val_loss: 0.9098 - val_accuracy: 0.6296\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8847 - accuracy: 0.6747 - val_loss: 0.8942 - val_accuracy: 0.6296\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8703 - accuracy: 0.6988 - val_loss: 0.8782 - val_accuracy: 0.6667\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8557 - accuracy: 0.7349 - val_loss: 0.8628 - val_accuracy: 0.6852\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8418 - accuracy: 0.7590 - val_loss: 0.8483 - val_accuracy: 0.7407\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8276 - accuracy: 0.7711 - val_loss: 0.8331 - val_accuracy: 0.7778\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8139 - accuracy: 0.8193 - val_loss: 0.8183 - val_accuracy: 0.7963\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8007 - accuracy: 0.8434 - val_loss: 0.8032 - val_accuracy: 0.7963\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7864 - accuracy: 0.8795 - val_loss: 0.7892 - val_accuracy: 0.7963\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.7732 - accuracy: 0.8795 - val_loss: 0.7755 - val_accuracy: 0.7963\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7599 - accuracy: 0.8916 - val_loss: 0.7613 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7465 - accuracy: 0.8916 - val_loss: 0.7478 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7333 - accuracy: 0.8916 - val_loss: 0.7341 - val_accuracy: 0.8519\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7207 - accuracy: 0.9036 - val_loss: 0.7203 - val_accuracy: 0.8519\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7076 - accuracy: 0.9157 - val_loss: 0.7074 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6946 - accuracy: 0.9157 - val_loss: 0.6945 - val_accuracy: 0.8704\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6825 - accuracy: 0.9157 - val_loss: 0.6815 - val_accuracy: 0.8704\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.6698 - accuracy: 0.9157 - val_loss: 0.6686 - val_accuracy: 0.9074\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6577 - accuracy: 0.9157 - val_loss: 0.6559 - val_accuracy: 0.9074\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6454 - accuracy: 0.9157 - val_loss: 0.6435 - val_accuracy: 0.9074\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6335 - accuracy: 0.9277 - val_loss: 0.6314 - val_accuracy: 0.9074\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.6215 - accuracy: 0.9277 - val_loss: 0.6199 - val_accuracy: 0.9074\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6100 - accuracy: 0.9277 - val_loss: 0.6086 - val_accuracy: 0.9074\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5989 - accuracy: 0.9277 - val_loss: 0.5978 - val_accuracy: 0.9074\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5872 - accuracy: 0.9277 - val_loss: 0.5864 - val_accuracy: 0.9074\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5763 - accuracy: 0.9277 - val_loss: 0.5750 - val_accuracy: 0.9259\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5652 - accuracy: 0.9398 - val_loss: 0.5633 - val_accuracy: 0.9259\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5544 - accuracy: 0.9398 - val_loss: 0.5521 - val_accuracy: 0.9259\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5440 - accuracy: 0.9398 - val_loss: 0.5413 - val_accuracy: 0.9259\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5334 - accuracy: 0.9398 - val_loss: 0.5308 - val_accuracy: 0.9259\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5235 - accuracy: 0.9398 - val_loss: 0.5204 - val_accuracy: 0.9259\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5134 - accuracy: 0.9398 - val_loss: 0.5111 - val_accuracy: 0.9259\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5037 - accuracy: 0.9398 - val_loss: 0.5015 - val_accuracy: 0.9259\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4944 - accuracy: 0.9398 - val_loss: 0.4914 - val_accuracy: 0.9259\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4848 - accuracy: 0.9398 - val_loss: 0.4821 - val_accuracy: 0.9259\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4758 - accuracy: 0.9398 - val_loss: 0.4726 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4667 - accuracy: 0.9518 - val_loss: 0.4633 - val_accuracy: 0.9259\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4581 - accuracy: 0.9518 - val_loss: 0.4543 - val_accuracy: 0.9259\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4495 - accuracy: 0.9518 - val_loss: 0.4451 - val_accuracy: 0.9259\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4410 - accuracy: 0.9518 - val_loss: 0.4363 - val_accuracy: 0.9259\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4329 - accuracy: 0.9518 - val_loss: 0.4278 - val_accuracy: 0.9259\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4249 - accuracy: 0.9518 - val_loss: 0.4201 - val_accuracy: 0.9259\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4171 - accuracy: 0.9518 - val_loss: 0.4126 - val_accuracy: 0.9259\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4099 - accuracy: 0.9518 - val_loss: 0.4044 - val_accuracy: 0.9444\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4020 - accuracy: 0.9518 - val_loss: 0.3974 - val_accuracy: 0.9444\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3947 - accuracy: 0.9518 - val_loss: 0.3901 - val_accuracy: 0.9444\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3876 - accuracy: 0.9518 - val_loss: 0.3831 - val_accuracy: 0.9444\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3806 - accuracy: 0.9518 - val_loss: 0.3764 - val_accuracy: 0.9444\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3739 - accuracy: 0.9518 - val_loss: 0.3699 - val_accuracy: 0.9444\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3672 - accuracy: 0.9518 - val_loss: 0.3628 - val_accuracy: 0.9444\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3607 - accuracy: 0.9518 - val_loss: 0.3559 - val_accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3545 - accuracy: 0.9518 - val_loss: 0.3498 - val_accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3483 - accuracy: 0.9518 - val_loss: 0.3432 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3422 - accuracy: 0.9518 - val_loss: 0.3371 - val_accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3364 - accuracy: 0.9518 - val_loss: 0.3309 - val_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3306 - accuracy: 0.9518 - val_loss: 0.3251 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3251 - accuracy: 0.9518 - val_loss: 0.3196 - val_accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3194 - accuracy: 0.9518 - val_loss: 0.3150 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3143 - accuracy: 0.9518 - val_loss: 0.3104 - val_accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3091 - accuracy: 0.9518 - val_loss: 0.3052 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3037 - accuracy: 0.9518 - val_loss: 0.3009 - val_accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2988 - accuracy: 0.9518 - val_loss: 0.2966 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2942 - accuracy: 0.9518 - val_loss: 0.2919 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 257us/sample - loss: 0.2894 - accuracy: 0.9518 - val_loss: 0.2876 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2847 - accuracy: 0.9518 - val_loss: 0.2829 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2802 - accuracy: 0.9639 - val_loss: 0.2782 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2758 - accuracy: 0.9639 - val_loss: 0.2737 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2715 - accuracy: 0.9639 - val_loss: 0.2688 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2675 - accuracy: 0.9639 - val_loss: 0.2644 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2634 - accuracy: 0.9759 - val_loss: 0.2604 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2598 - accuracy: 0.9759 - val_loss: 0.2578 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2552 - accuracy: 0.9759 - val_loss: 0.2543 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2514 - accuracy: 0.9759 - val_loss: 0.2509 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2476 - accuracy: 0.9759 - val_loss: 0.2477 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2439 - accuracy: 0.9759 - val_loss: 0.2453 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2410 - accuracy: 0.9639 - val_loss: 0.2430 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2370 - accuracy: 0.9639 - val_loss: 0.2392 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.2337 - accuracy: 0.9759 - val_loss: 0.2351 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2302 - accuracy: 0.9759 - val_loss: 0.2314 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2268 - accuracy: 0.9759 - val_loss: 0.2280 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.2237 - accuracy: 0.9759 - val_loss: 0.2246 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2207 - accuracy: 0.9759 - val_loss: 0.2219 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2174 - accuracy: 0.9759 - val_loss: 0.2197 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2146 - accuracy: 0.9759 - val_loss: 0.2174 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 242us/sample - loss: 0.2116 - accuracy: 0.9759 - val_loss: 0.2146 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2087 - accuracy: 0.9759 - val_loss: 0.2117 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2059 - accuracy: 0.9759 - val_loss: 0.2088 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2031 - accuracy: 0.9759 - val_loss: 0.2059 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2005 - accuracy: 0.9880 - val_loss: 0.2033 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.1979 - accuracy: 0.9880 - val_loss: 0.2013 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.2238 - accuracy: 0.9756\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1508 - accuracy: 0.5904 - val_loss: 1.1075 - val_accuracy: 0.5926\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.1254 - accuracy: 0.5904 - val_loss: 1.0835 - val_accuracy: 0.5926\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0996 - accuracy: 0.6145 - val_loss: 1.0622 - val_accuracy: 0.6111\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0766 - accuracy: 0.6265 - val_loss: 1.0418 - val_accuracy: 0.6296\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0553 - accuracy: 0.6145 - val_loss: 1.0220 - val_accuracy: 0.6296\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0366 - accuracy: 0.6024 - val_loss: 1.0033 - val_accuracy: 0.6111\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0170 - accuracy: 0.6024 - val_loss: 0.9854 - val_accuracy: 0.6111\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9998 - accuracy: 0.5904 - val_loss: 0.9676 - val_accuracy: 0.6481\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 231us/sample - loss: 0.9816 - accuracy: 0.5663 - val_loss: 0.9503 - val_accuracy: 0.6481\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9649 - accuracy: 0.5783 - val_loss: 0.9330 - val_accuracy: 0.6481\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9480 - accuracy: 0.5904 - val_loss: 0.9163 - val_accuracy: 0.6667\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9323 - accuracy: 0.5904 - val_loss: 0.8998 - val_accuracy: 0.6667\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9172 - accuracy: 0.6024 - val_loss: 0.8839 - val_accuracy: 0.7037\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9015 - accuracy: 0.6024 - val_loss: 0.8682 - val_accuracy: 0.7222\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.8865 - accuracy: 0.6386 - val_loss: 0.8526 - val_accuracy: 0.7407\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8721 - accuracy: 0.6506 - val_loss: 0.8372 - val_accuracy: 0.7407\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.8569 - accuracy: 0.6747 - val_loss: 0.8222 - val_accuracy: 0.7778\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.8428 - accuracy: 0.7229 - val_loss: 0.8073 - val_accuracy: 0.7778\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8285 - accuracy: 0.7229 - val_loss: 0.7926 - val_accuracy: 0.7778\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.8149 - accuracy: 0.7349 - val_loss: 0.7780 - val_accuracy: 0.7963\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.8014 - accuracy: 0.7470 - val_loss: 0.7638 - val_accuracy: 0.8148\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7869 - accuracy: 0.7590 - val_loss: 0.7500 - val_accuracy: 0.8704\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7735 - accuracy: 0.7711 - val_loss: 0.7362 - val_accuracy: 0.8704\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.7605 - accuracy: 0.7831 - val_loss: 0.7225 - val_accuracy: 0.8889\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7482 - accuracy: 0.8072 - val_loss: 0.7092 - val_accuracy: 0.8889\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7347 - accuracy: 0.8313 - val_loss: 0.6964 - val_accuracy: 0.8889\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7225 - accuracy: 0.8675 - val_loss: 0.6836 - val_accuracy: 0.8889\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7100 - accuracy: 0.8795 - val_loss: 0.6709 - val_accuracy: 0.8889\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6978 - accuracy: 0.8795 - val_loss: 0.6583 - val_accuracy: 0.8889\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6857 - accuracy: 0.8795 - val_loss: 0.6458 - val_accuracy: 0.8889\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6740 - accuracy: 0.8916 - val_loss: 0.6337 - val_accuracy: 0.8889\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6618 - accuracy: 0.8916 - val_loss: 0.6218 - val_accuracy: 0.9074\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6501 - accuracy: 0.8916 - val_loss: 0.6103 - val_accuracy: 0.9074\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.6400 - accuracy: 0.8675 - val_loss: 0.5989 - val_accuracy: 0.9074\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6283 - accuracy: 0.8916 - val_loss: 0.5879 - val_accuracy: 0.9074\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6170 - accuracy: 0.8916 - val_loss: 0.5770 - val_accuracy: 0.9259\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6065 - accuracy: 0.9036 - val_loss: 0.5664 - val_accuracy: 0.9259\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5959 - accuracy: 0.9036 - val_loss: 0.5560 - val_accuracy: 0.9444\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5857 - accuracy: 0.9036 - val_loss: 0.5459 - val_accuracy: 0.9444\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5757 - accuracy: 0.9157 - val_loss: 0.5359 - val_accuracy: 0.9444\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5662 - accuracy: 0.9157 - val_loss: 0.5262 - val_accuracy: 0.9444\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.5562 - accuracy: 0.9157 - val_loss: 0.5165 - val_accuracy: 0.9630\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.5466 - accuracy: 0.9157 - val_loss: 0.5070 - val_accuracy: 0.9630\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.5371 - accuracy: 0.9157 - val_loss: 0.4977 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.5279 - accuracy: 0.9398 - val_loss: 0.4885 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.5191 - accuracy: 0.9398 - val_loss: 0.4795 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5101 - accuracy: 0.9398 - val_loss: 0.4708 - val_accuracy: 0.9630\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5013 - accuracy: 0.9398 - val_loss: 0.4623 - val_accuracy: 0.9630\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4929 - accuracy: 0.9398 - val_loss: 0.4540 - val_accuracy: 0.9630\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.4751 - accuracy: 0.93 - 0s 277us/sample - loss: 0.4845 - accuracy: 0.9398 - val_loss: 0.4459 - val_accuracy: 0.9630\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 349us/sample - loss: 0.4767 - accuracy: 0.9398 - val_loss: 0.4381 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4684 - accuracy: 0.9398 - val_loss: 0.4304 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4607 - accuracy: 0.9398 - val_loss: 0.4230 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4534 - accuracy: 0.9518 - val_loss: 0.4157 - val_accuracy: 0.9630\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4460 - accuracy: 0.9518 - val_loss: 0.4082 - val_accuracy: 0.9630\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.4383 - accuracy: 0.9518 - val_loss: 0.4009 - val_accuracy: 0.9630\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4310 - accuracy: 0.9398 - val_loss: 0.3938 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4242 - accuracy: 0.9398 - val_loss: 0.3868 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4172 - accuracy: 0.9398 - val_loss: 0.3802 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4104 - accuracy: 0.9398 - val_loss: 0.3737 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4038 - accuracy: 0.9518 - val_loss: 0.3674 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3972 - accuracy: 0.9398 - val_loss: 0.3614 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3914 - accuracy: 0.9398 - val_loss: 0.3554 - val_accuracy: 0.9630\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 361us/sample - loss: 0.3850 - accuracy: 0.9639 - val_loss: 0.3494 - val_accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 361us/sample - loss: 0.3788 - accuracy: 0.9518 - val_loss: 0.3436 - val_accuracy: 0.9630\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.3728 - accuracy: 0.9518 - val_loss: 0.3380 - val_accuracy: 0.9630\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3671 - accuracy: 0.9518 - val_loss: 0.3325 - val_accuracy: 0.9630\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3615 - accuracy: 0.9518 - val_loss: 0.3272 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 236us/sample - loss: 0.3556 - accuracy: 0.9639 - val_loss: 0.3221 - val_accuracy: 0.9630\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 319us/sample - loss: 0.3506 - accuracy: 0.9639 - val_loss: 0.3171 - val_accuracy: 0.9630\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3451 - accuracy: 0.9639 - val_loss: 0.3121 - val_accuracy: 0.9630\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3398 - accuracy: 0.9639 - val_loss: 0.3072 - val_accuracy: 0.9630\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3349 - accuracy: 0.9639 - val_loss: 0.3026 - val_accuracy: 0.9630\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3300 - accuracy: 0.9639 - val_loss: 0.2977 - val_accuracy: 0.9630\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 235us/sample - loss: 0.3248 - accuracy: 0.9639 - val_loss: 0.2933 - val_accuracy: 0.9630\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3200 - accuracy: 0.9639 - val_loss: 0.2888 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3155 - accuracy: 0.9639 - val_loss: 0.2847 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.3106 - accuracy: 0.9639 - val_loss: 0.2803 - val_accuracy: 0.9630\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 296us/sample - loss: 0.3061 - accuracy: 0.9639 - val_loss: 0.2761 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3018 - accuracy: 0.9639 - val_loss: 0.2720 - val_accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2973 - accuracy: 0.9639 - val_loss: 0.2681 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.2932 - accuracy: 0.9639 - val_loss: 0.2642 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2890 - accuracy: 0.9639 - val_loss: 0.2604 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.2849 - accuracy: 0.9639 - val_loss: 0.2568 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2809 - accuracy: 0.9759 - val_loss: 0.2531 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 319us/sample - loss: 0.2774 - accuracy: 0.9759 - val_loss: 0.2497 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 307us/sample - loss: 0.2731 - accuracy: 0.9759 - val_loss: 0.2461 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.2697 - accuracy: 0.9759 - val_loss: 0.2426 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 374us/sample - loss: 0.2657 - accuracy: 0.9759 - val_loss: 0.2393 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 385us/sample - loss: 0.2625 - accuracy: 0.9759 - val_loss: 0.2359 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 361us/sample - loss: 0.2586 - accuracy: 0.9759 - val_loss: 0.2331 - val_accuracy: 0.9630\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 319us/sample - loss: 0.2550 - accuracy: 0.9759 - val_loss: 0.2301 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 314us/sample - loss: 0.2516 - accuracy: 0.9759 - val_loss: 0.2273 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 518us/sample - loss: 0.2484 - accuracy: 0.9759 - val_loss: 0.2245 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 398us/sample - loss: 0.2454 - accuracy: 0.9759 - val_loss: 0.2221 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2419 - accuracy: 0.9759 - val_loss: 0.2192 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.2387 - accuracy: 0.9759 - val_loss: 0.2162 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2357 - accuracy: 0.9759 - val_loss: 0.2131 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2326 - accuracy: 0.9759 - val_loss: 0.2103 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 235us/sample - loss: 0.2295 - accuracy: 0.9759 - val_loss: 0.2074 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 122us/sample - loss: 0.2151 - accuracy: 1.0000\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 4ms/sample - loss: 1.0222 - accuracy: 0.5610 - val_loss: 1.0518 - val_accuracy: 0.5185\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.0176 - accuracy: 0.5854 - val_loss: 1.0484 - val_accuracy: 0.5185\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 1.0138 - accuracy: 0.5854 - val_loss: 1.0450 - val_accuracy: 0.5185\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.0100 - accuracy: 0.5854 - val_loss: 1.0418 - val_accuracy: 0.5185\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.0059 - accuracy: 0.5854 - val_loss: 1.0386 - val_accuracy: 0.5185\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.0025 - accuracy: 0.5854 - val_loss: 1.0355 - val_accuracy: 0.5185\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9986 - accuracy: 0.5854 - val_loss: 1.0327 - val_accuracy: 0.5185\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9950 - accuracy: 0.6098 - val_loss: 1.0298 - val_accuracy: 0.5185\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9915 - accuracy: 0.6098 - val_loss: 1.0269 - val_accuracy: 0.5370\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9881 - accuracy: 0.6220 - val_loss: 1.0240 - val_accuracy: 0.5370\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9847 - accuracy: 0.6220 - val_loss: 1.0212 - val_accuracy: 0.5370\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.9817 - accuracy: 0.6220 - val_loss: 1.0184 - val_accuracy: 0.5370\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9782 - accuracy: 0.6220 - val_loss: 1.0155 - val_accuracy: 0.5370\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9751 - accuracy: 0.6220 - val_loss: 1.0125 - val_accuracy: 0.5370\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9720 - accuracy: 0.6220 - val_loss: 1.0095 - val_accuracy: 0.5370\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 250us/sample - loss: 0.9688 - accuracy: 0.6220 - val_loss: 1.0065 - val_accuracy: 0.5370\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9658 - accuracy: 0.6220 - val_loss: 1.0035 - val_accuracy: 0.5370\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 263us/sample - loss: 0.9626 - accuracy: 0.6220 - val_loss: 1.0007 - val_accuracy: 0.5556\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9595 - accuracy: 0.6220 - val_loss: 0.9978 - val_accuracy: 0.5741\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 214us/sample - loss: 0.9563 - accuracy: 0.6220 - val_loss: 0.9949 - val_accuracy: 0.5741\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.9534 - accuracy: 0.6220 - val_loss: 0.9921 - val_accuracy: 0.5741\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9502 - accuracy: 0.6341 - val_loss: 0.9892 - val_accuracy: 0.5741\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9472 - accuracy: 0.6341 - val_loss: 0.9866 - val_accuracy: 0.5741\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9440 - accuracy: 0.6341 - val_loss: 0.9838 - val_accuracy: 0.5741\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 354us/sample - loss: 0.9410 - accuracy: 0.6463 - val_loss: 0.9811 - val_accuracy: 0.5741\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 366us/sample - loss: 0.9379 - accuracy: 0.6463 - val_loss: 0.9782 - val_accuracy: 0.5741\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.9349 - accuracy: 0.6585 - val_loss: 0.9754 - val_accuracy: 0.5926\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.9320 - accuracy: 0.6585 - val_loss: 0.9725 - val_accuracy: 0.5741\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 378us/sample - loss: 0.9289 - accuracy: 0.6585 - val_loss: 0.9695 - val_accuracy: 0.6111\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9258 - accuracy: 0.6585 - val_loss: 0.9665 - val_accuracy: 0.6111\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9228 - accuracy: 0.6707 - val_loss: 0.9632 - val_accuracy: 0.6111\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9197 - accuracy: 0.6829 - val_loss: 0.9601 - val_accuracy: 0.6111\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 265us/sample - loss: 0.9166 - accuracy: 0.6829 - val_loss: 0.9569 - val_accuracy: 0.6111\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9135 - accuracy: 0.6951 - val_loss: 0.9537 - val_accuracy: 0.6296\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 300us/sample - loss: 0.9104 - accuracy: 0.6951 - val_loss: 0.9507 - val_accuracy: 0.6296\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9072 - accuracy: 0.6951 - val_loss: 0.9476 - val_accuracy: 0.6296\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 262us/sample - loss: 0.9042 - accuracy: 0.6951 - val_loss: 0.9443 - val_accuracy: 0.6296\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.9011 - accuracy: 0.6951 - val_loss: 0.9410 - val_accuracy: 0.6481\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8979 - accuracy: 0.7073 - val_loss: 0.9379 - val_accuracy: 0.6481\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 233us/sample - loss: 0.8947 - accuracy: 0.7195 - val_loss: 0.9346 - val_accuracy: 0.6481\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.8916 - accuracy: 0.7195 - val_loss: 0.9313 - val_accuracy: 0.6481\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.8884 - accuracy: 0.7195 - val_loss: 0.9280 - val_accuracy: 0.6481\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 269us/sample - loss: 0.8852 - accuracy: 0.7317 - val_loss: 0.9245 - val_accuracy: 0.6667\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 592us/sample - loss: 0.8820 - accuracy: 0.7317 - val_loss: 0.9211 - val_accuracy: 0.6667\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8787 - accuracy: 0.7317 - val_loss: 0.9178 - val_accuracy: 0.6667\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.8755 - accuracy: 0.7317 - val_loss: 0.9144 - val_accuracy: 0.6852\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 342us/sample - loss: 0.8721 - accuracy: 0.7317 - val_loss: 0.9111 - val_accuracy: 0.6852\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8689 - accuracy: 0.7317 - val_loss: 0.9075 - val_accuracy: 0.6852\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.8656 - accuracy: 0.7317 - val_loss: 0.9039 - val_accuracy: 0.6852\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.8623 - accuracy: 0.7317 - val_loss: 0.9003 - val_accuracy: 0.6852\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 360us/sample - loss: 0.8588 - accuracy: 0.7439 - val_loss: 0.8968 - val_accuracy: 0.7037\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 238us/sample - loss: 0.8557 - accuracy: 0.7561 - val_loss: 0.8931 - val_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8522 - accuracy: 0.7927 - val_loss: 0.8894 - val_accuracy: 0.7222\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8488 - accuracy: 0.7927 - val_loss: 0.8858 - val_accuracy: 0.7222\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.8453 - accuracy: 0.7927 - val_loss: 0.8820 - val_accuracy: 0.7222\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 250us/sample - loss: 0.8419 - accuracy: 0.7927 - val_loss: 0.8782 - val_accuracy: 0.7222\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8386 - accuracy: 0.8171 - val_loss: 0.8744 - val_accuracy: 0.7407\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 403us/sample - loss: 0.8351 - accuracy: 0.8171 - val_loss: 0.8706 - val_accuracy: 0.7593\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 329us/sample - loss: 0.8316 - accuracy: 0.8171 - val_loss: 0.8669 - val_accuracy: 0.7593\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8283 - accuracy: 0.8171 - val_loss: 0.8631 - val_accuracy: 0.7778\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8248 - accuracy: 0.8171 - val_loss: 0.8594 - val_accuracy: 0.7778\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8214 - accuracy: 0.8171 - val_loss: 0.8557 - val_accuracy: 0.7778\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8179 - accuracy: 0.8171 - val_loss: 0.8522 - val_accuracy: 0.7778\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 329us/sample - loss: 0.8143 - accuracy: 0.8171 - val_loss: 0.8486 - val_accuracy: 0.7778\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8109 - accuracy: 0.8171 - val_loss: 0.8449 - val_accuracy: 0.7778\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8074 - accuracy: 0.8293 - val_loss: 0.8413 - val_accuracy: 0.7778\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8038 - accuracy: 0.8293 - val_loss: 0.8375 - val_accuracy: 0.7778\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.8003 - accuracy: 0.8293 - val_loss: 0.8339 - val_accuracy: 0.7778\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7968 - accuracy: 0.8293 - val_loss: 0.8299 - val_accuracy: 0.7778\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 250us/sample - loss: 0.7931 - accuracy: 0.8293 - val_loss: 0.8261 - val_accuracy: 0.8148\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7896 - accuracy: 0.8293 - val_loss: 0.8224 - val_accuracy: 0.8148\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.7860 - accuracy: 0.8293 - val_loss: 0.8185 - val_accuracy: 0.8148\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7825 - accuracy: 0.8415 - val_loss: 0.8145 - val_accuracy: 0.8148\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7787 - accuracy: 0.8415 - val_loss: 0.8107 - val_accuracy: 0.8148\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7753 - accuracy: 0.8415 - val_loss: 0.8068 - val_accuracy: 0.8148\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7717 - accuracy: 0.8415 - val_loss: 0.8028 - val_accuracy: 0.8148\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.7680 - accuracy: 0.8537 - val_loss: 0.7989 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7645 - accuracy: 0.8659 - val_loss: 0.7949 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7608 - accuracy: 0.8659 - val_loss: 0.7911 - val_accuracy: 0.8519\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7574 - accuracy: 0.8659 - val_loss: 0.7873 - val_accuracy: 0.8519\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.7538 - accuracy: 0.8780 - val_loss: 0.7834 - val_accuracy: 0.8704\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7502 - accuracy: 0.8780 - val_loss: 0.7797 - val_accuracy: 0.8704\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7467 - accuracy: 0.8780 - val_loss: 0.7759 - val_accuracy: 0.8704\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.7431 - accuracy: 0.8780 - val_loss: 0.7723 - val_accuracy: 0.8704\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.7393 - accuracy: 0.8780 - val_loss: 0.7687 - val_accuracy: 0.8704\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7357 - accuracy: 0.8780 - val_loss: 0.7650 - val_accuracy: 0.8704\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7322 - accuracy: 0.8780 - val_loss: 0.7612 - val_accuracy: 0.8889\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7285 - accuracy: 0.8780 - val_loss: 0.7577 - val_accuracy: 0.8889\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7250 - accuracy: 0.8780 - val_loss: 0.7540 - val_accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7213 - accuracy: 0.8780 - val_loss: 0.7505 - val_accuracy: 0.8889\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7178 - accuracy: 0.8780 - val_loss: 0.7469 - val_accuracy: 0.8889\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7143 - accuracy: 0.8780 - val_loss: 0.7433 - val_accuracy: 0.8889\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7107 - accuracy: 0.8780 - val_loss: 0.7397 - val_accuracy: 0.8889\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 329us/sample - loss: 0.7071 - accuracy: 0.8902 - val_loss: 0.7361 - val_accuracy: 0.8889\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7035 - accuracy: 0.8902 - val_loss: 0.7323 - val_accuracy: 0.8889\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6999 - accuracy: 0.8902 - val_loss: 0.7286 - val_accuracy: 0.8889\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6965 - accuracy: 0.8902 - val_loss: 0.7248 - val_accuracy: 0.8889\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6929 - accuracy: 0.9024 - val_loss: 0.7212 - val_accuracy: 0.8889\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 281us/sample - loss: 0.6893 - accuracy: 0.9146 - val_loss: 0.7177 - val_accuracy: 0.8889\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.6859 - accuracy: 0.9268 - val_loss: 0.7141 - val_accuracy: 0.8889\n",
      "42/42 [==============================] - 0s 143us/sample - loss: 0.7317 - accuracy: 0.8571\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 5ms/sample - loss: 1.1289 - accuracy: 0.1928 - val_loss: 1.1250 - val_accuracy: 0.1852\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1251 - accuracy: 0.1928 - val_loss: 1.1224 - val_accuracy: 0.1481\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.1218 - accuracy: 0.1928 - val_loss: 1.1203 - val_accuracy: 0.1481\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1185 - accuracy: 0.1928 - val_loss: 1.1181 - val_accuracy: 0.1296\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1159 - accuracy: 0.1928 - val_loss: 1.1160 - val_accuracy: 0.1296\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.1124 - accuracy: 0.1928 - val_loss: 1.1139 - val_accuracy: 0.1296\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.1095 - accuracy: 0.1928 - val_loss: 1.1116 - val_accuracy: 0.1296\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1066 - accuracy: 0.2048 - val_loss: 1.1093 - val_accuracy: 0.1296\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1040 - accuracy: 0.1807 - val_loss: 1.1072 - val_accuracy: 0.1296\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1013 - accuracy: 0.1807 - val_loss: 1.1051 - val_accuracy: 0.1481\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 494us/sample - loss: 1.0984 - accuracy: 0.2048 - val_loss: 1.1030 - val_accuracy: 0.1481\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 1.0957 - accuracy: 0.2048 - val_loss: 1.1011 - val_accuracy: 0.1111\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0933 - accuracy: 0.2289 - val_loss: 1.0992 - val_accuracy: 0.1296\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0907 - accuracy: 0.2410 - val_loss: 1.0973 - val_accuracy: 0.1481\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 344us/sample - loss: 1.0885 - accuracy: 0.2771 - val_loss: 1.0953 - val_accuracy: 0.1667\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0860 - accuracy: 0.2892 - val_loss: 1.0933 - val_accuracy: 0.1852\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0836 - accuracy: 0.2892 - val_loss: 1.0914 - val_accuracy: 0.2037\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 422us/sample - loss: 1.0814 - accuracy: 0.2892 - val_loss: 1.0894 - val_accuracy: 0.2037\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0791 - accuracy: 0.3133 - val_loss: 1.0875 - val_accuracy: 0.2593\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0770 - accuracy: 0.3253 - val_loss: 1.0856 - val_accuracy: 0.2593\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0749 - accuracy: 0.3373 - val_loss: 1.0836 - val_accuracy: 0.2593\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 271us/sample - loss: 1.0727 - accuracy: 0.3494 - val_loss: 1.0817 - val_accuracy: 0.2963\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0706 - accuracy: 0.3373 - val_loss: 1.0798 - val_accuracy: 0.2963\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 410us/sample - loss: 1.0686 - accuracy: 0.3494 - val_loss: 1.0781 - val_accuracy: 0.2963\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 211us/sample - loss: 1.0664 - accuracy: 0.3735 - val_loss: 1.0765 - val_accuracy: 0.3889\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0647 - accuracy: 0.3614 - val_loss: 1.0747 - val_accuracy: 0.4074\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0628 - accuracy: 0.3735 - val_loss: 1.0731 - val_accuracy: 0.4074\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0607 - accuracy: 0.4096 - val_loss: 1.0714 - val_accuracy: 0.4074\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0588 - accuracy: 0.4458 - val_loss: 1.0696 - val_accuracy: 0.4259\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0570 - accuracy: 0.4699 - val_loss: 1.0679 - val_accuracy: 0.4074\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0553 - accuracy: 0.4699 - val_loss: 1.0661 - val_accuracy: 0.4074\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0533 - accuracy: 0.4819 - val_loss: 1.0645 - val_accuracy: 0.4259\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0515 - accuracy: 0.4940 - val_loss: 1.0628 - val_accuracy: 0.4259\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0497 - accuracy: 0.5301 - val_loss: 1.0611 - val_accuracy: 0.4444\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0478 - accuracy: 0.5422 - val_loss: 1.0595 - val_accuracy: 0.4444\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0462 - accuracy: 0.5422 - val_loss: 1.0581 - val_accuracy: 0.4630\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0446 - accuracy: 0.5422 - val_loss: 1.0565 - val_accuracy: 0.4630\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0425 - accuracy: 0.5542 - val_loss: 1.0547 - val_accuracy: 0.4630\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0409 - accuracy: 0.5542 - val_loss: 1.0527 - val_accuracy: 0.4815\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0390 - accuracy: 0.5663 - val_loss: 1.0507 - val_accuracy: 0.4815\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0373 - accuracy: 0.5904 - val_loss: 1.0487 - val_accuracy: 0.4815\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0356 - accuracy: 0.5904 - val_loss: 1.0467 - val_accuracy: 0.4815\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0340 - accuracy: 0.5904 - val_loss: 1.0447 - val_accuracy: 0.4815\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 307us/sample - loss: 1.0322 - accuracy: 0.5904 - val_loss: 1.0429 - val_accuracy: 0.4815\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0305 - accuracy: 0.5904 - val_loss: 1.0410 - val_accuracy: 0.4815\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0287 - accuracy: 0.6024 - val_loss: 1.0393 - val_accuracy: 0.4815\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0271 - accuracy: 0.6024 - val_loss: 1.0376 - val_accuracy: 0.4815\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0253 - accuracy: 0.6024 - val_loss: 1.0359 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0236 - accuracy: 0.6024 - val_loss: 1.0342 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 1.0219 - accuracy: 0.5904 - val_loss: 1.0324 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0202 - accuracy: 0.5904 - val_loss: 1.0306 - val_accuracy: 0.5185\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0184 - accuracy: 0.5904 - val_loss: 1.0286 - val_accuracy: 0.5370\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0167 - accuracy: 0.5904 - val_loss: 1.0265 - val_accuracy: 0.5370\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 1.0011 - accuracy: 0.62 - 0s 217us/sample - loss: 1.0149 - accuracy: 0.5904 - val_loss: 1.0247 - val_accuracy: 0.5370\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0131 - accuracy: 0.5904 - val_loss: 1.0229 - val_accuracy: 0.5370\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0113 - accuracy: 0.5904 - val_loss: 1.0210 - val_accuracy: 0.5556\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0096 - accuracy: 0.5904 - val_loss: 1.0192 - val_accuracy: 0.5556\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0077 - accuracy: 0.5904 - val_loss: 1.0170 - val_accuracy: 0.5556\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0060 - accuracy: 0.5904 - val_loss: 1.0147 - val_accuracy: 0.5556\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0044 - accuracy: 0.6024 - val_loss: 1.0126 - val_accuracy: 0.5370\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0023 - accuracy: 0.6024 - val_loss: 1.0107 - val_accuracy: 0.5741\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0005 - accuracy: 0.6024 - val_loss: 1.0090 - val_accuracy: 0.5741\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.9986 - accuracy: 0.6024 - val_loss: 1.0070 - val_accuracy: 0.5741\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.9968 - accuracy: 0.6024 - val_loss: 1.0052 - val_accuracy: 0.5556\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9950 - accuracy: 0.5904 - val_loss: 1.0032 - val_accuracy: 0.5556\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9931 - accuracy: 0.5904 - val_loss: 1.0012 - val_accuracy: 0.5556\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9911 - accuracy: 0.5904 - val_loss: 0.9991 - val_accuracy: 0.5556\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9891 - accuracy: 0.5904 - val_loss: 0.9969 - val_accuracy: 0.5926\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9872 - accuracy: 0.5904 - val_loss: 0.9944 - val_accuracy: 0.5926\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 434us/sample - loss: 0.9852 - accuracy: 0.5783 - val_loss: 0.9921 - val_accuracy: 0.5926\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 271us/sample - loss: 0.9832 - accuracy: 0.5783 - val_loss: 0.9898 - val_accuracy: 0.5926\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.9811 - accuracy: 0.5783 - val_loss: 0.9876 - val_accuracy: 0.6111\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.9790 - accuracy: 0.5904 - val_loss: 0.9854 - val_accuracy: 0.6111\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9770 - accuracy: 0.5904 - val_loss: 0.9831 - val_accuracy: 0.6111\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9748 - accuracy: 0.5904 - val_loss: 0.9809 - val_accuracy: 0.6111\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9727 - accuracy: 0.6024 - val_loss: 0.9787 - val_accuracy: 0.6111\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9705 - accuracy: 0.6024 - val_loss: 0.9766 - val_accuracy: 0.6111\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9682 - accuracy: 0.6024 - val_loss: 0.9744 - val_accuracy: 0.6111\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9661 - accuracy: 0.6145 - val_loss: 0.9721 - val_accuracy: 0.6296\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.9638 - accuracy: 0.6145 - val_loss: 0.9701 - val_accuracy: 0.6296\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9615 - accuracy: 0.6145 - val_loss: 0.9681 - val_accuracy: 0.6296\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9592 - accuracy: 0.6265 - val_loss: 0.9661 - val_accuracy: 0.6296\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9568 - accuracy: 0.6265 - val_loss: 0.9641 - val_accuracy: 0.6111\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9546 - accuracy: 0.6265 - val_loss: 0.9620 - val_accuracy: 0.6111\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9522 - accuracy: 0.6265 - val_loss: 0.9597 - val_accuracy: 0.6111\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9498 - accuracy: 0.6265 - val_loss: 0.9575 - val_accuracy: 0.6111\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.9474 - accuracy: 0.6265 - val_loss: 0.9553 - val_accuracy: 0.5926\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9449 - accuracy: 0.6386 - val_loss: 0.9527 - val_accuracy: 0.6111\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9424 - accuracy: 0.6386 - val_loss: 0.9500 - val_accuracy: 0.6296\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9400 - accuracy: 0.6386 - val_loss: 0.9473 - val_accuracy: 0.6296\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9372 - accuracy: 0.6506 - val_loss: 0.9445 - val_accuracy: 0.6296\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9346 - accuracy: 0.6386 - val_loss: 0.9418 - val_accuracy: 0.6481\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.9321 - accuracy: 0.6386 - val_loss: 0.9391 - val_accuracy: 0.6481\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9293 - accuracy: 0.6386 - val_loss: 0.9363 - val_accuracy: 0.6481\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 422us/sample - loss: 0.9265 - accuracy: 0.6386 - val_loss: 0.9330 - val_accuracy: 0.6481\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9238 - accuracy: 0.6386 - val_loss: 0.9298 - val_accuracy: 0.6481\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9210 - accuracy: 0.6386 - val_loss: 0.9268 - val_accuracy: 0.6481\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.9181 - accuracy: 0.6506 - val_loss: 0.9240 - val_accuracy: 0.6481\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9152 - accuracy: 0.6506 - val_loss: 0.9207 - val_accuracy: 0.6481\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9124 - accuracy: 0.6506 - val_loss: 0.9177 - val_accuracy: 0.6481\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.9259 - accuracy: 0.6585\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1574 - accuracy: 0.2048 - val_loss: 1.1597 - val_accuracy: 0.1481\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.1547 - accuracy: 0.1928 - val_loss: 1.1572 - val_accuracy: 0.1296\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 362us/sample - loss: 1.1518 - accuracy: 0.1928 - val_loss: 1.1547 - val_accuracy: 0.1296\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.1494 - accuracy: 0.1928 - val_loss: 1.1522 - val_accuracy: 0.1111\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.1467 - accuracy: 0.1928 - val_loss: 1.1498 - val_accuracy: 0.0926\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1442 - accuracy: 0.1928 - val_loss: 1.1473 - val_accuracy: 0.0926\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 259us/sample - loss: 1.1415 - accuracy: 0.1566 - val_loss: 1.1448 - val_accuracy: 0.1111\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.1390 - accuracy: 0.1687 - val_loss: 1.1423 - val_accuracy: 0.1111\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 277us/sample - loss: 1.1365 - accuracy: 0.1687 - val_loss: 1.1399 - val_accuracy: 0.1111\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1339 - accuracy: 0.1687 - val_loss: 1.1374 - val_accuracy: 0.1111\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1313 - accuracy: 0.1807 - val_loss: 1.1350 - val_accuracy: 0.1111\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 349us/sample - loss: 1.1291 - accuracy: 0.1687 - val_loss: 1.1326 - val_accuracy: 0.0926\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 531us/sample - loss: 1.1266 - accuracy: 0.1807 - val_loss: 1.1303 - val_accuracy: 0.0926\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.1239 - accuracy: 0.1807 - val_loss: 1.1280 - val_accuracy: 0.1667\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1216 - accuracy: 0.1928 - val_loss: 1.1257 - val_accuracy: 0.2222\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.1194 - accuracy: 0.2169 - val_loss: 1.1234 - val_accuracy: 0.2407\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1169 - accuracy: 0.2410 - val_loss: 1.1211 - val_accuracy: 0.2963\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.1146 - accuracy: 0.2771 - val_loss: 1.1189 - val_accuracy: 0.3333\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1124 - accuracy: 0.2892 - val_loss: 1.1166 - val_accuracy: 0.3333\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 1.1101 - accuracy: 0.3133 - val_loss: 1.1144 - val_accuracy: 0.3704\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 374us/sample - loss: 1.1078 - accuracy: 0.3133 - val_loss: 1.1121 - val_accuracy: 0.3889\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 416us/sample - loss: 1.1056 - accuracy: 0.3373 - val_loss: 1.1099 - val_accuracy: 0.4074\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 283us/sample - loss: 1.1033 - accuracy: 0.3614 - val_loss: 1.1077 - val_accuracy: 0.4074\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1013 - accuracy: 0.3855 - val_loss: 1.1055 - val_accuracy: 0.3704\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0990 - accuracy: 0.3855 - val_loss: 1.1034 - val_accuracy: 0.3704\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 349us/sample - loss: 1.0970 - accuracy: 0.4217 - val_loss: 1.1012 - val_accuracy: 0.3519\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 434us/sample - loss: 1.0947 - accuracy: 0.4217 - val_loss: 1.0991 - val_accuracy: 0.3519\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 320us/sample - loss: 1.0926 - accuracy: 0.4096 - val_loss: 1.0970 - val_accuracy: 0.3704\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0906 - accuracy: 0.4096 - val_loss: 1.0949 - val_accuracy: 0.3704\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 283us/sample - loss: 1.0885 - accuracy: 0.4337 - val_loss: 1.0928 - val_accuracy: 0.4444\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0866 - accuracy: 0.4337 - val_loss: 1.0906 - val_accuracy: 0.4259\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 554us/sample - loss: 1.0843 - accuracy: 0.4217 - val_loss: 1.0885 - val_accuracy: 0.4074\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 284us/sample - loss: 1.0824 - accuracy: 0.3976 - val_loss: 1.0864 - val_accuracy: 0.4630\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 302us/sample - loss: 1.0804 - accuracy: 0.4699 - val_loss: 1.0843 - val_accuracy: 0.4630\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 295us/sample - loss: 1.0783 - accuracy: 0.4699 - val_loss: 1.0822 - val_accuracy: 0.4815\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 307us/sample - loss: 1.0762 - accuracy: 0.4819 - val_loss: 1.0801 - val_accuracy: 0.4815\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 518us/sample - loss: 1.0741 - accuracy: 0.4337 - val_loss: 1.0779 - val_accuracy: 0.3704\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 687us/sample - loss: 1.0722 - accuracy: 0.4217 - val_loss: 1.0758 - val_accuracy: 0.3704\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 344us/sample - loss: 1.0701 - accuracy: 0.3976 - val_loss: 1.0736 - val_accuracy: 0.3889\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 1.0680 - accuracy: 0.4096 - val_loss: 1.0715 - val_accuracy: 0.3889\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 590us/sample - loss: 1.0660 - accuracy: 0.4217 - val_loss: 1.0694 - val_accuracy: 0.4259\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 1.0639 - accuracy: 0.4337 - val_loss: 1.0672 - val_accuracy: 0.4259\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0620 - accuracy: 0.4337 - val_loss: 1.0651 - val_accuracy: 0.4259\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 1.0599 - accuracy: 0.4337 - val_loss: 1.0630 - val_accuracy: 0.4259\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0578 - accuracy: 0.4337 - val_loss: 1.0608 - val_accuracy: 0.4259\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0559 - accuracy: 0.4337 - val_loss: 1.0586 - val_accuracy: 0.4259\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0538 - accuracy: 0.4337 - val_loss: 1.0564 - val_accuracy: 0.4259\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0518 - accuracy: 0.4337 - val_loss: 1.0542 - val_accuracy: 0.4444\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0497 - accuracy: 0.4337 - val_loss: 1.0520 - val_accuracy: 0.4444\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0476 - accuracy: 0.4337 - val_loss: 1.0498 - val_accuracy: 0.4444\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0456 - accuracy: 0.4337 - val_loss: 1.0476 - val_accuracy: 0.4444\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0435 - accuracy: 0.4337 - val_loss: 1.0454 - val_accuracy: 0.4444\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0414 - accuracy: 0.4337 - val_loss: 1.0431 - val_accuracy: 0.4444\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0394 - accuracy: 0.4337 - val_loss: 1.0409 - val_accuracy: 0.4444\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0373 - accuracy: 0.4337 - val_loss: 1.0386 - val_accuracy: 0.4444\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0352 - accuracy: 0.4337 - val_loss: 1.0363 - val_accuracy: 0.4444\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0331 - accuracy: 0.4337 - val_loss: 1.0340 - val_accuracy: 0.4444\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0309 - accuracy: 0.4337 - val_loss: 1.0317 - val_accuracy: 0.4444\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0288 - accuracy: 0.4337 - val_loss: 1.0294 - val_accuracy: 0.4444\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0266 - accuracy: 0.4337 - val_loss: 1.0271 - val_accuracy: 0.4630\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0245 - accuracy: 0.4337 - val_loss: 1.0247 - val_accuracy: 0.4630\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0223 - accuracy: 0.4458 - val_loss: 1.0223 - val_accuracy: 0.4630\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0203 - accuracy: 0.4458 - val_loss: 1.0199 - val_accuracy: 0.4630\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.0179 - accuracy: 0.4578 - val_loss: 1.0175 - val_accuracy: 0.4815\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0157 - accuracy: 0.4578 - val_loss: 1.0152 - val_accuracy: 0.4815\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0136 - accuracy: 0.4578 - val_loss: 1.0128 - val_accuracy: 0.4815\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0114 - accuracy: 0.4578 - val_loss: 1.0104 - val_accuracy: 0.4815\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0092 - accuracy: 0.4578 - val_loss: 1.0079 - val_accuracy: 0.4815\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0070 - accuracy: 0.4578 - val_loss: 1.0055 - val_accuracy: 0.4815\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0049 - accuracy: 0.4699 - val_loss: 1.0030 - val_accuracy: 0.4815\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0025 - accuracy: 0.4699 - val_loss: 1.0006 - val_accuracy: 0.4815\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0003 - accuracy: 0.4940 - val_loss: 0.9981 - val_accuracy: 0.4815\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9981 - accuracy: 0.4940 - val_loss: 0.9957 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9958 - accuracy: 0.5060 - val_loss: 0.9932 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9935 - accuracy: 0.5060 - val_loss: 0.9907 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9913 - accuracy: 0.5060 - val_loss: 0.9883 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9890 - accuracy: 0.5060 - val_loss: 0.9858 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9867 - accuracy: 0.5301 - val_loss: 0.9833 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9844 - accuracy: 0.5301 - val_loss: 0.9808 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 240us/sample - loss: 0.9821 - accuracy: 0.5301 - val_loss: 0.9782 - val_accuracy: 0.5185\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9798 - accuracy: 0.5422 - val_loss: 0.9756 - val_accuracy: 0.5556\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9774 - accuracy: 0.5663 - val_loss: 0.9731 - val_accuracy: 0.5556\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 256us/sample - loss: 0.9751 - accuracy: 0.5663 - val_loss: 0.9705 - val_accuracy: 0.5741\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9728 - accuracy: 0.5663 - val_loss: 0.9678 - val_accuracy: 0.5741\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9703 - accuracy: 0.5663 - val_loss: 0.9652 - val_accuracy: 0.5741\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9680 - accuracy: 0.5783 - val_loss: 0.9626 - val_accuracy: 0.5741\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9655 - accuracy: 0.5904 - val_loss: 0.9600 - val_accuracy: 0.5741\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9632 - accuracy: 0.5904 - val_loss: 0.9574 - val_accuracy: 0.5741\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9608 - accuracy: 0.6024 - val_loss: 0.9547 - val_accuracy: 0.5741\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 266us/sample - loss: 0.9584 - accuracy: 0.6024 - val_loss: 0.9520 - val_accuracy: 0.5741\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9559 - accuracy: 0.6145 - val_loss: 0.9493 - val_accuracy: 0.6111\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9534 - accuracy: 0.6145 - val_loss: 0.9466 - val_accuracy: 0.5926\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9511 - accuracy: 0.6627 - val_loss: 0.9439 - val_accuracy: 0.5926\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9485 - accuracy: 0.6627 - val_loss: 0.9412 - val_accuracy: 0.5926\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9461 - accuracy: 0.6747 - val_loss: 0.9385 - val_accuracy: 0.6111\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9437 - accuracy: 0.6747 - val_loss: 0.9358 - val_accuracy: 0.6111\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9413 - accuracy: 0.6988 - val_loss: 0.9330 - val_accuracy: 0.6111\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9387 - accuracy: 0.6988 - val_loss: 0.9303 - val_accuracy: 0.6111\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9362 - accuracy: 0.6988 - val_loss: 0.9276 - val_accuracy: 0.6296\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9337 - accuracy: 0.6988 - val_loss: 0.9249 - val_accuracy: 0.6296\n",
      "41/41 [==============================] - 0s 98us/sample - loss: 0.9286 - accuracy: 0.5854\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 4ms/sample - loss: 1.2584 - accuracy: 0.4268 - val_loss: 1.2033 - val_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.2182 - accuracy: 0.4146 - val_loss: 1.1729 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.1801 - accuracy: 0.4268 - val_loss: 1.1469 - val_accuracy: 0.4074\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.1470 - accuracy: 0.4390 - val_loss: 1.1240 - val_accuracy: 0.4259\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.1168 - accuracy: 0.4512 - val_loss: 1.1043 - val_accuracy: 0.4259\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.0919 - accuracy: 0.4512 - val_loss: 1.0872 - val_accuracy: 0.4259\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.0687 - accuracy: 0.4512 - val_loss: 1.0721 - val_accuracy: 0.4074\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.0487 - accuracy: 0.4512 - val_loss: 1.0586 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.0323 - accuracy: 0.4390 - val_loss: 1.0461 - val_accuracy: 0.4444\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 1.0144 - accuracy: 0.4268 - val_loss: 1.0336 - val_accuracy: 0.4444\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 561us/sample - loss: 0.9988 - accuracy: 0.5244 - val_loss: 1.0211 - val_accuracy: 0.5185\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9840 - accuracy: 0.5732 - val_loss: 1.0082 - val_accuracy: 0.5556\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.9689 - accuracy: 0.6341 - val_loss: 0.9949 - val_accuracy: 0.5926\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.9549 - accuracy: 0.6951 - val_loss: 0.9815 - val_accuracy: 0.6111\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9404 - accuracy: 0.7195 - val_loss: 0.9675 - val_accuracy: 0.6111\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9267 - accuracy: 0.7195 - val_loss: 0.9541 - val_accuracy: 0.6111\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9129 - accuracy: 0.7195 - val_loss: 0.9406 - val_accuracy: 0.6296\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9000 - accuracy: 0.7317 - val_loss: 0.9272 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 216us/sample - loss: 0.8872 - accuracy: 0.7561 - val_loss: 0.9147 - val_accuracy: 0.6852\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8744 - accuracy: 0.7927 - val_loss: 0.9025 - val_accuracy: 0.7037\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8619 - accuracy: 0.7927 - val_loss: 0.8900 - val_accuracy: 0.7037\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8499 - accuracy: 0.7927 - val_loss: 0.8777 - val_accuracy: 0.7222\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.8375 - accuracy: 0.7927 - val_loss: 0.8652 - val_accuracy: 0.7222\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8255 - accuracy: 0.8171 - val_loss: 0.8527 - val_accuracy: 0.7407\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8136 - accuracy: 0.8171 - val_loss: 0.8405 - val_accuracy: 0.7222\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.8018 - accuracy: 0.8293 - val_loss: 0.8287 - val_accuracy: 0.7222\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7899 - accuracy: 0.8415 - val_loss: 0.8171 - val_accuracy: 0.7593\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.7786 - accuracy: 0.8537 - val_loss: 0.8053 - val_accuracy: 0.7778\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.7670 - accuracy: 0.8537 - val_loss: 0.7940 - val_accuracy: 0.7963\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7558 - accuracy: 0.8537 - val_loss: 0.7821 - val_accuracy: 0.7963\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7445 - accuracy: 0.8537 - val_loss: 0.7704 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7330 - accuracy: 0.8537 - val_loss: 0.7585 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.7224 - accuracy: 0.8659 - val_loss: 0.7458 - val_accuracy: 0.8519\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7109 - accuracy: 0.8780 - val_loss: 0.7342 - val_accuracy: 0.8704\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7002 - accuracy: 0.8902 - val_loss: 0.7224 - val_accuracy: 0.8704\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6892 - accuracy: 0.9146 - val_loss: 0.7110 - val_accuracy: 0.8704\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6787 - accuracy: 0.9146 - val_loss: 0.6997 - val_accuracy: 0.8704\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6678 - accuracy: 0.9390 - val_loss: 0.6888 - val_accuracy: 0.8704\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6574 - accuracy: 0.9390 - val_loss: 0.6780 - val_accuracy: 0.8704\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.6470 - accuracy: 0.9390 - val_loss: 0.6671 - val_accuracy: 0.8889\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6368 - accuracy: 0.9390 - val_loss: 0.6564 - val_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.6269 - accuracy: 0.9512 - val_loss: 0.6464 - val_accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6164 - accuracy: 0.9512 - val_loss: 0.6362 - val_accuracy: 0.8889\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6064 - accuracy: 0.9512 - val_loss: 0.6262 - val_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5969 - accuracy: 0.9512 - val_loss: 0.6164 - val_accuracy: 0.9074\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.5870 - accuracy: 0.9634 - val_loss: 0.6073 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5777 - accuracy: 0.9634 - val_loss: 0.5980 - val_accuracy: 0.9259\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5686 - accuracy: 0.9634 - val_loss: 0.5883 - val_accuracy: 0.9259\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5593 - accuracy: 0.9634 - val_loss: 0.5790 - val_accuracy: 0.9259\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5502 - accuracy: 0.9634 - val_loss: 0.5700 - val_accuracy: 0.9259\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5410 - accuracy: 0.9756 - val_loss: 0.5605 - val_accuracy: 0.9259\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.5320 - accuracy: 0.9756 - val_loss: 0.5511 - val_accuracy: 0.9259\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5233 - accuracy: 0.9756 - val_loss: 0.5417 - val_accuracy: 0.9259\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5146 - accuracy: 0.9756 - val_loss: 0.5325 - val_accuracy: 0.9259\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.5061 - accuracy: 0.9756 - val_loss: 0.5237 - val_accuracy: 0.9259\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4976 - accuracy: 0.9756 - val_loss: 0.5152 - val_accuracy: 0.9259\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4896 - accuracy: 0.9756 - val_loss: 0.5071 - val_accuracy: 0.9259\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4814 - accuracy: 0.9756 - val_loss: 0.4986 - val_accuracy: 0.9259\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4733 - accuracy: 0.9756 - val_loss: 0.4907 - val_accuracy: 0.9259\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.4654 - accuracy: 0.9756 - val_loss: 0.4832 - val_accuracy: 0.9259\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4577 - accuracy: 0.9756 - val_loss: 0.4759 - val_accuracy: 0.9259\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4500 - accuracy: 0.9756 - val_loss: 0.4688 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4425 - accuracy: 0.9756 - val_loss: 0.4617 - val_accuracy: 0.9259\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.4353 - accuracy: 0.9756 - val_loss: 0.4543 - val_accuracy: 0.9259\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.4279 - accuracy: 0.9756 - val_loss: 0.4473 - val_accuracy: 0.9259\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4208 - accuracy: 0.9756 - val_loss: 0.4406 - val_accuracy: 0.9259\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4140 - accuracy: 0.9756 - val_loss: 0.4336 - val_accuracy: 0.9259\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4069 - accuracy: 0.9756 - val_loss: 0.4268 - val_accuracy: 0.9259\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4004 - accuracy: 0.9756 - val_loss: 0.4203 - val_accuracy: 0.9259\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3936 - accuracy: 0.9756 - val_loss: 0.4141 - val_accuracy: 0.9259\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.3872 - accuracy: 0.9756 - val_loss: 0.4082 - val_accuracy: 0.9259\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 233us/sample - loss: 0.3809 - accuracy: 0.9756 - val_loss: 0.4025 - val_accuracy: 0.9259\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.3747 - accuracy: 0.9756 - val_loss: 0.3967 - val_accuracy: 0.9259\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.3685 - accuracy: 0.9756 - val_loss: 0.3909 - val_accuracy: 0.9259\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3626 - accuracy: 0.9756 - val_loss: 0.3850 - val_accuracy: 0.9259\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3566 - accuracy: 0.9756 - val_loss: 0.3796 - val_accuracy: 0.9259\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3509 - accuracy: 0.9756 - val_loss: 0.3738 - val_accuracy: 0.9259\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.3453 - accuracy: 0.9756 - val_loss: 0.3683 - val_accuracy: 0.9259\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3396 - accuracy: 0.9756 - val_loss: 0.3632 - val_accuracy: 0.9259\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3343 - accuracy: 0.9756 - val_loss: 0.3583 - val_accuracy: 0.9259\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.3291 - accuracy: 0.9756 - val_loss: 0.3528 - val_accuracy: 0.9259\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3239 - accuracy: 0.9756 - val_loss: 0.3478 - val_accuracy: 0.9259\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.3186 - accuracy: 0.9756 - val_loss: 0.3437 - val_accuracy: 0.9259\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.3138 - accuracy: 0.9756 - val_loss: 0.3397 - val_accuracy: 0.9259\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 250us/sample - loss: 0.3087 - accuracy: 0.9756 - val_loss: 0.3351 - val_accuracy: 0.9259\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3041 - accuracy: 0.9756 - val_loss: 0.3309 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2993 - accuracy: 0.9756 - val_loss: 0.3261 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2946 - accuracy: 0.9756 - val_loss: 0.3213 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2901 - accuracy: 0.9878 - val_loss: 0.3166 - val_accuracy: 0.9259\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2857 - accuracy: 0.9878 - val_loss: 0.3119 - val_accuracy: 0.9259\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2822 - accuracy: 0.9878 - val_loss: 0.3074 - val_accuracy: 0.9259\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2776 - accuracy: 0.9878 - val_loss: 0.3043 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2730 - accuracy: 0.9878 - val_loss: 0.3010 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2689 - accuracy: 0.9878 - val_loss: 0.2978 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2649 - accuracy: 0.9878 - val_loss: 0.2946 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2612 - accuracy: 0.9878 - val_loss: 0.2918 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2574 - accuracy: 0.9878 - val_loss: 0.2886 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2537 - accuracy: 0.9878 - val_loss: 0.2856 - val_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2501 - accuracy: 0.9878 - val_loss: 0.2822 - val_accuracy: 0.9630\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2464 - accuracy: 0.9878 - val_loss: 0.2786 - val_accuracy: 0.9630\n",
      "42/42 [==============================] - 0s 143us/sample - loss: 0.3127 - accuracy: 0.9524\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1878 - accuracy: 0.0482 - val_loss: 1.1808 - val_accuracy: 0.0926\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.1610 - accuracy: 0.1205 - val_loss: 1.1577 - val_accuracy: 0.2407\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.1359 - accuracy: 0.2530 - val_loss: 1.1371 - val_accuracy: 0.3519\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.1148 - accuracy: 0.3735 - val_loss: 1.1171 - val_accuracy: 0.3519\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 216us/sample - loss: 1.0944 - accuracy: 0.4458 - val_loss: 1.0985 - val_accuracy: 0.3704\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 204us/sample - loss: 1.0753 - accuracy: 0.5060 - val_loss: 1.0805 - val_accuracy: 0.3889\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0568 - accuracy: 0.5542 - val_loss: 1.0635 - val_accuracy: 0.3889\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0401 - accuracy: 0.5542 - val_loss: 1.0469 - val_accuracy: 0.4259\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0224 - accuracy: 0.5542 - val_loss: 1.0307 - val_accuracy: 0.4259\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0059 - accuracy: 0.5783 - val_loss: 1.0150 - val_accuracy: 0.4444\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9897 - accuracy: 0.5904 - val_loss: 0.9997 - val_accuracy: 0.4630\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9738 - accuracy: 0.6024 - val_loss: 0.9849 - val_accuracy: 0.5185\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9583 - accuracy: 0.6386 - val_loss: 0.9706 - val_accuracy: 0.5370\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9425 - accuracy: 0.6506 - val_loss: 0.9561 - val_accuracy: 0.5556\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 211us/sample - loss: 0.9274 - accuracy: 0.6747 - val_loss: 0.9419 - val_accuracy: 0.6111\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9122 - accuracy: 0.7108 - val_loss: 0.9281 - val_accuracy: 0.6296\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8980 - accuracy: 0.7349 - val_loss: 0.9143 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8832 - accuracy: 0.7470 - val_loss: 0.9002 - val_accuracy: 0.6852\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8689 - accuracy: 0.7590 - val_loss: 0.8857 - val_accuracy: 0.7037\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8549 - accuracy: 0.7711 - val_loss: 0.8712 - val_accuracy: 0.7037\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8407 - accuracy: 0.7711 - val_loss: 0.8571 - val_accuracy: 0.7222\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8279 - accuracy: 0.8193 - val_loss: 0.8433 - val_accuracy: 0.7593\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8140 - accuracy: 0.8313 - val_loss: 0.8301 - val_accuracy: 0.7593\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8005 - accuracy: 0.8554 - val_loss: 0.8170 - val_accuracy: 0.7593\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7876 - accuracy: 0.8675 - val_loss: 0.8040 - val_accuracy: 0.7778\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7749 - accuracy: 0.8916 - val_loss: 0.7915 - val_accuracy: 0.7778\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7619 - accuracy: 0.8916 - val_loss: 0.7783 - val_accuracy: 0.7963\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7493 - accuracy: 0.8916 - val_loss: 0.7651 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7371 - accuracy: 0.9036 - val_loss: 0.7524 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7248 - accuracy: 0.9157 - val_loss: 0.7406 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7127 - accuracy: 0.9157 - val_loss: 0.7283 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7008 - accuracy: 0.9157 - val_loss: 0.7162 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6889 - accuracy: 0.9157 - val_loss: 0.7048 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6773 - accuracy: 0.9157 - val_loss: 0.6933 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 204us/sample - loss: 0.6658 - accuracy: 0.9277 - val_loss: 0.6814 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6551 - accuracy: 0.9277 - val_loss: 0.6701 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6430 - accuracy: 0.9277 - val_loss: 0.6592 - val_accuracy: 0.8333\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6323 - accuracy: 0.9277 - val_loss: 0.6483 - val_accuracy: 0.8519\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6215 - accuracy: 0.9398 - val_loss: 0.6378 - val_accuracy: 0.8519\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6109 - accuracy: 0.9398 - val_loss: 0.6271 - val_accuracy: 0.8519\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6003 - accuracy: 0.9398 - val_loss: 0.6163 - val_accuracy: 0.8704\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5902 - accuracy: 0.9398 - val_loss: 0.6058 - val_accuracy: 0.8704\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5799 - accuracy: 0.9398 - val_loss: 0.5960 - val_accuracy: 0.8704\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 285us/sample - loss: 0.5700 - accuracy: 0.9398 - val_loss: 0.5861 - val_accuracy: 0.8704\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5603 - accuracy: 0.9398 - val_loss: 0.5760 - val_accuracy: 0.8704\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5508 - accuracy: 0.9398 - val_loss: 0.5660 - val_accuracy: 0.8704\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 263us/sample - loss: 0.5411 - accuracy: 0.9398 - val_loss: 0.5566 - val_accuracy: 0.8704\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5318 - accuracy: 0.9398 - val_loss: 0.5478 - val_accuracy: 0.8704\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5228 - accuracy: 0.9398 - val_loss: 0.5396 - val_accuracy: 0.8704\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5141 - accuracy: 0.9398 - val_loss: 0.5315 - val_accuracy: 0.8704\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 219us/sample - loss: 0.5050 - accuracy: 0.9398 - val_loss: 0.5232 - val_accuracy: 0.8704\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4971 - accuracy: 0.9518 - val_loss: 0.5158 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.4883 - accuracy: 0.9518 - val_loss: 0.5075 - val_accuracy: 0.8704\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4800 - accuracy: 0.9518 - val_loss: 0.4995 - val_accuracy: 0.8704\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4719 - accuracy: 0.9518 - val_loss: 0.4911 - val_accuracy: 0.8704\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4638 - accuracy: 0.9518 - val_loss: 0.4835 - val_accuracy: 0.8704\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4560 - accuracy: 0.9518 - val_loss: 0.4753 - val_accuracy: 0.8704\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4485 - accuracy: 0.9518 - val_loss: 0.4674 - val_accuracy: 0.8704\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4408 - accuracy: 0.9518 - val_loss: 0.4598 - val_accuracy: 0.8704\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4333 - accuracy: 0.9518 - val_loss: 0.4523 - val_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4265 - accuracy: 0.9518 - val_loss: 0.4446 - val_accuracy: 0.9259\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.4192 - accuracy: 0.9518 - val_loss: 0.4379 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4122 - accuracy: 0.9518 - val_loss: 0.4314 - val_accuracy: 0.9259\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 259us/sample - loss: 0.4055 - accuracy: 0.9518 - val_loss: 0.4254 - val_accuracy: 0.9259\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3990 - accuracy: 0.9518 - val_loss: 0.4198 - val_accuracy: 0.9259\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3924 - accuracy: 0.9518 - val_loss: 0.4133 - val_accuracy: 0.9259\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3859 - accuracy: 0.9518 - val_loss: 0.4066 - val_accuracy: 0.9259\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3797 - accuracy: 0.9518 - val_loss: 0.3995 - val_accuracy: 0.9259\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.3735 - accuracy: 0.9639 - val_loss: 0.3920 - val_accuracy: 0.9259\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3680 - accuracy: 0.9639 - val_loss: 0.3850 - val_accuracy: 0.9259\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3619 - accuracy: 0.9639 - val_loss: 0.3793 - val_accuracy: 0.9259\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3561 - accuracy: 0.9639 - val_loss: 0.3732 - val_accuracy: 0.9259\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3504 - accuracy: 0.9639 - val_loss: 0.3679 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3450 - accuracy: 0.9639 - val_loss: 0.3629 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3397 - accuracy: 0.9639 - val_loss: 0.3587 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3341 - accuracy: 0.9639 - val_loss: 0.3538 - val_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3291 - accuracy: 0.9639 - val_loss: 0.3497 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3240 - accuracy: 0.9639 - val_loss: 0.3456 - val_accuracy: 0.9630\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3190 - accuracy: 0.9639 - val_loss: 0.3409 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3140 - accuracy: 0.9639 - val_loss: 0.3372 - val_accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3094 - accuracy: 0.9639 - val_loss: 0.3337 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3046 - accuracy: 0.9639 - val_loss: 0.3291 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2999 - accuracy: 0.9639 - val_loss: 0.3240 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2953 - accuracy: 0.9639 - val_loss: 0.3190 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2907 - accuracy: 0.9639 - val_loss: 0.3138 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2868 - accuracy: 0.9639 - val_loss: 0.3080 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2824 - accuracy: 0.9639 - val_loss: 0.3032 - val_accuracy: 0.9630\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2787 - accuracy: 0.9639 - val_loss: 0.2988 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2743 - accuracy: 0.9639 - val_loss: 0.2957 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2703 - accuracy: 0.9639 - val_loss: 0.2926 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2663 - accuracy: 0.9639 - val_loss: 0.2899 - val_accuracy: 0.9630\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2626 - accuracy: 0.9639 - val_loss: 0.2870 - val_accuracy: 0.9630\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2587 - accuracy: 0.9639 - val_loss: 0.2837 - val_accuracy: 0.9630\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2551 - accuracy: 0.9639 - val_loss: 0.2806 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2515 - accuracy: 0.9639 - val_loss: 0.2771 - val_accuracy: 0.9630\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2480 - accuracy: 0.9639 - val_loss: 0.2739 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2446 - accuracy: 0.9639 - val_loss: 0.2707 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2413 - accuracy: 0.9639 - val_loss: 0.2674 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2379 - accuracy: 0.9639 - val_loss: 0.2646 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2348 - accuracy: 0.9639 - val_loss: 0.2616 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.2700 - accuracy: 1.0000\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 5ms/sample - loss: 1.1253 - accuracy: 0.2651 - val_loss: 1.0867 - val_accuracy: 0.2963\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0908 - accuracy: 0.2651 - val_loss: 1.0600 - val_accuracy: 0.3148\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0637 - accuracy: 0.3012 - val_loss: 1.0352 - val_accuracy: 0.3889\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0372 - accuracy: 0.4217 - val_loss: 1.0132 - val_accuracy: 0.5741\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 219us/sample - loss: 1.0157 - accuracy: 0.5542 - val_loss: 0.9933 - val_accuracy: 0.7222\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9954 - accuracy: 0.7470 - val_loss: 0.9755 - val_accuracy: 0.8148\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9767 - accuracy: 0.7831 - val_loss: 0.9592 - val_accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9617 - accuracy: 0.8193 - val_loss: 0.9441 - val_accuracy: 0.8704\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9444 - accuracy: 0.8313 - val_loss: 0.9302 - val_accuracy: 0.8704\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9311 - accuracy: 0.8313 - val_loss: 0.9170 - val_accuracy: 0.7963\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9177 - accuracy: 0.7952 - val_loss: 0.9043 - val_accuracy: 0.7778\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9059 - accuracy: 0.7952 - val_loss: 0.8918 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8940 - accuracy: 0.8072 - val_loss: 0.8795 - val_accuracy: 0.7963\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8822 - accuracy: 0.8072 - val_loss: 0.8672 - val_accuracy: 0.8148\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8708 - accuracy: 0.8193 - val_loss: 0.8550 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8602 - accuracy: 0.8313 - val_loss: 0.8433 - val_accuracy: 0.8519\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8488 - accuracy: 0.8313 - val_loss: 0.8314 - val_accuracy: 0.8519\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8376 - accuracy: 0.8434 - val_loss: 0.8192 - val_accuracy: 0.8889\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8270 - accuracy: 0.8434 - val_loss: 0.8070 - val_accuracy: 0.8889\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8159 - accuracy: 0.8916 - val_loss: 0.7950 - val_accuracy: 0.8889\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8050 - accuracy: 0.9036 - val_loss: 0.7834 - val_accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7940 - accuracy: 0.9036 - val_loss: 0.7718 - val_accuracy: 0.8889\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7834 - accuracy: 0.9157 - val_loss: 0.7601 - val_accuracy: 0.8889\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7727 - accuracy: 0.9157 - val_loss: 0.7483 - val_accuracy: 0.9074\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7619 - accuracy: 0.9157 - val_loss: 0.7366 - val_accuracy: 0.9074\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7511 - accuracy: 0.9398 - val_loss: 0.7249 - val_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.7408 - accuracy: 0.9398 - val_loss: 0.7132 - val_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7299 - accuracy: 0.9518 - val_loss: 0.7017 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.7193 - accuracy: 0.9518 - val_loss: 0.6903 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7090 - accuracy: 0.9518 - val_loss: 0.6790 - val_accuracy: 0.9630\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6981 - accuracy: 0.9518 - val_loss: 0.6679 - val_accuracy: 0.9630\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6878 - accuracy: 0.9518 - val_loss: 0.6567 - val_accuracy: 0.9630\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.6773 - accuracy: 0.9398 - val_loss: 0.6457 - val_accuracy: 0.9630\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 283us/sample - loss: 0.6672 - accuracy: 0.9398 - val_loss: 0.6347 - val_accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.6569 - accuracy: 0.9398 - val_loss: 0.6237 - val_accuracy: 0.9815\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6463 - accuracy: 0.9398 - val_loss: 0.6129 - val_accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6363 - accuracy: 0.9398 - val_loss: 0.6020 - val_accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6264 - accuracy: 0.9398 - val_loss: 0.5912 - val_accuracy: 0.9630\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6159 - accuracy: 0.9518 - val_loss: 0.5807 - val_accuracy: 0.9630\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6065 - accuracy: 0.9518 - val_loss: 0.5705 - val_accuracy: 0.9630\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5968 - accuracy: 0.9639 - val_loss: 0.5603 - val_accuracy: 0.9630\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5870 - accuracy: 0.9639 - val_loss: 0.5502 - val_accuracy: 0.9630\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5777 - accuracy: 0.9639 - val_loss: 0.5404 - val_accuracy: 0.9630\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.5683 - accuracy: 0.9639 - val_loss: 0.5305 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5587 - accuracy: 0.9639 - val_loss: 0.5209 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.5494 - accuracy: 0.9518 - val_loss: 0.5112 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5401 - accuracy: 0.9639 - val_loss: 0.5017 - val_accuracy: 0.9630\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.5309 - accuracy: 0.9639 - val_loss: 0.4924 - val_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5222 - accuracy: 0.9639 - val_loss: 0.4832 - val_accuracy: 0.9630\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5133 - accuracy: 0.9639 - val_loss: 0.4741 - val_accuracy: 0.9630\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5048 - accuracy: 0.9759 - val_loss: 0.4653 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4961 - accuracy: 0.9880 - val_loss: 0.4566 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4877 - accuracy: 0.9880 - val_loss: 0.4481 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4794 - accuracy: 0.9880 - val_loss: 0.4398 - val_accuracy: 0.9630\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 218us/sample - loss: 0.4712 - accuracy: 0.9880 - val_loss: 0.4317 - val_accuracy: 0.9630\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 216us/sample - loss: 0.4634 - accuracy: 0.9759 - val_loss: 0.4238 - val_accuracy: 0.9630\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4556 - accuracy: 0.9759 - val_loss: 0.4160 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4480 - accuracy: 0.9759 - val_loss: 0.4083 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4401 - accuracy: 0.9759 - val_loss: 0.4007 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4328 - accuracy: 0.9759 - val_loss: 0.3932 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4254 - accuracy: 0.9759 - val_loss: 0.3860 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4184 - accuracy: 0.9759 - val_loss: 0.3790 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4112 - accuracy: 0.9759 - val_loss: 0.3720 - val_accuracy: 0.9630\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.4045 - accuracy: 0.9759 - val_loss: 0.3652 - val_accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3978 - accuracy: 0.9759 - val_loss: 0.3587 - val_accuracy: 0.9630\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.3993 - accuracy: 0.96 - 0s 229us/sample - loss: 0.3913 - accuracy: 0.9759 - val_loss: 0.3522 - val_accuracy: 0.9630\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3852 - accuracy: 0.9759 - val_loss: 0.3460 - val_accuracy: 0.9630\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3787 - accuracy: 0.9759 - val_loss: 0.3399 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3724 - accuracy: 0.9759 - val_loss: 0.3339 - val_accuracy: 0.9630\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3662 - accuracy: 0.9759 - val_loss: 0.3282 - val_accuracy: 0.9630\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3602 - accuracy: 0.9759 - val_loss: 0.3226 - val_accuracy: 0.9630\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3546 - accuracy: 0.9759 - val_loss: 0.3172 - val_accuracy: 0.9630\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3489 - accuracy: 0.9759 - val_loss: 0.3119 - val_accuracy: 0.9630\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3436 - accuracy: 0.9759 - val_loss: 0.3065 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3380 - accuracy: 0.9759 - val_loss: 0.3013 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3323 - accuracy: 0.9759 - val_loss: 0.2964 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3276 - accuracy: 0.9759 - val_loss: 0.2917 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3224 - accuracy: 0.9759 - val_loss: 0.2870 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3175 - accuracy: 0.9759 - val_loss: 0.2821 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3124 - accuracy: 0.9759 - val_loss: 0.2776 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3076 - accuracy: 0.9759 - val_loss: 0.2731 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 259us/sample - loss: 0.3031 - accuracy: 0.9759 - val_loss: 0.2688 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.2983 - accuracy: 0.9759 - val_loss: 0.2644 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2937 - accuracy: 0.9759 - val_loss: 0.2601 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.2894 - accuracy: 0.9759 - val_loss: 0.2559 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2857 - accuracy: 0.9759 - val_loss: 0.2518 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2811 - accuracy: 0.9759 - val_loss: 0.2481 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2772 - accuracy: 0.9759 - val_loss: 0.2445 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2730 - accuracy: 0.9759 - val_loss: 0.2410 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2690 - accuracy: 0.9759 - val_loss: 0.2374 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2652 - accuracy: 0.9759 - val_loss: 0.2340 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2616 - accuracy: 0.9759 - val_loss: 0.2309 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2577 - accuracy: 0.9759 - val_loss: 0.2275 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2541 - accuracy: 0.9759 - val_loss: 0.2244 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2506 - accuracy: 0.9759 - val_loss: 0.2214 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2473 - accuracy: 0.9759 - val_loss: 0.2185 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2439 - accuracy: 0.9759 - val_loss: 0.2156 - val_accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2406 - accuracy: 0.9759 - val_loss: 0.2129 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 251us/sample - loss: 0.2374 - accuracy: 0.9759 - val_loss: 0.2101 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2343 - accuracy: 0.9759 - val_loss: 0.2071 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.2252 - accuracy: 0.9756\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 4ms/sample - loss: 1.3256 - accuracy: 0.3537 - val_loss: 1.3049 - val_accuracy: 0.2963\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 212us/sample - loss: 1.3017 - accuracy: 0.3537 - val_loss: 1.2801 - val_accuracy: 0.2963\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 1.2778 - accuracy: 0.3537 - val_loss: 1.2559 - val_accuracy: 0.2963\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.2550 - accuracy: 0.3537 - val_loss: 1.2326 - val_accuracy: 0.2963\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.2343 - accuracy: 0.3537 - val_loss: 1.2099 - val_accuracy: 0.2963\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.2125 - accuracy: 0.3537 - val_loss: 1.1884 - val_accuracy: 0.2963\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 1.1924 - accuracy: 0.3537 - val_loss: 1.1677 - val_accuracy: 0.2963\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.1717 - accuracy: 0.3537 - val_loss: 1.1481 - val_accuracy: 0.2963\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 234us/sample - loss: 1.1540 - accuracy: 0.3537 - val_loss: 1.1288 - val_accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 1.1348 - accuracy: 0.3537 - val_loss: 1.1104 - val_accuracy: 0.3333\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 197us/sample - loss: 1.1175 - accuracy: 0.3537 - val_loss: 1.0929 - val_accuracy: 0.3519\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 1.1010 - accuracy: 0.3659 - val_loss: 1.0762 - val_accuracy: 0.3519\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 1.0845 - accuracy: 0.3659 - val_loss: 1.0604 - val_accuracy: 0.3889\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 1.0695 - accuracy: 0.3659 - val_loss: 1.0450 - val_accuracy: 0.4444\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 1.0538 - accuracy: 0.3780 - val_loss: 1.0304 - val_accuracy: 0.4815\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.0416 - accuracy: 0.3780 - val_loss: 1.0163 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 1.0267 - accuracy: 0.4024 - val_loss: 1.0031 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 1.0136 - accuracy: 0.4268 - val_loss: 0.9904 - val_accuracy: 0.5185\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 1.0021 - accuracy: 0.4756 - val_loss: 0.9781 - val_accuracy: 0.5370\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.9905 - accuracy: 0.4756 - val_loss: 0.9666 - val_accuracy: 0.5370\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.9794 - accuracy: 0.4756 - val_loss: 0.9556 - val_accuracy: 0.5741\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9689 - accuracy: 0.4756 - val_loss: 0.9450 - val_accuracy: 0.5741\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.9586 - accuracy: 0.4878 - val_loss: 0.9350 - val_accuracy: 0.5741\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9490 - accuracy: 0.4878 - val_loss: 0.9254 - val_accuracy: 0.5926\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9393 - accuracy: 0.5122 - val_loss: 0.9160 - val_accuracy: 0.5926\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9309 - accuracy: 0.5244 - val_loss: 0.9066 - val_accuracy: 0.5926\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9224 - accuracy: 0.5366 - val_loss: 0.8977 - val_accuracy: 0.5926\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9138 - accuracy: 0.5488 - val_loss: 0.8888 - val_accuracy: 0.6111\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9056 - accuracy: 0.5610 - val_loss: 0.8804 - val_accuracy: 0.6667\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8978 - accuracy: 0.5854 - val_loss: 0.8723 - val_accuracy: 0.6667\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8898 - accuracy: 0.5976 - val_loss: 0.8643 - val_accuracy: 0.6667\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8825 - accuracy: 0.6098 - val_loss: 0.8563 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8749 - accuracy: 0.6098 - val_loss: 0.8487 - val_accuracy: 0.6852\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8675 - accuracy: 0.6098 - val_loss: 0.8410 - val_accuracy: 0.6852\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8608 - accuracy: 0.6098 - val_loss: 0.8332 - val_accuracy: 0.7037\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8534 - accuracy: 0.6220 - val_loss: 0.8259 - val_accuracy: 0.7222\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8467 - accuracy: 0.6220 - val_loss: 0.8187 - val_accuracy: 0.7222\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8401 - accuracy: 0.6341 - val_loss: 0.8115 - val_accuracy: 0.7407\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.8332 - accuracy: 0.6707 - val_loss: 0.8045 - val_accuracy: 0.7593\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.8267 - accuracy: 0.6707 - val_loss: 0.7975 - val_accuracy: 0.7593\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8203 - accuracy: 0.6951 - val_loss: 0.7905 - val_accuracy: 0.7593\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8138 - accuracy: 0.7439 - val_loss: 0.7837 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.8075 - accuracy: 0.7561 - val_loss: 0.7768 - val_accuracy: 0.8519\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.8013 - accuracy: 0.7683 - val_loss: 0.7701 - val_accuracy: 0.8519\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7951 - accuracy: 0.7683 - val_loss: 0.7634 - val_accuracy: 0.8519\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7887 - accuracy: 0.7683 - val_loss: 0.7568 - val_accuracy: 0.8519\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7824 - accuracy: 0.7683 - val_loss: 0.7503 - val_accuracy: 0.8704\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 254us/sample - loss: 0.7766 - accuracy: 0.7805 - val_loss: 0.7438 - val_accuracy: 0.8704\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7703 - accuracy: 0.7927 - val_loss: 0.7375 - val_accuracy: 0.8704\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7643 - accuracy: 0.8049 - val_loss: 0.7310 - val_accuracy: 0.8889\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7582 - accuracy: 0.8049 - val_loss: 0.7245 - val_accuracy: 0.8889\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7521 - accuracy: 0.8049 - val_loss: 0.7181 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7464 - accuracy: 0.8049 - val_loss: 0.7118 - val_accuracy: 0.8704\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7406 - accuracy: 0.8293 - val_loss: 0.7055 - val_accuracy: 0.8704\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7345 - accuracy: 0.8415 - val_loss: 0.6994 - val_accuracy: 0.8704\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7288 - accuracy: 0.8415 - val_loss: 0.6932 - val_accuracy: 0.8704\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7231 - accuracy: 0.8537 - val_loss: 0.6872 - val_accuracy: 0.9074\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.7172 - accuracy: 0.8537 - val_loss: 0.6813 - val_accuracy: 0.9074\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7116 - accuracy: 0.8537 - val_loss: 0.6754 - val_accuracy: 0.9074\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7059 - accuracy: 0.8537 - val_loss: 0.6694 - val_accuracy: 0.9074\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7005 - accuracy: 0.8537 - val_loss: 0.6635 - val_accuracy: 0.9074\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.6946 - accuracy: 0.8537 - val_loss: 0.6577 - val_accuracy: 0.9074\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.6893 - accuracy: 0.8537 - val_loss: 0.6520 - val_accuracy: 0.9074\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.6835 - accuracy: 0.8537 - val_loss: 0.6464 - val_accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6781 - accuracy: 0.8537 - val_loss: 0.6409 - val_accuracy: 0.9074\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 226us/sample - loss: 0.6728 - accuracy: 0.8537 - val_loss: 0.6353 - val_accuracy: 0.9074\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.6671 - accuracy: 0.8537 - val_loss: 0.6298 - val_accuracy: 0.9074\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6617 - accuracy: 0.8537 - val_loss: 0.6242 - val_accuracy: 0.9074\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6564 - accuracy: 0.8537 - val_loss: 0.6186 - val_accuracy: 0.9074\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6510 - accuracy: 0.8659 - val_loss: 0.6131 - val_accuracy: 0.9074\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6458 - accuracy: 0.8659 - val_loss: 0.6076 - val_accuracy: 0.9074\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6405 - accuracy: 0.8659 - val_loss: 0.6022 - val_accuracy: 0.9074\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.6352 - accuracy: 0.8659 - val_loss: 0.5969 - val_accuracy: 0.9074\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6300 - accuracy: 0.8659 - val_loss: 0.5915 - val_accuracy: 0.9074\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 275us/sample - loss: 0.6247 - accuracy: 0.8659 - val_loss: 0.5863 - val_accuracy: 0.9074\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 278us/sample - loss: 0.6196 - accuracy: 0.8780 - val_loss: 0.5810 - val_accuracy: 0.9074\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.6144 - accuracy: 0.8780 - val_loss: 0.5759 - val_accuracy: 0.9074\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 255us/sample - loss: 0.6092 - accuracy: 0.8780 - val_loss: 0.5709 - val_accuracy: 0.9074\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6042 - accuracy: 0.8780 - val_loss: 0.5659 - val_accuracy: 0.9259\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5992 - accuracy: 0.8780 - val_loss: 0.5609 - val_accuracy: 0.9259\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5941 - accuracy: 0.8780 - val_loss: 0.5560 - val_accuracy: 0.9259\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5894 - accuracy: 0.8780 - val_loss: 0.5512 - val_accuracy: 0.9259\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5843 - accuracy: 0.8780 - val_loss: 0.5462 - val_accuracy: 0.9259\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5795 - accuracy: 0.8780 - val_loss: 0.5412 - val_accuracy: 0.9259\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5745 - accuracy: 0.8780 - val_loss: 0.5364 - val_accuracy: 0.9259\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5697 - accuracy: 0.8780 - val_loss: 0.5316 - val_accuracy: 0.9259\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5649 - accuracy: 0.8780 - val_loss: 0.5269 - val_accuracy: 0.9259\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5603 - accuracy: 0.8780 - val_loss: 0.5221 - val_accuracy: 0.9259\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.5556 - accuracy: 0.8780 - val_loss: 0.5174 - val_accuracy: 0.9259\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5509 - accuracy: 0.8780 - val_loss: 0.5129 - val_accuracy: 0.9259\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.5463 - accuracy: 0.8902 - val_loss: 0.5084 - val_accuracy: 0.9259\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5417 - accuracy: 0.9024 - val_loss: 0.5039 - val_accuracy: 0.9259\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5372 - accuracy: 0.9146 - val_loss: 0.4994 - val_accuracy: 0.9259\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 238us/sample - loss: 0.5327 - accuracy: 0.9146 - val_loss: 0.4949 - val_accuracy: 0.9259\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 306us/sample - loss: 0.5283 - accuracy: 0.9146 - val_loss: 0.4905 - val_accuracy: 0.9259\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5237 - accuracy: 0.8902 - val_loss: 0.4861 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.5197 - accuracy: 0.8902 - val_loss: 0.4817 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 329us/sample - loss: 0.5153 - accuracy: 0.9024 - val_loss: 0.4774 - val_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5110 - accuracy: 0.9024 - val_loss: 0.4733 - val_accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5068 - accuracy: 0.9146 - val_loss: 0.4692 - val_accuracy: 0.9444\n",
      "42/42 [==============================] - 0s 167us/sample - loss: 0.5256 - accuracy: 0.8333\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 5ms/sample - loss: 1.0615 - accuracy: 0.6145 - val_loss: 1.1299 - val_accuracy: 0.5741\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0440 - accuracy: 0.6386 - val_loss: 1.1085 - val_accuracy: 0.5741\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 270us/sample - loss: 1.0268 - accuracy: 0.6506 - val_loss: 1.0880 - val_accuracy: 0.5926\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 1.0107 - accuracy: 0.6506 - val_loss: 1.0683 - val_accuracy: 0.5926\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.9939 - accuracy: 0.6627 - val_loss: 1.0498 - val_accuracy: 0.6111\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9808 - accuracy: 0.6627 - val_loss: 1.0315 - val_accuracy: 0.5926\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9675 - accuracy: 0.6627 - val_loss: 1.0141 - val_accuracy: 0.5926\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9534 - accuracy: 0.6627 - val_loss: 0.9984 - val_accuracy: 0.5926\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9419 - accuracy: 0.6627 - val_loss: 0.9832 - val_accuracy: 0.5926\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9301 - accuracy: 0.6627 - val_loss: 0.9692 - val_accuracy: 0.5926\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.9194 - accuracy: 0.6747 - val_loss: 0.9555 - val_accuracy: 0.5926\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9089 - accuracy: 0.6747 - val_loss: 0.9425 - val_accuracy: 0.5926\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8989 - accuracy: 0.6747 - val_loss: 0.9298 - val_accuracy: 0.6296\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 251us/sample - loss: 0.8896 - accuracy: 0.6747 - val_loss: 0.9176 - val_accuracy: 0.6296\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8803 - accuracy: 0.6988 - val_loss: 0.9059 - val_accuracy: 0.6296\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8714 - accuracy: 0.7349 - val_loss: 0.8947 - val_accuracy: 0.6481\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 235us/sample - loss: 0.8625 - accuracy: 0.7590 - val_loss: 0.8840 - val_accuracy: 0.6481\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8549 - accuracy: 0.7711 - val_loss: 0.8735 - val_accuracy: 0.6667\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8467 - accuracy: 0.7952 - val_loss: 0.8636 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8386 - accuracy: 0.7952 - val_loss: 0.8541 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8307 - accuracy: 0.7952 - val_loss: 0.8449 - val_accuracy: 0.6852\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8231 - accuracy: 0.8072 - val_loss: 0.8362 - val_accuracy: 0.7037\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8159 - accuracy: 0.8072 - val_loss: 0.8273 - val_accuracy: 0.7407\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8086 - accuracy: 0.8193 - val_loss: 0.8187 - val_accuracy: 0.7593\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8015 - accuracy: 0.8313 - val_loss: 0.8103 - val_accuracy: 0.7593\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7942 - accuracy: 0.8434 - val_loss: 0.8026 - val_accuracy: 0.7593\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7870 - accuracy: 0.8434 - val_loss: 0.7949 - val_accuracy: 0.7778\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.7800 - accuracy: 0.8554 - val_loss: 0.7874 - val_accuracy: 0.8148\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.7730 - accuracy: 0.8675 - val_loss: 0.7802 - val_accuracy: 0.8148\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.7660 - accuracy: 0.8795 - val_loss: 0.7731 - val_accuracy: 0.8333\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.7592 - accuracy: 0.8795 - val_loss: 0.7662 - val_accuracy: 0.8333\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7524 - accuracy: 0.8795 - val_loss: 0.7590 - val_accuracy: 0.8333\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7456 - accuracy: 0.8795 - val_loss: 0.7513 - val_accuracy: 0.8333\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 284us/sample - loss: 0.7388 - accuracy: 0.8916 - val_loss: 0.7440 - val_accuracy: 0.8333\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7319 - accuracy: 0.9036 - val_loss: 0.7372 - val_accuracy: 0.8519\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.7254 - accuracy: 0.9036 - val_loss: 0.7306 - val_accuracy: 0.8519\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7188 - accuracy: 0.9036 - val_loss: 0.7234 - val_accuracy: 0.8519\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7121 - accuracy: 0.9036 - val_loss: 0.7167 - val_accuracy: 0.8519\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 216us/sample - loss: 0.7056 - accuracy: 0.9036 - val_loss: 0.7101 - val_accuracy: 0.8519\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6992 - accuracy: 0.9157 - val_loss: 0.7034 - val_accuracy: 0.8519\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6928 - accuracy: 0.9157 - val_loss: 0.6974 - val_accuracy: 0.8519\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6863 - accuracy: 0.9157 - val_loss: 0.6911 - val_accuracy: 0.8519\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 446us/sample - loss: 0.6800 - accuracy: 0.9157 - val_loss: 0.6842 - val_accuracy: 0.8519\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 410us/sample - loss: 0.6737 - accuracy: 0.9157 - val_loss: 0.6777 - val_accuracy: 0.8519\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 446us/sample - loss: 0.6673 - accuracy: 0.9157 - val_loss: 0.6716 - val_accuracy: 0.8519\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.6612 - accuracy: 0.9157 - val_loss: 0.6649 - val_accuracy: 0.8519\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 218us/sample - loss: 0.6550 - accuracy: 0.9157 - val_loss: 0.6584 - val_accuracy: 0.8519\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6488 - accuracy: 0.9157 - val_loss: 0.6519 - val_accuracy: 0.8519\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6428 - accuracy: 0.9157 - val_loss: 0.6454 - val_accuracy: 0.8519\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6366 - accuracy: 0.9157 - val_loss: 0.6396 - val_accuracy: 0.8519\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6305 - accuracy: 0.9277 - val_loss: 0.6331 - val_accuracy: 0.8704\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6246 - accuracy: 0.9277 - val_loss: 0.6267 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6187 - accuracy: 0.9277 - val_loss: 0.6207 - val_accuracy: 0.8704\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6127 - accuracy: 0.9277 - val_loss: 0.6144 - val_accuracy: 0.8704\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6070 - accuracy: 0.9277 - val_loss: 0.6082 - val_accuracy: 0.8704\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6009 - accuracy: 0.9277 - val_loss: 0.6018 - val_accuracy: 0.9074\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 220us/sample - loss: 0.5954 - accuracy: 0.9277 - val_loss: 0.5950 - val_accuracy: 0.9074\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5895 - accuracy: 0.9277 - val_loss: 0.5888 - val_accuracy: 0.9074\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5838 - accuracy: 0.9277 - val_loss: 0.5830 - val_accuracy: 0.9259\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5785 - accuracy: 0.9277 - val_loss: 0.5766 - val_accuracy: 0.9259\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5727 - accuracy: 0.9277 - val_loss: 0.5709 - val_accuracy: 0.9259\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 204us/sample - loss: 0.5671 - accuracy: 0.9277 - val_loss: 0.5660 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5614 - accuracy: 0.9277 - val_loss: 0.5608 - val_accuracy: 0.9259\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5560 - accuracy: 0.9277 - val_loss: 0.5552 - val_accuracy: 0.9259\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5505 - accuracy: 0.9277 - val_loss: 0.5499 - val_accuracy: 0.9259\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5453 - accuracy: 0.9277 - val_loss: 0.5448 - val_accuracy: 0.9259\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5399 - accuracy: 0.9277 - val_loss: 0.5395 - val_accuracy: 0.9259\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5345 - accuracy: 0.9277 - val_loss: 0.5337 - val_accuracy: 0.9259\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5292 - accuracy: 0.9398 - val_loss: 0.5277 - val_accuracy: 0.9444\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5244 - accuracy: 0.9398 - val_loss: 0.5218 - val_accuracy: 0.9444\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5189 - accuracy: 0.9398 - val_loss: 0.5167 - val_accuracy: 0.9444\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 215us/sample - loss: 0.5138 - accuracy: 0.9398 - val_loss: 0.5117 - val_accuracy: 0.9444\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5088 - accuracy: 0.9398 - val_loss: 0.5068 - val_accuracy: 0.9444\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5038 - accuracy: 0.9398 - val_loss: 0.5024 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4989 - accuracy: 0.9398 - val_loss: 0.4977 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.4939 - accuracy: 0.9398 - val_loss: 0.4932 - val_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.4890 - accuracy: 0.9639 - val_loss: 0.4888 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.4842 - accuracy: 0.9639 - val_loss: 0.4842 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.4795 - accuracy: 0.9639 - val_loss: 0.4793 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.4747 - accuracy: 0.9639 - val_loss: 0.4748 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.4701 - accuracy: 0.9639 - val_loss: 0.4703 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.4654 - accuracy: 0.9639 - val_loss: 0.4662 - val_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.4608 - accuracy: 0.9639 - val_loss: 0.4618 - val_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 191us/sample - loss: 0.4564 - accuracy: 0.9639 - val_loss: 0.4568 - val_accuracy: 0.9444\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 167us/sample - loss: 0.4518 - accuracy: 0.9639 - val_loss: 0.4521 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.4473 - accuracy: 0.9639 - val_loss: 0.4478 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.4429 - accuracy: 0.9639 - val_loss: 0.4435 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.4386 - accuracy: 0.9639 - val_loss: 0.4396 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.4343 - accuracy: 0.9639 - val_loss: 0.4352 - val_accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.4300 - accuracy: 0.9639 - val_loss: 0.4308 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 186us/sample - loss: 0.4258 - accuracy: 0.9639 - val_loss: 0.4266 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 177us/sample - loss: 0.4217 - accuracy: 0.9639 - val_loss: 0.4220 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 187us/sample - loss: 0.4176 - accuracy: 0.9639 - val_loss: 0.4180 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 211us/sample - loss: 0.4136 - accuracy: 0.9639 - val_loss: 0.4133 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.4097 - accuracy: 0.9639 - val_loss: 0.4090 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 219us/sample - loss: 0.4057 - accuracy: 0.9639 - val_loss: 0.4058 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.4016 - accuracy: 0.9639 - val_loss: 0.4023 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3977 - accuracy: 0.9639 - val_loss: 0.3988 - val_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3939 - accuracy: 0.9639 - val_loss: 0.3956 - val_accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3901 - accuracy: 0.9639 - val_loss: 0.3922 - val_accuracy: 0.9444\n",
      "41/41 [==============================] - 0s 151us/sample - loss: 0.4236 - accuracy: 1.0000\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1509 - accuracy: 0.3494 - val_loss: 1.1806 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 307us/sample - loss: 1.1414 - accuracy: 0.3614 - val_loss: 1.1708 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 196us/sample - loss: 1.1337 - accuracy: 0.3735 - val_loss: 1.1612 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.1245 - accuracy: 0.3735 - val_loss: 1.1526 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.1170 - accuracy: 0.3855 - val_loss: 1.1435 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.1083 - accuracy: 0.3855 - val_loss: 1.1348 - val_accuracy: 0.3519\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.1007 - accuracy: 0.3855 - val_loss: 1.1259 - val_accuracy: 0.3704\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 199us/sample - loss: 1.0925 - accuracy: 0.3855 - val_loss: 1.1171 - val_accuracy: 0.3704\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0847 - accuracy: 0.4096 - val_loss: 1.1082 - val_accuracy: 0.3704\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0770 - accuracy: 0.4217 - val_loss: 1.0995 - val_accuracy: 0.3704\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0688 - accuracy: 0.4217 - val_loss: 1.0911 - val_accuracy: 0.3889\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0614 - accuracy: 0.4217 - val_loss: 1.0826 - val_accuracy: 0.3889\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0536 - accuracy: 0.4217 - val_loss: 1.0744 - val_accuracy: 0.3889\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 251us/sample - loss: 1.0461 - accuracy: 0.4217 - val_loss: 1.0660 - val_accuracy: 0.4074\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0385 - accuracy: 0.4217 - val_loss: 1.0577 - val_accuracy: 0.4074\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0314 - accuracy: 0.4217 - val_loss: 1.0495 - val_accuracy: 0.4074\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 1.0238 - accuracy: 0.4217 - val_loss: 1.0415 - val_accuracy: 0.4074\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0165 - accuracy: 0.4337 - val_loss: 1.0335 - val_accuracy: 0.4259\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0092 - accuracy: 0.4458 - val_loss: 1.0256 - val_accuracy: 0.4259\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0022 - accuracy: 0.4699 - val_loss: 1.0177 - val_accuracy: 0.4444\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9949 - accuracy: 0.4819 - val_loss: 1.0099 - val_accuracy: 0.4444\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9879 - accuracy: 0.4699 - val_loss: 1.0021 - val_accuracy: 0.4815\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9805 - accuracy: 0.5181 - val_loss: 0.9944 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9737 - accuracy: 0.5301 - val_loss: 0.9866 - val_accuracy: 0.5556\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9668 - accuracy: 0.5422 - val_loss: 0.9790 - val_accuracy: 0.5556\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9593 - accuracy: 0.5422 - val_loss: 0.9715 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 271us/sample - loss: 0.9525 - accuracy: 0.5663 - val_loss: 0.9638 - val_accuracy: 0.5556\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 230us/sample - loss: 0.9455 - accuracy: 0.5663 - val_loss: 0.9562 - val_accuracy: 0.5556\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9387 - accuracy: 0.5663 - val_loss: 0.9487 - val_accuracy: 0.5556\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9317 - accuracy: 0.6024 - val_loss: 0.9412 - val_accuracy: 0.5741\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9251 - accuracy: 0.6024 - val_loss: 0.9337 - val_accuracy: 0.6111\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9180 - accuracy: 0.6265 - val_loss: 0.9263 - val_accuracy: 0.6111\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.9112 - accuracy: 0.6506 - val_loss: 0.9191 - val_accuracy: 0.6111\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9044 - accuracy: 0.6627 - val_loss: 0.9121 - val_accuracy: 0.6481\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8980 - accuracy: 0.6867 - val_loss: 0.9049 - val_accuracy: 0.6481\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8911 - accuracy: 0.6988 - val_loss: 0.8979 - val_accuracy: 0.6481\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 180us/sample - loss: 0.8845 - accuracy: 0.6988 - val_loss: 0.8909 - val_accuracy: 0.6296\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8783 - accuracy: 0.6988 - val_loss: 0.8840 - val_accuracy: 0.6481\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 184us/sample - loss: 0.8714 - accuracy: 0.6988 - val_loss: 0.8772 - val_accuracy: 0.6481\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 206us/sample - loss: 0.8649 - accuracy: 0.6988 - val_loss: 0.8706 - val_accuracy: 0.6481\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8587 - accuracy: 0.6988 - val_loss: 0.8639 - val_accuracy: 0.6481\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8523 - accuracy: 0.6988 - val_loss: 0.8573 - val_accuracy: 0.6481\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8459 - accuracy: 0.6988 - val_loss: 0.8508 - val_accuracy: 0.6481\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8399 - accuracy: 0.6988 - val_loss: 0.8443 - val_accuracy: 0.6481\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.8337 - accuracy: 0.6988 - val_loss: 0.8378 - val_accuracy: 0.6481\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8272 - accuracy: 0.6988 - val_loss: 0.8315 - val_accuracy: 0.6481\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8213 - accuracy: 0.7108 - val_loss: 0.8250 - val_accuracy: 0.6481\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8151 - accuracy: 0.7108 - val_loss: 0.8186 - val_accuracy: 0.6481\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8090 - accuracy: 0.7108 - val_loss: 0.8122 - val_accuracy: 0.6667\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8028 - accuracy: 0.7229 - val_loss: 0.8059 - val_accuracy: 0.7037\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7968 - accuracy: 0.7229 - val_loss: 0.7997 - val_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7908 - accuracy: 0.7229 - val_loss: 0.7935 - val_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7848 - accuracy: 0.7349 - val_loss: 0.7872 - val_accuracy: 0.7222\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7788 - accuracy: 0.7349 - val_loss: 0.7810 - val_accuracy: 0.7222\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7730 - accuracy: 0.7470 - val_loss: 0.7750 - val_accuracy: 0.7222\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7675 - accuracy: 0.7590 - val_loss: 0.7689 - val_accuracy: 0.7222\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7614 - accuracy: 0.7711 - val_loss: 0.7630 - val_accuracy: 0.7222\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7558 - accuracy: 0.7831 - val_loss: 0.7571 - val_accuracy: 0.7222\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 158us/sample - loss: 0.7500 - accuracy: 0.7831 - val_loss: 0.7513 - val_accuracy: 0.7222\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7443 - accuracy: 0.7831 - val_loss: 0.7456 - val_accuracy: 0.7222\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7387 - accuracy: 0.7831 - val_loss: 0.7399 - val_accuracy: 0.7778\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7334 - accuracy: 0.7831 - val_loss: 0.7342 - val_accuracy: 0.7778\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7277 - accuracy: 0.7952 - val_loss: 0.7286 - val_accuracy: 0.7778\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7223 - accuracy: 0.7952 - val_loss: 0.7231 - val_accuracy: 0.7778\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7169 - accuracy: 0.8072 - val_loss: 0.7177 - val_accuracy: 0.7778\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.7117 - accuracy: 0.8072 - val_loss: 0.7123 - val_accuracy: 0.7963\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 374us/sample - loss: 0.7067 - accuracy: 0.8072 - val_loss: 0.7069 - val_accuracy: 0.7963\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 470us/sample - loss: 0.7010 - accuracy: 0.8193 - val_loss: 0.7017 - val_accuracy: 0.7963\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.6959 - accuracy: 0.8193 - val_loss: 0.6964 - val_accuracy: 0.8148\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6908 - accuracy: 0.8193 - val_loss: 0.6912 - val_accuracy: 0.8148\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6856 - accuracy: 0.8193 - val_loss: 0.6860 - val_accuracy: 0.8148\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6805 - accuracy: 0.8193 - val_loss: 0.6809 - val_accuracy: 0.8148\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6754 - accuracy: 0.8193 - val_loss: 0.6758 - val_accuracy: 0.8148\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6704 - accuracy: 0.8193 - val_loss: 0.6707 - val_accuracy: 0.8148\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6656 - accuracy: 0.8313 - val_loss: 0.6657 - val_accuracy: 0.8148\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6606 - accuracy: 0.8554 - val_loss: 0.6607 - val_accuracy: 0.8148\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6558 - accuracy: 0.8554 - val_loss: 0.6558 - val_accuracy: 0.8148\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6510 - accuracy: 0.8554 - val_loss: 0.6510 - val_accuracy: 0.8148\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6462 - accuracy: 0.8554 - val_loss: 0.6462 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6414 - accuracy: 0.8675 - val_loss: 0.6415 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.6368 - accuracy: 0.8675 - val_loss: 0.6367 - val_accuracy: 0.8519\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6322 - accuracy: 0.8675 - val_loss: 0.6321 - val_accuracy: 0.8519\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6276 - accuracy: 0.8675 - val_loss: 0.6274 - val_accuracy: 0.8519\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6229 - accuracy: 0.8675 - val_loss: 0.6228 - val_accuracy: 0.8519\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6186 - accuracy: 0.8675 - val_loss: 0.6182 - val_accuracy: 0.8519\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6140 - accuracy: 0.8675 - val_loss: 0.6137 - val_accuracy: 0.8519\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.6094 - accuracy: 0.8675 - val_loss: 0.6093 - val_accuracy: 0.8519\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6052 - accuracy: 0.8795 - val_loss: 0.6048 - val_accuracy: 0.8519\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 163us/sample - loss: 0.6007 - accuracy: 0.8795 - val_loss: 0.6005 - val_accuracy: 0.8519\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5964 - accuracy: 0.8795 - val_loss: 0.5961 - val_accuracy: 0.8519\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5921 - accuracy: 0.8795 - val_loss: 0.5918 - val_accuracy: 0.8704\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5879 - accuracy: 0.8916 - val_loss: 0.5875 - val_accuracy: 0.8704\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5839 - accuracy: 0.8916 - val_loss: 0.5833 - val_accuracy: 0.8704\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5797 - accuracy: 0.9036 - val_loss: 0.5792 - val_accuracy: 0.8704\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5756 - accuracy: 0.9036 - val_loss: 0.5751 - val_accuracy: 0.8704\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5714 - accuracy: 0.9036 - val_loss: 0.5710 - val_accuracy: 0.8704\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 157us/sample - loss: 0.5675 - accuracy: 0.9036 - val_loss: 0.5669 - val_accuracy: 0.8704\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5634 - accuracy: 0.9036 - val_loss: 0.5629 - val_accuracy: 0.8704\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5595 - accuracy: 0.9036 - val_loss: 0.5589 - val_accuracy: 0.8704\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5555 - accuracy: 0.9036 - val_loss: 0.5550 - val_accuracy: 0.8889\n",
      "41/41 [==============================] - 0s 171us/sample - loss: 0.5727 - accuracy: 0.8537\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 6ms/sample - loss: 1.0720 - accuracy: 0.5000 - val_loss: 1.0299 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 1.0462 - accuracy: 0.4756 - val_loss: 1.0096 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 1.0221 - accuracy: 0.4634 - val_loss: 0.9909 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 196us/sample - loss: 1.0003 - accuracy: 0.4634 - val_loss: 0.9730 - val_accuracy: 0.4815\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9796 - accuracy: 0.4512 - val_loss: 0.9553 - val_accuracy: 0.4815\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9611 - accuracy: 0.4756 - val_loss: 0.9385 - val_accuracy: 0.5185\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9426 - accuracy: 0.5244 - val_loss: 0.9219 - val_accuracy: 0.5185\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9257 - accuracy: 0.5854 - val_loss: 0.9055 - val_accuracy: 0.6481\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9086 - accuracy: 0.6341 - val_loss: 0.8889 - val_accuracy: 0.7407\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8925 - accuracy: 0.6585 - val_loss: 0.8725 - val_accuracy: 0.7593\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8776 - accuracy: 0.6707 - val_loss: 0.8568 - val_accuracy: 0.8333\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8616 - accuracy: 0.7073 - val_loss: 0.8410 - val_accuracy: 0.8519\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.8462 - accuracy: 0.7073 - val_loss: 0.8250 - val_accuracy: 0.8889\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8313 - accuracy: 0.7561 - val_loss: 0.8091 - val_accuracy: 0.8889\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.8170 - accuracy: 0.7805 - val_loss: 0.7932 - val_accuracy: 0.8889\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8025 - accuracy: 0.8171 - val_loss: 0.7777 - val_accuracy: 0.9074\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.7877 - accuracy: 0.8171 - val_loss: 0.7627 - val_accuracy: 0.9074\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7735 - accuracy: 0.8537 - val_loss: 0.7478 - val_accuracy: 0.8889\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7599 - accuracy: 0.8902 - val_loss: 0.7330 - val_accuracy: 0.9074\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7458 - accuracy: 0.9024 - val_loss: 0.7186 - val_accuracy: 0.9074\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 311us/sample - loss: 0.7323 - accuracy: 0.9024 - val_loss: 0.7043 - val_accuracy: 0.9259\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7193 - accuracy: 0.9146 - val_loss: 0.6901 - val_accuracy: 0.9259\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.7058 - accuracy: 0.9146 - val_loss: 0.6761 - val_accuracy: 0.9259\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.6928 - accuracy: 0.9268 - val_loss: 0.6624 - val_accuracy: 0.9444\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 315us/sample - loss: 0.6797 - accuracy: 0.9268 - val_loss: 0.6493 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.6670 - accuracy: 0.9268 - val_loss: 0.6363 - val_accuracy: 0.9630\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.6544 - accuracy: 0.9268 - val_loss: 0.6236 - val_accuracy: 0.9630\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 282us/sample - loss: 0.6423 - accuracy: 0.9268 - val_loss: 0.6111 - val_accuracy: 0.9630\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6302 - accuracy: 0.9268 - val_loss: 0.5990 - val_accuracy: 0.9630\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 293us/sample - loss: 0.6182 - accuracy: 0.9390 - val_loss: 0.5874 - val_accuracy: 0.9630\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6067 - accuracy: 0.9390 - val_loss: 0.5761 - val_accuracy: 0.9630\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5954 - accuracy: 0.9390 - val_loss: 0.5646 - val_accuracy: 0.9630\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.5841 - accuracy: 0.9512 - val_loss: 0.5532 - val_accuracy: 0.9630\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 262us/sample - loss: 0.5728 - accuracy: 0.9634 - val_loss: 0.5421 - val_accuracy: 0.9630\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.5625 - accuracy: 0.9634 - val_loss: 0.5307 - val_accuracy: 0.9630\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.5514 - accuracy: 0.9634 - val_loss: 0.5200 - val_accuracy: 0.9630\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5405 - accuracy: 0.9634 - val_loss: 0.5093 - val_accuracy: 0.9630\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.5301 - accuracy: 0.9634 - val_loss: 0.4986 - val_accuracy: 0.9630\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.5208 - accuracy: 0.9634 - val_loss: 0.4882 - val_accuracy: 0.9630\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.5106 - accuracy: 0.9634 - val_loss: 0.4785 - val_accuracy: 0.9630\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.5008 - accuracy: 0.9634 - val_loss: 0.4691 - val_accuracy: 0.9630\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.4913 - accuracy: 0.9756 - val_loss: 0.4600 - val_accuracy: 0.9630\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 185us/sample - loss: 0.4819 - accuracy: 0.9756 - val_loss: 0.4511 - val_accuracy: 0.9815\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.4727 - accuracy: 0.9756 - val_loss: 0.4425 - val_accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.4639 - accuracy: 0.9756 - val_loss: 0.4341 - val_accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4550 - accuracy: 0.9756 - val_loss: 0.4256 - val_accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.4468 - accuracy: 0.9756 - val_loss: 0.4177 - val_accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.4380 - accuracy: 0.9756 - val_loss: 0.4094 - val_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.4298 - accuracy: 0.9756 - val_loss: 0.4015 - val_accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.4217 - accuracy: 0.9878 - val_loss: 0.3937 - val_accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.4141 - accuracy: 0.9878 - val_loss: 0.3860 - val_accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 231us/sample - loss: 0.4062 - accuracy: 0.9878 - val_loss: 0.3787 - val_accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.3987 - accuracy: 0.9878 - val_loss: 0.3716 - val_accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.3915 - accuracy: 0.9878 - val_loss: 0.3647 - val_accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.3842 - accuracy: 0.9878 - val_loss: 0.3581 - val_accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.3771 - accuracy: 0.9878 - val_loss: 0.3514 - val_accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.3705 - accuracy: 0.9878 - val_loss: 0.3451 - val_accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.3634 - accuracy: 0.9878 - val_loss: 0.3389 - val_accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.3570 - accuracy: 0.9878 - val_loss: 0.3330 - val_accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.3507 - accuracy: 0.9878 - val_loss: 0.3273 - val_accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 184us/sample - loss: 0.3443 - accuracy: 0.9878 - val_loss: 0.3214 - val_accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.3382 - accuracy: 0.9878 - val_loss: 0.3158 - val_accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.3322 - accuracy: 0.9878 - val_loss: 0.3106 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 184us/sample - loss: 0.3263 - accuracy: 0.9878 - val_loss: 0.3055 - val_accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.3207 - accuracy: 0.9878 - val_loss: 0.3006 - val_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.3150 - accuracy: 0.9878 - val_loss: 0.2955 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.3094 - accuracy: 0.9878 - val_loss: 0.2903 - val_accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.3040 - accuracy: 0.9878 - val_loss: 0.2854 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2990 - accuracy: 0.9878 - val_loss: 0.2805 - val_accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2939 - accuracy: 0.9878 - val_loss: 0.2760 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.2888 - accuracy: 0.9878 - val_loss: 0.2716 - val_accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.2839 - accuracy: 0.9878 - val_loss: 0.2674 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2793 - accuracy: 0.9878 - val_loss: 0.2635 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2744 - accuracy: 0.9878 - val_loss: 0.2596 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 181us/sample - loss: 0.2699 - accuracy: 0.9878 - val_loss: 0.2556 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.2657 - accuracy: 0.9878 - val_loss: 0.2522 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2614 - accuracy: 0.9878 - val_loss: 0.2486 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.2572 - accuracy: 0.9878 - val_loss: 0.2456 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.2528 - accuracy: 0.9878 - val_loss: 0.2421 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.2489 - accuracy: 0.9878 - val_loss: 0.2386 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.2449 - accuracy: 0.9878 - val_loss: 0.2350 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2408 - accuracy: 0.9878 - val_loss: 0.2311 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2370 - accuracy: 0.9878 - val_loss: 0.2274 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.2336 - accuracy: 0.9878 - val_loss: 0.2237 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2299 - accuracy: 0.9878 - val_loss: 0.2206 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2265 - accuracy: 0.9878 - val_loss: 0.2175 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.2231 - accuracy: 0.9878 - val_loss: 0.2147 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 159us/sample - loss: 0.2197 - accuracy: 0.9878 - val_loss: 0.2120 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2164 - accuracy: 0.9878 - val_loss: 0.2094 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.2132 - accuracy: 0.9878 - val_loss: 0.2075 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.2099 - accuracy: 0.9878 - val_loss: 0.2053 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.2068 - accuracy: 0.9878 - val_loss: 0.2032 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.2041 - accuracy: 0.9878 - val_loss: 0.2014 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.2008 - accuracy: 0.9878 - val_loss: 0.1989 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.1981 - accuracy: 0.9878 - val_loss: 0.1962 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.1951 - accuracy: 0.9878 - val_loss: 0.1941 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.1923 - accuracy: 0.9878 - val_loss: 0.1919 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.1898 - accuracy: 0.9878 - val_loss: 0.1897 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.1870 - accuracy: 0.9878 - val_loss: 0.1872 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.1844 - accuracy: 0.9878 - val_loss: 0.1852 - val_accuracy: 0.9815\n",
      "42/42 [==============================] - 0s 143us/sample - loss: 0.2269 - accuracy: 0.9762\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 5ms/sample - loss: 1.0858 - accuracy: 0.5422 - val_loss: 1.1661 - val_accuracy: 0.5556\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0564 - accuracy: 0.6024 - val_loss: 1.1393 - val_accuracy: 0.5741\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0313 - accuracy: 0.6265 - val_loss: 1.1141 - val_accuracy: 0.5926\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0093 - accuracy: 0.6627 - val_loss: 1.0901 - val_accuracy: 0.6111\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9891 - accuracy: 0.6627 - val_loss: 1.0684 - val_accuracy: 0.6111\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9690 - accuracy: 0.6627 - val_loss: 1.0483 - val_accuracy: 0.5926\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9507 - accuracy: 0.6627 - val_loss: 1.0281 - val_accuracy: 0.5926\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9327 - accuracy: 0.6867 - val_loss: 1.0082 - val_accuracy: 0.5926\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9153 - accuracy: 0.6867 - val_loss: 0.9882 - val_accuracy: 0.6111\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8979 - accuracy: 0.6988 - val_loss: 0.9691 - val_accuracy: 0.6111\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.8808 - accuracy: 0.6988 - val_loss: 0.9493 - val_accuracy: 0.6296\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.8645 - accuracy: 0.7108 - val_loss: 0.9295 - val_accuracy: 0.6296\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.8481 - accuracy: 0.7108 - val_loss: 0.9105 - val_accuracy: 0.6296\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 361us/sample - loss: 0.8324 - accuracy: 0.7229 - val_loss: 0.8919 - val_accuracy: 0.6296\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 361us/sample - loss: 0.8169 - accuracy: 0.7470 - val_loss: 0.8748 - val_accuracy: 0.6296\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8023 - accuracy: 0.7470 - val_loss: 0.8574 - val_accuracy: 0.6296\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7875 - accuracy: 0.7470 - val_loss: 0.8411 - val_accuracy: 0.6481\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7732 - accuracy: 0.7470 - val_loss: 0.8265 - val_accuracy: 0.6481\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.7590 - accuracy: 0.7470 - val_loss: 0.8127 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 482us/sample - loss: 0.7450 - accuracy: 0.7470 - val_loss: 0.7982 - val_accuracy: 0.6852\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 458us/sample - loss: 0.7311 - accuracy: 0.7711 - val_loss: 0.7849 - val_accuracy: 0.6852\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 374us/sample - loss: 0.7180 - accuracy: 0.7711 - val_loss: 0.7716 - val_accuracy: 0.6852\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.7051 - accuracy: 0.7831 - val_loss: 0.7585 - val_accuracy: 0.6852\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6922 - accuracy: 0.7952 - val_loss: 0.7451 - val_accuracy: 0.6852\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6797 - accuracy: 0.7952 - val_loss: 0.7318 - val_accuracy: 0.7037\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6675 - accuracy: 0.8072 - val_loss: 0.7192 - val_accuracy: 0.7222\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 194us/sample - loss: 0.6554 - accuracy: 0.8193 - val_loss: 0.7064 - val_accuracy: 0.7593\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6435 - accuracy: 0.8313 - val_loss: 0.6939 - val_accuracy: 0.7593\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 187us/sample - loss: 0.6319 - accuracy: 0.8313 - val_loss: 0.6811 - val_accuracy: 0.7778\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6203 - accuracy: 0.8554 - val_loss: 0.6683 - val_accuracy: 0.7778\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6100 - accuracy: 0.8675 - val_loss: 0.6553 - val_accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5984 - accuracy: 0.8675 - val_loss: 0.6441 - val_accuracy: 0.7963\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5876 - accuracy: 0.8795 - val_loss: 0.6330 - val_accuracy: 0.7963\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 186us/sample - loss: 0.5771 - accuracy: 0.8916 - val_loss: 0.6220 - val_accuracy: 0.7963\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5672 - accuracy: 0.8916 - val_loss: 0.6118 - val_accuracy: 0.7963\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5569 - accuracy: 0.9036 - val_loss: 0.6011 - val_accuracy: 0.7963\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5469 - accuracy: 0.9157 - val_loss: 0.5912 - val_accuracy: 0.7963\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5374 - accuracy: 0.9157 - val_loss: 0.5817 - val_accuracy: 0.7963\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5281 - accuracy: 0.9157 - val_loss: 0.5722 - val_accuracy: 0.7963\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5187 - accuracy: 0.9157 - val_loss: 0.5626 - val_accuracy: 0.7963\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5094 - accuracy: 0.9157 - val_loss: 0.5522 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5007 - accuracy: 0.9157 - val_loss: 0.5420 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4919 - accuracy: 0.9157 - val_loss: 0.5324 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4831 - accuracy: 0.9277 - val_loss: 0.5234 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4748 - accuracy: 0.9277 - val_loss: 0.5152 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4664 - accuracy: 0.9277 - val_loss: 0.5067 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.4586 - accuracy: 0.9277 - val_loss: 0.4979 - val_accuracy: 0.8519\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.4503 - accuracy: 0.9277 - val_loss: 0.4903 - val_accuracy: 0.8519\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4425 - accuracy: 0.9277 - val_loss: 0.4825 - val_accuracy: 0.8519\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.4348 - accuracy: 0.9277 - val_loss: 0.4747 - val_accuracy: 0.8519\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4272 - accuracy: 0.9277 - val_loss: 0.4668 - val_accuracy: 0.8519\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.4198 - accuracy: 0.9277 - val_loss: 0.4588 - val_accuracy: 0.8519\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.4128 - accuracy: 0.9277 - val_loss: 0.4510 - val_accuracy: 0.8704\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.4055 - accuracy: 0.9277 - val_loss: 0.4438 - val_accuracy: 0.8704\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3984 - accuracy: 0.9277 - val_loss: 0.4363 - val_accuracy: 0.8704\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.3918 - accuracy: 0.9277 - val_loss: 0.4285 - val_accuracy: 0.8704\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.3848 - accuracy: 0.9277 - val_loss: 0.4218 - val_accuracy: 0.8704\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.3781 - accuracy: 0.9277 - val_loss: 0.4145 - val_accuracy: 0.8704\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3716 - accuracy: 0.9398 - val_loss: 0.4074 - val_accuracy: 0.8704\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 225us/sample - loss: 0.3654 - accuracy: 0.9398 - val_loss: 0.4007 - val_accuracy: 0.8704\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 226us/sample - loss: 0.3589 - accuracy: 0.9398 - val_loss: 0.3936 - val_accuracy: 0.8704\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3529 - accuracy: 0.9398 - val_loss: 0.3864 - val_accuracy: 0.8704\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3473 - accuracy: 0.9518 - val_loss: 0.3799 - val_accuracy: 0.8704\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3414 - accuracy: 0.9518 - val_loss: 0.3744 - val_accuracy: 0.8704\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3356 - accuracy: 0.9518 - val_loss: 0.3690 - val_accuracy: 0.8704\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3299 - accuracy: 0.9518 - val_loss: 0.3630 - val_accuracy: 0.8889\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3245 - accuracy: 0.9518 - val_loss: 0.3580 - val_accuracy: 0.8889\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3188 - accuracy: 0.9518 - val_loss: 0.3535 - val_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.3135 - accuracy: 0.9518 - val_loss: 0.3497 - val_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3086 - accuracy: 0.9518 - val_loss: 0.3461 - val_accuracy: 0.8704\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.3034 - accuracy: 0.9518 - val_loss: 0.3415 - val_accuracy: 0.8889\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2984 - accuracy: 0.9518 - val_loss: 0.3369 - val_accuracy: 0.8889\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2936 - accuracy: 0.9518 - val_loss: 0.3314 - val_accuracy: 0.8889\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.2888 - accuracy: 0.9518 - val_loss: 0.3263 - val_accuracy: 0.9074\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2842 - accuracy: 0.9639 - val_loss: 0.3205 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2795 - accuracy: 0.9639 - val_loss: 0.3155 - val_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2752 - accuracy: 0.9639 - val_loss: 0.3109 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 445us/sample - loss: 0.2707 - accuracy: 0.9639 - val_loss: 0.3070 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 434us/sample - loss: 0.2665 - accuracy: 0.9639 - val_loss: 0.3037 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 410us/sample - loss: 0.2622 - accuracy: 0.9639 - val_loss: 0.2999 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.2579 - accuracy: 0.9639 - val_loss: 0.2955 - val_accuracy: 0.9444\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.2540 - accuracy: 0.9639 - val_loss: 0.2908 - val_accuracy: 0.9444\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.2501 - accuracy: 0.9639 - val_loss: 0.2867 - val_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2463 - accuracy: 0.9639 - val_loss: 0.2823 - val_accuracy: 0.9444\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.2425 - accuracy: 0.9639 - val_loss: 0.2793 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.2387 - accuracy: 0.9639 - val_loss: 0.2752 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.2353 - accuracy: 0.9639 - val_loss: 0.2723 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2314 - accuracy: 0.9639 - val_loss: 0.2681 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2281 - accuracy: 0.9759 - val_loss: 0.2641 - val_accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2247 - accuracy: 0.9759 - val_loss: 0.2594 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2214 - accuracy: 0.9759 - val_loss: 0.2556 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2183 - accuracy: 0.9759 - val_loss: 0.2518 - val_accuracy: 0.9630\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2150 - accuracy: 0.9759 - val_loss: 0.2490 - val_accuracy: 0.9630\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2118 - accuracy: 0.9759 - val_loss: 0.2463 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 286us/sample - loss: 0.2088 - accuracy: 0.9759 - val_loss: 0.2436 - val_accuracy: 0.9630\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.2057 - accuracy: 0.9759 - val_loss: 0.2415 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2030 - accuracy: 0.9759 - val_loss: 0.2395 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 230us/sample - loss: 0.1999 - accuracy: 0.9759 - val_loss: 0.2370 - val_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.1975 - accuracy: 0.9759 - val_loss: 0.2333 - val_accuracy: 0.9630\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.1944 - accuracy: 0.9759 - val_loss: 0.2303 - val_accuracy: 0.9630\n",
      "41/41 [==============================] - 0s 122us/sample - loss: 0.2347 - accuracy: 0.9756\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 5ms/sample - loss: 1.2531 - accuracy: 0.2651 - val_loss: 1.2171 - val_accuracy: 0.2963\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.2061 - accuracy: 0.2771 - val_loss: 1.1794 - val_accuracy: 0.3704\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.1718 - accuracy: 0.3012 - val_loss: 1.1467 - val_accuracy: 0.4259\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 236us/sample - loss: 1.1354 - accuracy: 0.3494 - val_loss: 1.1186 - val_accuracy: 0.4815\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 488us/sample - loss: 1.1064 - accuracy: 0.4819 - val_loss: 1.0939 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 410us/sample - loss: 1.0816 - accuracy: 0.5181 - val_loss: 1.0716 - val_accuracy: 0.4259\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 398us/sample - loss: 1.0591 - accuracy: 0.5301 - val_loss: 1.0514 - val_accuracy: 0.4444\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 349us/sample - loss: 1.0384 - accuracy: 0.5060 - val_loss: 1.0326 - val_accuracy: 0.4815\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0206 - accuracy: 0.4940 - val_loss: 1.0150 - val_accuracy: 0.4630\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0030 - accuracy: 0.5060 - val_loss: 0.9979 - val_accuracy: 0.4815\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9856 - accuracy: 0.5060 - val_loss: 0.9808 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9700 - accuracy: 0.5181 - val_loss: 0.9640 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9534 - accuracy: 0.5301 - val_loss: 0.9473 - val_accuracy: 0.5370\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9379 - accuracy: 0.5542 - val_loss: 0.9307 - val_accuracy: 0.5741\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9229 - accuracy: 0.5904 - val_loss: 0.9141 - val_accuracy: 0.5926\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.9063 - accuracy: 0.6386 - val_loss: 0.8979 - val_accuracy: 0.6481\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8912 - accuracy: 0.7229 - val_loss: 0.8819 - val_accuracy: 0.6852\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8764 - accuracy: 0.7711 - val_loss: 0.8659 - val_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8619 - accuracy: 0.8193 - val_loss: 0.8500 - val_accuracy: 0.7593\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 176us/sample - loss: 0.8471 - accuracy: 0.8554 - val_loss: 0.8345 - val_accuracy: 0.8148\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8328 - accuracy: 0.8675 - val_loss: 0.8191 - val_accuracy: 0.8889\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8182 - accuracy: 0.8916 - val_loss: 0.8040 - val_accuracy: 0.8889\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8040 - accuracy: 0.9036 - val_loss: 0.7890 - val_accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 216us/sample - loss: 0.7901 - accuracy: 0.9157 - val_loss: 0.7741 - val_accuracy: 0.9074\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7759 - accuracy: 0.9157 - val_loss: 0.7593 - val_accuracy: 0.9259\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7627 - accuracy: 0.9277 - val_loss: 0.7446 - val_accuracy: 0.9259\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7488 - accuracy: 0.9277 - val_loss: 0.7303 - val_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7352 - accuracy: 0.9398 - val_loss: 0.7162 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7225 - accuracy: 0.9518 - val_loss: 0.7024 - val_accuracy: 0.9815\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 196us/sample - loss: 0.7089 - accuracy: 0.9518 - val_loss: 0.6885 - val_accuracy: 0.9815\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6958 - accuracy: 0.9639 - val_loss: 0.6748 - val_accuracy: 0.9815\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6830 - accuracy: 0.9639 - val_loss: 0.6614 - val_accuracy: 0.9815\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 211us/sample - loss: 0.6705 - accuracy: 0.9639 - val_loss: 0.6482 - val_accuracy: 0.9815\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6578 - accuracy: 0.9639 - val_loss: 0.6352 - val_accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6455 - accuracy: 0.9518 - val_loss: 0.6224 - val_accuracy: 0.9815\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6337 - accuracy: 0.9639 - val_loss: 0.6097 - val_accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6216 - accuracy: 0.9639 - val_loss: 0.5973 - val_accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6101 - accuracy: 0.9639 - val_loss: 0.5851 - val_accuracy: 0.9815\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.5982 - accuracy: 0.9759 - val_loss: 0.5732 - val_accuracy: 0.9815\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5868 - accuracy: 0.9759 - val_loss: 0.5614 - val_accuracy: 0.9630\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 675us/sample - loss: 0.5757 - accuracy: 0.9759 - val_loss: 0.5499 - val_accuracy: 0.9630\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 590us/sample - loss: 0.5646 - accuracy: 0.9759 - val_loss: 0.5385 - val_accuracy: 0.9630\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 422us/sample - loss: 0.5535 - accuracy: 0.9759 - val_loss: 0.5275 - val_accuracy: 0.9630\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.5430 - accuracy: 0.9759 - val_loss: 0.5166 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5325 - accuracy: 0.9759 - val_loss: 0.5060 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.5226 - accuracy: 0.9759 - val_loss: 0.4958 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.5122 - accuracy: 0.9759 - val_loss: 0.4855 - val_accuracy: 0.9630\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5024 - accuracy: 0.9759 - val_loss: 0.4754 - val_accuracy: 0.9630\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.4928 - accuracy: 0.9759 - val_loss: 0.4656 - val_accuracy: 0.9630\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 349us/sample - loss: 0.4831 - accuracy: 0.9759 - val_loss: 0.4560 - val_accuracy: 0.9630\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4747 - accuracy: 0.9639 - val_loss: 0.4469 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 349us/sample - loss: 0.4648 - accuracy: 0.9759 - val_loss: 0.4377 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.4563 - accuracy: 0.9639 - val_loss: 0.4287 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4473 - accuracy: 0.9759 - val_loss: 0.4201 - val_accuracy: 0.9630\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.4390 - accuracy: 0.9759 - val_loss: 0.4118 - val_accuracy: 0.9630\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4307 - accuracy: 0.9639 - val_loss: 0.4037 - val_accuracy: 0.9630\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4229 - accuracy: 0.9759 - val_loss: 0.3960 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4151 - accuracy: 0.9759 - val_loss: 0.3885 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4079 - accuracy: 0.9759 - val_loss: 0.3813 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.4000 - accuracy: 0.9759 - val_loss: 0.3739 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3929 - accuracy: 0.9759 - val_loss: 0.3662 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3853 - accuracy: 0.9759 - val_loss: 0.3591 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3785 - accuracy: 0.9759 - val_loss: 0.3522 - val_accuracy: 0.9630\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.3718 - accuracy: 0.9759 - val_loss: 0.3455 - val_accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3654 - accuracy: 0.9759 - val_loss: 0.3391 - val_accuracy: 0.9630\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3585 - accuracy: 0.9759 - val_loss: 0.3328 - val_accuracy: 0.9630\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3523 - accuracy: 0.9759 - val_loss: 0.3267 - val_accuracy: 0.9630\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3461 - accuracy: 0.9759 - val_loss: 0.3208 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3402 - accuracy: 0.9759 - val_loss: 0.3151 - val_accuracy: 0.9630\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3345 - accuracy: 0.9759 - val_loss: 0.3095 - val_accuracy: 0.9630\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3286 - accuracy: 0.9759 - val_loss: 0.3040 - val_accuracy: 0.9630\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3232 - accuracy: 0.9759 - val_loss: 0.2988 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3177 - accuracy: 0.9759 - val_loss: 0.2935 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3126 - accuracy: 0.9759 - val_loss: 0.2884 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3071 - accuracy: 0.9759 - val_loss: 0.2832 - val_accuracy: 0.9630\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3022 - accuracy: 0.9759 - val_loss: 0.2782 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2972 - accuracy: 0.9759 - val_loss: 0.2735 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2926 - accuracy: 0.9759 - val_loss: 0.2689 - val_accuracy: 0.9630\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2879 - accuracy: 0.9759 - val_loss: 0.2646 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2832 - accuracy: 0.9759 - val_loss: 0.2604 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2787 - accuracy: 0.9759 - val_loss: 0.2564 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2746 - accuracy: 0.9759 - val_loss: 0.2525 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2702 - accuracy: 0.9759 - val_loss: 0.2486 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 223us/sample - loss: 0.2663 - accuracy: 0.9759 - val_loss: 0.2453 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2620 - accuracy: 0.9759 - val_loss: 0.2414 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2582 - accuracy: 0.9759 - val_loss: 0.2374 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2542 - accuracy: 0.9759 - val_loss: 0.2336 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2505 - accuracy: 0.9759 - val_loss: 0.2300 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2467 - accuracy: 0.9759 - val_loss: 0.2265 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2432 - accuracy: 0.9759 - val_loss: 0.2229 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2400 - accuracy: 0.9759 - val_loss: 0.2196 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2366 - accuracy: 0.9759 - val_loss: 0.2165 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2330 - accuracy: 0.9759 - val_loss: 0.2134 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2300 - accuracy: 0.9759 - val_loss: 0.2103 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2269 - accuracy: 0.9759 - val_loss: 0.2075 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2236 - accuracy: 0.9759 - val_loss: 0.2048 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2206 - accuracy: 0.9759 - val_loss: 0.2023 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2176 - accuracy: 0.9759 - val_loss: 0.1998 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2145 - accuracy: 0.9759 - val_loss: 0.1973 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2116 - accuracy: 0.9759 - val_loss: 0.1948 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 171us/sample - loss: 0.2041 - accuracy: 1.0000\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 4ms/sample - loss: 1.0008 - accuracy: 0.4390 - val_loss: 0.9961 - val_accuracy: 0.4074\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.9854 - accuracy: 0.5122 - val_loss: 0.9810 - val_accuracy: 0.4630\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.9709 - accuracy: 0.5854 - val_loss: 0.9669 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9565 - accuracy: 0.6220 - val_loss: 0.9531 - val_accuracy: 0.5185\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.9428 - accuracy: 0.6341 - val_loss: 0.9395 - val_accuracy: 0.5741\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.9295 - accuracy: 0.6463 - val_loss: 0.9262 - val_accuracy: 0.5926\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9161 - accuracy: 0.6463 - val_loss: 0.9124 - val_accuracy: 0.6111\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.9027 - accuracy: 0.6463 - val_loss: 0.8989 - val_accuracy: 0.6481\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.8895 - accuracy: 0.6463 - val_loss: 0.8852 - val_accuracy: 0.7037\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.8764 - accuracy: 0.6829 - val_loss: 0.8721 - val_accuracy: 0.7037\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8638 - accuracy: 0.6951 - val_loss: 0.8590 - val_accuracy: 0.7593\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8514 - accuracy: 0.7195 - val_loss: 0.8459 - val_accuracy: 0.7778\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8387 - accuracy: 0.7805 - val_loss: 0.8326 - val_accuracy: 0.7963\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.8265 - accuracy: 0.8293 - val_loss: 0.8193 - val_accuracy: 0.8148\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8145 - accuracy: 0.8659 - val_loss: 0.8062 - val_accuracy: 0.8704\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.8032 - accuracy: 0.8659 - val_loss: 0.7937 - val_accuracy: 0.8889\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7907 - accuracy: 0.8659 - val_loss: 0.7809 - val_accuracy: 0.8889\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.7788 - accuracy: 0.8780 - val_loss: 0.7685 - val_accuracy: 0.8889\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7676 - accuracy: 0.9024 - val_loss: 0.7562 - val_accuracy: 0.9074\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.7561 - accuracy: 0.9390 - val_loss: 0.7445 - val_accuracy: 0.9074\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.7448 - accuracy: 0.9390 - val_loss: 0.7329 - val_accuracy: 0.9259\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.7337 - accuracy: 0.9390 - val_loss: 0.7214 - val_accuracy: 0.9444\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7228 - accuracy: 0.9512 - val_loss: 0.7098 - val_accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.7117 - accuracy: 0.9512 - val_loss: 0.6983 - val_accuracy: 0.9444\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.7009 - accuracy: 0.9512 - val_loss: 0.6868 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 287us/sample - loss: 0.6902 - accuracy: 0.9512 - val_loss: 0.6754 - val_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.6796 - accuracy: 0.9512 - val_loss: 0.6641 - val_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.6693 - accuracy: 0.9512 - val_loss: 0.6530 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.6585 - accuracy: 0.9512 - val_loss: 0.6425 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.6481 - accuracy: 0.9512 - val_loss: 0.6320 - val_accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 238us/sample - loss: 0.6381 - accuracy: 0.9512 - val_loss: 0.6216 - val_accuracy: 0.9444\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6280 - accuracy: 0.9512 - val_loss: 0.6113 - val_accuracy: 0.9444\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6178 - accuracy: 0.9512 - val_loss: 0.6011 - val_accuracy: 0.9444\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.6082 - accuracy: 0.9512 - val_loss: 0.5910 - val_accuracy: 0.9444\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5985 - accuracy: 0.9512 - val_loss: 0.5808 - val_accuracy: 0.9444\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5884 - accuracy: 0.9634 - val_loss: 0.5709 - val_accuracy: 0.9259\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.5792 - accuracy: 0.9634 - val_loss: 0.5611 - val_accuracy: 0.9259\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5697 - accuracy: 0.9634 - val_loss: 0.5519 - val_accuracy: 0.9259\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5607 - accuracy: 0.9634 - val_loss: 0.5423 - val_accuracy: 0.9259\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5514 - accuracy: 0.9634 - val_loss: 0.5329 - val_accuracy: 0.9259\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5421 - accuracy: 0.9634 - val_loss: 0.5234 - val_accuracy: 0.9444\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5335 - accuracy: 0.9634 - val_loss: 0.5140 - val_accuracy: 0.9444\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5245 - accuracy: 0.9634 - val_loss: 0.5051 - val_accuracy: 0.9630\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5162 - accuracy: 0.9634 - val_loss: 0.4961 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5074 - accuracy: 0.9634 - val_loss: 0.4875 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4993 - accuracy: 0.9634 - val_loss: 0.4791 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4910 - accuracy: 0.9634 - val_loss: 0.4708 - val_accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4829 - accuracy: 0.9634 - val_loss: 0.4630 - val_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4750 - accuracy: 0.9634 - val_loss: 0.4551 - val_accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4670 - accuracy: 0.9634 - val_loss: 0.4477 - val_accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.4596 - accuracy: 0.9634 - val_loss: 0.4404 - val_accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4520 - accuracy: 0.9634 - val_loss: 0.4331 - val_accuracy: 0.9815\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.4446 - accuracy: 0.9634 - val_loss: 0.4257 - val_accuracy: 0.9815\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4373 - accuracy: 0.9634 - val_loss: 0.4186 - val_accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.4300 - accuracy: 0.9634 - val_loss: 0.4114 - val_accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4233 - accuracy: 0.9634 - val_loss: 0.4040 - val_accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4164 - accuracy: 0.9634 - val_loss: 0.3969 - val_accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4093 - accuracy: 0.9634 - val_loss: 0.3903 - val_accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.4028 - accuracy: 0.9634 - val_loss: 0.3839 - val_accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.3963 - accuracy: 0.9634 - val_loss: 0.3776 - val_accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.3900 - accuracy: 0.9756 - val_loss: 0.3717 - val_accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 366us/sample - loss: 0.3837 - accuracy: 0.9756 - val_loss: 0.3659 - val_accuracy: 0.9815\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 293us/sample - loss: 0.3778 - accuracy: 0.9756 - val_loss: 0.3602 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 346us/sample - loss: 0.3718 - accuracy: 0.9756 - val_loss: 0.3542 - val_accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.3659 - accuracy: 0.9756 - val_loss: 0.3485 - val_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 342us/sample - loss: 0.3601 - accuracy: 0.9756 - val_loss: 0.3430 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3547 - accuracy: 0.9756 - val_loss: 0.3374 - val_accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.3491 - accuracy: 0.9756 - val_loss: 0.3322 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3436 - accuracy: 0.9756 - val_loss: 0.3275 - val_accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3386 - accuracy: 0.9756 - val_loss: 0.3230 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3332 - accuracy: 0.9756 - val_loss: 0.3180 - val_accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3282 - accuracy: 0.9756 - val_loss: 0.3132 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.3232 - accuracy: 0.9756 - val_loss: 0.3084 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3183 - accuracy: 0.9756 - val_loss: 0.3036 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3139 - accuracy: 0.9756 - val_loss: 0.2988 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3089 - accuracy: 0.9756 - val_loss: 0.2943 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.3045 - accuracy: 0.9878 - val_loss: 0.2900 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2999 - accuracy: 0.9878 - val_loss: 0.2858 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2956 - accuracy: 0.9878 - val_loss: 0.2818 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2915 - accuracy: 0.9878 - val_loss: 0.2778 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2874 - accuracy: 0.9878 - val_loss: 0.2745 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2832 - accuracy: 0.9878 - val_loss: 0.2708 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2791 - accuracy: 0.9878 - val_loss: 0.2676 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.2753 - accuracy: 0.9878 - val_loss: 0.2647 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2715 - accuracy: 0.9756 - val_loss: 0.2616 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 226us/sample - loss: 0.2683 - accuracy: 0.9756 - val_loss: 0.2588 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2645 - accuracy: 0.9756 - val_loss: 0.2552 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2608 - accuracy: 0.9756 - val_loss: 0.2518 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.2572 - accuracy: 0.9878 - val_loss: 0.2481 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.2536 - accuracy: 0.9878 - val_loss: 0.2448 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2503 - accuracy: 0.9878 - val_loss: 0.2413 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2470 - accuracy: 0.9878 - val_loss: 0.2380 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2437 - accuracy: 0.9878 - val_loss: 0.2350 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2405 - accuracy: 0.9878 - val_loss: 0.2321 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.2374 - accuracy: 0.9878 - val_loss: 0.2295 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.2344 - accuracy: 0.9878 - val_loss: 0.2265 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2317 - accuracy: 0.9878 - val_loss: 0.2236 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2285 - accuracy: 0.9878 - val_loss: 0.2212 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2255 - accuracy: 0.9878 - val_loss: 0.2188 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2228 - accuracy: 0.9878 - val_loss: 0.2166 - val_accuracy: 0.9815\n",
      "42/42 [==============================] - 0s 119us/sample - loss: 0.2644 - accuracy: 0.9762\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1253 - accuracy: 0.5783 - val_loss: 1.0372 - val_accuracy: 0.6481\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0919 - accuracy: 0.5663 - val_loss: 1.0159 - val_accuracy: 0.6481\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0624 - accuracy: 0.5663 - val_loss: 0.9964 - val_accuracy: 0.6296\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0363 - accuracy: 0.5663 - val_loss: 0.9789 - val_accuracy: 0.6296\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0102 - accuracy: 0.5542 - val_loss: 0.9633 - val_accuracy: 0.6481\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9848 - accuracy: 0.5542 - val_loss: 0.9491 - val_accuracy: 0.6481\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9653 - accuracy: 0.5422 - val_loss: 0.9359 - val_accuracy: 0.6296\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9460 - accuracy: 0.5301 - val_loss: 0.9238 - val_accuracy: 0.6296\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9260 - accuracy: 0.5181 - val_loss: 0.9126 - val_accuracy: 0.6111\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.9114 - accuracy: 0.5060 - val_loss: 0.9022 - val_accuracy: 0.5926\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8959 - accuracy: 0.5060 - val_loss: 0.8924 - val_accuracy: 0.5926\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8804 - accuracy: 0.5060 - val_loss: 0.8830 - val_accuracy: 0.5370\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8687 - accuracy: 0.4940 - val_loss: 0.8740 - val_accuracy: 0.5185\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8552 - accuracy: 0.5181 - val_loss: 0.8651 - val_accuracy: 0.5185\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8435 - accuracy: 0.5663 - val_loss: 0.8566 - val_accuracy: 0.5370\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8331 - accuracy: 0.6747 - val_loss: 0.8481 - val_accuracy: 0.5926\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.8217 - accuracy: 0.6988 - val_loss: 0.8395 - val_accuracy: 0.6111\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8113 - accuracy: 0.7108 - val_loss: 0.8309 - val_accuracy: 0.6111\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8017 - accuracy: 0.7229 - val_loss: 0.8223 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7919 - accuracy: 0.7590 - val_loss: 0.8136 - val_accuracy: 0.6667\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7820 - accuracy: 0.7952 - val_loss: 0.8049 - val_accuracy: 0.6852\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7736 - accuracy: 0.7952 - val_loss: 0.7967 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7638 - accuracy: 0.8072 - val_loss: 0.7878 - val_accuracy: 0.6852\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7546 - accuracy: 0.8072 - val_loss: 0.7788 - val_accuracy: 0.7222\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 259us/sample - loss: 0.7458 - accuracy: 0.8072 - val_loss: 0.7698 - val_accuracy: 0.7407\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7369 - accuracy: 0.8072 - val_loss: 0.7606 - val_accuracy: 0.7407\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7283 - accuracy: 0.8072 - val_loss: 0.7517 - val_accuracy: 0.7593\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 211us/sample - loss: 0.7197 - accuracy: 0.8193 - val_loss: 0.7430 - val_accuracy: 0.7593\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7109 - accuracy: 0.8193 - val_loss: 0.7342 - val_accuracy: 0.7593\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7026 - accuracy: 0.8193 - val_loss: 0.7251 - val_accuracy: 0.7593\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6942 - accuracy: 0.8313 - val_loss: 0.7166 - val_accuracy: 0.7593\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6861 - accuracy: 0.8313 - val_loss: 0.7082 - val_accuracy: 0.7593\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6780 - accuracy: 0.8434 - val_loss: 0.7000 - val_accuracy: 0.7593\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6700 - accuracy: 0.8434 - val_loss: 0.6917 - val_accuracy: 0.7778\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6619 - accuracy: 0.8554 - val_loss: 0.6837 - val_accuracy: 0.7963\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6543 - accuracy: 0.8554 - val_loss: 0.6759 - val_accuracy: 0.7963\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6465 - accuracy: 0.8554 - val_loss: 0.6676 - val_accuracy: 0.7963\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6389 - accuracy: 0.8675 - val_loss: 0.6597 - val_accuracy: 0.7963\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 218us/sample - loss: 0.6311 - accuracy: 0.8675 - val_loss: 0.6518 - val_accuracy: 0.7963\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6240 - accuracy: 0.8675 - val_loss: 0.6436 - val_accuracy: 0.7963\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6165 - accuracy: 0.8675 - val_loss: 0.6360 - val_accuracy: 0.7963\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6094 - accuracy: 0.8795 - val_loss: 0.6291 - val_accuracy: 0.7963\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6020 - accuracy: 0.8795 - val_loss: 0.6216 - val_accuracy: 0.7963\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5950 - accuracy: 0.8795 - val_loss: 0.6145 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5879 - accuracy: 0.8795 - val_loss: 0.6072 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5810 - accuracy: 0.8795 - val_loss: 0.6004 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5741 - accuracy: 0.8916 - val_loss: 0.5937 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5674 - accuracy: 0.8795 - val_loss: 0.5871 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5610 - accuracy: 0.8795 - val_loss: 0.5802 - val_accuracy: 0.8519\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5543 - accuracy: 0.8795 - val_loss: 0.5740 - val_accuracy: 0.8519\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5478 - accuracy: 0.8795 - val_loss: 0.5677 - val_accuracy: 0.8519\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5415 - accuracy: 0.8916 - val_loss: 0.5606 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5350 - accuracy: 0.8916 - val_loss: 0.5539 - val_accuracy: 0.8704\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5287 - accuracy: 0.9036 - val_loss: 0.5470 - val_accuracy: 0.8704\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5226 - accuracy: 0.9036 - val_loss: 0.5403 - val_accuracy: 0.8704\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5164 - accuracy: 0.9036 - val_loss: 0.5343 - val_accuracy: 0.8704\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5103 - accuracy: 0.9036 - val_loss: 0.5279 - val_accuracy: 0.8704\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5042 - accuracy: 0.9036 - val_loss: 0.5213 - val_accuracy: 0.8889\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4986 - accuracy: 0.9036 - val_loss: 0.5154 - val_accuracy: 0.8889\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4924 - accuracy: 0.9036 - val_loss: 0.5086 - val_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4867 - accuracy: 0.9036 - val_loss: 0.5018 - val_accuracy: 0.8889\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 349us/sample - loss: 0.4810 - accuracy: 0.9036 - val_loss: 0.4956 - val_accuracy: 0.8889\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4753 - accuracy: 0.9036 - val_loss: 0.4896 - val_accuracy: 0.8889\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4698 - accuracy: 0.9036 - val_loss: 0.4837 - val_accuracy: 0.8889\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4642 - accuracy: 0.9036 - val_loss: 0.4779 - val_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4588 - accuracy: 0.9157 - val_loss: 0.4722 - val_accuracy: 0.8889\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4533 - accuracy: 0.9157 - val_loss: 0.4664 - val_accuracy: 0.8889\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4480 - accuracy: 0.9157 - val_loss: 0.4611 - val_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4428 - accuracy: 0.9157 - val_loss: 0.4559 - val_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4374 - accuracy: 0.9157 - val_loss: 0.4511 - val_accuracy: 0.8889\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4324 - accuracy: 0.9157 - val_loss: 0.4461 - val_accuracy: 0.8889\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4273 - accuracy: 0.9157 - val_loss: 0.4415 - val_accuracy: 0.8889\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4222 - accuracy: 0.9157 - val_loss: 0.4367 - val_accuracy: 0.8889\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4175 - accuracy: 0.9157 - val_loss: 0.4320 - val_accuracy: 0.8889\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4124 - accuracy: 0.9157 - val_loss: 0.4267 - val_accuracy: 0.9074\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.4075 - accuracy: 0.9157 - val_loss: 0.4215 - val_accuracy: 0.9074\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4027 - accuracy: 0.9157 - val_loss: 0.4158 - val_accuracy: 0.9074\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3979 - accuracy: 0.9157 - val_loss: 0.4103 - val_accuracy: 0.9074\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3934 - accuracy: 0.9157 - val_loss: 0.4052 - val_accuracy: 0.9259\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3885 - accuracy: 0.9157 - val_loss: 0.4004 - val_accuracy: 0.9259\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3841 - accuracy: 0.9157 - val_loss: 0.3954 - val_accuracy: 0.9259\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3795 - accuracy: 0.9157 - val_loss: 0.3907 - val_accuracy: 0.9259\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3750 - accuracy: 0.9277 - val_loss: 0.3859 - val_accuracy: 0.9444\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3707 - accuracy: 0.9277 - val_loss: 0.3812 - val_accuracy: 0.9444\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3666 - accuracy: 0.9277 - val_loss: 0.3766 - val_accuracy: 0.9444\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3622 - accuracy: 0.9277 - val_loss: 0.3728 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3579 - accuracy: 0.9277 - val_loss: 0.3689 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3539 - accuracy: 0.9277 - val_loss: 0.3657 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3494 - accuracy: 0.9277 - val_loss: 0.3618 - val_accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3454 - accuracy: 0.9277 - val_loss: 0.3579 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3414 - accuracy: 0.9277 - val_loss: 0.3541 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3375 - accuracy: 0.9277 - val_loss: 0.3503 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3335 - accuracy: 0.9277 - val_loss: 0.3467 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3297 - accuracy: 0.9277 - val_loss: 0.3430 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3260 - accuracy: 0.9277 - val_loss: 0.3395 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3223 - accuracy: 0.9277 - val_loss: 0.3355 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3185 - accuracy: 0.9277 - val_loss: 0.3318 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3149 - accuracy: 0.9518 - val_loss: 0.3279 - val_accuracy: 0.9630\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3113 - accuracy: 0.9518 - val_loss: 0.3245 - val_accuracy: 0.9630\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3079 - accuracy: 0.9518 - val_loss: 0.3208 - val_accuracy: 0.9630\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.3562 - accuracy: 0.9512\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 5ms/sample - loss: 1.2114 - accuracy: 0.3133 - val_loss: 1.1974 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 397us/sample - loss: 1.1855 - accuracy: 0.3133 - val_loss: 1.1741 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.1620 - accuracy: 0.3133 - val_loss: 1.1519 - val_accuracy: 0.3519\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1411 - accuracy: 0.3494 - val_loss: 1.1309 - val_accuracy: 0.3704\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.1208 - accuracy: 0.3494 - val_loss: 1.1119 - val_accuracy: 0.3889\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.1003 - accuracy: 0.3614 - val_loss: 1.0937 - val_accuracy: 0.3889\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0830 - accuracy: 0.3976 - val_loss: 1.0760 - val_accuracy: 0.4259\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0657 - accuracy: 0.3976 - val_loss: 1.0590 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0499 - accuracy: 0.4217 - val_loss: 1.0427 - val_accuracy: 0.4630\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.0338 - accuracy: 0.4819 - val_loss: 1.0270 - val_accuracy: 0.4815\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.0180 - accuracy: 0.4940 - val_loss: 1.0121 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0041 - accuracy: 0.4940 - val_loss: 0.9973 - val_accuracy: 0.5370\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9904 - accuracy: 0.5422 - val_loss: 0.9828 - val_accuracy: 0.5556\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9768 - accuracy: 0.5542 - val_loss: 0.9688 - val_accuracy: 0.5926\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9636 - accuracy: 0.5663 - val_loss: 0.9550 - val_accuracy: 0.6111\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9509 - accuracy: 0.5663 - val_loss: 0.9415 - val_accuracy: 0.6296\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9385 - accuracy: 0.5663 - val_loss: 0.9284 - val_accuracy: 0.6296\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.9744 - accuracy: 0.53 - 0s 229us/sample - loss: 0.9260 - accuracy: 0.5663 - val_loss: 0.9159 - val_accuracy: 0.6296\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9143 - accuracy: 0.5783 - val_loss: 0.9033 - val_accuracy: 0.6296\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9028 - accuracy: 0.5904 - val_loss: 0.8905 - val_accuracy: 0.6296\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8911 - accuracy: 0.5904 - val_loss: 0.8778 - val_accuracy: 0.6296\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8795 - accuracy: 0.5904 - val_loss: 0.8651 - val_accuracy: 0.6667\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 254us/sample - loss: 0.8684 - accuracy: 0.6145 - val_loss: 0.8524 - val_accuracy: 0.6852\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8573 - accuracy: 0.6145 - val_loss: 0.8399 - val_accuracy: 0.7037\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8463 - accuracy: 0.6145 - val_loss: 0.8276 - val_accuracy: 0.7037\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8352 - accuracy: 0.6506 - val_loss: 0.8153 - val_accuracy: 0.7037\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8245 - accuracy: 0.6506 - val_loss: 0.8032 - val_accuracy: 0.7222\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8141 - accuracy: 0.6867 - val_loss: 0.7912 - val_accuracy: 0.7778\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 229us/sample - loss: 0.8038 - accuracy: 0.7349 - val_loss: 0.7793 - val_accuracy: 0.7778\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7930 - accuracy: 0.7590 - val_loss: 0.7679 - val_accuracy: 0.7778\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.7830 - accuracy: 0.7590 - val_loss: 0.7564 - val_accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.7729 - accuracy: 0.7831 - val_loss: 0.7452 - val_accuracy: 0.7778\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7627 - accuracy: 0.7831 - val_loss: 0.7343 - val_accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7528 - accuracy: 0.7831 - val_loss: 0.7234 - val_accuracy: 0.7778\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7429 - accuracy: 0.8193 - val_loss: 0.7125 - val_accuracy: 0.7778\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7331 - accuracy: 0.8313 - val_loss: 0.7019 - val_accuracy: 0.7778\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7235 - accuracy: 0.8434 - val_loss: 0.6914 - val_accuracy: 0.7778\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.7150 - accuracy: 0.8434 - val_loss: 0.6808 - val_accuracy: 0.8148\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.7046 - accuracy: 0.8434 - val_loss: 0.6706 - val_accuracy: 0.8148\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6955 - accuracy: 0.8434 - val_loss: 0.6606 - val_accuracy: 0.8148\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6861 - accuracy: 0.8554 - val_loss: 0.6507 - val_accuracy: 0.8148\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6772 - accuracy: 0.8554 - val_loss: 0.6410 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6684 - accuracy: 0.8554 - val_loss: 0.6314 - val_accuracy: 0.8333\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6598 - accuracy: 0.8554 - val_loss: 0.6219 - val_accuracy: 0.8333\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 259us/sample - loss: 0.6507 - accuracy: 0.8554 - val_loss: 0.6125 - val_accuracy: 0.8519\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6421 - accuracy: 0.8554 - val_loss: 0.6032 - val_accuracy: 0.8519\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6336 - accuracy: 0.8675 - val_loss: 0.5941 - val_accuracy: 0.8519\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6252 - accuracy: 0.8675 - val_loss: 0.5850 - val_accuracy: 0.8519\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6170 - accuracy: 0.8675 - val_loss: 0.5760 - val_accuracy: 0.8519\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6086 - accuracy: 0.8675 - val_loss: 0.5674 - val_accuracy: 0.8889\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6010 - accuracy: 0.8795 - val_loss: 0.5586 - val_accuracy: 0.9259\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5924 - accuracy: 0.8795 - val_loss: 0.5502 - val_accuracy: 0.9259\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5848 - accuracy: 0.8916 - val_loss: 0.5419 - val_accuracy: 0.9259\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5771 - accuracy: 0.9157 - val_loss: 0.5338 - val_accuracy: 0.9259\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.5693 - accuracy: 0.9157 - val_loss: 0.5259 - val_accuracy: 0.9259\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.5618 - accuracy: 0.9157 - val_loss: 0.5178 - val_accuracy: 0.9259\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5544 - accuracy: 0.9157 - val_loss: 0.5101 - val_accuracy: 0.9259\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5468 - accuracy: 0.9157 - val_loss: 0.5024 - val_accuracy: 0.9259\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5395 - accuracy: 0.9157 - val_loss: 0.4949 - val_accuracy: 0.9259\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5326 - accuracy: 0.9157 - val_loss: 0.4873 - val_accuracy: 0.9259\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5253 - accuracy: 0.9157 - val_loss: 0.4799 - val_accuracy: 0.9259\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5183 - accuracy: 0.9157 - val_loss: 0.4727 - val_accuracy: 0.9259\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5113 - accuracy: 0.9157 - val_loss: 0.4654 - val_accuracy: 0.9259\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.5045 - accuracy: 0.9157 - val_loss: 0.4584 - val_accuracy: 0.9259\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4978 - accuracy: 0.9157 - val_loss: 0.4513 - val_accuracy: 0.9259\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4914 - accuracy: 0.9277 - val_loss: 0.4445 - val_accuracy: 0.9259\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4847 - accuracy: 0.9277 - val_loss: 0.4378 - val_accuracy: 0.9259\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4780 - accuracy: 0.9398 - val_loss: 0.4315 - val_accuracy: 0.9259\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4719 - accuracy: 0.9398 - val_loss: 0.4252 - val_accuracy: 0.9259\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4655 - accuracy: 0.9398 - val_loss: 0.4190 - val_accuracy: 0.9259\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4597 - accuracy: 0.9398 - val_loss: 0.4126 - val_accuracy: 0.9259\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4536 - accuracy: 0.9398 - val_loss: 0.4065 - val_accuracy: 0.9259\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4474 - accuracy: 0.9398 - val_loss: 0.4005 - val_accuracy: 0.9259\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4416 - accuracy: 0.9398 - val_loss: 0.3947 - val_accuracy: 0.9444\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4358 - accuracy: 0.9398 - val_loss: 0.3891 - val_accuracy: 0.9444\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4300 - accuracy: 0.9398 - val_loss: 0.3835 - val_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.4245 - accuracy: 0.9398 - val_loss: 0.3780 - val_accuracy: 0.9444\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 374us/sample - loss: 0.4189 - accuracy: 0.9518 - val_loss: 0.3727 - val_accuracy: 0.9444\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4137 - accuracy: 0.9518 - val_loss: 0.3677 - val_accuracy: 0.9444\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 361us/sample - loss: 0.4083 - accuracy: 0.9518 - val_loss: 0.3625 - val_accuracy: 0.9444\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4030 - accuracy: 0.9518 - val_loss: 0.3574 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 325us/sample - loss: 0.3980 - accuracy: 0.9518 - val_loss: 0.3523 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3926 - accuracy: 0.9518 - val_loss: 0.3475 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.3877 - accuracy: 0.9518 - val_loss: 0.3427 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3827 - accuracy: 0.9518 - val_loss: 0.3380 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.3782 - accuracy: 0.9518 - val_loss: 0.3333 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3731 - accuracy: 0.9518 - val_loss: 0.3290 - val_accuracy: 0.9630\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.3684 - accuracy: 0.9518 - val_loss: 0.3247 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3638 - accuracy: 0.9518 - val_loss: 0.3204 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3594 - accuracy: 0.9518 - val_loss: 0.3161 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.3547 - accuracy: 0.9518 - val_loss: 0.3120 - val_accuracy: 0.9630\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 235us/sample - loss: 0.3505 - accuracy: 0.9518 - val_loss: 0.3079 - val_accuracy: 0.9630\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3461 - accuracy: 0.9518 - val_loss: 0.3038 - val_accuracy: 0.9630\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3417 - accuracy: 0.9518 - val_loss: 0.2996 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3374 - accuracy: 0.9639 - val_loss: 0.2955 - val_accuracy: 0.9630\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3337 - accuracy: 0.9639 - val_loss: 0.2914 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3294 - accuracy: 0.9639 - val_loss: 0.2876 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3254 - accuracy: 0.9639 - val_loss: 0.2840 - val_accuracy: 0.9630\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3216 - accuracy: 0.9639 - val_loss: 0.2804 - val_accuracy: 0.9630\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3177 - accuracy: 0.9639 - val_loss: 0.2771 - val_accuracy: 0.9630\n",
      "41/41 [==============================] - 0s 122us/sample - loss: 0.2932 - accuracy: 0.9512\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 5ms/sample - loss: 1.1869 - accuracy: 0.1585 - val_loss: 1.2261 - val_accuracy: 0.2037\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.1547 - accuracy: 0.2561 - val_loss: 1.2004 - val_accuracy: 0.2778\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 1.1266 - accuracy: 0.2927 - val_loss: 1.1752 - val_accuracy: 0.2963\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 1.1009 - accuracy: 0.3537 - val_loss: 1.1499 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 1.0764 - accuracy: 0.4024 - val_loss: 1.1258 - val_accuracy: 0.4074\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 303us/sample - loss: 1.0529 - accuracy: 0.4634 - val_loss: 1.1021 - val_accuracy: 0.4444\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 1.0302 - accuracy: 0.5488 - val_loss: 1.0779 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 354us/sample - loss: 1.0077 - accuracy: 0.5976 - val_loss: 1.0538 - val_accuracy: 0.5741\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 433us/sample - loss: 0.9863 - accuracy: 0.6220 - val_loss: 1.0306 - val_accuracy: 0.5741\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.9657 - accuracy: 0.6341 - val_loss: 1.0069 - val_accuracy: 0.5926\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 359us/sample - loss: 0.9451 - accuracy: 0.6585 - val_loss: 0.9838 - val_accuracy: 0.5926\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.9256 - accuracy: 0.6829 - val_loss: 0.9607 - val_accuracy: 0.6296\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.9060 - accuracy: 0.6829 - val_loss: 0.9380 - val_accuracy: 0.6481\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.8883 - accuracy: 0.6829 - val_loss: 0.9150 - val_accuracy: 0.6481\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.8691 - accuracy: 0.7073 - val_loss: 0.8933 - val_accuracy: 0.6852\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.8513 - accuracy: 0.7439 - val_loss: 0.8726 - val_accuracy: 0.7222\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 317us/sample - loss: 0.8338 - accuracy: 0.7927 - val_loss: 0.8531 - val_accuracy: 0.7407\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.8163 - accuracy: 0.8415 - val_loss: 0.8328 - val_accuracy: 0.7963\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7998 - accuracy: 0.8537 - val_loss: 0.8131 - val_accuracy: 0.7963\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.7842 - accuracy: 0.8780 - val_loss: 0.7944 - val_accuracy: 0.7963\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7671 - accuracy: 0.9024 - val_loss: 0.7776 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.7519 - accuracy: 0.9024 - val_loss: 0.7612 - val_accuracy: 0.8333\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7363 - accuracy: 0.9024 - val_loss: 0.7447 - val_accuracy: 0.9074\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7214 - accuracy: 0.9146 - val_loss: 0.7283 - val_accuracy: 0.9259\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 283us/sample - loss: 0.7070 - accuracy: 0.9146 - val_loss: 0.7126 - val_accuracy: 0.9444\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6922 - accuracy: 0.9268 - val_loss: 0.6958 - val_accuracy: 0.9444\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.6781 - accuracy: 0.9268 - val_loss: 0.6795 - val_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.6639 - accuracy: 0.9268 - val_loss: 0.6631 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6498 - accuracy: 0.9390 - val_loss: 0.6480 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.6365 - accuracy: 0.9512 - val_loss: 0.6328 - val_accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6231 - accuracy: 0.9512 - val_loss: 0.6182 - val_accuracy: 0.9630\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6099 - accuracy: 0.9512 - val_loss: 0.6041 - val_accuracy: 0.9815\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5972 - accuracy: 0.9634 - val_loss: 0.5903 - val_accuracy: 0.9815\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 282us/sample - loss: 0.5847 - accuracy: 0.9634 - val_loss: 0.5768 - val_accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.5725 - accuracy: 0.9634 - val_loss: 0.5634 - val_accuracy: 0.9815\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5601 - accuracy: 0.9634 - val_loss: 0.5510 - val_accuracy: 0.9815\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.5482 - accuracy: 0.9634 - val_loss: 0.5387 - val_accuracy: 0.9815\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.5365 - accuracy: 0.9634 - val_loss: 0.5265 - val_accuracy: 0.9815\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.5253 - accuracy: 0.9634 - val_loss: 0.5147 - val_accuracy: 0.9815\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 232us/sample - loss: 0.5140 - accuracy: 0.9634 - val_loss: 0.5033 - val_accuracy: 0.9815\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.5030 - accuracy: 0.9634 - val_loss: 0.4924 - val_accuracy: 0.9815\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.4924 - accuracy: 0.9634 - val_loss: 0.4819 - val_accuracy: 0.9815\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.4820 - accuracy: 0.9634 - val_loss: 0.4712 - val_accuracy: 0.9815\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.4714 - accuracy: 0.9634 - val_loss: 0.4605 - val_accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.4614 - accuracy: 0.9634 - val_loss: 0.4501 - val_accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.4516 - accuracy: 0.9634 - val_loss: 0.4401 - val_accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4420 - accuracy: 0.9634 - val_loss: 0.4306 - val_accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4330 - accuracy: 0.9756 - val_loss: 0.4210 - val_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.4235 - accuracy: 0.9756 - val_loss: 0.4119 - val_accuracy: 0.9815\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4146 - accuracy: 0.9756 - val_loss: 0.4033 - val_accuracy: 0.9815\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.4058 - accuracy: 0.9756 - val_loss: 0.3948 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.3974 - accuracy: 0.9756 - val_loss: 0.3862 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3891 - accuracy: 0.9756 - val_loss: 0.3780 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3807 - accuracy: 0.9756 - val_loss: 0.3699 - val_accuracy: 0.9815\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3728 - accuracy: 0.9756 - val_loss: 0.3619 - val_accuracy: 0.9815\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3652 - accuracy: 0.9756 - val_loss: 0.3543 - val_accuracy: 0.9815\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3577 - accuracy: 0.9756 - val_loss: 0.3467 - val_accuracy: 0.9815\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3504 - accuracy: 0.9756 - val_loss: 0.3393 - val_accuracy: 0.9815\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.3433 - accuracy: 0.9756 - val_loss: 0.3325 - val_accuracy: 0.9815\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3363 - accuracy: 0.9756 - val_loss: 0.3258 - val_accuracy: 0.9815\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3298 - accuracy: 0.9756 - val_loss: 0.3194 - val_accuracy: 0.9815\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.3229 - accuracy: 0.9756 - val_loss: 0.3130 - val_accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.3167 - accuracy: 0.9756 - val_loss: 0.3070 - val_accuracy: 0.9815\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.3103 - accuracy: 0.9756 - val_loss: 0.3011 - val_accuracy: 0.9815\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.3043 - accuracy: 0.9756 - val_loss: 0.2957 - val_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2982 - accuracy: 0.9756 - val_loss: 0.2902 - val_accuracy: 0.9815\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2925 - accuracy: 0.9756 - val_loss: 0.2850 - val_accuracy: 0.9815\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2869 - accuracy: 0.9756 - val_loss: 0.2799 - val_accuracy: 0.9815\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2812 - accuracy: 0.9756 - val_loss: 0.2748 - val_accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.2760 - accuracy: 0.9756 - val_loss: 0.2700 - val_accuracy: 0.9815\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2706 - accuracy: 0.9756 - val_loss: 0.2657 - val_accuracy: 0.9815\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.2656 - accuracy: 0.9756 - val_loss: 0.2618 - val_accuracy: 0.9815\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2608 - accuracy: 0.9756 - val_loss: 0.2581 - val_accuracy: 0.9815\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.2560 - accuracy: 0.9756 - val_loss: 0.2543 - val_accuracy: 0.9815\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2513 - accuracy: 0.9756 - val_loss: 0.2502 - val_accuracy: 0.9815\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 264us/sample - loss: 0.2467 - accuracy: 0.9756 - val_loss: 0.2462 - val_accuracy: 0.9815\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2423 - accuracy: 0.9756 - val_loss: 0.2422 - val_accuracy: 0.9815\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.2380 - accuracy: 0.9878 - val_loss: 0.2377 - val_accuracy: 0.9815\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.2337 - accuracy: 0.9878 - val_loss: 0.2333 - val_accuracy: 0.9815\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.2297 - accuracy: 0.9878 - val_loss: 0.2291 - val_accuracy: 0.9815\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 305us/sample - loss: 0.2256 - accuracy: 0.9878 - val_loss: 0.2253 - val_accuracy: 0.9815\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 267us/sample - loss: 0.2218 - accuracy: 0.9878 - val_loss: 0.2218 - val_accuracy: 0.9815\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.2178 - accuracy: 0.9878 - val_loss: 0.2192 - val_accuracy: 0.9815\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 267us/sample - loss: 0.2143 - accuracy: 0.9878 - val_loss: 0.2166 - val_accuracy: 0.9815\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.2104 - accuracy: 0.9878 - val_loss: 0.2135 - val_accuracy: 0.9815\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2070 - accuracy: 0.9878 - val_loss: 0.2103 - val_accuracy: 0.9815\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.2034 - accuracy: 0.9878 - val_loss: 0.2078 - val_accuracy: 0.9815\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.2003 - accuracy: 0.9878 - val_loss: 0.2049 - val_accuracy: 0.9815\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.1968 - accuracy: 0.9878 - val_loss: 0.2022 - val_accuracy: 0.9815\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.1936 - accuracy: 0.9878 - val_loss: 0.1997 - val_accuracy: 0.9815\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 1.00 - 0s 281us/sample - loss: 0.1905 - accuracy: 0.9878 - val_loss: 0.1978 - val_accuracy: 0.9815\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 281us/sample - loss: 0.1874 - accuracy: 0.9878 - val_loss: 0.1955 - val_accuracy: 0.9815\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 280us/sample - loss: 0.1846 - accuracy: 0.9878 - val_loss: 0.1931 - val_accuracy: 0.9815\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.1817 - accuracy: 0.9878 - val_loss: 0.1904 - val_accuracy: 0.9815\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.1789 - accuracy: 0.9878 - val_loss: 0.1879 - val_accuracy: 0.9815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 250us/sample - loss: 0.1761 - accuracy: 0.9878 - val_loss: 0.1858 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 268us/sample - loss: 0.1733 - accuracy: 0.9878 - val_loss: 0.1839 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.1708 - accuracy: 0.9878 - val_loss: 0.1819 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.1682 - accuracy: 0.9878 - val_loss: 0.1798 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 293us/sample - loss: 0.1656 - accuracy: 0.9878 - val_loss: 0.1774 - val_accuracy: 0.9815\n",
      "42/42 [==============================] - 0s 143us/sample - loss: 0.2289 - accuracy: 0.9286\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1990 - accuracy: 0.1928 - val_loss: 1.1782 - val_accuracy: 0.2593\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 1.1632 - accuracy: 0.2048 - val_loss: 1.1522 - val_accuracy: 0.2963\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 1.1357 - accuracy: 0.2410 - val_loss: 1.1293 - val_accuracy: 0.2407\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 1.1038 - accuracy: 0.3133 - val_loss: 1.1089 - val_accuracy: 0.2593\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 1.0776 - accuracy: 0.4217 - val_loss: 1.0904 - val_accuracy: 0.4074\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0568 - accuracy: 0.4940 - val_loss: 1.0736 - val_accuracy: 0.4074\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.0346 - accuracy: 0.5301 - val_loss: 1.0574 - val_accuracy: 0.4259\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 274us/sample - loss: 1.0167 - accuracy: 0.4940 - val_loss: 1.0423 - val_accuracy: 0.3889\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.9972 - accuracy: 0.4578 - val_loss: 1.0265 - val_accuracy: 0.3889\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9801 - accuracy: 0.4578 - val_loss: 1.0100 - val_accuracy: 0.3889\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 283us/sample - loss: 0.9642 - accuracy: 0.4578 - val_loss: 0.9935 - val_accuracy: 0.4259\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9468 - accuracy: 0.4699 - val_loss: 0.9751 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9294 - accuracy: 0.5181 - val_loss: 0.9553 - val_accuracy: 0.5556\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.9126 - accuracy: 0.5904 - val_loss: 0.9358 - val_accuracy: 0.6296\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8958 - accuracy: 0.6747 - val_loss: 0.9164 - val_accuracy: 0.7037\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.8805 - accuracy: 0.7470 - val_loss: 0.8976 - val_accuracy: 0.7037\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8639 - accuracy: 0.7711 - val_loss: 0.8813 - val_accuracy: 0.7037\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8479 - accuracy: 0.7711 - val_loss: 0.8649 - val_accuracy: 0.7222\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8328 - accuracy: 0.7831 - val_loss: 0.8493 - val_accuracy: 0.7222\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.8176 - accuracy: 0.8072 - val_loss: 0.8331 - val_accuracy: 0.7407\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.8032 - accuracy: 0.8193 - val_loss: 0.8176 - val_accuracy: 0.7593\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7887 - accuracy: 0.8193 - val_loss: 0.8025 - val_accuracy: 0.7963\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7743 - accuracy: 0.8193 - val_loss: 0.7879 - val_accuracy: 0.8148\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.7599 - accuracy: 0.8193 - val_loss: 0.7730 - val_accuracy: 0.8333\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7466 - accuracy: 0.8434 - val_loss: 0.7581 - val_accuracy: 0.8333\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.7324 - accuracy: 0.8675 - val_loss: 0.7436 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 259us/sample - loss: 0.7189 - accuracy: 0.8795 - val_loss: 0.7292 - val_accuracy: 0.8704\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 283us/sample - loss: 0.7061 - accuracy: 0.9036 - val_loss: 0.7153 - val_accuracy: 0.8704\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6927 - accuracy: 0.9157 - val_loss: 0.7015 - val_accuracy: 0.8704\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6798 - accuracy: 0.9157 - val_loss: 0.6884 - val_accuracy: 0.8704\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.6675 - accuracy: 0.9157 - val_loss: 0.6750 - val_accuracy: 0.8704\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.6548 - accuracy: 0.9157 - val_loss: 0.6620 - val_accuracy: 0.8889\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.6422 - accuracy: 0.9157 - val_loss: 0.6487 - val_accuracy: 0.8889\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6305 - accuracy: 0.9277 - val_loss: 0.6359 - val_accuracy: 0.8889\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6183 - accuracy: 0.9277 - val_loss: 0.6243 - val_accuracy: 0.9074\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - ETA: 0s - loss: 0.5718 - accuracy: 0.96 - 0s 253us/sample - loss: 0.6071 - accuracy: 0.9277 - val_loss: 0.6128 - val_accuracy: 0.9074\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5952 - accuracy: 0.9277 - val_loss: 0.6026 - val_accuracy: 0.8889\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5844 - accuracy: 0.9277 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.5732 - accuracy: 0.9277 - val_loss: 0.5812 - val_accuracy: 0.9074\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5624 - accuracy: 0.9277 - val_loss: 0.5693 - val_accuracy: 0.9074\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5519 - accuracy: 0.9398 - val_loss: 0.5573 - val_accuracy: 0.9074\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.5416 - accuracy: 0.9398 - val_loss: 0.5457 - val_accuracy: 0.9074\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 374us/sample - loss: 0.5310 - accuracy: 0.9398 - val_loss: 0.5348 - val_accuracy: 0.9074\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.5209 - accuracy: 0.9398 - val_loss: 0.5243 - val_accuracy: 0.9259\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5111 - accuracy: 0.9518 - val_loss: 0.5139 - val_accuracy: 0.9259\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5012 - accuracy: 0.9518 - val_loss: 0.5039 - val_accuracy: 0.9259\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4920 - accuracy: 0.9398 - val_loss: 0.4939 - val_accuracy: 0.9259\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4826 - accuracy: 0.9518 - val_loss: 0.4838 - val_accuracy: 0.9259\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.4736 - accuracy: 0.9518 - val_loss: 0.4743 - val_accuracy: 0.9259\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4646 - accuracy: 0.9518 - val_loss: 0.4656 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4560 - accuracy: 0.9518 - val_loss: 0.4564 - val_accuracy: 0.9259\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4474 - accuracy: 0.9518 - val_loss: 0.4487 - val_accuracy: 0.9259\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4389 - accuracy: 0.9518 - val_loss: 0.4408 - val_accuracy: 0.9259\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4307 - accuracy: 0.9518 - val_loss: 0.4327 - val_accuracy: 0.9259\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4231 - accuracy: 0.9518 - val_loss: 0.4262 - val_accuracy: 0.9259\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.4148 - accuracy: 0.9518 - val_loss: 0.4184 - val_accuracy: 0.9259\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 216us/sample - loss: 0.4073 - accuracy: 0.9639 - val_loss: 0.4101 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3999 - accuracy: 0.9639 - val_loss: 0.4026 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.3924 - accuracy: 0.9639 - val_loss: 0.3960 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3854 - accuracy: 0.9639 - val_loss: 0.3896 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3784 - accuracy: 0.9639 - val_loss: 0.3824 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 216us/sample - loss: 0.3716 - accuracy: 0.9639 - val_loss: 0.3755 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3649 - accuracy: 0.9639 - val_loss: 0.3687 - val_accuracy: 0.9630\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3584 - accuracy: 0.9759 - val_loss: 0.3623 - val_accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3524 - accuracy: 0.9759 - val_loss: 0.3553 - val_accuracy: 0.9630\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3458 - accuracy: 0.9759 - val_loss: 0.3497 - val_accuracy: 0.9630\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3397 - accuracy: 0.9759 - val_loss: 0.3443 - val_accuracy: 0.9630\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3337 - accuracy: 0.9759 - val_loss: 0.3385 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.3284 - accuracy: 0.9759 - val_loss: 0.3328 - val_accuracy: 0.9630\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3227 - accuracy: 0.9759 - val_loss: 0.3280 - val_accuracy: 0.9630\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3172 - accuracy: 0.9759 - val_loss: 0.3245 - val_accuracy: 0.9630\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3118 - accuracy: 0.9759 - val_loss: 0.3196 - val_accuracy: 0.9630\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3069 - accuracy: 0.9759 - val_loss: 0.3155 - val_accuracy: 0.9630\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3016 - accuracy: 0.9759 - val_loss: 0.3109 - val_accuracy: 0.9630\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2966 - accuracy: 0.9759 - val_loss: 0.3055 - val_accuracy: 0.9630\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2920 - accuracy: 0.9759 - val_loss: 0.2995 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2871 - accuracy: 0.9759 - val_loss: 0.2945 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2823 - accuracy: 0.9759 - val_loss: 0.2904 - val_accuracy: 0.9630\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2778 - accuracy: 0.9759 - val_loss: 0.2864 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.2734 - accuracy: 0.9759 - val_loss: 0.2819 - val_accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2693 - accuracy: 0.9759 - val_loss: 0.2783 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2649 - accuracy: 0.9759 - val_loss: 0.2737 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2607 - accuracy: 0.9759 - val_loss: 0.2694 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2572 - accuracy: 0.9759 - val_loss: 0.2648 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2528 - accuracy: 0.9759 - val_loss: 0.2619 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2489 - accuracy: 0.9759 - val_loss: 0.2581 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2451 - accuracy: 0.9759 - val_loss: 0.2548 - val_accuracy: 0.9630\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 243us/sample - loss: 0.2414 - accuracy: 0.9759 - val_loss: 0.2521 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2378 - accuracy: 0.9759 - val_loss: 0.2489 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2343 - accuracy: 0.9759 - val_loss: 0.2456 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2309 - accuracy: 0.9759 - val_loss: 0.2430 - val_accuracy: 0.9630\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.2276 - accuracy: 0.9759 - val_loss: 0.2400 - val_accuracy: 0.9630\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.2243 - accuracy: 0.9759 - val_loss: 0.2377 - val_accuracy: 0.9630\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2210 - accuracy: 0.9759 - val_loss: 0.2345 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2178 - accuracy: 0.9759 - val_loss: 0.2307 - val_accuracy: 0.9630\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 279us/sample - loss: 0.2147 - accuracy: 0.9759 - val_loss: 0.2272 - val_accuracy: 0.9630\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2116 - accuracy: 0.9759 - val_loss: 0.2241 - val_accuracy: 0.9630\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2086 - accuracy: 0.9759 - val_loss: 0.2212 - val_accuracy: 0.9630\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.2062 - accuracy: 0.9759 - val_loss: 0.2194 - val_accuracy: 0.9630\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2027 - accuracy: 0.9759 - val_loss: 0.2164 - val_accuracy: 0.9630\n",
      "41/41 [==============================] - 0s 171us/sample - loss: 0.2389 - accuracy: 0.9512\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1746 - accuracy: 0.2892 - val_loss: 1.1339 - val_accuracy: 0.3148\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 1.1340 - accuracy: 0.3253 - val_loss: 1.0968 - val_accuracy: 0.3148\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.1007 - accuracy: 0.3494 - val_loss: 1.0648 - val_accuracy: 0.3519\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 1.0663 - accuracy: 0.4337 - val_loss: 1.0364 - val_accuracy: 0.5185\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 1.0414 - accuracy: 0.5181 - val_loss: 1.0105 - val_accuracy: 0.6111\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 319us/sample - loss: 1.0154 - accuracy: 0.6145 - val_loss: 0.9866 - val_accuracy: 0.6481\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.9921 - accuracy: 0.6024 - val_loss: 0.9637 - val_accuracy: 0.6481\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9706 - accuracy: 0.6265 - val_loss: 0.9420 - val_accuracy: 0.6481\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9507 - accuracy: 0.6506 - val_loss: 0.9213 - val_accuracy: 0.6481\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.9312 - accuracy: 0.6506 - val_loss: 0.9010 - val_accuracy: 0.6481\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.9125 - accuracy: 0.6506 - val_loss: 0.8812 - val_accuracy: 0.6481\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8941 - accuracy: 0.6506 - val_loss: 0.8619 - val_accuracy: 0.6852\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.8764 - accuracy: 0.6747 - val_loss: 0.8431 - val_accuracy: 0.7222\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.8587 - accuracy: 0.6747 - val_loss: 0.8245 - val_accuracy: 0.7407\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.8415 - accuracy: 0.6747 - val_loss: 0.8060 - val_accuracy: 0.7778\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.8248 - accuracy: 0.6867 - val_loss: 0.7877 - val_accuracy: 0.8333\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.8084 - accuracy: 0.7229 - val_loss: 0.7698 - val_accuracy: 0.8704\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7916 - accuracy: 0.7952 - val_loss: 0.7524 - val_accuracy: 0.8704\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7754 - accuracy: 0.8193 - val_loss: 0.7352 - val_accuracy: 0.9074\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.7599 - accuracy: 0.8795 - val_loss: 0.7184 - val_accuracy: 0.9259\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.7448 - accuracy: 0.9157 - val_loss: 0.7018 - val_accuracy: 0.9630\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.7291 - accuracy: 0.9277 - val_loss: 0.6856 - val_accuracy: 0.9630\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.7143 - accuracy: 0.9398 - val_loss: 0.6695 - val_accuracy: 0.9630\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6995 - accuracy: 0.9398 - val_loss: 0.6538 - val_accuracy: 0.9630\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6850 - accuracy: 0.9518 - val_loss: 0.6385 - val_accuracy: 0.9630\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.6708 - accuracy: 0.9518 - val_loss: 0.6236 - val_accuracy: 0.9630\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.6566 - accuracy: 0.9518 - val_loss: 0.6091 - val_accuracy: 0.9630\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 247us/sample - loss: 0.6441 - accuracy: 0.9518 - val_loss: 0.5950 - val_accuracy: 0.9444\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.6298 - accuracy: 0.9518 - val_loss: 0.5812 - val_accuracy: 0.9444\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.6172 - accuracy: 0.9398 - val_loss: 0.5676 - val_accuracy: 0.9630\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 301us/sample - loss: 0.6043 - accuracy: 0.9398 - val_loss: 0.5546 - val_accuracy: 0.9630\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5918 - accuracy: 0.9398 - val_loss: 0.5419 - val_accuracy: 0.9630\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5799 - accuracy: 0.9518 - val_loss: 0.5293 - val_accuracy: 0.9630\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5675 - accuracy: 0.9518 - val_loss: 0.5172 - val_accuracy: 0.9630\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.5559 - accuracy: 0.9518 - val_loss: 0.5053 - val_accuracy: 0.9630\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5448 - accuracy: 0.9518 - val_loss: 0.4937 - val_accuracy: 0.9630\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5332 - accuracy: 0.9639 - val_loss: 0.4822 - val_accuracy: 0.9630\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.5224 - accuracy: 0.9518 - val_loss: 0.4711 - val_accuracy: 0.9630\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.5118 - accuracy: 0.9518 - val_loss: 0.4604 - val_accuracy: 0.9630\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.5012 - accuracy: 0.9639 - val_loss: 0.4499 - val_accuracy: 0.9630\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4909 - accuracy: 0.9639 - val_loss: 0.4400 - val_accuracy: 0.9630\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4810 - accuracy: 0.9639 - val_loss: 0.4302 - val_accuracy: 0.9630\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.4712 - accuracy: 0.9639 - val_loss: 0.4207 - val_accuracy: 0.9630\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 313us/sample - loss: 0.4622 - accuracy: 0.9639 - val_loss: 0.4116 - val_accuracy: 0.9630\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4524 - accuracy: 0.9639 - val_loss: 0.4024 - val_accuracy: 0.9630\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 337us/sample - loss: 0.4433 - accuracy: 0.9639 - val_loss: 0.3936 - val_accuracy: 0.9630\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.4345 - accuracy: 0.9639 - val_loss: 0.3850 - val_accuracy: 0.9630\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4259 - accuracy: 0.9639 - val_loss: 0.3765 - val_accuracy: 0.9630\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.4174 - accuracy: 0.9639 - val_loss: 0.3682 - val_accuracy: 0.9630\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.4095 - accuracy: 0.9639 - val_loss: 0.3603 - val_accuracy: 0.9630\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.4015 - accuracy: 0.9639 - val_loss: 0.3526 - val_accuracy: 0.9630\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3939 - accuracy: 0.9639 - val_loss: 0.3452 - val_accuracy: 0.9630\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3863 - accuracy: 0.9639 - val_loss: 0.3381 - val_accuracy: 0.9630\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.3790 - accuracy: 0.9639 - val_loss: 0.3313 - val_accuracy: 0.9630\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.3715 - accuracy: 0.9639 - val_loss: 0.3248 - val_accuracy: 0.9630\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3647 - accuracy: 0.9639 - val_loss: 0.3185 - val_accuracy: 0.9630\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.3578 - accuracy: 0.9639 - val_loss: 0.3123 - val_accuracy: 0.9630\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 289us/sample - loss: 0.3511 - accuracy: 0.9639 - val_loss: 0.3065 - val_accuracy: 0.9630\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 482us/sample - loss: 0.3446 - accuracy: 0.9639 - val_loss: 0.3007 - val_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 349us/sample - loss: 0.3383 - accuracy: 0.9639 - val_loss: 0.2950 - val_accuracy: 0.9630\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 422us/sample - loss: 0.3321 - accuracy: 0.9759 - val_loss: 0.2894 - val_accuracy: 0.9630\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 410us/sample - loss: 0.3262 - accuracy: 0.9759 - val_loss: 0.2838 - val_accuracy: 0.9630\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 244us/sample - loss: 0.3206 - accuracy: 0.9639 - val_loss: 0.2783 - val_accuracy: 0.9630\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.3146 - accuracy: 0.9639 - val_loss: 0.2734 - val_accuracy: 0.9630\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3090 - accuracy: 0.9759 - val_loss: 0.2688 - val_accuracy: 0.9630\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.3038 - accuracy: 0.9759 - val_loss: 0.2640 - val_accuracy: 0.9630\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2985 - accuracy: 0.9759 - val_loss: 0.2597 - val_accuracy: 0.9630\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2934 - accuracy: 0.9759 - val_loss: 0.2554 - val_accuracy: 0.9630\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2885 - accuracy: 0.9759 - val_loss: 0.2509 - val_accuracy: 0.9630\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2838 - accuracy: 0.9759 - val_loss: 0.2468 - val_accuracy: 0.9630\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2789 - accuracy: 0.9759 - val_loss: 0.2425 - val_accuracy: 0.9630\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2743 - accuracy: 0.9759 - val_loss: 0.2382 - val_accuracy: 0.9630\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2702 - accuracy: 0.9759 - val_loss: 0.2338 - val_accuracy: 0.9630\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2659 - accuracy: 0.9759 - val_loss: 0.2304 - val_accuracy: 0.9630\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2613 - accuracy: 0.9759 - val_loss: 0.2260 - val_accuracy: 0.9630\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2568 - accuracy: 0.9759 - val_loss: 0.2225 - val_accuracy: 0.9630\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 265us/sample - loss: 0.2527 - accuracy: 0.9759 - val_loss: 0.2189 - val_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.2489 - accuracy: 0.9759 - val_loss: 0.2153 - val_accuracy: 0.9630\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2450 - accuracy: 0.9759 - val_loss: 0.2120 - val_accuracy: 0.9630\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2412 - accuracy: 0.9759 - val_loss: 0.2089 - val_accuracy: 0.9630\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2376 - accuracy: 0.9759 - val_loss: 0.2063 - val_accuracy: 0.9630\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2338 - accuracy: 0.9759 - val_loss: 0.2037 - val_accuracy: 0.9630\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2307 - accuracy: 0.9759 - val_loss: 0.2014 - val_accuracy: 0.9630\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2273 - accuracy: 0.9759 - val_loss: 0.1985 - val_accuracy: 0.9630\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2237 - accuracy: 0.9759 - val_loss: 0.1953 - val_accuracy: 0.9630\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.2203 - accuracy: 0.9759 - val_loss: 0.1921 - val_accuracy: 0.9630\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2173 - accuracy: 0.9759 - val_loss: 0.1890 - val_accuracy: 0.9630\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 251us/sample - loss: 0.2140 - accuracy: 0.9759 - val_loss: 0.1864 - val_accuracy: 0.9630\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2109 - accuracy: 0.9759 - val_loss: 0.1838 - val_accuracy: 0.9630\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 229us/sample - loss: 0.2079 - accuracy: 0.9759 - val_loss: 0.1812 - val_accuracy: 0.9630\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.2048 - accuracy: 0.9759 - val_loss: 0.1788 - val_accuracy: 0.9630\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.2020 - accuracy: 0.9759 - val_loss: 0.1764 - val_accuracy: 0.9630\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.1993 - accuracy: 0.9759 - val_loss: 0.1743 - val_accuracy: 0.9630\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.1964 - accuracy: 0.9759 - val_loss: 0.1723 - val_accuracy: 0.9630\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 277us/sample - loss: 0.1938 - accuracy: 0.9759 - val_loss: 0.1700 - val_accuracy: 0.9815\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.1910 - accuracy: 0.9759 - val_loss: 0.1681 - val_accuracy: 0.9815\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 253us/sample - loss: 0.1885 - accuracy: 0.9759 - val_loss: 0.1662 - val_accuracy: 0.9815\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.1860 - accuracy: 0.9759 - val_loss: 0.1646 - val_accuracy: 0.9815\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.1834 - accuracy: 0.9759 - val_loss: 0.1627 - val_accuracy: 0.9815\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 249us/sample - loss: 0.1810 - accuracy: 0.9759 - val_loss: 0.1608 - val_accuracy: 0.9815\n",
      "41/41 [==============================] - 0s 171us/sample - loss: 0.1715 - accuracy: 1.0000\n",
      "Train on 82 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 0s 5ms/sample - loss: 1.0808 - accuracy: 0.4146 - val_loss: 1.1209 - val_accuracy: 0.4074\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.0732 - accuracy: 0.4268 - val_loss: 1.1161 - val_accuracy: 0.3889\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 1.0661 - accuracy: 0.4390 - val_loss: 1.1117 - val_accuracy: 0.3889\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 1.0597 - accuracy: 0.4756 - val_loss: 1.1074 - val_accuracy: 0.3889\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 1.0536 - accuracy: 0.5122 - val_loss: 1.1033 - val_accuracy: 0.4074\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 1.0477 - accuracy: 0.5366 - val_loss: 1.0992 - val_accuracy: 0.4259\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.0426 - accuracy: 0.5610 - val_loss: 1.0955 - val_accuracy: 0.4815\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.0376 - accuracy: 0.5854 - val_loss: 1.0918 - val_accuracy: 0.4444\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 0s 199us/sample - loss: 1.0319 - accuracy: 0.5854 - val_loss: 1.0880 - val_accuracy: 0.4444\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 0s 187us/sample - loss: 1.0269 - accuracy: 0.6220 - val_loss: 1.0842 - val_accuracy: 0.4444\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 1.0224 - accuracy: 0.6220 - val_loss: 1.0804 - val_accuracy: 0.4444\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 1.0177 - accuracy: 0.6220 - val_loss: 1.0766 - val_accuracy: 0.4630\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 0s 188us/sample - loss: 1.0133 - accuracy: 0.6220 - val_loss: 1.0727 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 1.0086 - accuracy: 0.6341 - val_loss: 1.0687 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 1.0044 - accuracy: 0.6463 - val_loss: 1.0648 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 1.0002 - accuracy: 0.6463 - val_loss: 1.0610 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.9956 - accuracy: 0.6463 - val_loss: 1.0568 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 0s 220us/sample - loss: 0.9917 - accuracy: 0.6463 - val_loss: 1.0532 - val_accuracy: 0.5185\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9871 - accuracy: 0.6707 - val_loss: 1.0493 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9835 - accuracy: 0.6707 - val_loss: 1.0456 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.9791 - accuracy: 0.6707 - val_loss: 1.0415 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.9750 - accuracy: 0.6707 - val_loss: 1.0373 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9710 - accuracy: 0.6707 - val_loss: 1.0330 - val_accuracy: 0.5185\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9668 - accuracy: 0.6707 - val_loss: 1.0291 - val_accuracy: 0.5370\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9629 - accuracy: 0.6707 - val_loss: 1.0251 - val_accuracy: 0.5556\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 0s 172us/sample - loss: 0.9588 - accuracy: 0.6707 - val_loss: 1.0211 - val_accuracy: 0.5556\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9550 - accuracy: 0.6707 - val_loss: 1.0175 - val_accuracy: 0.5370\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9508 - accuracy: 0.6707 - val_loss: 1.0136 - val_accuracy: 0.5370\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9468 - accuracy: 0.6707 - val_loss: 1.0095 - val_accuracy: 0.5556\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9427 - accuracy: 0.6707 - val_loss: 1.0054 - val_accuracy: 0.5556\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.9388 - accuracy: 0.6707 - val_loss: 1.0012 - val_accuracy: 0.5741\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9345 - accuracy: 0.6707 - val_loss: 0.9969 - val_accuracy: 0.5741\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9305 - accuracy: 0.6707 - val_loss: 0.9925 - val_accuracy: 0.5741\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9262 - accuracy: 0.6829 - val_loss: 0.9882 - val_accuracy: 0.5741\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.9222 - accuracy: 0.6829 - val_loss: 0.9840 - val_accuracy: 0.5741\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9179 - accuracy: 0.6829 - val_loss: 0.9796 - val_accuracy: 0.5741\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9137 - accuracy: 0.6829 - val_loss: 0.9750 - val_accuracy: 0.5741\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.9095 - accuracy: 0.6829 - val_loss: 0.9705 - val_accuracy: 0.5741\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9053 - accuracy: 0.6829 - val_loss: 0.9661 - val_accuracy: 0.5741\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.9012 - accuracy: 0.6829 - val_loss: 0.9621 - val_accuracy: 0.6111\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8968 - accuracy: 0.6951 - val_loss: 0.9576 - val_accuracy: 0.6111\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8926 - accuracy: 0.6951 - val_loss: 0.9528 - val_accuracy: 0.6111\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8882 - accuracy: 0.6951 - val_loss: 0.9482 - val_accuracy: 0.6111\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.8839 - accuracy: 0.6951 - val_loss: 0.9436 - val_accuracy: 0.6111\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8796 - accuracy: 0.7073 - val_loss: 0.9392 - val_accuracy: 0.6111\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.8753 - accuracy: 0.7073 - val_loss: 0.9347 - val_accuracy: 0.6296\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8709 - accuracy: 0.7195 - val_loss: 0.9302 - val_accuracy: 0.6296\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8665 - accuracy: 0.7195 - val_loss: 0.9254 - val_accuracy: 0.6481\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8620 - accuracy: 0.7195 - val_loss: 0.9209 - val_accuracy: 0.6481\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.8577 - accuracy: 0.7317 - val_loss: 0.9162 - val_accuracy: 0.6481\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8531 - accuracy: 0.7317 - val_loss: 0.9117 - val_accuracy: 0.6481\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8488 - accuracy: 0.7195 - val_loss: 0.9073 - val_accuracy: 0.6481\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8443 - accuracy: 0.7195 - val_loss: 0.9027 - val_accuracy: 0.6481\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 0s 201us/sample - loss: 0.8397 - accuracy: 0.7195 - val_loss: 0.8983 - val_accuracy: 0.6481\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8353 - accuracy: 0.7195 - val_loss: 0.8937 - val_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8310 - accuracy: 0.7195 - val_loss: 0.8887 - val_accuracy: 0.6667\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8264 - accuracy: 0.7195 - val_loss: 0.8842 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8218 - accuracy: 0.7195 - val_loss: 0.8794 - val_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.8172 - accuracy: 0.7195 - val_loss: 0.8748 - val_accuracy: 0.6852\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.8127 - accuracy: 0.7195 - val_loss: 0.8701 - val_accuracy: 0.6852\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.8081 - accuracy: 0.7195 - val_loss: 0.8653 - val_accuracy: 0.6852\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 0s 209us/sample - loss: 0.8035 - accuracy: 0.7195 - val_loss: 0.8601 - val_accuracy: 0.6852\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.7988 - accuracy: 0.7195 - val_loss: 0.8549 - val_accuracy: 0.6852\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.7940 - accuracy: 0.7195 - val_loss: 0.8496 - val_accuracy: 0.6852\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.7894 - accuracy: 0.7195 - val_loss: 0.8443 - val_accuracy: 0.7037\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.7846 - accuracy: 0.7195 - val_loss: 0.8390 - val_accuracy: 0.7037\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 0s 180us/sample - loss: 0.7802 - accuracy: 0.7439 - val_loss: 0.8333 - val_accuracy: 0.7037\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 0s 172us/sample - loss: 0.7754 - accuracy: 0.7561 - val_loss: 0.8280 - val_accuracy: 0.7037\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 0s 199us/sample - loss: 0.7708 - accuracy: 0.7561 - val_loss: 0.8230 - val_accuracy: 0.7222\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.7660 - accuracy: 0.7561 - val_loss: 0.8181 - val_accuracy: 0.7222\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 0s 219us/sample - loss: 0.7613 - accuracy: 0.7561 - val_loss: 0.8133 - val_accuracy: 0.7222\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7566 - accuracy: 0.7561 - val_loss: 0.8085 - val_accuracy: 0.7222\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7518 - accuracy: 0.7805 - val_loss: 0.8035 - val_accuracy: 0.7222\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.7470 - accuracy: 0.7805 - val_loss: 0.7984 - val_accuracy: 0.7222\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7422 - accuracy: 0.7805 - val_loss: 0.7933 - val_accuracy: 0.7407\n",
      "Epoch 76/100\n",
      "82/82 [==============================] - 0s 244us/sample - loss: 0.7374 - accuracy: 0.7805 - val_loss: 0.7885 - val_accuracy: 0.7593\n",
      "Epoch 77/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.7326 - accuracy: 0.7805 - val_loss: 0.7838 - val_accuracy: 0.7593\n",
      "Epoch 78/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.7278 - accuracy: 0.7805 - val_loss: 0.7790 - val_accuracy: 0.7593\n",
      "Epoch 79/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.7229 - accuracy: 0.7927 - val_loss: 0.7740 - val_accuracy: 0.7593\n",
      "Epoch 80/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.7182 - accuracy: 0.7927 - val_loss: 0.7692 - val_accuracy: 0.7593\n",
      "Epoch 81/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.7134 - accuracy: 0.7927 - val_loss: 0.7646 - val_accuracy: 0.7593\n",
      "Epoch 82/100\n",
      "82/82 [==============================] - 0s 256us/sample - loss: 0.7086 - accuracy: 0.8171 - val_loss: 0.7595 - val_accuracy: 0.7593\n",
      "Epoch 83/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.7037 - accuracy: 0.8171 - val_loss: 0.7545 - val_accuracy: 0.7593\n",
      "Epoch 84/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.6989 - accuracy: 0.8171 - val_loss: 0.7495 - val_accuracy: 0.7778\n",
      "Epoch 85/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.6940 - accuracy: 0.8171 - val_loss: 0.7445 - val_accuracy: 0.7778\n",
      "Epoch 86/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.6893 - accuracy: 0.8171 - val_loss: 0.7394 - val_accuracy: 0.7778\n",
      "Epoch 87/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.6845 - accuracy: 0.8293 - val_loss: 0.7349 - val_accuracy: 0.7778\n",
      "Epoch 88/100\n",
      "82/82 [==============================] - 0s 232us/sample - loss: 0.6795 - accuracy: 0.8293 - val_loss: 0.7298 - val_accuracy: 0.7778\n",
      "Epoch 89/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.6747 - accuracy: 0.8293 - val_loss: 0.7247 - val_accuracy: 0.7963\n",
      "Epoch 90/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.6699 - accuracy: 0.8293 - val_loss: 0.7193 - val_accuracy: 0.7963\n",
      "Epoch 91/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.6651 - accuracy: 0.8415 - val_loss: 0.7142 - val_accuracy: 0.7963\n",
      "Epoch 92/100\n",
      "82/82 [==============================] - 0s 206us/sample - loss: 0.6600 - accuracy: 0.8415 - val_loss: 0.7095 - val_accuracy: 0.7963\n",
      "Epoch 93/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.6553 - accuracy: 0.8415 - val_loss: 0.7046 - val_accuracy: 0.7963\n",
      "Epoch 94/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.6505 - accuracy: 0.8537 - val_loss: 0.6994 - val_accuracy: 0.7963\n",
      "Epoch 95/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.6457 - accuracy: 0.8537 - val_loss: 0.6942 - val_accuracy: 0.7963\n",
      "Epoch 96/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.6407 - accuracy: 0.8537 - val_loss: 0.6890 - val_accuracy: 0.7963\n",
      "Epoch 97/100\n",
      "82/82 [==============================] - 0s 207us/sample - loss: 0.6360 - accuracy: 0.8537 - val_loss: 0.6840 - val_accuracy: 0.7963\n",
      "Epoch 98/100\n",
      "82/82 [==============================] - 0s 195us/sample - loss: 0.6311 - accuracy: 0.8659 - val_loss: 0.6788 - val_accuracy: 0.7963\n",
      "Epoch 99/100\n",
      "82/82 [==============================] - 0s 171us/sample - loss: 0.6264 - accuracy: 0.8659 - val_loss: 0.6733 - val_accuracy: 0.7963\n",
      "Epoch 100/100\n",
      "82/82 [==============================] - 0s 183us/sample - loss: 0.6215 - accuracy: 0.8780 - val_loss: 0.6681 - val_accuracy: 0.7963\n",
      "42/42 [==============================] - 0s 119us/sample - loss: 0.7437 - accuracy: 0.6905\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.2489 - accuracy: 0.4096 - val_loss: 1.2050 - val_accuracy: 0.3519\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.2366 - accuracy: 0.4217 - val_loss: 1.1952 - val_accuracy: 0.3889\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 190us/sample - loss: 1.2238 - accuracy: 0.4458 - val_loss: 1.1863 - val_accuracy: 0.3704\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.2127 - accuracy: 0.4699 - val_loss: 1.1776 - val_accuracy: 0.4259\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.2030 - accuracy: 0.4940 - val_loss: 1.1689 - val_accuracy: 0.4444\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.1915 - accuracy: 0.4578 - val_loss: 1.1606 - val_accuracy: 0.4630\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 192us/sample - loss: 1.1821 - accuracy: 0.4578 - val_loss: 1.1526 - val_accuracy: 0.4630\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.1712 - accuracy: 0.4578 - val_loss: 1.1450 - val_accuracy: 0.4815\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 187us/sample - loss: 1.1615 - accuracy: 0.4578 - val_loss: 1.1375 - val_accuracy: 0.4815\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 174us/sample - loss: 1.1514 - accuracy: 0.4458 - val_loss: 1.1304 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.1438 - accuracy: 0.4699 - val_loss: 1.1234 - val_accuracy: 0.5370\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.1349 - accuracy: 0.4578 - val_loss: 1.1167 - val_accuracy: 0.5370\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.1269 - accuracy: 0.4578 - val_loss: 1.1103 - val_accuracy: 0.5185\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.1189 - accuracy: 0.4699 - val_loss: 1.1042 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.1112 - accuracy: 0.4578 - val_loss: 1.0983 - val_accuracy: 0.4444\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.1033 - accuracy: 0.4578 - val_loss: 1.0925 - val_accuracy: 0.4074\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 182us/sample - loss: 1.0969 - accuracy: 0.4578 - val_loss: 1.0870 - val_accuracy: 0.4074\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0892 - accuracy: 0.4458 - val_loss: 1.0815 - val_accuracy: 0.4074\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0827 - accuracy: 0.4578 - val_loss: 1.0762 - val_accuracy: 0.4444\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0763 - accuracy: 0.4458 - val_loss: 1.0711 - val_accuracy: 0.4074\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 1.0697 - accuracy: 0.4578 - val_loss: 1.0662 - val_accuracy: 0.4630\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0640 - accuracy: 0.4217 - val_loss: 1.0613 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0577 - accuracy: 0.3976 - val_loss: 1.0565 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 211us/sample - loss: 1.0519 - accuracy: 0.4578 - val_loss: 1.0517 - val_accuracy: 0.4815\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 1.0462 - accuracy: 0.4819 - val_loss: 1.0474 - val_accuracy: 0.4815\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0406 - accuracy: 0.4940 - val_loss: 1.0430 - val_accuracy: 0.4444\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0353 - accuracy: 0.5181 - val_loss: 1.0385 - val_accuracy: 0.4444\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 1.0300 - accuracy: 0.5181 - val_loss: 1.0340 - val_accuracy: 0.4815\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 191us/sample - loss: 1.0249 - accuracy: 0.5181 - val_loss: 1.0296 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0197 - accuracy: 0.5181 - val_loss: 1.0252 - val_accuracy: 0.5370\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0145 - accuracy: 0.5422 - val_loss: 1.0209 - val_accuracy: 0.5556\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0100 - accuracy: 0.5422 - val_loss: 1.0167 - val_accuracy: 0.5556\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 195us/sample - loss: 1.0049 - accuracy: 0.5542 - val_loss: 1.0125 - val_accuracy: 0.5556\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0003 - accuracy: 0.5542 - val_loss: 1.0082 - val_accuracy: 0.5556\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9952 - accuracy: 0.5904 - val_loss: 1.0036 - val_accuracy: 0.5556\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9904 - accuracy: 0.6265 - val_loss: 0.9992 - val_accuracy: 0.5556\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9857 - accuracy: 0.6386 - val_loss: 0.9947 - val_accuracy: 0.5741\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 155us/sample - loss: 0.9809 - accuracy: 0.6627 - val_loss: 0.9902 - val_accuracy: 0.5741\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 192us/sample - loss: 0.9761 - accuracy: 0.6627 - val_loss: 0.9860 - val_accuracy: 0.5556\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.9715 - accuracy: 0.6867 - val_loss: 0.9819 - val_accuracy: 0.5556\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9668 - accuracy: 0.6867 - val_loss: 0.9779 - val_accuracy: 0.5370\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9619 - accuracy: 0.6988 - val_loss: 0.9737 - val_accuracy: 0.5556\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9571 - accuracy: 0.7229 - val_loss: 0.9695 - val_accuracy: 0.5556\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9525 - accuracy: 0.7229 - val_loss: 0.9652 - val_accuracy: 0.5741\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9477 - accuracy: 0.7349 - val_loss: 0.9609 - val_accuracy: 0.5741\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9431 - accuracy: 0.7349 - val_loss: 0.9567 - val_accuracy: 0.6296\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 157us/sample - loss: 0.9384 - accuracy: 0.7470 - val_loss: 0.9524 - val_accuracy: 0.6296\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.9337 - accuracy: 0.7470 - val_loss: 0.9480 - val_accuracy: 0.6111\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9292 - accuracy: 0.7470 - val_loss: 0.9437 - val_accuracy: 0.6296\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9244 - accuracy: 0.7470 - val_loss: 0.9390 - val_accuracy: 0.6481\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9197 - accuracy: 0.7470 - val_loss: 0.9344 - val_accuracy: 0.6481\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.9150 - accuracy: 0.7470 - val_loss: 0.9298 - val_accuracy: 0.6481\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9103 - accuracy: 0.7590 - val_loss: 0.9253 - val_accuracy: 0.6667\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9057 - accuracy: 0.7590 - val_loss: 0.9206 - val_accuracy: 0.6667\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9010 - accuracy: 0.7590 - val_loss: 0.9161 - val_accuracy: 0.6667\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8961 - accuracy: 0.7590 - val_loss: 0.9112 - val_accuracy: 0.6852\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8915 - accuracy: 0.7711 - val_loss: 0.9063 - val_accuracy: 0.7037\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8868 - accuracy: 0.7711 - val_loss: 0.9016 - val_accuracy: 0.7037\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8818 - accuracy: 0.7952 - val_loss: 0.8970 - val_accuracy: 0.7037\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 177us/sample - loss: 0.8770 - accuracy: 0.7952 - val_loss: 0.8924 - val_accuracy: 0.7222\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8722 - accuracy: 0.7952 - val_loss: 0.8877 - val_accuracy: 0.7222\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8673 - accuracy: 0.7952 - val_loss: 0.8829 - val_accuracy: 0.7222\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8624 - accuracy: 0.7952 - val_loss: 0.8778 - val_accuracy: 0.7222\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8576 - accuracy: 0.8072 - val_loss: 0.8731 - val_accuracy: 0.7222\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8527 - accuracy: 0.8072 - val_loss: 0.8683 - val_accuracy: 0.7407\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8478 - accuracy: 0.8313 - val_loss: 0.8633 - val_accuracy: 0.7593\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8428 - accuracy: 0.8313 - val_loss: 0.8585 - val_accuracy: 0.7593\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8378 - accuracy: 0.8313 - val_loss: 0.8535 - val_accuracy: 0.7963\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8329 - accuracy: 0.8313 - val_loss: 0.8486 - val_accuracy: 0.7963\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8278 - accuracy: 0.8313 - val_loss: 0.8437 - val_accuracy: 0.8148\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8228 - accuracy: 0.8434 - val_loss: 0.8388 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8179 - accuracy: 0.8554 - val_loss: 0.8339 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8127 - accuracy: 0.8554 - val_loss: 0.8287 - val_accuracy: 0.8519\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8077 - accuracy: 0.8554 - val_loss: 0.8237 - val_accuracy: 0.8519\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8030 - accuracy: 0.8554 - val_loss: 0.8185 - val_accuracy: 0.8519\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7975 - accuracy: 0.8675 - val_loss: 0.8135 - val_accuracy: 0.8519\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7925 - accuracy: 0.8675 - val_loss: 0.8086 - val_accuracy: 0.8519\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7874 - accuracy: 0.8675 - val_loss: 0.8035 - val_accuracy: 0.8519\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7823 - accuracy: 0.8675 - val_loss: 0.7985 - val_accuracy: 0.8519\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 187us/sample - loss: 0.7771 - accuracy: 0.8675 - val_loss: 0.7936 - val_accuracy: 0.8519\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7719 - accuracy: 0.8675 - val_loss: 0.7886 - val_accuracy: 0.8519\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7668 - accuracy: 0.8675 - val_loss: 0.7837 - val_accuracy: 0.8519\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7616 - accuracy: 0.8795 - val_loss: 0.7786 - val_accuracy: 0.8519\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7565 - accuracy: 0.8795 - val_loss: 0.7735 - val_accuracy: 0.8519\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7515 - accuracy: 0.8795 - val_loss: 0.7686 - val_accuracy: 0.8519\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7462 - accuracy: 0.8795 - val_loss: 0.7635 - val_accuracy: 0.8519\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7409 - accuracy: 0.8795 - val_loss: 0.7585 - val_accuracy: 0.8519\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 241us/sample - loss: 0.7357 - accuracy: 0.8916 - val_loss: 0.7536 - val_accuracy: 0.8519\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.7304 - accuracy: 0.8916 - val_loss: 0.7489 - val_accuracy: 0.8519\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7251 - accuracy: 0.8916 - val_loss: 0.7444 - val_accuracy: 0.8519\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7201 - accuracy: 0.8795 - val_loss: 0.7401 - val_accuracy: 0.8519\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7150 - accuracy: 0.8795 - val_loss: 0.7358 - val_accuracy: 0.8519\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7100 - accuracy: 0.8795 - val_loss: 0.7311 - val_accuracy: 0.8519\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.7047 - accuracy: 0.8795 - val_loss: 0.7262 - val_accuracy: 0.8519\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6995 - accuracy: 0.8795 - val_loss: 0.7208 - val_accuracy: 0.8519\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6944 - accuracy: 0.8795 - val_loss: 0.7156 - val_accuracy: 0.8519\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6892 - accuracy: 0.8916 - val_loss: 0.7102 - val_accuracy: 0.8519\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6841 - accuracy: 0.9036 - val_loss: 0.7045 - val_accuracy: 0.8889\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6788 - accuracy: 0.9036 - val_loss: 0.6992 - val_accuracy: 0.8889\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.6737 - accuracy: 0.9157 - val_loss: 0.6938 - val_accuracy: 0.9074\n",
      "41/41 [==============================] - 0s 98us/sample - loss: 0.6901 - accuracy: 0.9512\n",
      "Train on 83 samples, validate on 54 samples\n",
      "Epoch 1/100\n",
      "83/83 [==============================] - 0s 4ms/sample - loss: 1.1096 - accuracy: 0.4217 - val_loss: 1.0995 - val_accuracy: 0.4074\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0966 - accuracy: 0.4217 - val_loss: 1.0857 - val_accuracy: 0.4074\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0817 - accuracy: 0.4217 - val_loss: 1.0734 - val_accuracy: 0.4074\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 162us/sample - loss: 1.0709 - accuracy: 0.4217 - val_loss: 1.0618 - val_accuracy: 0.4074\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0617 - accuracy: 0.4217 - val_loss: 1.0510 - val_accuracy: 0.4074\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0499 - accuracy: 0.4217 - val_loss: 1.0414 - val_accuracy: 0.4074\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0415 - accuracy: 0.4217 - val_loss: 1.0322 - val_accuracy: 0.4074\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 1.0333 - accuracy: 0.4337 - val_loss: 1.0237 - val_accuracy: 0.4259\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 1.0263 - accuracy: 0.4458 - val_loss: 1.0158 - val_accuracy: 0.4444\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0177 - accuracy: 0.4578 - val_loss: 1.0086 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 1.0116 - accuracy: 0.5060 - val_loss: 1.0017 - val_accuracy: 0.5185\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 1.0059 - accuracy: 0.5060 - val_loss: 0.9951 - val_accuracy: 0.5741\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.9996 - accuracy: 0.5181 - val_loss: 0.9890 - val_accuracy: 0.5741\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9940 - accuracy: 0.5542 - val_loss: 0.9830 - val_accuracy: 0.5926\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9890 - accuracy: 0.5422 - val_loss: 0.9772 - val_accuracy: 0.6296\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9837 - accuracy: 0.5663 - val_loss: 0.9715 - val_accuracy: 0.6481\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 175us/sample - loss: 0.9789 - accuracy: 0.6024 - val_loss: 0.9659 - val_accuracy: 0.6481\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9736 - accuracy: 0.6265 - val_loss: 0.9604 - val_accuracy: 0.6481\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9689 - accuracy: 0.6265 - val_loss: 0.9549 - val_accuracy: 0.6667\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.9638 - accuracy: 0.6265 - val_loss: 0.9495 - val_accuracy: 0.6852\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9593 - accuracy: 0.6386 - val_loss: 0.9440 - val_accuracy: 0.6852\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9541 - accuracy: 0.6386 - val_loss: 0.9386 - val_accuracy: 0.6852\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9491 - accuracy: 0.6386 - val_loss: 0.9332 - val_accuracy: 0.6852\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9444 - accuracy: 0.6506 - val_loss: 0.9277 - val_accuracy: 0.6852\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9394 - accuracy: 0.6506 - val_loss: 0.9223 - val_accuracy: 0.6852\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.9344 - accuracy: 0.6627 - val_loss: 0.9167 - val_accuracy: 0.6852\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9296 - accuracy: 0.6867 - val_loss: 0.9112 - val_accuracy: 0.7037\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9246 - accuracy: 0.6867 - val_loss: 0.9057 - val_accuracy: 0.7222\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.9198 - accuracy: 0.6867 - val_loss: 0.9002 - val_accuracy: 0.7593\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 180us/sample - loss: 0.9148 - accuracy: 0.6867 - val_loss: 0.8948 - val_accuracy: 0.7593\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.9097 - accuracy: 0.6867 - val_loss: 0.8893 - val_accuracy: 0.7778\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.9047 - accuracy: 0.6867 - val_loss: 0.8838 - val_accuracy: 0.7778\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8999 - accuracy: 0.6867 - val_loss: 0.8782 - val_accuracy: 0.7778\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8946 - accuracy: 0.6867 - val_loss: 0.8726 - val_accuracy: 0.7778\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8895 - accuracy: 0.6867 - val_loss: 0.8670 - val_accuracy: 0.7778\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8845 - accuracy: 0.6867 - val_loss: 0.8613 - val_accuracy: 0.7778\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 200us/sample - loss: 0.8792 - accuracy: 0.6988 - val_loss: 0.8556 - val_accuracy: 0.7778\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8741 - accuracy: 0.6988 - val_loss: 0.8498 - val_accuracy: 0.7778\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8686 - accuracy: 0.6988 - val_loss: 0.8440 - val_accuracy: 0.7778\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 194us/sample - loss: 0.8633 - accuracy: 0.7108 - val_loss: 0.8382 - val_accuracy: 0.7963\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 187us/sample - loss: 0.8579 - accuracy: 0.7108 - val_loss: 0.8323 - val_accuracy: 0.8333\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8527 - accuracy: 0.7108 - val_loss: 0.8264 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8473 - accuracy: 0.7108 - val_loss: 0.8204 - val_accuracy: 0.8519\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8420 - accuracy: 0.7108 - val_loss: 0.8145 - val_accuracy: 0.8519\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8366 - accuracy: 0.7108 - val_loss: 0.8085 - val_accuracy: 0.8704\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8308 - accuracy: 0.7108 - val_loss: 0.8026 - val_accuracy: 0.8889\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8253 - accuracy: 0.7108 - val_loss: 0.7965 - val_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.8199 - accuracy: 0.7590 - val_loss: 0.7904 - val_accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.8141 - accuracy: 0.7711 - val_loss: 0.7844 - val_accuracy: 0.8889\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.8085 - accuracy: 0.7711 - val_loss: 0.7783 - val_accuracy: 0.8889\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 205us/sample - loss: 0.8029 - accuracy: 0.7831 - val_loss: 0.7722 - val_accuracy: 0.8889\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7973 - accuracy: 0.7952 - val_loss: 0.7660 - val_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7914 - accuracy: 0.7952 - val_loss: 0.7597 - val_accuracy: 0.8889\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7858 - accuracy: 0.7952 - val_loss: 0.7533 - val_accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7798 - accuracy: 0.7952 - val_loss: 0.7471 - val_accuracy: 0.8889\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7738 - accuracy: 0.8193 - val_loss: 0.7407 - val_accuracy: 0.8889\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7680 - accuracy: 0.8193 - val_loss: 0.7342 - val_accuracy: 0.8889\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7620 - accuracy: 0.8193 - val_loss: 0.7278 - val_accuracy: 0.8889\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.7560 - accuracy: 0.8313 - val_loss: 0.7214 - val_accuracy: 0.8889\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 166us/sample - loss: 0.7499 - accuracy: 0.8313 - val_loss: 0.7149 - val_accuracy: 0.8889\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7439 - accuracy: 0.8434 - val_loss: 0.7084 - val_accuracy: 0.8889\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7377 - accuracy: 0.8554 - val_loss: 0.7019 - val_accuracy: 0.8704\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.7318 - accuracy: 0.8554 - val_loss: 0.6953 - val_accuracy: 0.8889\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7256 - accuracy: 0.8554 - val_loss: 0.6888 - val_accuracy: 0.8889\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7194 - accuracy: 0.8554 - val_loss: 0.6823 - val_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7132 - accuracy: 0.8554 - val_loss: 0.6759 - val_accuracy: 0.8889\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7073 - accuracy: 0.8554 - val_loss: 0.6695 - val_accuracy: 0.9074\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.7014 - accuracy: 0.8916 - val_loss: 0.6630 - val_accuracy: 0.9074\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6950 - accuracy: 0.8916 - val_loss: 0.6567 - val_accuracy: 0.9074\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 167us/sample - loss: 0.6890 - accuracy: 0.8916 - val_loss: 0.6504 - val_accuracy: 0.9074\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 175us/sample - loss: 0.6829 - accuracy: 0.8916 - val_loss: 0.6440 - val_accuracy: 0.9074\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 225us/sample - loss: 0.6771 - accuracy: 0.8916 - val_loss: 0.6377 - val_accuracy: 0.9074\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6708 - accuracy: 0.8916 - val_loss: 0.6313 - val_accuracy: 0.9074\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6647 - accuracy: 0.8916 - val_loss: 0.6249 - val_accuracy: 0.9074\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6587 - accuracy: 0.8916 - val_loss: 0.6186 - val_accuracy: 0.9259\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6525 - accuracy: 0.8916 - val_loss: 0.6123 - val_accuracy: 0.9259\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.6465 - accuracy: 0.9036 - val_loss: 0.6061 - val_accuracy: 0.9259\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 217us/sample - loss: 0.6403 - accuracy: 0.9036 - val_loss: 0.5998 - val_accuracy: 0.9259\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6349 - accuracy: 0.9036 - val_loss: 0.5936 - val_accuracy: 0.9259\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6286 - accuracy: 0.9277 - val_loss: 0.5875 - val_accuracy: 0.9259\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.6226 - accuracy: 0.9277 - val_loss: 0.5815 - val_accuracy: 0.9259\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.6166 - accuracy: 0.9277 - val_loss: 0.5755 - val_accuracy: 0.9259\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 167us/sample - loss: 0.6107 - accuracy: 0.9277 - val_loss: 0.5695 - val_accuracy: 0.9259\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.6049 - accuracy: 0.9277 - val_loss: 0.5635 - val_accuracy: 0.9259\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5992 - accuracy: 0.9277 - val_loss: 0.5576 - val_accuracy: 0.9259\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5932 - accuracy: 0.9277 - val_loss: 0.5518 - val_accuracy: 0.9444\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5877 - accuracy: 0.9518 - val_loss: 0.5461 - val_accuracy: 0.9444\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5820 - accuracy: 0.9518 - val_loss: 0.5404 - val_accuracy: 0.9444\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 173us/sample - loss: 0.5761 - accuracy: 0.9518 - val_loss: 0.5347 - val_accuracy: 0.9444\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5708 - accuracy: 0.9398 - val_loss: 0.5291 - val_accuracy: 0.9444\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5651 - accuracy: 0.9398 - val_loss: 0.5234 - val_accuracy: 0.9444\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5597 - accuracy: 0.9398 - val_loss: 0.5179 - val_accuracy: 0.9444\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5543 - accuracy: 0.9398 - val_loss: 0.5124 - val_accuracy: 0.9444\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5489 - accuracy: 0.9398 - val_loss: 0.5070 - val_accuracy: 0.9444\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 169us/sample - loss: 0.5437 - accuracy: 0.9398 - val_loss: 0.5017 - val_accuracy: 0.9444\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 174us/sample - loss: 0.5384 - accuracy: 0.9398 - val_loss: 0.4967 - val_accuracy: 0.9444\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 193us/sample - loss: 0.5330 - accuracy: 0.9398 - val_loss: 0.4916 - val_accuracy: 0.9444\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5278 - accuracy: 0.9518 - val_loss: 0.4866 - val_accuracy: 0.9444\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 181us/sample - loss: 0.5228 - accuracy: 0.9518 - val_loss: 0.4817 - val_accuracy: 0.9444\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 195us/sample - loss: 0.5178 - accuracy: 0.9518 - val_loss: 0.4767 - val_accuracy: 0.9444\n",
      "41/41 [==============================] - 0s 146us/sample - loss: 0.5008 - accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x0000020D6604FF28>, as the constructor either does not set or modifies parameter n_neurons",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-65161b064097>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#sklearn 0.21에서는 아래가 돌아가나, 내가 가진 버전은 0.22 이다. 그래서 좀 손봐야함.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m search_cv.fit(x_train,y_train,\n\u001b[1;32m----> 3\u001b[1;33m               validation_data=(x_test,y_test))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\82104\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    736\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 738\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\82104\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     80\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     81\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x0000020D6604FF28>, as the constructor either does not set or modifies parameter n_neurons"
     ]
    }
   ],
   "source": [
    "#sklearn 0.21에서는 아래가 돌아가나, 내가 가진 버전은 0.22 이다. 결국...미해결\n",
    "search_cv.fit(x_train,y_train,\n",
    "              validation_data=(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neurons': 21}\n",
      "0.43263646960258484\n"
     ]
    }
   ],
   "source": [
    "print(search_cv.best_params_) \n",
    "print(search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-902bd1bad03f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;31m# save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "model = search_cv.best_estimator_.model # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"loss:\",result[0]) # 0.1158\n",
    "print(\"accuracy:\",result[1]) # 0.9815\n",
    "#===== 1개 은닉층을 갖는 신경망 모형의 은닉노드 개수 결정 (end)  =====#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== 위와 동일한 결과인지 확인하기 =====#\n",
    "model_con = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(37,activation=\"tanh\",input_shape=[13]),\n",
    "        tf.keras.layers.Dense(3,activation=\"softmax\")\n",
    "        ])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_con.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_cv = RandomizedSearchCV(keras_class,para_distribs,n_iter=10,cv=3)\n",
    "# hyper parameter의 공간이 커지면 RandomizedSearchCV를 쓰는게 좋음.\n",
    "# 3 fold cv로 , n_iter은 parameters가 셈플링 되는 수. 1\n",
    "# 우리는 40개중 10개만 셈플링해서 보는중.\n",
    "# 자세한건 아래의 Reference 참고\n",
    "\n",
    "\n",
    "################################ 아래는 미해결 ##########################\n",
    "# 오류가 발생하는데, 해결을 못했다. 다만, 뭘 하려고하는지는 이해완료.\n",
    "\n",
    "# search_cv.fit(x_train,y_train,epochs=100,\n",
    "#               validation_data=(x_test,y_test),\n",
    "#               callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
    "# \n",
    "# search_cv.best_params_ \n",
    "# search_cv.best_score_ \n",
    "# model = search_cv.best_estimator_.model # save model\n",
    "# \n",
    "# model.fit(x_train, y_train, epochs=100)\n",
    "# result = model.evaluate(x_test,y_test)\n",
    "# \n",
    "# print(\"loss:\",result[0]) # 0.1158\n",
    "# print(\"accuracy:\",result[1]) # 0.9815\n",
    "# #===== 1개 은닉층을 갖는 신경망 모형의 은닉노드 개수 결정 (end)  =====#\n",
    "# \n",
    "# #===== 위와 동일한 결과인지 확인하기 =====#\n",
    "# model_con = tf.keras.models.Sequential([\n",
    "#         tf.keras.layers.Dense(37,activation=\"tanh\",input_shape=[13]),\n",
    "#         tf.keras.layers.Dense(3,activation=\"softmax\")\n",
    "#         ])\n",
    "#     \n",
    "# model_con.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "# model_con.summary()\n",
    "# model_con.fit(x_train, y_train, epochs=100)\n",
    "# model_con.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example 1-3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "참고교재: 텐서플로로 배우는 딥러닝 (박혜정, 석경하, 심주용, 황창하 공저)\n",
    "\n",
    "예제 1-3. UCI 기계학습 저장소에 있는 Boston 집값 데이터를 활용하여 \n",
    "집값(MEDV)을 출력변수로 하는 신경망 회귀모형을 생성하여 검증용 자료에 회귀모형의 \n",
    "성능을 평가하시오. 평가는 housing 데이터 중 훈련자료 70%와 검정자료 30%로 \n",
    "분할하여 검정하시오(random.state=200으로 고정).\n",
    "\"\"\"\n",
    "\n",
    "# 변수명 설정\n",
    "boston_name = [\"CRIM\",\"ZN\",\"INDUS\",\n",
    "          \"CHAS\",\"NOX\",\"RM\",\"AGE\",\"DIS\",\n",
    "          \"RAD\",\"TAX\",\"PTRATIO\",    \n",
    "          \"B\", \"LSTAT\", \"MEDV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 불러오기\n",
    "boston = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\",\n",
    "     header=None, sep=\"\\s+\", names=boston_name, na_values=[\"NA\", \"null\", \"\"])\n",
    "# \"\\s+\" 는 정규표현식으로, 공백이 하나 이상인 경우를 구분자로 지으라는 뜻."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      "CRIM       506 non-null float64\n",
      "ZN         506 non-null float64\n",
      "INDUS      506 non-null float64\n",
      "CHAS       506 non-null int64\n",
      "NOX        506 non-null float64\n",
      "RM         506 non-null float64\n",
      "AGE        506 non-null float64\n",
      "DIS        506 non-null float64\n",
      "RAD        506 non-null int64\n",
      "TAX        506 non-null float64\n",
      "PTRATIO    506 non-null float64\n",
      "B          506 non-null float64\n",
      "LSTAT      506 non-null float64\n",
      "MEDV       506 non-null float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677082</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       float64\n",
       "ZN         float64\n",
       "INDUS      float64\n",
       "CHAS         int64\n",
       "NOX        float64\n",
       "RM         float64\n",
       "AGE        float64\n",
       "DIS        float64\n",
       "RAD          int64\n",
       "TAX        float64\n",
       "PTRATIO    float64\n",
       "B          float64\n",
       "LSTAT      float64\n",
       "MEDV       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측값 제거\n",
    "pd.isnull(boston).sum()\n",
    "boston1 = boston.dropna()\n",
    "boston1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종속변수 설정\n",
    "y4 = boston1[\"MEDV\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(boston1[boston_name[0:-1]], y4, test_size=0.3, random_state=200)\n",
    "# boston_name[0:-1] 은 0부터 -1번째 전까지 불러오라는뜻. -1번째란, 뒤에서 첫번째를 뜻함.\n",
    "# 즉, 0이상 -1번째 미만."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax4 = MinMaxScaler()\n",
    "x_train4 = minmax4.fit_transform(x_train4)\n",
    "x_test4 = minmax4.transform(x_test4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model4(n_hidden=1,n_neurons=30,input_shape=[x_train4.shape[1]]):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    options = {\"input_shape\":input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons,activation=\"relu\",**options))\n",
    "        options={}\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(loss=\"mse\",optimizer=tf.keras.optimizers.RMSprop(0.001),metrics=[\"mae\",\"mse\"])\n",
    "    return model\n",
    "\n",
    "# **options 는 키워드 파라미터이다. \n",
    "# 위에서는 후에 options={}로 초기화 시켜서 사용했다.\n",
    "# 이런것도 있다고 알아두기.\n",
    "# 측도로 MAE 와 MSE를 사용하였으며, Adam에서 RMSprop를 사용함을 확인하기.\n",
    "# loss로도 MSE를 사용.\n",
    "\n",
    "#아래의 Reference 를 참고하면 더 자세히 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "para4={\n",
    "      \"n_hidden\":np.arange(1,10),\n",
    "      \"n_neurons\":np.arange(1,100)\n",
    "      }\n",
    "\n",
    "#조합은 천개."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_class4 = tf.keras.wrappers.scikit_learn.KerasRegressor(build_model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cv4_1 = RandomizedSearchCV(keras_class4,para4,n_iter=10,cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#역시나, 이후의 작업들이 되지 않는다... \n",
    "\n",
    "# search_cv4_1.fit(x_train4,y_train4,epochs=100,\n",
    "#               validation_data=(x_test4,y_test4),\n",
    "#               callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "# search_cv4_1.best_params_ # 5hidden 70 neuron\n",
    "# search_cv4_1.best_score_\n",
    "# model4_1 = search_cv4_1.best_estimator_.model\n",
    "\n",
    "# # 검정용 데이터 적용\n",
    "# pred4_1 = model4_1.predict(x_test4)\n",
    "# result4_1 = model4_1.evaluate(x_test4, y_test4)\n",
    "# print(\"MSE:\",result4_1[0]) # 18.88\n",
    "# print(\"MAE:\",result4_1[1]) # 3.11\n",
    "\n",
    "\n",
    "## 한 번 더  \n",
    "## randomized이기 때문에 돌릴때마다 달라짐. 일부의 조합만 봤기 때문.\n",
    "## 이 경우 10개의 조합만 살펴본 셈이다.\n",
    "\n",
    "# search_cv4_2 = RandomizedSearchCV(keras_class4,para4,n_iter=10,cv=3)\n",
    "# search_cv4_2.fit(x_train4,y_train4,epochs=100,\n",
    "#               validation_data=(x_test4,y_test4),\n",
    "#               callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
    "\n",
    "# search_cv4_2.best_params_ # 6hidden 36 neuron\n",
    "# model4_2 = search_cv4_2.best_estimator_.model\n",
    "\n",
    "# # 검정용 데이터 적용\n",
    "# pred4_2 = model4_2.predict(x_test4)\n",
    "# result4_2 = model4_2.evaluate(x_test4, y_test4)\n",
    "# print(\"MSE:\",result4_2[0])\n",
    "# print(\"MAE:\",result4_2[1])\n",
    "\n",
    "#달라진 결과값 확인."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reference\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "- [Keyword Parameter](https://wikidocs.net/24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

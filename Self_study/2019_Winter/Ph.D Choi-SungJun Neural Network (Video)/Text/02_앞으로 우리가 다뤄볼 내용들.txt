딥러닝, 기계학습, advanced topic인 논문들에 대해 이야기 해보겠다.
김성훈교수님 강의를 듣고오면 굉장히 도움이 되리라 생각함.
아래의 내용들을 전반적으로 다룰 것이다.

1. 다양한 CNN모형을 우선적으로 보려고 한다.

2. Regularization에 대해서도 알아볼 것이다.
특히 이 규제화는 머신러닝 전반적인 분야에서 쓰이므로, 굉장히 중요하다. 
Overfitting을 방지하는 목적으로 사용된다.

3. Optimization Methods
학습할 때 Momentum, AdaGrad, AdaDelta , ADAM 등에 대해 알아보려고 함.

4. RBM에 대해서도 알아보려고 한다. 비지도학습법이다. 
그러나 지금 사람들이 많이 사용하지는 않긴 하다.

5. Denoising Auto-Encoder
노이즈가 있는데이터에서 노이즈가 없는 데이터로 재구성해서 보여준다.

6. Semantic Segmentation
어떤 이미지가 들어오면 각 픽셀별로 그게 뜻하는게 무엇인지 맞추는 알고리즘

7. Weakly-Supervised Localization
Semantic Segmentation과 굉장히 비슷하다. 
이미지가 들어오면 그 이미지에서 각 픽셀들이 어떤 클래스에 속하는지를 알 수 있게 된다.
Semantic Segmentation과의 차이점은 다음과 같다.
Semantic Segmentation는 이미지 각 픽셀이 어떤 label(하늘이면 하늘, 도로면 도로)을 가지고 있는지 알고 있어야함.
다만 Weakly-Supervised Localization는 이미지와 이 이미지 전체에 해당하는 클래스 정보만 알고 있으면 된다. 
금붕어 사진을 예로들면 금붕어 사진이라는 사실이 중요하지, 
금붕어가 왼쪽에 있는지 오른쪽에 있는지에 대한 사실은 알 필요가 없다. 
그럼에도 불구하고 금붕어가 이미지에 어디에 있는지를 알 수 있게 된다.

8. Detection
Detection은 굉장히 많은 방법들이 있다. 2시간 넘게 10편이 넘는 논문들을 자세히 볼거임.
딥러닝의 시작이 됐던 R-CNN부터 SPPnet , Fast R-CNN, Faster R-CNN을 볼거임.
Detection이란, 이미지가 주어지면 그 이미지의 위치를 찾는거임. 
Semantic Segmentation과 굉장히 비슷함. 
다만 Semantic Segmentation는 픽셀단위, 
Detection은 이미지안의 물체에 'bounding box'를 만들어줌으로써 Detection을 하게 된다.

9. RNN - LSTM
RNN - LSTM에 대해 이야기 할거임. 이 구조가 어떤지를 알아보고 어떻게 동작되는지를 알아볼거임.
(GRU는 개인적으로 공부함)

10. Visual Q&A
앞과의 차이점은, 앞에서는 이미지에 대한 정보만 다룬다. 
예를들면 이미지를 분류하고, 이미지안에서 물체가 어딨는지 찾고, RNN을 이용해서 시계열데이터, 연속형 데이터를 처리만했다.
Visual Q&A는 사진과 문장이 같이 들어간다. 
테니스 사진을 주고, 그 사진과 관련된 질문을 하나준다.(ex. 무슨 스포츠를 하고있는가?) 
이를 통해서 정답을 찾게되는 알고리즘이다.

11. Super Resolution
저해상도 이미지가 들어왔을때 고해상도 이미지를 찾는 알고리즘.(?) 간단히만 다룰 예정

12. Deep Reinforcement Learning
딥러닝 기법들이 고전적인 강화학습과 섞이면서 할 수 없었던 문제들을 풀 수 있게 되었다. 
그 예로, 비디오로 하는 게임들을 풀게 되는데, 
Raw 비디오 input을 그대로 받아 조이스틱을 어떻게 움직이게 되는지를 풀게되는 알고리즘을 강화학습을 통해 구현할 수 있다.
우리는 가장 기본이 되는 강화학습, DQN 알고리즘에 대해서 알아보려고 한다.

13. Sequence Generation
앞에서 봤던 주어진 데이터를 어떻게 해석하고 분류할까에 대한 토픽이었다면, 
이번엔 어떤 새로운 것을 직접 만들어보려고 한다.
우리는 그중에 특히 손글씨들을 어떻게 처리할수 있는지에 대해 알아보려고 한다.

14. Word Embedding
단어를 어떻게 하면 해석하게 쉬운, 컴퓨터가 이해하기 쉬운 숫자들로 옮길 수 있는지에 대한 알고리즘을 알아볼 것이다.

15. Image Captioning
이미지가 주어지면 그 이미지를 설명하는 문장을 만들어내는 알고리즘. 

16. Hangul-RNN
우리가 한국인이니까, 한국말을 어떻게 처리할 수 있는지에 대해 알아볼 것이다.
한국말이 영어에 비해 가지는 복잡도가 있으므로, 그걸 어떻게 처리하는지를 알아볼 것이다. 
대표적인 예로 구운몽을 가지고 학습한 모형이 구운몽을 써보는 RNN을 만들어보려고 한다.

17. Residual Network & Analyses
bottleneck architecture라는 것에 대해, 즉 Resnet구조를 알아보고,
그 구조가 왜 잘 작동되는지에 대해 알아볼 것이다.

18. Neural Style
사진을 주면 수진을 고흐풍, 피카소풍으로 바꾸는 방법론들에 대해 알아볼 것이다.
2가지 논문 (Texture Synsthesis Using Convolutional Neural Networks NIPS2015 와
Understanding Deep Image Representations by Inverting Them CVPR2015)을 잘 섞은게 Neural Style임.

19. GAN
이 분야가 현재 연구되는 딥러닝 분야에서 가장 핫한분야. 
논문이 활발하게 만들어지고 있음. 2014년 Ian Goodfellow가 처음 제안.
어떻게 발전되고 있는지를 알아볼 것이다.
이미지 captioning을 반대로 하는것. 
문장을 보고 문장에 해당하는 이미지를 만들어내게 된다.
또는 모델이 옷을 입고있는 착용샷을 볼때, 옷만 끄집어 내는 기술에 대해서도 알아볼 것이다.

20. Basic Python
기본적인 파이썬 코드는 굉장히 많이 다룰것이며,

21. Mnist dataset
굉장히 많이 다룰 것이다.

22. TensorFlow
TensorFlow를 다룰것이다.

23. Logistic Reg. & MLP 
가장 기본적인 Logistic Reg. 을 알아보고 MLP를 알아본다.

24. Generating Own Datasets
데이터 셋이 label별로 모여있으면 그 데이터들 별로 분류기를 학습시키는 방법을 알아볼 것이다.

28. Word2vec 
단어를 숫자로 바꾸는 알고리즘 해볼것이다.

(28-29 사이에있는 주제에서 많은 내용들이 나왔지만 다 적지 않았음.)
그밖에 여러가지 주제들을 다뤄볼 내용이다.

29. One-Shot Learning
우리가 NN에 가장 큰 단점은, 새로운 데이터를 처리하기 힘들다.
어떤 분류기가 있을 때 새로운 클래스를 추가하면 그 클래스에 해당하는 학습데이터를 집어놓고, 학습을 처음부터 다시 해야함.
이렇게 하는것 대신에, 주어졌던 데이터를 어떻게 하면 빠르게 학습시키고 넘길 수 있는지에 대해 알아본다.

30. Domain Adaptation
우리가 Input과 Output을 둘다 잘 얻을 수 있는 공간에서 학습을 시키고,
target공간에서는 입력만 주어졌을 때 이미지들이 이 공간에 있다고 가정하면
이 traget공간에서 어떻게 분류를 잘 할수 있을지에 대한 내용.

31. Metric Learning
두개의 이미지가 주어졌을 때, 그 두개의 이미지의 거리를 나타내는게 Metric Learning.
그 거리를 어떻게 잘 학습할 수 있을 지에 대한 내용.

32. Memory Network
Deep mind에서 나온 논문으로 컴퓨터를 굉장히 따라한 논문이다. 
NN으로 만들었으며, 컴퓨터 구조는 어떤 입력이 들어오면 메모리에 접근할 수 있고
그 메모리에서부터 특정 정보를 빼올수 있고, 새로운 정보를 그 메모리에 집어넣을 수도 있다.
그래서 메모리에 쓰고 메모리로부터 읽어오는 구조를 NN으로 만든게 
2016 Hybrid computing using a neural network with dynamic external memory임. 
메모리 네트워크에 속함.

33. Uncertainty in Neural Networks
우리가 딥러닝이 있을때 잘 된다는건 안다. 
예를들어 Semantic Segmentation 있을 때, 이미지를 잘 분류할 수 있으리란 사실은 안다. 
그러나 항상 잘 하는건 아닐것이다. 내가 보지못한 입력이 들어오면 잘 못 맞출수도있다.
그러면 그때 NN이 잘 확실하지 않은 정보(Uncertainty)를 같이 구별하면 좋을텐데, 
일반적인 NN은 잘 확실하지 않은 정보를 구별하지 못한다.
어떻게 하면 NN이 분류 output을 뱉음과 동시에 얼마나 예측을 잘하는지 알게되는 모형을 알아볼 것이다.




기계 학습 용어 정리
Input Data, Output Data, Neural Net등 이 뭔지에 대해 알아보자.

NN이란, 
연결이 되어있는 어떠한 구조를 통칭함.

Input Data
입력받는 데이터이며, 기본적으로 숫자임.

Output Data
결과로 나오는 데이터. 

Class = Label
분류의 경우에 속하는 집단.

one-hot coding
하나만 1이고, 나머지는 0인 벡터. 어떠한 클래스를 숫자로 표현하여 할당.

Training / Learning
학습을 하는 과정을 말함. 모델링한 구조를 데이터를 입력하여 잘 적용될수 있게끔 함.

Training Data - 학습에 사용하는 데이터
Validataion Data - 학습에 사용하는 데이터 : 하이퍼 파라미터를 잡을때 사용하는데이터
Test Data - 모형을 만들때 절대로 개입해서는 안됨.
Cross Validation - Validation data도 train에 개입시켜 데이터를 날리지 않게 하려는 방법. 
그렇게 초모수들이 결정된다면, 전체 데이터(Training+Validation)로 다시 학습을 최종적으로 시킨다.

MLP ( = dense layer = fully connected)
매 layer마다 행렬을 곱하고 activation function을 통과시키는 모든것을 이야기함.

activation function의 역할 
비선형성을 주기위함. 층을 여러개 쌓을때 중요해진다.
여러층을 나눈 뒤 아무리 가중치를 주고 편차를 주는것만으로 끝낸다면, 
그건결국 한개짜리 층과 다를게 없어진다.
결국, 형태가 비선형이기만 하면 됨.

sigmoid -> 0에서 1로 떨굴때 (확률)
tanh : -1 ~ 1 -> 알파고에 들어가는 네트워크처럼 단계별 결과치가 음수가 필요하는 상황이 있을 수 있음.
ReLu -> 일반적인 분류에서 엄청난 성능을 보임.
softplus-> 회귀분석시 나름 장점을 갖는다고 알려져있음.

Epoch
전체 데이터를 한번 다 사용했을 때 까지의 단위. 상당히 큰 단위이다.
데이터가 2천만개이면, 2천만개 데이터를 전체 다 말한다.
Batch Size
그러나 우리는 2천만개를 한꺼번에 학습을 시킬 수 없으므로, 일정한 단위를 나눠 학습한다.
즉, 한번 gradient를 구할때 사용하는 데이터의 크기이다.
Iteration
1Epoch를 위한 Batch Size 반복수. 즉, 전체 데이터를 Batch Size로 나눈 값이다.

Cost function
우리가 줄이고자 하는 함수. 이게 줄어들었을 때, 내가 원하는 현상이 일어남.
Cost function 종류는 여러개이다. 
남들 따라서 항상 같은 Cost function을 쓰는것이 아닌 다른것을 쓰려고 고민해야한다.
또한 미분 가능해야 하며(미분 불가능할 시 back propagation이 안됨.), convex여야 한다.
만약 미분이 안되면, 강화학습 알고리즘을 사용할 수 있음. 그러면 학습은 여전히 가능.
자연어 처리에서는 강화학습을 계속 사용함.

MNIST
우리가 계속해서 보게될 dataset
28X28이 있고, 흑백이미지이다. 숫자 dataset이다.



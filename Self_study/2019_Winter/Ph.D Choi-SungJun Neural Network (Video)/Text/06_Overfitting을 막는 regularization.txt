Regularization에 대해 알아보자.
딥러닝에 대한 이야기가 아닌, 머신러닝 전반적인 분야에서 적용되므로 잘 이해하자.

Regularization?
목적 : Overfitting을 막는 방법을 말한다.

그러면 Overfitting이란 무엇인가?
학습데이터를 너무 믿는것을 의미한다. 
학습데이터를 너무 믿는 나머지, 테스트 데이터를 못맞추는 것을 의미함.

이는 회귀 문제에서도 동일하게 적용된다.
데이터들을 다 지나는, 완벽한 곡선을 가질 수 있지만
새로운 데이터가 들어올 때 의미가 없게 된다.

기본적으로 Training Error가 줄어드는 것은 문제가 되지 않는다.
Training Error와 Test의 Error의 차이가 중요함. 
그렇다고, 10차함수 fitting이 2차함수 fitting보다 무조건 나쁘다는게 아님.

오버피팅은 노이즈 때문에 일어나는거임. 
그렇지만, 노이즈가 없는 데이터는 세상에 없음.
그러므로 늘 조심해야 하는 주제.

우리가 잘 생각하는 Test Error, Train Error의 그래프를 생각해보자.
in-sample error : Training Error (위쪽으로 곡선이 생성)
out-of-sample error : Test Error (아래쪽으로 곡선이 생성)
이 둘의 차 : Generalization Performance
즉, Generalization Performance이 작게 되는것이 중요하다.
주의 해야할 점은 그래프에서 x축은 모형복잡도임. 이를 꼭 인지하자.
(참고로 y축은 Error)

그렇다면, Preventing Overfitting?
1. 데이터를 많이 얻는다.
2. 제대로 담을 수 있는 모형을 갖춘다.
3. 앙상블 모형을 사용한다. (Voting기법)
4. 그리고 나서, 세부적으로 DropOut, DropConnect, BatchNorm 등의 방법을 사용한다.

Early Stopping : Training Error가 올라가는 기점을 기준으로 끊어버리는거임.
Weight-decay : 어떤 모형의 학습 파라미터를 너무 크게 하지 않기위해 하는 방법.
(ex. L_1 , L_2 정규화)
DropOut : 한 레이어가 있을 때, 그 안의 노드를 꺼버리는거임. 
(training할때만 끔. )
DropConnect : dropout과 유사. 다만, 노드를 끄는것이 아닌 weight를 끔.
(혹은 0으로 바꿔놓는다는지)
Batch Normalization : 굉장히 중요. 그냥 웬만한 문제에서 다 쓰면됨.
한 배치안에 들어간 데이터들을 표준화 시키는거임.

BN의 이점.
1. learning rate를 늘릴수있다.(발산하는 문제를 해결함)
(internal covariate shift를 줄일 수 있게 됨.)
-> 학습을 빨리할 수 있음.
2. DropOut을 안써도 됨.
3. L2 규제화를 줄일수 있음.
4. Accelerate learning rate decay. (스탭을 진행할 때마다 걸음폭을 줄이는게 가속화됨)
5. LRN을 안써도 잘된다.
즉, BN만 있어도 잘됨.

결론 :
overfitting 은 어떤 문제를 풀든 발생하기 때문에 regularization 을 반드시 고려할 것.
어떤 Regularization을 쓸 것인지에 대한건 감이 필요하다. 노하우가 필요함.

-------------------------------------------------------------------------------------
이어서,
Ian Goodfellow가 쓴 책 중에 regularization 파트로 다음과 같은 하위 항목들이 있음.
1. Parameter Norm Penalties
2. Dataset Augmentation
3. Noise Robustness : to input, weights, and output
4. Semi-Supervised Learning = learning a representation
5. Multitask Learning
6. Early Stopping
7. Parameter Tying and Parameter Sharing
8. Sparse Representation
9. Bagging and Other Ensemble Methods
10. DropOut
11. Adversarial Training
하나씩 알아보자.

1. Parameter Norm Penalties
L_1, L_2 규제화에 대한 이야기.
제곱합을 더하거나, 절대값의 합을 더한느 형태를 취함. 잘 알기에 생략

2. Dataset Augmentation
Ian Goodfellow 왈, 최고의 머신러닝 모형을 만드는것은 데이터를 많이 쓰는것.
하지만, 데이터는 한계가 있고 이를 보완하는 방법은 가짜데이터를 늘려서 Training Dataset으로 쓰는것.
label을 바꾸지 않으면서 Transforming을 하는것.
노이즈를 주는것이 하나의 방법이 될 수 있음.
또는, 좌우반전이나 RGB값의 어떤 값의 노이즈를 추가해 변화시키든지,
sub-sampling으로도 해결한다든지,
GAN 구조를 통해 시뮬레이션 눈(가짜눈)을 만들고 얻은 가짜사진을
실제 사진으로 바꿔서 데이터를 추가시키니 performance가 더 뛰어나짐.
즉, GAN을 이용해서 데이터 증대를 할 수 있음.

3. Noise Robustness
일반적으로 hidden layer의 node에 추가 Noise를 주는것이 
단순히 parameters를 shrinking하는 것보다 더 강력할 수 있다는 뜻.

쉽게 dropout은 node를 0으로 바꾸는것인데 이 대신에 노이즈를 주는게
좀 덜 엄격한 방법임. 
더불어서, weight 자체에도 조금 noise를 줄 수 있음. 마친 dropconnect 대신하듯.

그리고 label-smoothing도 해줌. 
대부분의 데이터셋의 실수로 y label을 명확히 갖고 있다는 점임.
우리가 classification 문제를 풀 때 label을 (1,0,0)로 주는게 아닌
(0.8, 0.1 , 0.1) 로 주게 되는 행위를 말함.

4. Semi-Supervised Learning
suprervised learning과 unsupervised learning을 합친것.
딥러닝에 있어서 만큼은 semi-supervised learning은 representation을 학습하는걸 얘기함.
CNN을 예로들면, convolution과 subsampling을 반복하므로써 feature extraction을 진행한다.
이게 일종의 representation을 찾는 행위임. 이미지에서 유용한 feature을 찾는거임.
CNN의 경우, 만약 우리가 conv. 연산에서 모수값을 unsupervised learning을 
통해 pre-training을 한다고 생각하면, 그게 unsupervised learning에도 적합한 
representation을 찾았다고 볼 수있음. 이런 방법은 autoencoder의 방법으로 진행됨.

5. Multi-Task Learning
결론부터, 한번에 여러문제를 동시에 푸는것을 이야기함.
하나의 모형을 가지고 사람들을 구분한다는지, 차들을 구분한다는지 등등.
이때 구분이라는 하나의 공통특성 학습이 가장 초기에 진행이 되고
(representation 선행), 각 주제에 맞게끔 세부적으로 모형이 뻗어나가는거임. 
이렇게 공통된 특성을 기본으로 많이 학습했기 때문에 각각의 모형(사람구분, 
차구분) 들은 단일 모형에 비해 더욱 성능이 좋아짐. (딥러닝의 재밋는 특징)

서로 다른 언어들을 번역하는 모형과 감정을 구분하는 모형을 동시에 합친 모형이
각각을 학습한 모형보다 더 성능이 좋아진다는 흥미로운 논문결과도 있음.

6. Early Stopping
validation error가 올라갈때, 멈추는걸 이야기

7. Parameter Tying and Parameter Sharing
특정 층의 파라미터 값을 같게하거나 유사하게 만듦. 즉, 파라미터 수를 줄여버림.
입력은 다른데 거의 비슷한 분류작업을 행하는 모형에 대해 효과적임.
어느 단의 layer을 공유하거나 비슷하게 만들어서 모형을 간소화함.
가장 대표적인 예로, CNN이 있을 수 있음.
CNN은 같은 필터로 이미지의 구석구석을 모두 한번씩 훑기 때문에 일종의
parameter sharing이라고 볼 수 있음.

8. Sparse Representations
어떤 output이 나왔을 때 그 대부분이 0이 되길 원하는거임.(또는 0을 많이 가진 상태)
크게 아래의 두가지 상태가 있음.
1) Sparse Weights
- weight(행렬)에 0이 많은것.
<y = Ax 에서, A에 0이 많은것.>
2) Sparse Activations
- 뒷단의 hidden node들의 값이 0이 많은것.
<y = Bh 에서, h에 0이 많은것>
그리고 2)가 상대적으로 더 중요하며, 2)에 해당하는 가장 대표적인 예는 ReLU.
0보다 작은 activation을 0으로 바꿔버린다. 이는, output(혹은 hidden node)들이 
sparse activation이 되기 때문에 성능이 증가한다.

또한 norm penalty(L1, L2) 를 주는게 결과적으론 sparse representation과 같다. 

9. Bagging and Other Ensemble Methods

우리가 일반적으로 모형을 얘기할 때는 bias와 variance에 대한 이야기를 빼놓을 수 없음.
mse = v + b^2 의 형태이며, trade-off가 가능함.
일반적으로,
variance가 높다는건 내가 어떤 예측을 할 때 다양하게 나온다라는 의미임.
bias가 높다는건 그냥 틀린거임. (평균에서 멀어진것)

당연히 high variance & high bias 은 매우 안좋은 것이며,
우리는 low variance & low bias를 저격하게 됨.

그럼 어떻게 이를 개선할까? bagging과 boosting을 통해 개선한다.
bias는 유지하고, high variance -> low variance (bagging)
variance는 유지하고, high bias -> low bias (boosting)

1) bagging
가장 대표적인 예로 그냥 나온 여러개의 값들을 평균내면 된다.
- boostrap 을 이용해서 B개의 sample set을 만든다. 
(sample set의 사이즈는 전체 데이터 대비로 설정가능)
- B개의 서로다른 데이터 집합을 각 모형에 적용시키고, 결과를 취합함.
- 예측값을 평균낸다든지 해서
- 가장 대표적인 예로 random forest가 있음.
2) boosting
- 많은 weak learner을 생성하고, strong learner로 탈바꿈 하는게 목적
- 그냥 더하는건 의미가없고, sequential하게 더하면 된다. 
- 이 의미는, 차이가 나는 만큼을 학습시켜가면서 개선해나간다는 뜻.
- 가장 대표적인 예로 boosting, adaboost

10. DropOut
했으므로 넘어간다.

11. Adversarial Training
사람이 눈으로 구별 불가능한 noise를 섞게 되면, 완전 다른 class가 튀어 나오는것
x + 0.07 * noise = new_x 일때, 
x가 57.7%의 신뢰도를 갖는 판다사진이라 할 때, 사람눈으로 뭔지 모르는 
noise를 주게 되면 new_x가 긴팔원숭이 사진(신뢰도 99.3%)으로 분류해 버릴 수 있다.

이 의미는 NN을 어떤 함수라고 본다면, 입력을 매우 살짝 변화시켰는데 결과가 
전혀 다른 값이 튀어나온 상황이라고 볼 수 있음. 기울기가 굉장히 가파르다는거임.
이는 overfitting과 비슷함. overfitting이 일어나면, 함수의 모양이 굉장히 가파르게 변한다.
그러므로 이런 adversarial example이 발생하는게 overfitting이 문제가 아닌가
의심을 해봐야함.

또한, 99.3%의 높은 신뢰도를 갖게 된 이유는 엄청나게 많은 데이터들에 대해
overfitting 이 되었기 때문에 경우에 따라 이정도의 높은 신뢰도도 나올 수 있음(이 의도가 맞나?)

결국, 학습시킬 때 noise를 주고 data augmentation을 하면, 이러한
adversarial examples에 대한 문제에 좀 더 robust해질 수 있게 된다. 










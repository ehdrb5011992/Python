11-1)

우리가 지금까지 배운 네트워크는 Fully Connected 네트워크  (=Forward NN) 라고도 한다.
X - ㅁ - ㅁ - ㅁ - Y / 단순선형인것.
CNN은 고양이 실험에서 시작됨.
고양이에게 사진을 보여줬더니, 고양이의 시선이 어떤 그림의 부분에 초점을 둔 뒤, 이에 해당하는 뉴런이 반응함을 확인함.
어찌보면 입력을 나누어 집중적으로 받는것이며, 이에 착안하여 CNN을 시행하고 성공을 거둠.

*뭘하는거냐면, 이전까지는 n*n 이미지를 쭉 길게 늘여놓고, 벡터로 연산했다면,
*이제는 n*n 행렬 그자체로 보고, 각 연산을 시행하는거임.


CNN은 간단히, 아래의 구조를 가짐.
[ CONV  -> RELU -> CONV  -> RELU -> POOL ] * 3 정도 하고,
FC를 한 뒤, 마지막의 softmax로 분류를 때리게 됨.

32*32*3 image가 주어졌다고 하자. 이때 3은 color임.
이때, 부분적으로 설명을 하기 위해 필터를 도입한다. (5*5*3)

이때, 필터의 size는 각 개인이 정의 할 수 있음. (5*5로 우리가 정의함.)
이때, 3은 늘 같게 됨. (역시 같이 RGB)

그리고 Filter는 하나의 값을 연산하게 함. 즉, 5*5*3 이 연산을 통해 1개의 숫자로 변함.
1개의 값으로 변환하는 방법은 XW + b를 통해 진행하고, ReLU를 연산한다.
즉, ReLU(XW + b) 이다. 이때, W(weight)는 어떤 숫자로 만들어 낼껀지를 결정하는 필터의
특성치라고 말할 수 있다.

즉, 필터는 W에 따라 달라지는 것이며, 같은 W(필터)를 가지고 32*32*3 인 전체 이미지를 
훑는다.

이때, 
이런 과정을 거치게 되면 몇개의 값을 얻게 될 수 있을까?? (간단한 산수임, 중요함)

ex)
7*7 이미지에 3*3 필터를 거른다고 하자. 그러면,
--> 5*5 개의 개수가 나온다. 이때 Stride=1일때 5*5이며,  Stride=1이란 한칸씩 움직이며 전체 이미지를
훑었다는 뜻이다.

만약 Stride = 2이면,
--> 3*3개의 output이 생겨나게 된다.

결론 : Output size : { (N-F) / Stride } + 1 이다. 
(N은 전체 이미지의 차원 - 가로or세로 각각봄. F는 필터의 차원  - 가로or세로 각각봄.)
위의 예에서 stride 3 을 주면, 2.33이게 되고, 이는 할 수 없게 되는거임.

이때, 위에서 보듯 Output이 작아지는 것을 확인할 수 있고, 이는 우리가 정보를 잃어버린
다는 뜻임.

그래서 실제로 CNN을 사용할때는 Zero Padding이라는 것을 사용함.
예를들어,
7*7의 테두리에 0짜리를 1pixel(1줄) 둘러 쌓는다. 그러면, 9*9짜리가 되고,
Stride=1이라면, 3*3필터를 사용한 경우, 7*7짜리 Output이 나온다! -> 같은 Size의 결과가 나온다.

이렇게 Padding을 통해서 Size가 같아지게 하는 방식을 일반적으로 취함.
그리고 Zero Padding을 하는 줄의 수는 (F-1)/2이며, 예를들면
F = 3 -> zero pad with 1
F = 5 -> zero pad with 2
F = 7 -> zero pad with 3
이다.

가급적 필터의 개수는 짝수가 아닌 홀수를 사용하는데, 이는 input에 따른 output의 개수를 조절하기 쉽게 하려고
그러는거임. 짝수로 필터를 쓰면 코딩이 머리아픔. 홀수개를 쓰자!

참고 : (찾기: 짝수)
https://tensorflow.blog/%ED%95%B4%EC%BB%A4%EC%97%90%EA%B2%8C-%EC%A0%84%ED%95%B4%EB%93%A4%EC%9D%80-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-4/



이제 전반적인 알고리즘을 살펴보자.
전체 이미지가 32*32*3 짜리 있다고 해보자.
그리고 필터1, 필터2 는 5*5*3 짜리를 갖는다고 하자 (필터 1과 2는 W가 다르고 차원은같음)

이렇게 필터를 2개를 하는게 아니라, 필터를 6개를 사용한다고 하자.
그러면, Convolution Layer은 (?,?,6) 이 되게 된다. 
?는 Stride=1이고, Padding이 되지 않는다는 가정하에 28이 됨. (6개의 필터가 훑어진 하나의 층)
즉, 28*28*6짜리 Activation Map이 생김.

그리고 다시한번 CONV , RELU를 적용한다고 하면, 
필터는 5*5*6 (6짜리 깊이로 필터를 만들어야 함.) 이 되고, 이런 필터를 10개를 사용한다고하면
다음 Convolution Layer은 24*24*10짜리 Activation Map이 생김.

이런 방식으로 Convolution Layer가 진행됨.


그렇다면, Weight에 사요되는 Variables는 얼마나 될까? 에 초점을 둘 수 있다.

첫번째 Filter에서 5*5*3*6개 였고, 두번째 Filter에서 5*5*6*10 개 였다.
이 weight도 처음에 초기화를 하고 가진 데이터로 학습하게 만드는거임.


11-2)

Max Pooling과 나머지에 대해 이야기해보자.

위에서 
[ CONV  -> RELU -> CONV  -> RELU -> POOL ] 이 있었는데
POOL 이 무엇일까?

Pooling layer 은 간단히 Sampling 이라고 생각할 수 있다. 
우리가 1개의 Convolution Layer를 만들었다고 했을 때 이 두께는 Filter의 수로 결정된다.
그리고 이 두께중 한 층을 잘라내어서 살펴보자.

이것을 Resize를 시행하고, 작게 만들어 낸다. (차원을 줄임. 이를 Pooling(통합)이라고 함.)
이렇게 두께의 각 slice마다 진행해서 다시 차원을 축소한다.

예를들어 보자.
MAX POOLING은 다음과 같이 진행된다.

4*4*k짜리 Activation Map 중 한조각을 떼네어 와서 4*4*1짜리를 본다고 하자.
그리고 Max Pooling을 위해 2*2 Filter로 Stride=2짜리를 사용한다.
--> 이러면 2*2 Output이 주어질 것이다. 
이때 2*2 짜리 Output에는 어떤 값들을 채우게 할 것인가? 에 대한 이야기로
기존에 가진 4*4*1에서 2*2필터로 훑어지는 값들 중 각 구역(4개)의 최댓값을 Output의 2*2에 
채워넣게 된다.

* Pooling은 보통 Zero Padding을 하지 않으며, 너무 많이 버릴 수 없다. (정보의 손실이므로)
* 그렇기에, 보통 2*2필터로 stride=2를 주고 Pooling을 하게 된다.

이게 우리가 자주 쓰는 MAX POOLING이다. 그리고, 전체의 값들 중에 뽑기 때문에 Sampling이라고 불림.
이렇게 나오는 Output 또한 { (N-F)/stirde } +1로 정해진다.

이렇게,  
[ CONV  -> RELU -> CONV  -> RELU -> POOL ] 를 시행하게 된다.
여기서 , 위의 형태는 고정이 된 것이 아니다. 내가 원하는데로 쌓는거임
CONV 한 뒤 바로 Pooling할 수 있고, CONV를 굉장히 많이 한 뒤 Pooling 할 수 있다.
참고) ReLU는 sparse하게 만드는 성질을 가지고 있다. - 약간 dropout의 효과와 비슷하게 만드나봄?

그리고 마지막에 Pooling 을 하게 되서 나온 값들이 있다고 하자.
예를 들면 그 값이 3*3*10 이라고 하자.
3
그러면 이걸 우리가 원하는 만큼 일반적인 NN을 시행하게 된다. (Fully Connected를 통해)
그리고 Softmax를 사용해서 Classifier을 진행하게 된다.  이렇게 NN을 구성하면 된다.


11-3)

CNN의 case study

사람들이 어떻게 응용했는지에 대해 살펴보도록 하자.


1. Case Study : LeNet-5
처음 CNN을 고안한 사람 : LeCun 교수님.

손으로 쓴 글씨가 주어지면,  CNN을 사용 하게 되고
원래 28*28이 주어졌다면,

처음엔 5*5짜리 필터로 stride=1을 준다. 6개의 필터를 사용
Pooling은 2*2짜리 stride =2를 줌. 

이렇게 쭉 가게 됨. (위에서 했던 일반적인 CNN과 매우 흡사)


2. Case Study : AlexNet
2012년 많은사람들의 관심을 끌었던 Net

227*227*3과 같은 큰 이미지에,

첫번째 CONV에 96개짜리 11*11*3짜리 필터를 사용, stride=4를 준다.
-> 계산하면 55*55*96짜리 Activation Map이 만들어짐.
이때 모수의 개수는 11*11*3*96 = 35K의 개수가 필요함. -> 학습

두번째는 Pooling Layer을 주고 3*3짜리 필터에 stride=2 를 줬다.
Output은 27*27*96 이 되고,
이건 Pooling이니 모수의 개수는 0 개가 필요. 
(0인지, 0!인지 모르겠다.. 특별한 변수가 필요없다 하였으므로, 아마 0인듯)

이렇게 여러번 반복하는데, 좀 깊다.
이 중, 우리가 이야기 하지 않은 Normalization Layer이 있으며, 중간중간에 사용함을
볼 수 있다. 그냥 정규화 시키는거며, 최근들어서는 자주 사용하지는 않는다.
-안해도 된다고 한다.-

AlexNet은
[ CONV -> MAXPOOL -> NORM ] *2 -> CONV * 3 -> MAXPOOL
을 시행함.
이렇게 마지막 MAXPOOL까지 시행하고 얻어진 값을 하나의 Fully Connected된
벡터에 넣어서 4096개의 출력을 만들어 낸다.

주의!!!!) 우리는 계속 1장의 데이터를 가지고 시행중임. 
즉, 6*6*256이 최종적으로 MAXPOOLING을 통해 만들어졌다면,
9216개의 x변수가 있는거나 다름없으며, 파이썬에는
X = tf.placeholder(tf.float32 , name='X', shape=[None,9216] 인풋으로 시작되는것이나 다름없음.

다시 돌아와,
마지막에 4096, 4096, 1000은 우리가 계속 지금까지 해왔던 NN을 적용시킨것
이라고 생각하면 됨.

좀더 자세히는,
AlexNet는 ReLU도 사용했으며, Droput=0.5 , batchsize = 128, 
learning_rate = 0.01 , 7개의 앙상블, L2 weight를 사용 등등이 있다.
(SGD Momentum = 0.9)


3. Case Study : GoogLeNet
2014년 나옴.

조금 다르게 생긴건 흩어졌다 모이는 형태를 가지고 있는데,
이를 Inception Module이라고 함.
병렬적으로 사용하고, 각 라인마다 다른형태의 Convolution을 함.
(각 라인마다 순서도 뒤죽박죽이며, 다양한 횟수로 진행함.)

재밌는 구조로 되어 있으며, 이걸 굉장히 deep하게 구성하게 함.


4. Case Study : ResNet  - He et al. 
ILSVRC 2015 winner.
사람이 이미지를 잘못분류하는 5%를 깨고 , 인공지능이 이기게 되는 알고리즘
3.6%까지 오분류율을 줄임.

다른 대회에서도 굉장히 적용이 잘되는 알고리즘

ResNet은 152개의 층이 있음.
(알렉스넷은 8층, VGG는 19층인것에 비해 굉장히 깊음)

이러면, 학습하기 어려울것이라고 생각한다. 이를 어떻게 극복했을까?
이를 Fast Forward를 통해서 극복함.

층을 건너 뛰어나가면서 더해지기 때문에, 전체적인 깊이는 깊지만 
실제로 학습하는 입장에서 보면 그렇게 깊지는 않다.
구체적으로 잘 작동되는 원리는 아직 나오지 않음.

GoogLeNet과 ResNet은 상당히 유사하다.

기타로,
Yoon Kim 박사가(한국)  텍스트에서도 CNN을 사용했고 잘 적용이 된다.
또 DeepMind의 알파고가 CNN을 사용했음.
네이쳐에 구체적인 정보가 수록되어있음.
